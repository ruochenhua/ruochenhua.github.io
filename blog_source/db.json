{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"themes/fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"themes/fluid/source/css/highlight-dark.styl","path":"css/highlight-dark.styl","modified":0,"renderable":1},{"_id":"themes/fluid/source/css/highlight.styl","path":"css/highlight.styl","modified":0,"renderable":1},{"_id":"themes/fluid/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/default.png","path":"img/default.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/fluid.png","path":"img/fluid.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/image.png","path":"img/image.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/loading.gif","path":"img/loading.gif","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/boot.js","path":"js/boot.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/events.js","path":"js/events.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/plugins.js","path":"js/plugins.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/umami-view.js","path":"js/umami-view.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":0,"renderable":1},{"_id":"source/img/og_tinyGL.png","path":"img/og_tinyGL.png","modified":0,"renderable":0},{"_id":"source/display-cabinet/og_tinyGL.png","path":"display-cabinet/og_tinyGL.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/_posts/defer-render.md","hash":"24f009f8f1273dbdff57f8e4c479d18e4a59f320","modified":1729330996358},{"_id":"source/_posts/StartMyBlog.md","hash":"c601978189c6966addf9039420907b7f4b2a9a48","modified":1728572314819},{"_id":"source/_posts/single-scatter-atmosphere.md","hash":"8db5bd0a173622c39ddfd4da72eed1964e1f9915","modified":1729002701794},{"_id":"source/_posts/ProceduralTerrainGeneration2.md","hash":"f5856b3f60ef694696b8edf70bde55d43cee037d","modified":1730820527932},{"_id":"source/_posts/ProceduralTerrainGeneration.md","hash":"6228f932cc309d89ac16cf199b924bb074ed361c","modified":1729002666374},{"_id":"source/about/index.md","hash":"05cf53d0da2e813ced689b9b5ae126b571cadc03","modified":1730212344736},{"_id":"source/display-cabinet/index.md","hash":"388b252d55531e265f8aaf5041e81219f1132235","modified":1730213320119},{"_id":"source/_posts/cascade-shadow-map.md","hash":"b7d06ca65fd16b88e0379f12fac1bdb685f062f8","modified":1729002713649},{"_id":"source/_posts/depth-of-field.md","hash":"0d6a72a99aacf18dbecf821964595633b4aeaabe","modified":1730128759418},{"_id":"source/_posts/cascade-shadow-map/csm_far.png","hash":"d6f8dce239df0ca3fb8008e6beea34d08fee464a","modified":1726459035207},{"_id":"source/_posts/cascade-shadow-map/csm_near.png","hash":"e575a785c09d4c192db4c0e094d919f88e31029a","modified":1726459059738},{"_id":"source/_posts/cascade-shadow-map/csm_mid.png","hash":"886730be4cb07cf725f965acf50bd8dbe28ba87e","modified":1726459011390},{"_id":"source/_posts/ProceduralTerrainGeneration/calc_soft_shadow.png","hash":"7bc24f450d820326f7c05fc625259f59481db0db","modified":1728292147567},{"_id":"source/_posts/defer-render/ssao.png","hash":"b208b05bfddb222235f6617fd22ae6d272f861cb","modified":1725633120670},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_oc5_noshadow.png","hash":"64c2e7528dfe87ea1e450decd23c569918479c18","modified":1727864785397},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_terrain_oct5.png","hash":"0f4daabfa7d24bf09919beb71c0701d1c9c7e524","modified":1727864061852},{"_id":"source/_posts/depth-of-field/game1.jpg","hash":"0034e1ebc0e270dca6ea9c6fc878f3889d54e091","modified":1730128605763},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_oc11_hardshadow.png","hash":"4c4b64ea717fa659999b44c3218fe77f304e1d12","modified":1727864947470},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_terrain.png","hash":"56cc9ca4c38d9dea545c3fc71e930ff792e46fac","modified":1727862639660},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_no_grass.png","hash":"6fd3d29360d763f99afc976dbec8ca77c4edcf2c","modified":1730732749897},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_oc11_noshadow.png","hash":"48d0f8a6b7cd0289041b3bea39c24782aaf930f7","modified":1727864806418},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_grass.png","hash":"ecbed0af037da143c48b1dc2a52c3ed6d1569808","modified":1730732760150},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky_fog.png","hash":"dc9fa37962207b51ec4b3659057a2eccc49f6bb0","modified":1730733326815},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky.png","hash":"25bc38e72b9bde4ea69bbde7a25029becdf3a757","modified":1730733306047},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky_fog_less_ambient.png","hash":"819633b9a30cd7a285f4a8f3fecd454bee8468d4","modified":1730733338763},{"_id":"source/_posts/single-scatter-atmosphere/single-scatter-atmosphere.png","hash":"7266482600228204c32e0fa281e85f626baf7773","modified":1724580719028},{"_id":"source/_posts/defer-render/defer_render_banner.png","hash":"1962262b49a5eff662ac3a76846d4f6414660bc8","modified":1725633833915},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_sky.png","hash":"8b3ddaad30616a7b0b5c606aa4bf89b43afb7192","modified":1730733362737},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_mountain.png","hash":"82daa3b5403c88308c8fae59330d9a9c008b24aa","modified":1730733353026},{"_id":"themes/fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1721800613000},{"_id":"themes/fluid/.editorconfig","hash":"33218fbd623feb43edf5f99f15965392cecc44a6","modified":1721800613000},{"_id":"themes/fluid/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1721800613000},{"_id":"themes/fluid/.gitignore","hash":"ae3bfcb89777657c5dfb5169d91445dcb0e5ab98","modified":1721800613000},{"_id":"themes/fluid/.eslintrc","hash":"4bc2b19ce2b8c4d242f97d4ccf2d741e68ab0097","modified":1721800613000},{"_id":"themes/fluid/_config.yml","hash":"fedf0812c0b0f20989e05e51a3571904789ceb4a","modified":1730212969072},{"_id":"themes/fluid/package.json","hash":"7746460fc2eba7439b494c46aa9b5ded81370819","modified":1721800613000},{"_id":"themes/fluid/README_en.md","hash":"365184a73af40e7365504c3077f3d80dfee1d80e","modified":1721800613000},{"_id":"themes/fluid/languages/en.yml","hash":"9c580471257f5a32bee701a059a45ea96755dcdc","modified":1721800613000},{"_id":"themes/fluid/languages/de.yml","hash":"58dccef1d98b472dc4e6f4693c2297b0c9c5afba","modified":1721800613000},{"_id":"themes/fluid/languages/eo.yml","hash":"7c1a0c9f6186b6643b19d3980f055329bdb4efa4","modified":1721800613000},{"_id":"themes/fluid/languages/ru.yml","hash":"93818f8bf07195fb1ebffbb5210e531b0e3a6ec4","modified":1721800613000},{"_id":"themes/fluid/languages/es.yml","hash":"026ddf1a49bf8ddfef6ed86ab4d6af143c1dd95f","modified":1721800613000},{"_id":"themes/fluid/README.md","hash":"ff9b0e1fb9dba665af2f1e4a577f8cb9e840464b","modified":1721800613000},{"_id":"themes/fluid/LICENSE","hash":"26f9356fd6e84b5a88df6d9014378f41b65ba209","modified":1721800613000},{"_id":"themes/fluid/languages/ja.yml","hash":"550b95d3614a64592f02666938d235e9f11e449e","modified":1721800613000},{"_id":"themes/fluid/languages/zh-TW.yml","hash":"e1043de394f6dcf5c0647adcfdefe60637f78426","modified":1721800613000},{"_id":"themes/fluid/languages/zh-CN.yml","hash":"a60847136709bb95586a98d9d67b50390a8d2c96","modified":1721800613000},{"_id":"themes/fluid/languages/zh-HK.yml","hash":"51c2b4d64c6992a39bfd2586a1bdf5fbbbdf0175","modified":1721800613000},{"_id":"themes/fluid/layout/404.ejs","hash":"b84d575c7b7f778b4cb64e89ad3d0aed4a896820","modified":1721800613000},{"_id":"themes/fluid/layout/categories.ejs","hash":"13859726c27b6c79b5876ec174176d0f9c1ee164","modified":1721800613000},{"_id":"themes/fluid/layout/category.ejs","hash":"f099161b738a16a32253f42085b5444f902018ed","modified":1721800613000},{"_id":"themes/fluid/layout/about.ejs","hash":"052e9fc19c753f53fdc083c7fb098e3668880140","modified":1721800613000},{"_id":"themes/fluid/layout/archive.ejs","hash":"7c1f44005849791feae4abaa10fae4cb983d3277","modified":1721800613000},{"_id":"themes/fluid/layout/layout.ejs","hash":"7e0023474128fbe4d68c467704c41f1712432415","modified":1721800613000},{"_id":"themes/fluid/layout/page.ejs","hash":"ed5007a3feb8f14d3d2843271bfb298eb0c56219","modified":1721800613000},{"_id":"themes/fluid/layout/links.ejs","hash":"1cac32ec4579aaf7b9fa39d317497331d4c5e1dd","modified":1721800613000},{"_id":"themes/fluid/layout/index.ejs","hash":"33c3317cdcee062789de2336dd8d0cc7f86d3650","modified":1721800613000},{"_id":"themes/fluid/layout/post.ejs","hash":"9bf0d357a607a282f3b9cb04525a4df0cc2a8b76","modified":1721800613000},{"_id":"themes/fluid/layout/tag.ejs","hash":"9d686364c4d16a1a9219471623af452035c5b966","modified":1721800613000},{"_id":"themes/fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":1721800613000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"ed08574b196447376dd74411cca664ac9227a5d4","modified":1721800613000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question.md","hash":"ab5eab9e3ff889c4ba7fd82846e7f5b7ae15bebc","modified":1721800613000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"554c0d0e086a0784d83ee71c83f8bceeb60aecc8","modified":1721800613000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"c8b0d49c49e3c88872fd3b37909345ff5b2b6aa0","modified":1721800613000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"c134dd57ffd269b93402ccfffe7dbe0f0b583bec","modified":1721800613000},{"_id":"themes/fluid/.github/workflows/limit.yaml","hash":"f8bd2edeb4424ee7a055b31583445d5d5dff91a4","modified":1721800613000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"fff07ce0472afc368d388637cb9d438195da9b5b","modified":1721800613000},{"_id":"themes/fluid/.github/workflows/publish.yaml","hash":"6f02e6440d88629229556e3fd47d0280fe2240db","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/archive-list.ejs","hash":"7520fbf91f762207c2ab06b2c293235cd5b23905","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/category-chains.ejs","hash":"18309584aab83bc4deb20723ebad832149dd2e24","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/category-list.ejs","hash":"f8d2f1907450e61968e6d54443e9be8138196a77","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments.ejs","hash":"d707c47b2638c94e489bc43d4cfd098b7c58447f","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/css.ejs","hash":"1dadb118d580280524ed0a5f69bd34d234a92276","modified":1721800613000},{"_id":"themes/fluid/.github/workflows/cr.yaml","hash":"19a8a00f5ba9607d82265572fe1202b64a8b0822","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/head.ejs","hash":"67be642f99482c07904474f410cfbc2f99003288","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/header.ejs","hash":"0d5e397d30051e5fbabe7b47cfd1f1e6a5820af1","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/footer.ejs","hash":"40c8b0852873032e7aaef3f68e8ea08706cdef13","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/markdown-plugins.ejs","hash":"fc4bdf7de0cf1a66d0e5e4fba1b31d6f7ed49468","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/paginator.ejs","hash":"0f38a2c238169edcb63fc46c23bfc529ff3859b7","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/scripts.ejs","hash":"da5810785105e5075861593c7ac22c7aa9665a72","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/search.ejs","hash":"70e1c929e084ca8a2648cedabf29b372511ea2b8","modified":1721800613000},{"_id":"themes/fluid/scripts/events/index.js","hash":"79de5a379b28cad759a49048351c7f6b8915bd7d","modified":1721800613000},{"_id":"themes/fluid/scripts/filters/default-injects.js","hash":"b2013ae8e189cd07ebc8a2ff48a78e153345210f","modified":1721800613000},{"_id":"themes/fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":1721800613000},{"_id":"themes/fluid/scripts/filters/post-filter.js","hash":"82bb06686158ebe160a631c79f156cd4fde35656","modified":1721800613000},{"_id":"themes/fluid/scripts/generators/index-generator.js","hash":"9159fc22fa84a7b605dd15fe4104f01fe9c71147","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/date.js","hash":"9bda6382f61b40a20c24af466fe10c8366ebb74c","modified":1721800613000},{"_id":"themes/fluid/scripts/generators/local-search.js","hash":"9ac5ddad06e9b0e6015ce531430018182a4bc0fa","modified":1721800613000},{"_id":"themes/fluid/scripts/generators/pages.js","hash":"d3e75f53c59674d171309e50702954671f31f1a4","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/engine.js","hash":"d3a231d106795ce99cb0bc77eb65f9ae44515933","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/export-config.js","hash":"8e67b522c47aa250860e3fe2c733f1f958a506c0","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/import.js","hash":"ca53e8dbf7d44cfd372cfa79ac60f35a7d5b0076","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/injects.js","hash":"1ad2ae6b11bd8806ee7dd6eb7140d8b54a95d613","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/scope.js","hash":"d41d9d658fcb54964b388598e996747aadb85b0f","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/url.js","hash":"2a6a8288176d0e0f6ec008056bf2745a86e8943e","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/wordcount.js","hash":"4d48c424e47ff9a17a563167ea5f480890267adf","modified":1721800613000},{"_id":"themes/fluid/scripts/helpers/utils.js","hash":"966689d7c5e4320008285395fbaa2751f6209be5","modified":1721800613000},{"_id":"themes/fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":1721800613000},{"_id":"themes/fluid/scripts/tags/checkbox.js","hash":"6eaf53cf4bfc756a65bda18184cf8998a12c861d","modified":1721800613000},{"_id":"themes/fluid/scripts/tags/fold.js","hash":"73e4fd12ce3e47981479391ed354b7d9d3279f70","modified":1721800613000},{"_id":"themes/fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":1721800613000},{"_id":"themes/fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":1721800613000},{"_id":"themes/fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":1721800613000},{"_id":"themes/fluid/scripts/tags/note.js","hash":"e3b456a079e5dc0032473b516c865b20f83d2c26","modified":1721800613000},{"_id":"themes/fluid/scripts/utils/compare-versions.js","hash":"dbbc928c914fc2bd242cd66aa0c45971aec13a5d","modified":1721800613000},{"_id":"themes/fluid/scripts/utils/crypto.js","hash":"ae4ad8a188ef5b3fa6818b01629fc962b3de8551","modified":1721800613000},{"_id":"themes/fluid/scripts/utils/object.js","hash":"33b57e4decdc5e75c518859f168c8ba80b2c665b","modified":1721800613000},{"_id":"themes/fluid/scripts/utils/resolve.js","hash":"8c4a8b62aa8608f12f1e9046231dff04859dc3e9","modified":1721800613000},{"_id":"themes/fluid/scripts/utils/url-join.js","hash":"718aab5e7b2059a06b093ca738de420d9afa44ba","modified":1721800613000},{"_id":"themes/fluid/source/css/highlight.styl","hash":"a9efc52a646a9e585439c768557e3e3c9e3326dc","modified":1721800613000},{"_id":"themes/fluid/source/css/highlight-dark.styl","hash":"45695ef75c31a4aa57324dd408b7e2327a337018","modified":1721800613000},{"_id":"themes/fluid/source/css/main.styl","hash":"855ae5fe229c51afa57f7645f6997a27a705d7e4","modified":1721800613000},{"_id":"themes/fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1721800613000},{"_id":"themes/fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1721800613000},{"_id":"themes/fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1721800613000},{"_id":"themes/fluid/source/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1721800613000},{"_id":"themes/fluid/source/js/color-schema.js","hash":"1ef88c881b9f942deadde3d890387b94c617342a","modified":1721800613000},{"_id":"themes/fluid/source/js/events.js","hash":"6869811f67e4c3de3edfa4b08464bb242b97a402","modified":1721800613000},{"_id":"themes/fluid/source/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1721800613000},{"_id":"themes/fluid/source/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1721800613000},{"_id":"themes/fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1721800613000},{"_id":"themes/fluid/source/js/local-search.js","hash":"b9945f76f8682f3ec32edfb285b26eb559f7b7e8","modified":1721800613000},{"_id":"themes/fluid/source/js/plugins.js","hash":"c34916291e392a774ff3e85c55badb83e8661297","modified":1721800613000},{"_id":"themes/fluid/source/js/utils.js","hash":"b82e7c289a66dfd36064470fd41c0e96fc598b43","modified":1721800613000},{"_id":"themes/fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/changyan.ejs","hash":"c9b2d68ed3d375f1953e7007307d2a3f75ed6249","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/cusdis.ejs","hash":"5f9dc012be27040bbe874d0c093c0d53958cc987","modified":1721800613000},{"_id":"themes/fluid/source/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/disqus.ejs","hash":"aab4a4d24c55231a37db308ae94414319cecdd9b","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/giscus.ejs","hash":"95f8b866b158eff9352c381c243b332a155a5110","modified":1721800613000},{"_id":"themes/fluid/source/js/umami-view.js","hash":"33c4b3883fa747604074ad3921606eeeaeb50716","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/discuss.ejs","hash":"98d065b58ce06b7d18bff3c974e96fa0f34ae03a","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/livere.ejs","hash":"2264758fed57542a7389c7aa9f00f1aefa17eb87","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/gitalk.ejs","hash":"843bc141a4545eb20d1c92fb63c85d459b4271ec","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/utterances.ejs","hash":"c7ccf7f28308334a6da6f5425b141a24b5eca0e2","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/remark42.ejs","hash":"d4e9532feeb02aed61bd15eda536b5b631454dac","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/twikoo.ejs","hash":"d84bcb5ccd78470a60c067fc914ac0ac67ac8777","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/valine.ejs","hash":"19ba937553dddd317f827d682661a1066a7b1f30","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/comments/waline.ejs","hash":"3d08c73b77e412d2f06a24d9344565fc7dbc76f8","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/footer/beian.ejs","hash":"4fb9b5dd3f3e41a586d6af44e5069afe7c81fff2","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/footer/statistics.ejs","hash":"954a29b58d72647d20450da270b5d8fb2e0824f5","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/header/banner.ejs","hash":"e07757b59e7b89eea213d0e595cb5932f812fd32","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/header/navigation.ejs","hash":"37d750428772d7c71ba36ce0c2540780d90fadea","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/analytics.ejs","hash":"e6dcbf1c2f56314d56bb46b50aca86ff68cacebd","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/anchorjs.ejs","hash":"40181442d3a2b8734783a0ad7caf2d2522e3f2ab","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/code-widget.ejs","hash":"3a505cba37942badf62a56bbb8b605b72af330aa","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/encrypt.ejs","hash":"0fff24cf5bf99fbe5c56c292e2eac4a89bf29db4","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/fancybox.ejs","hash":"9d1ea2a46b8c8ad8c168594d578f40764818ef13","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/highlight.ejs","hash":"7529dd215b09d3557804333942377b9e20fa554e","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/math.ejs","hash":"dcbf9a381ee76f2f1f75fcbc22c50a502ec85023","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/moment.ejs","hash":"4ff3fb1b60ccc95a0af3bbdbd0757fedefc088b5","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/typed.ejs","hash":"f345374885cd6a334f09a11f59c443b5d577c06c","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/nprogress.ejs","hash":"4c2d39ce816b8a6dcd6b53113c8695f8bd650a23","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/plugins/mermaid.ejs","hash":"03ac02762f801970d1c4e73d6ec8d4c503780e50","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/post/category-bar.ejs","hash":"8772bce97ed297e7a88523f4e939ed6436c22f87","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/post/copyright.ejs","hash":"cbfa32c5f5973133afd043853b24f8200455cb2d","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/post/meta-top.ejs","hash":"54dd479dbb440126e4ddd9d902229db5afaaae98","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/post/meta-bottom.ejs","hash":"375974ec017696e294dc12469fb0ae257800dc2d","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/post/sidebar-left.ejs","hash":"9992c99b3eb728ad195970e1b84d665f2c8691c4","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/post/sidebar-right.ejs","hash":"d5fcc9b60e02f869a29a8c17a16a6028ecc1e6d8","modified":1721800613000},{"_id":"themes/fluid/layout/_partials/post/toc.ejs","hash":"635a89060fbf72eeda066fc4bd0a97462f069417","modified":1721800613000},{"_id":"themes/fluid/scripts/events/lib/compatible-configs.js","hash":"ef474d1fa5bbafc52619ced0f9dc7eaf2affb363","modified":1721800613000},{"_id":"themes/fluid/scripts/events/lib/footnote.js","hash":"c19ac8050b82c3676b0332a56099ccfcc36d9d52","modified":1721800613000},{"_id":"themes/fluid/scripts/events/lib/hello.js","hash":"bd8376e1cf7892dc2daa58f2f443574be559fdbf","modified":1721800613000},{"_id":"themes/fluid/scripts/events/lib/highlight.js","hash":"a5fe1deccb73b5f578797dbb11038efc15f63ce8","modified":1721800613000},{"_id":"themes/fluid/scripts/events/lib/injects.js","hash":"5ae4b07204683e54b5a1b74e931702bbce2ac23e","modified":1721800613000},{"_id":"themes/fluid/scripts/events/lib/lazyload.js","hash":"9ba0d4bc224e22af8a5a48d6ff13e5a0fcfee2a4","modified":1721800613000},{"_id":"themes/fluid/scripts/events/lib/merge-configs.js","hash":"7c944c43b2ece5dd84859bd9d1fe955d13427387","modified":1721800613000},{"_id":"themes/fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":1721800613000},{"_id":"themes/fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":1721800613000},{"_id":"themes/fluid/source/css/_variables/base.styl","hash":"4ed5f0ae105ef4c7dd92eaf652ceda176c38e502","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_archive/archive.styl","hash":"c475e6681546d30350eaed11f23081ecae80c375","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_about/about.styl","hash":"97fe42516ea531fdad771489b68aa8b2a7f6ae46","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/base.styl","hash":"643284c567665f96915f0b64e59934dda315f74d","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/color-schema.styl","hash":"85492ef64d7e5f70f0f7e46d570bbc911e686d7e","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_category/category-bar.styl","hash":"cc6df43fef6bb3efecbfdd8b9e467424a1dea581","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/print.styl","hash":"166afbc596ea4b552bad7290ec372d25ec34db7b","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_category/category-chain.styl","hash":"0cdf7ef50dfd0669d3b257821384ff31cd81b7c9","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_category/category-list.styl","hash":"7edfe1b571ecca7d08f5f4dbcf76f4ffdcfbf0b5","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/inline.styl","hash":"411a3fa3f924a87e00ff04d18b5c83283b049a4d","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_links/links.styl","hash":"5c7f2044e3f1da05a3229537c06bd879836f8d6e","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_index/index.styl","hash":"25fb6fa4c783b847c632584c49a7e1593cdb2f5d","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_post/comment.styl","hash":"780f3788e7357bcd3f3262d781cb91bb53976a93","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_post/markdown.styl","hash":"1e3d3a82721e7c10bcfcecec6d81cf2979039452","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_post/highlight.styl","hash":"4df764d298fe556e501db4afc2b05686fe6ebcfb","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_post/post-page.styl","hash":"7eee3f78296a3c81849a5415d1d43dcc6e03e6aa","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_post/post-tag.styl","hash":"c96d36aa8fe20f0c3c1a29ee2473cd8064b10f73","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/anchorjs.styl","hash":"e0cebda4a6f499aff75e71417d88caa7ceb13b94","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/banner.styl","hash":"7a0bd629bc234fc75e3cc8e3715ffada92f09e73","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/code-widget.styl","hash":"b66ab013f0f37d724a149b85b3c7432afcf460ad","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/board.styl","hash":"4397037fc3f0033dbe546c33cd9dbdabd8cb1632","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/copyright.styl","hash":"26f71a9cd60d96bb0cb5bbdf58150b8e524d9707","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footer.styl","hash":"2caaca71dd1ff63d583099ed817677dd267b457e","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/header.styl","hash":"d42b748f2f49ef32aafb1a21d75991d2459da927","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/ngrogress.styl","hash":"5d225357b4a58d46118e6616377168336ed44cb2","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/modal.styl","hash":"adf6c1e5c8e1fb41c77ce6e2258001df61245aa2","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/noscript.styl","hash":"0cf2f2bb44f456150d428016675d5876a9d2e2aa","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/pagination.styl","hash":"8bb1b68e5f3552cb48c2ffa31edbc53646a8fb4c","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"78704a94c0436097abfb0e0a57abeb3429c749b7","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"f0e429a27fa8a7658fcbddbb4d4dbe4afa12499a","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":1721800613000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/toc.styl","hash":"9e7452aa2372153f25d7a4675c9d36d281a65d24","modified":1721800613000},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_high_cloud.png","hash":"17f1b24ce2e0e425166da356780fdd6e9c38343c","modified":1730733383869},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_all_cloud.png","hash":"89318f0a3a168ac5b9cbfde0a729f45e6d918d80","modified":1730820129800},{"_id":"source/_posts/depth-of-field/dilate_after.png","hash":"c5e1bc9574c43cf344e177a7a0bbb501bc6eddb9","modified":1730127373710},{"_id":"source/_posts/single-scatter-atmosphere/single-scatter-atmosphere.mp4","hash":"cf48cd4f4e5bf60302882e4ab93cca403793b8eb","modified":1724773813109},{"_id":"source/display-cabinet/og_tinyGL.png","hash":"e64a65a8e7f65f77498e678481bfe0cc65645caf","modified":1730212141075},{"_id":"source/img/og_tinyGL.png","hash":"e64a65a8e7f65f77498e678481bfe0cc65645caf","modified":1730212141075},{"_id":"source/_posts/depth-of-field/dilate_before.png","hash":"c37d5697d706fcf09ae6ef0ac82f4b3abb278cf4","modified":1730127367993},{"_id":"source/_posts/cascade-shadow-map/sm_near.png","hash":"3a2e2ba049b19ee345a7944d5eed95bc9bec4d38","modified":1726475189766},{"_id":"source/_posts/depth-of-field/dof_far.png","hash":"a158cb25f92b20004de9a54390d55cbb760f114d","modified":1730128139308},{"_id":"source/_posts/depth-of-field/dof_near.png","hash":"13cf595da86662b7836a26beb4230a5fb2cdf58a","modified":1730128130810},{"_id":"themes/fluid/source/img/image.png","hash":"77d6c488036d5caa852b645e753011476668d168","modified":1707126287675},{"_id":"themes/fluid/source/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1721800613000},{"_id":"source/_posts/cascade-shadow-map/sm_far.png","hash":"4ebea9aeec6dfbdc98466a6fc2813949f8687f65","modified":1726475241147},{"_id":"source/_posts/defer-render/defer_render.png","hash":"674b2ebba5e97d292f2459382ebee9322476993b","modified":1725631498369},{"_id":"source/_posts/defer-render/no_defer_render.png","hash":"19969d958ab565da447389bae3bd72abfb8bd34f","modified":1725631457606},{"_id":"source/_posts/single-scatter-atmosphere/kong-screen-shot.png","hash":"f54c4ce1299d4e9f4ad89f97fdb86eafaa35ee3f","modified":1724575733127},{"_id":"source/_posts/cascade-shadow-map/csm_result.png","hash":"a29eba82d35e09260b7ec148c9c55c17cbfd05b4","modified":1726386766572},{"_id":"source/_posts/depth-of-field/dof_butterfly.JPG","hash":"171654a74a208937641a465da8c3d08453d734a7","modified":1693023971000},{"_id":"public/local-search.xml","hash":"e666b72ea47947f4f217bc6127069175ecd17d9f","modified":1730820545848},{"_id":"public/about/index.html","hash":"98f9c5de030bc712f269862eb37b28ecf87bb555","modified":1730820545848},{"_id":"public/display-cabinet/index.html","hash":"733b91446437dbb94b73faacdd31c65bd8f6cc9d","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/index.html","hash":"42951a491945fb4e6ba32f6960df9194a99a837c","modified":1730820545848},{"_id":"public/2024/10/28/depth-of-field/index.html","hash":"1b78ed4d420ddfef34b09bf74c9c6557621476bc","modified":1730820545848},{"_id":"public/2024/10/19/defer-render/index.html","hash":"b7bd27c68b270df78113fdc6caf27fd6c061bcfd","modified":1730820545848},{"_id":"public/2024/10/15/single-scatter-atmosphere/index.html","hash":"947c1f3833667d6c5dcd74f44fb2e23e89aad1de","modified":1730820545848},{"_id":"public/2024/10/13/cascade-shadow-map/index.html","hash":"2ed0eef3576b150ae9b5f552681f68d8593de45d","modified":1730820545848},{"_id":"public/2024/10/11/ProceduralTerrainGeneration/index.html","hash":"548ba10d66fd4ef34d2dac52db678eee91a8a435","modified":1730820545848},{"_id":"public/2024/10/09/StartMyBlog/index.html","hash":"efed617d1f351388c2577d50cb0cc5becf2cd874","modified":1730820545848},{"_id":"public/archives/index.html","hash":"4a168f9844516af95e53f00b58b791c6ca481f8b","modified":1730820545848},{"_id":"public/archives/2024/index.html","hash":"aba34aa3171c9eaac230a47bce65bf084a5e80f7","modified":1730820545848},{"_id":"public/archives/2024/10/index.html","hash":"d1fc3ed20bfd13c9ab76b555f1a45c2c94f76cc2","modified":1730820545848},{"_id":"public/archives/2024/11/index.html","hash":"bdcff229c554322203f75082a6c06388b997e7f6","modified":1730820545848},{"_id":"public/categories/技术漫谈/index.html","hash":"dccea52948ab2660a248dce54dc97e3861721b53","modified":1730820545848},{"_id":"public/categories/生活杂谈/index.html","hash":"9bb9e24ca9a52680600452b5f7219c9cd8dba012","modified":1730820545848},{"_id":"public/index.html","hash":"25cdcbfaabd45131cbc06950e2a6536704ae4945","modified":1730820545848},{"_id":"public/tags/3D/index.html","hash":"2ae3f0bcdae16b2d5b8b62364fc4925885bbaa26","modified":1730820545848},{"_id":"public/tags/render/index.html","hash":"dbd23cc0d8aec6cbb0eea32f1b2af85eb2635dd9","modified":1730820545848},{"_id":"public/tags/渲染/index.html","hash":"07c06cf504c37aa2cd931e04bf3030d639bd7f44","modified":1730820545848},{"_id":"public/tags/编程/index.html","hash":"0545a932c19cc1683d5b9203964ef55a6b3da457","modified":1730820545848},{"_id":"public/tags/程序化生成/index.html","hash":"602f1c99caed3a312dc1ea2404e2c8e10fbb6f1f","modified":1730820545848},{"_id":"public/tags/生活/index.html","hash":"9fb2334a9d9c7e819d782d2516719bd2b2056451","modified":1730820545848},{"_id":"public/404.html","hash":"eb1938515f55ccc12b35944c7322dde683b69425","modified":1730820545848},{"_id":"public/tags/index.html","hash":"43327e839003b01e23a707cb25e796f6295b5a6b","modified":1730820545848},{"_id":"public/categories/index.html","hash":"70959f58ade4857e8a30206ff4580ef0e934e805","modified":1730820545848},{"_id":"public/links/index.html","hash":"a9485d639952ec6a870a4d5891ccce237de389dc","modified":1730820545848},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1730820545848},{"_id":"public/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1730820545848},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1730820545848},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1730820545848},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1730820545848},{"_id":"public/2024/10/13/cascade-shadow-map/csm_far.png","hash":"d6f8dce239df0ca3fb8008e6beea34d08fee464a","modified":1730820545848},{"_id":"public/2024/10/13/cascade-shadow-map/csm_mid.png","hash":"886730be4cb07cf725f965acf50bd8dbe28ba87e","modified":1730820545848},{"_id":"public/2024/10/13/cascade-shadow-map/csm_near.png","hash":"e575a785c09d4c192db4c0e094d919f88e31029a","modified":1730820545848},{"_id":"public/2024/10/11/ProceduralTerrainGeneration/calc_soft_shadow.png","hash":"7bc24f450d820326f7c05fc625259f59481db0db","modified":1730820545848},{"_id":"public/2024/10/19/defer-render/ssao.png","hash":"b208b05bfddb222235f6617fd22ae6d272f861cb","modified":1730820545848},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1730820545848},{"_id":"public/css/highlight-dark.css","hash":"902294bada4323c0f51502d67cba8c3a0298952f","modified":1730820545848},{"_id":"public/css/highlight.css","hash":"04d4ddbb5e1d1007447c2fe293ee05aae9b9563e","modified":1730820545848},{"_id":"public/css/main.css","hash":"14ebd9b515085666cee29bbcbe362ad3604ab62a","modified":1730820545848},{"_id":"public/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1730820545848},{"_id":"public/js/color-schema.js","hash":"1ef88c881b9f942deadde3d890387b94c617342a","modified":1730820545848},{"_id":"public/js/events.js","hash":"6869811f67e4c3de3edfa4b08464bb242b97a402","modified":1730820545848},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1730820545848},{"_id":"public/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1730820545848},{"_id":"public/js/local-search.js","hash":"b9945f76f8682f3ec32edfb285b26eb559f7b7e8","modified":1730820545848},{"_id":"public/js/umami-view.js","hash":"33c4b3883fa747604074ad3921606eeeaeb50716","modified":1730820545848},{"_id":"public/js/plugins.js","hash":"c34916291e392a774ff3e85c55badb83e8661297","modified":1730820545848},{"_id":"public/js/utils.js","hash":"b82e7c289a66dfd36064470fd41c0e96fc598b43","modified":1730820545848},{"_id":"public/2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain_oct5.png","hash":"0f4daabfa7d24bf09919beb71c0701d1c9c7e524","modified":1730820545848},{"_id":"public/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc5_noshadow.png","hash":"64c2e7528dfe87ea1e450decd23c569918479c18","modified":1730820545848},{"_id":"public/2024/10/28/depth-of-field/game1.jpg","hash":"0034e1ebc0e270dca6ea9c6fc878f3889d54e091","modified":1730820545848},{"_id":"public/img/image.png","hash":"77d6c488036d5caa852b645e753011476668d168","modified":1730820545848},{"_id":"public/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_hardshadow.png","hash":"4c4b64ea717fa659999b44c3218fe77f304e1d12","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/terrain_no_grass.png","hash":"6fd3d29360d763f99afc976dbec8ca77c4edcf2c","modified":1730820545848},{"_id":"public/2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain.png","hash":"56cc9ca4c38d9dea545c3fc71e930ff792e46fac","modified":1730820545848},{"_id":"public/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1730820545848},{"_id":"public/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_noshadow.png","hash":"48d0f8a6b7cd0289041b3bea39c24782aaf930f7","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/terrain_with_grass.png","hash":"ecbed0af037da143c48b1dc2a52c3ed6d1569808","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog.png","hash":"dc9fa37962207b51ec4b3659057a2eccc49f6bb0","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky.png","hash":"25bc38e72b9bde4ea69bbde7a25029becdf3a757","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_less_ambient.png","hash":"819633b9a30cd7a285f4a8f3fecd454bee8468d4","modified":1730820545848},{"_id":"public/2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.png","hash":"7266482600228204c32e0fa281e85f626baf7773","modified":1730820545848},{"_id":"public/2024/10/19/defer-render/defer_render_banner.png","hash":"1962262b49a5eff662ac3a76846d4f6414660bc8","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_mountain.png","hash":"82daa3b5403c88308c8fae59330d9a9c008b24aa","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_sky.png","hash":"8b3ddaad30616a7b0b5c606aa4bf89b43afb7192","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/terrain_with_all_cloud.png","hash":"89318f0a3a168ac5b9cbfde0a729f45e6d918d80","modified":1730820545848},{"_id":"public/2024/11/04/ProceduralTerrainGeneration2/terrain_with_high_cloud.png","hash":"17f1b24ce2e0e425166da356780fdd6e9c38343c","modified":1730820545848},{"_id":"public/2024/10/28/depth-of-field/dilate_after.png","hash":"c5e1bc9574c43cf344e177a7a0bbb501bc6eddb9","modified":1730820545848},{"_id":"public/2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.mp4","hash":"cf48cd4f4e5bf60302882e4ab93cca403793b8eb","modified":1730820545848},{"_id":"public/img/og_tinyGL.png","hash":"e64a65a8e7f65f77498e678481bfe0cc65645caf","modified":1730820545848},{"_id":"public/display-cabinet/og_tinyGL.png","hash":"e64a65a8e7f65f77498e678481bfe0cc65645caf","modified":1730820545848},{"_id":"public/2024/10/28/depth-of-field/dilate_before.png","hash":"c37d5697d706fcf09ae6ef0ac82f4b3abb278cf4","modified":1730820545848},{"_id":"public/2024/10/13/cascade-shadow-map/sm_near.png","hash":"3a2e2ba049b19ee345a7944d5eed95bc9bec4d38","modified":1730820545848},{"_id":"public/2024/10/28/depth-of-field/dof_near.png","hash":"13cf595da86662b7836a26beb4230a5fb2cdf58a","modified":1730820545848},{"_id":"public/2024/10/28/depth-of-field/dof_far.png","hash":"a158cb25f92b20004de9a54390d55cbb760f114d","modified":1730820545848},{"_id":"public/2024/10/13/cascade-shadow-map/sm_far.png","hash":"4ebea9aeec6dfbdc98466a6fc2813949f8687f65","modified":1730820545848},{"_id":"public/2024/10/19/defer-render/defer_render.png","hash":"674b2ebba5e97d292f2459382ebee9322476993b","modified":1730820545848},{"_id":"public/2024/10/19/defer-render/no_defer_render.png","hash":"19969d958ab565da447389bae3bd72abfb8bd34f","modified":1730820545848},{"_id":"public/2024/10/15/single-scatter-atmosphere/kong-screen-shot.png","hash":"f54c4ce1299d4e9f4ad89f97fdb86eafaa35ee3f","modified":1730820545848},{"_id":"public/2024/10/13/cascade-shadow-map/csm_result.png","hash":"a29eba82d35e09260b7ec148c9c55c17cbfd05b4","modified":1730820545848},{"_id":"public/2024/10/28/depth-of-field/dof_butterfly.JPG","hash":"171654a74a208937641a465da8c3d08453d734a7","modified":1730820545848}],"Category":[{"name":"技术漫谈","_id":"cm34lv4qe0003y0577mjbbi3q"},{"name":"生活杂谈","_id":"cm34lv4qj000jy057exu62lns"}],"Data":[],"Page":[{"title":"about","layout":"about","_content":"\n你好，这里是RC。\n\n我是一位有着多年游戏行业工作经验的“小白”，做过不少自研引擎和UE相关的工作。\n\n在这个小小的网站空间里，我想把自己在生活和学习中的一些小碎片记录下来，可能是技术上的实践和思考，也可能只是生活中的小小杂念或者是感动。\n\n希望在如白驹过隙的时光，偷偷留下我的几份痕迹。","source":"about/index.md","raw":"---\ntitle: about\nlayout: about\n---\n\n你好，这里是RC。\n\n我是一位有着多年游戏行业工作经验的“小白”，做过不少自研引擎和UE相关的工作。\n\n在这个小小的网站空间里，我想把自己在生活和学习中的一些小碎片记录下来，可能是技术上的实践和思考，也可能只是生活中的小小杂念或者是感动。\n\n希望在如白驹过隙的时光，偷偷留下我的几份痕迹。","date":"2024-10-29T14:32:24.736Z","updated":"2024-10-29T14:32:24.736Z","path":"about/index.html","comments":1,"_id":"cm34lv4q90000y057ak26684d","content":"<p>你好，这里是RC。</p>\n<p>我是一位有着多年游戏行业工作经验的“小白”，做过不少自研引擎和UE相关的工作。</p>\n<p>在这个小小的网站空间里，我想把自己在生活和学习中的一些小碎片记录下来，可能是技术上的实践和思考，也可能只是生活中的小小杂念或者是感动。</p>\n<p>希望在如白驹过隙的时光，偷偷留下我的几份痕迹。</p>\n","excerpt":"","more":"<p>你好，这里是RC。</p>\n<p>我是一位有着多年游戏行业工作经验的“小白”，做过不少自研引擎和UE相关的工作。</p>\n<p>在这个小小的网站空间里，我想把自己在生活和学习中的一些小碎片记录下来，可能是技术上的实践和思考，也可能只是生活中的小小杂念或者是感动。</p>\n<p>希望在如白驹过隙的时光，偷偷留下我的几份痕迹。</p>\n"},{"title":"展示窗","subtitle":"我的作品展示","date":"2024-10-29T14:01:23.000Z","_content":"\n这里是展示窗，是我showcase一些自己的成果的地方，包括代码、github链接等等各种各样的小玩意。\n\n<div class=\"markdown-body\">\n\n# ShaderToy\nShaderToy是一个很有趣的网站，它上面分享了很多实现很酷炫效果的着色器代码。我在上面也有一些分享，下面展示的是我认为可能还算不错作品，或者是对我有意义的学习内容。\n\n## 大气渲染\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/XXBcRR?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo是天空大气的渲染，基于单次散射模型（有一篇文章有提到过）。是个挺有趣的小例子，修改Shader代码可以尝试将相机抬升，将会展示在外太空看向地球的大气效果。\n\n\n## 简单海平面\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/X3ByDD?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo稍微复杂了那么一丢丢，它是由上面的天空大气的demo增加了一些细节而来。云和海水的纹理都是通过柏林噪声来生成的（这就是图形编程的魅力所在吧，仅仅通过代码就能生成逼真的画面）。\n\n流程大概是先计算天空大气的颜色；然后通过噪音生成3D空间的云的密度函数，通过采样一定范围的空气密度来在画面的上半部分渲染云。渲染完成后将云沿着横轴翻转，再配合上噪音生成的海水波纹。\n\n\n## 程序化地形\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo的灵感来源于Inigo大佬的一篇教程：https://www.shadertoy.com/view/4ttSWf。\n\n和教程有所差异的是我选择了使用无线地形的生成，而不是一个固定的角度。\n\n从效果来看是比较震撼的，不过性能上还是有诸多问题，raymarch地形在现在看来还是比较难做到高性能和高质量检具的结果。\n\n另外云（高层和低层）的效果我并不是特别满意，后续还想改成更为复杂一点的效果，并且加上阴影等。\n\n## domain warp\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/lXfBWX?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo是用于学习domain warp的例子。domain warp实际上就是将FBM的输出作为另一个FBM的输入，调整合适的参数和迭代后得到的很特殊的效果。这个demo里面我默认将domain wrap的结果作为raymarch sphere的材质。\n\n## flow effect\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/MXffDX?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo和上面的类似，是我学习flow效果的一个练手作品。\n其实现过程是用FBM计算出平面上某个点的流动方向f，并在0帧初始化最初的颜色后，然后从往后的每一帧，每个像素的颜色都遵循f的方向流动并记录成材质，循环往复。\n\n另外这个flow上的阴影效果是根据颜色的blue值来决定的，只是调了一个好看的效果而已。\n\n\n# GitHub\n这里是我做的一些放在GitHub上面的工程。\n\n## KongEngine\nhttps://github.com/ruochenhua/KongEngine\n\nKongEngine是我在2019年开始的一个基于OpenGL的渲染项目，但是后面由于各种原因更新了没有多少功能就弃置了，在2020年提交了最后一个commit就没有动静，最终的效果也如下图所示。\n\n![2020年的最后一次提交](/img/og_tinyGL.png)\n\n\n2024年我重新拾起这个项目的开发，并在原来非常简单的渲染效果上增加了很多额外的功能，这也是我希望我能够一直进行下去的项目。\n\n</div>","source":"display-cabinet/index.md","raw":"---\ntitle: 展示窗\nsubtitle: 我的作品展示\ndate: 2024-10-29 22:01:23\n---\n\n这里是展示窗，是我showcase一些自己的成果的地方，包括代码、github链接等等各种各样的小玩意。\n\n<div class=\"markdown-body\">\n\n# ShaderToy\nShaderToy是一个很有趣的网站，它上面分享了很多实现很酷炫效果的着色器代码。我在上面也有一些分享，下面展示的是我认为可能还算不错作品，或者是对我有意义的学习内容。\n\n## 大气渲染\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/XXBcRR?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo是天空大气的渲染，基于单次散射模型（有一篇文章有提到过）。是个挺有趣的小例子，修改Shader代码可以尝试将相机抬升，将会展示在外太空看向地球的大气效果。\n\n\n## 简单海平面\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/X3ByDD?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo稍微复杂了那么一丢丢，它是由上面的天空大气的demo增加了一些细节而来。云和海水的纹理都是通过柏林噪声来生成的（这就是图形编程的魅力所在吧，仅仅通过代码就能生成逼真的画面）。\n\n流程大概是先计算天空大气的颜色；然后通过噪音生成3D空间的云的密度函数，通过采样一定范围的空气密度来在画面的上半部分渲染云。渲染完成后将云沿着横轴翻转，再配合上噪音生成的海水波纹。\n\n\n## 程序化地形\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo的灵感来源于Inigo大佬的一篇教程：https://www.shadertoy.com/view/4ttSWf。\n\n和教程有所差异的是我选择了使用无线地形的生成，而不是一个固定的角度。\n\n从效果来看是比较震撼的，不过性能上还是有诸多问题，raymarch地形在现在看来还是比较难做到高性能和高质量检具的结果。\n\n另外云（高层和低层）的效果我并不是特别满意，后续还想改成更为复杂一点的效果，并且加上阴影等。\n\n## domain warp\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/lXfBWX?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo是用于学习domain warp的例子。domain warp实际上就是将FBM的输出作为另一个FBM的输入，调整合适的参数和迭代后得到的很特殊的效果。这个demo里面我默认将domain wrap的结果作为raymarch sphere的材质。\n\n## flow effect\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/MXffDX?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n这个demo和上面的类似，是我学习flow效果的一个练手作品。\n其实现过程是用FBM计算出平面上某个点的流动方向f，并在0帧初始化最初的颜色后，然后从往后的每一帧，每个像素的颜色都遵循f的方向流动并记录成材质，循环往复。\n\n另外这个flow上的阴影效果是根据颜色的blue值来决定的，只是调了一个好看的效果而已。\n\n\n# GitHub\n这里是我做的一些放在GitHub上面的工程。\n\n## KongEngine\nhttps://github.com/ruochenhua/KongEngine\n\nKongEngine是我在2019年开始的一个基于OpenGL的渲染项目，但是后面由于各种原因更新了没有多少功能就弃置了，在2020年提交了最后一个commit就没有动静，最终的效果也如下图所示。\n\n![2020年的最后一次提交](/img/og_tinyGL.png)\n\n\n2024年我重新拾起这个项目的开发，并在原来非常简单的渲染效果上增加了很多额外的功能，这也是我希望我能够一直进行下去的项目。\n\n</div>","updated":"2024-10-29T14:48:40.119Z","path":"display-cabinet/index.html","comments":1,"layout":"page","_id":"cm34lv4qd0002y0573pvxbvzp","content":"<p>这里是展示窗，是我showcase一些自己的成果的地方，包括代码、github链接等等各种各样的小玩意。</p>\n<div class=\"markdown-body\">\n\n<h1 id=\"ShaderToy\"><a href=\"#ShaderToy\" class=\"headerlink\" title=\"ShaderToy\"></a>ShaderToy</h1><p>ShaderToy是一个很有趣的网站，它上面分享了很多实现很酷炫效果的着色器代码。我在上面也有一些分享，下面展示的是我认为可能还算不错作品，或者是对我有意义的学习内容。</p>\n<h2 id=\"大气渲染\"><a href=\"#大气渲染\" class=\"headerlink\" title=\"大气渲染\"></a>大气渲染</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/XXBcRR?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo是天空大气的渲染，基于单次散射模型（有一篇文章有提到过）。是个挺有趣的小例子，修改Shader代码可以尝试将相机抬升，将会展示在外太空看向地球的大气效果。</p>\n<h2 id=\"简单海平面\"><a href=\"#简单海平面\" class=\"headerlink\" title=\"简单海平面\"></a>简单海平面</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/X3ByDD?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo稍微复杂了那么一丢丢，它是由上面的天空大气的demo增加了一些细节而来。云和海水的纹理都是通过柏林噪声来生成的（这就是图形编程的魅力所在吧，仅仅通过代码就能生成逼真的画面）。</p>\n<p>流程大概是先计算天空大气的颜色；然后通过噪音生成3D空间的云的密度函数，通过采样一定范围的空气密度来在画面的上半部分渲染云。渲染完成后将云沿着横轴翻转，再配合上噪音生成的海水波纹。</p>\n<h2 id=\"程序化地形\"><a href=\"#程序化地形\" class=\"headerlink\" title=\"程序化地形\"></a>程序化地形</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo的灵感来源于Inigo大佬的一篇教程：<a href=\"https://www.shadertoy.com/view/4ttSWf%E3%80%82\">https://www.shadertoy.com/view/4ttSWf。</a></p>\n<p>和教程有所差异的是我选择了使用无线地形的生成，而不是一个固定的角度。</p>\n<p>从效果来看是比较震撼的，不过性能上还是有诸多问题，raymarch地形在现在看来还是比较难做到高性能和高质量检具的结果。</p>\n<p>另外云（高层和低层）的效果我并不是特别满意，后续还想改成更为复杂一点的效果，并且加上阴影等。</p>\n<h2 id=\"domain-warp\"><a href=\"#domain-warp\" class=\"headerlink\" title=\"domain warp\"></a>domain warp</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/lXfBWX?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo是用于学习domain warp的例子。domain warp实际上就是将FBM的输出作为另一个FBM的输入，调整合适的参数和迭代后得到的很特殊的效果。这个demo里面我默认将domain wrap的结果作为raymarch sphere的材质。</p>\n<h2 id=\"flow-effect\"><a href=\"#flow-effect\" class=\"headerlink\" title=\"flow effect\"></a>flow effect</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/MXffDX?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo和上面的类似，是我学习flow效果的一个练手作品。<br>其实现过程是用FBM计算出平面上某个点的流动方向f，并在0帧初始化最初的颜色后，然后从往后的每一帧，每个像素的颜色都遵循f的方向流动并记录成材质，循环往复。</p>\n<p>另外这个flow上的阴影效果是根据颜色的blue值来决定的，只是调了一个好看的效果而已。</p>\n<h1 id=\"GitHub\"><a href=\"#GitHub\" class=\"headerlink\" title=\"GitHub\"></a>GitHub</h1><p>这里是我做的一些放在GitHub上面的工程。</p>\n<h2 id=\"KongEngine\"><a href=\"#KongEngine\" class=\"headerlink\" title=\"KongEngine\"></a>KongEngine</h2><p><a href=\"https://github.com/ruochenhua/KongEngine\">https://github.com/ruochenhua/KongEngine</a></p>\n<p>KongEngine是我在2019年开始的一个基于OpenGL的渲染项目，但是后面由于各种原因更新了没有多少功能就弃置了，在2020年提交了最后一个commit就没有动静，最终的效果也如下图所示。</p>\n<p><img src=\"/img/og_tinyGL.png\" alt=\"2020年的最后一次提交\"></p>\n<p>2024年我重新拾起这个项目的开发，并在原来非常简单的渲染效果上增加了很多额外的功能，这也是我希望我能够一直进行下去的项目。</p>\n</div>","excerpt":"","more":"<p>这里是展示窗，是我showcase一些自己的成果的地方，包括代码、github链接等等各种各样的小玩意。</p>\n<div class=\"markdown-body\">\n\n<h1 id=\"ShaderToy\"><a href=\"#ShaderToy\" class=\"headerlink\" title=\"ShaderToy\"></a>ShaderToy</h1><p>ShaderToy是一个很有趣的网站，它上面分享了很多实现很酷炫效果的着色器代码。我在上面也有一些分享，下面展示的是我认为可能还算不错作品，或者是对我有意义的学习内容。</p>\n<h2 id=\"大气渲染\"><a href=\"#大气渲染\" class=\"headerlink\" title=\"大气渲染\"></a>大气渲染</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/XXBcRR?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo是天空大气的渲染，基于单次散射模型（有一篇文章有提到过）。是个挺有趣的小例子，修改Shader代码可以尝试将相机抬升，将会展示在外太空看向地球的大气效果。</p>\n<h2 id=\"简单海平面\"><a href=\"#简单海平面\" class=\"headerlink\" title=\"简单海平面\"></a>简单海平面</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/X3ByDD?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo稍微复杂了那么一丢丢，它是由上面的天空大气的demo增加了一些细节而来。云和海水的纹理都是通过柏林噪声来生成的（这就是图形编程的魅力所在吧，仅仅通过代码就能生成逼真的画面）。</p>\n<p>流程大概是先计算天空大气的颜色；然后通过噪音生成3D空间的云的密度函数，通过采样一定范围的空气密度来在画面的上半部分渲染云。渲染完成后将云沿着横轴翻转，再配合上噪音生成的海水波纹。</p>\n<h2 id=\"程序化地形\"><a href=\"#程序化地形\" class=\"headerlink\" title=\"程序化地形\"></a>程序化地形</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo的灵感来源于Inigo大佬的一篇教程：<a href=\"https://www.shadertoy.com/view/4ttSWf%E3%80%82\">https://www.shadertoy.com/view/4ttSWf。</a></p>\n<p>和教程有所差异的是我选择了使用无线地形的生成，而不是一个固定的角度。</p>\n<p>从效果来看是比较震撼的，不过性能上还是有诸多问题，raymarch地形在现在看来还是比较难做到高性能和高质量检具的结果。</p>\n<p>另外云（高层和低层）的效果我并不是特别满意，后续还想改成更为复杂一点的效果，并且加上阴影等。</p>\n<h2 id=\"domain-warp\"><a href=\"#domain-warp\" class=\"headerlink\" title=\"domain warp\"></a>domain warp</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/lXfBWX?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo是用于学习domain warp的例子。domain warp实际上就是将FBM的输出作为另一个FBM的输入，调整合适的参数和迭代后得到的很特殊的效果。这个demo里面我默认将domain wrap的结果作为raymarch sphere的材质。</p>\n<h2 id=\"flow-effect\"><a href=\"#flow-effect\" class=\"headerlink\" title=\"flow effect\"></a>flow effect</h2><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/MXffDX?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>这个demo和上面的类似，是我学习flow效果的一个练手作品。<br>其实现过程是用FBM计算出平面上某个点的流动方向f，并在0帧初始化最初的颜色后，然后从往后的每一帧，每个像素的颜色都遵循f的方向流动并记录成材质，循环往复。</p>\n<p>另外这个flow上的阴影效果是根据颜色的blue值来决定的，只是调了一个好看的效果而已。</p>\n<h1 id=\"GitHub\"><a href=\"#GitHub\" class=\"headerlink\" title=\"GitHub\"></a>GitHub</h1><p>这里是我做的一些放在GitHub上面的工程。</p>\n<h2 id=\"KongEngine\"><a href=\"#KongEngine\" class=\"headerlink\" title=\"KongEngine\"></a>KongEngine</h2><p><a href=\"https://github.com/ruochenhua/KongEngine\">https://github.com/ruochenhua/KongEngine</a></p>\n<p>KongEngine是我在2019年开始的一个基于OpenGL的渲染项目，但是后面由于各种原因更新了没有多少功能就弃置了，在2020年提交了最后一个commit就没有动静，最终的效果也如下图所示。</p>\n<p><img src=\"/img/og_tinyGL.png\" alt=\"2020年的最后一次提交\"></p>\n<p>2024年我重新拾起这个项目的开发，并在原来非常简单的渲染效果上增加了很多额外的功能，这也是我希望我能够一直进行下去的项目。</p>\n</div>"}],"Post":[{"title":"程序化地形生成-1","date":"2024-10-11T14:59:27.000Z","index_img":"/2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain.png","banner_img":"/2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain.png","_content":"\n[ShaderToy](https://www.shadertoy.com/)是一个很有趣的网站，它上面有着非常多的渲染案例分享，最近一段时间我也是沉迷了。在看了不少大佬的作品之后，不禁手痒。前一段时间看了Inigo大佬的一个[教程案例](https://www.shadertoy.com/view/4ttSWf)，想着把这个效果自己来实现一次，因此就有了今天的这篇文章。\n\n我最终的成品也放到了shadertoy上面，有兴趣的同学可以一起讨论参考一下。看起来还不错对吧，虽然还有不少地方需要完善，但这个demo已经实现了我心中的大部分效果，包括无限的基于噪音的地形生成、地形阴影、雾气、云等等。\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n那么下面，就让我来一步步说明这个demo的实现过程吧。\n\n# 基础知识\n## 在ST上渲染地形\n对ShaderToy上运行的Shader代码，对应着可编程渲染管线的片段着色器(或者叫像素着色器)。片段着色器主要是是图形光栅化后的像素信息，所以渲染3D场景需要进行一些额外的步骤。\n\nShaderToy的程序一般是这样的：\n```c\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n\t...\n}\n```\n**fragColor**是输出，代表这这个像素的最终颜色；**fragCoord**是输入，代表这个像素点的xy坐标。ShaderToy提供了固定变量**iResolution**用来表示整个屏幕的xy的分辨率。\n\n为了渲染3D物体，我们需要采用ray cast/marching的方法，构建一个相机的位置作为光线射出的起点**ro**，再根据当前像素点的坐标和ro的差获得光线射出的方向**rd**。\n```c\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    vec2 uv = fragCoord / iResolution.xy;\n\t// 以屏幕中心为（0,0）\n    uv = uv * 2.0 - 1.0;\n\t// 缩放x，在画面拉伸的时候保证比例正确\n    uv.x *= iResolution.x/iResolution.y;\n\t// 原点位置\n    vec3 ro = vec3(0, 0, -1);\n    // 射线方向\n    vec3 rd = normalize(vec3(uv, 2));\n\n\tfragColor = rayMarching(ro, rd);\n}\n```\n\n## 和地形相交\n在shadertoy中渲染3D物体，一般是使用raymarching方法配合SDFs来渲染3D的物体。SDF（Signed Distance Field）是一种物体的隐式表达，用于存储和计算点到图形表面的最近距离。经由一个起点和一个方向，可以用SDF来达到低消耗的射线检测效果。\n\n这里可以参考Inigo对SDF的介绍的介绍：https://iquilezles.org/articles/distfunctions/\n\n地形的渲染也是类似的，我们通过ray marching方法来找到距离地形最近的点，以此来获取地形的形状。但是和SDF不同的是，我们无法很轻易的判断射线当前距离地形的最近距离，尤其是当我们的地形完全是通过噪音来随机生成的时候，这变成了一个不可能完成的任务。所以在判断地形相交的时候，只能回归到笨办法，一步一步慢慢的往前“挪”，*若当前的顶点在地形之下，而之前的一个迭代在地形之上的话*，那我们就找到了击中地表的区间段。\n![射线和地表相交](https://iquilezles.org/articles/terrainmarching/gfx02.png)\n``` c\nbool rayMarch(vec3 ro, vec3 rd, out float hit_t)\n{\n\tconst float dt = 0.01f;\n\tconst float min_t = 1e-3;\n\tconst float max_t = 1e3;\n\tfor(float t = min_t; t < max_t; t+=dt)\n\t{\n\t\tconst vec3 p = ro+rd*t;\n\t\tif(p.y < f(p.x, p.z));\n\t\t{\n\t\t\t// 取中间点减小误差\n\t\t\thit_t = t - 0.5f*dt;\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n```\n这个方法简单易懂，但显而易见在性能上并不是最优的，尤其是涉及到范围很大的地形的时候，dt的值如果取得太小，那么渲染完成一个场景的时间将会非常的长，消耗巨大；而若是dt的值取得太大，则很有可能会出现取值错误的情况。\n\n当场景距离我们足够远的时候，由于透视的原因，近大远小，远处的场景精度对于观察者来说是越来越不重要了，因此dt的值可以随着光线步近而逐渐组建增大，动态变化。在合适的dt取值和变化曲线下，能够满足精度和性能的要求。Inigo给出的方法是类似这样的：\n```c\n//其他和上方代码一致\nfor(float t = min_t; t<max_t; t+=dt)\n{\n    const vec3 p = ro+rd*t;\n    const float h = f(p.xz);\n    if(p.y<h)\n    {\n        hit_t = t - 0.5f*dt;\n        return true;\n    }\n    dt=0.01f*t;\n}\nreturn false;\n```\nt的起始值和dt的增长倍数可以自己尝试选择一个合适的值。\n\n另外，如果我们能对最终渲染的效果有所了解的话，可以通过过滤掉很多不需要做射线检测的情况来极大的提升性能。如果我们最终的效果是一个在空中的相机，天空和地面占据画面各一半的话，那么上半部分的画面（通过rd.y>0判断）是可以完全跳过射线检测的。或者通过增加min_t的值来减少前期昂贵且不必要的性能消耗。\n\n在相交点的取值上，也可以进一步优化。原来仅仅是取两次光线步近的平均值，我们可以额外获取两次步近时位置的地形高度，用高度变化的连线和光线步近的线段做相交的判定取交点。这样得到的值将会更加精确。\n```c\n//其他和上方代码一致\nfloat lh = 0.0f;\nfloat ly = 0.0f;\nfor(float t = min_t; t<max_t; t+=dt)\n{\n    const vec3 p = ro+rd*t;\n    const float h = f(p.xz);\n    if(p.y<h)\n    {\n        // 计算两个线段的相交点\n        hit_t = t - dt + dt*(lh-ly)/(p.y-ly-h+lh);\n        return true;\n    }\n    dt=0.01f*t;\n    lh = h;\n    ly = p.y;\n}\nreturn false;\n```\n至此，我们就可以在ShaderToy渲染出地形了。\n\n# 地形生成\n## 生成的基础：噪音\n当我们提到噪音，往往会很生活化的把噪音和声音连接起来，从声学的角度来说是正确的。噪音其实可以用来表示所有通过振幅（amplitude）和频率（frequency）描述的波动，它可以是声音，它可以是辐射，也可以是其他的任意一种波动。\n\n在数学课上，我们学过正弦、余弦等三角函数，sin和cos其实就是一种噪音的表现方式。\n```c\nfloat amplitude = 1.0;\nfloat frequencey = 1.0;\nfloat y = amplitude * sin(frequency * x);\n```\n就像上面的代码所示，通过改变amplitude和frequency，我们可以改变sin波形的状态。\n\n噪音在很多程序化生成算法中都有着举足轻重的地位。\n\n## 分形布朗运动\n噪音是一种波，它是可以相互叠加的。两个相同的sin波形叠加会形成振幅更加强大的sin波形，而频率相差π/2的两个sin波形叠加后会相互抵消。\n\n在地形随机生成中，为了最终的结果噪音有着更好的随机性和更好的细节，将会循环多次计算噪音，循环的次数为我们称之为octave。每次循环的同一个噪音以一定倍数（lacunarity）升高频率，同时以一定比例（gain）降低振幅，最终将每个噪音计算的结果叠加得到一个最终的噪音，这个噪音的生成技术叫做“分形布朗运动”（fractal brownian motion，fbm）。\n\n下面是分形布朗运动的一个简单的代码演示：\n```c\nfloat fbm(vec2 uv, float frequency, float amplitude, int octave)\n{\n\tfloat lacunarity = 2.0;\n\tfloat gain = 0.5;\n\tfloat noise_val = 0.0;\n\tfloat amp = amplitude;\n\tfor(int index = 0; index < octave; ++index)\n\t{\n\t\tnose_val += noiseInterpolate(uv * frequency) * amp;\n\t\tamp *= gain;\n\t\tfrequency *= lacunarity;\n\t}\n\t\n\treturn noise_val;\n}\n```\n其中noiseInterpolate可以是perlin noise或者是simplex noise等任意一种噪音算法。\ndemo中的地形生成和云层的生成，也使用了该技术。关于FBM除了上面简单的使用还有很多其他的变种，这里我们就不扩展了，后面有机会的话可以专门介绍一下。\n\n## 地形的基础表现\n这里我将地形部分拆解出来。demo的地形计算使用了perlin noise，octave数量达到了11。更多的octave数量会给地形带来更多的细节，但是一般来说后面的效果收益会越来越少。下方是octave数量分布为5和11下的地形的形状对比。\n![](shadertoy_oc5_noshadow.png)\n![](shadertoy_oc11_noshadow.png)\n\n除了每次叠加噪音会进行频率和振幅的变化，为了获得更好的随机性，以及进一步减少噪音可能出现的重复pattern，可以将噪音进行旋转（也就是将传入的uv或者是坐标乘以一个默认的旋转矩阵）后再叠加到原来的噪音上。\n\n我们也需要地形的法线来和光源结合，渲染出地形的明暗部分。获得法线的方法有很多种，可以采样当前计算的地形上点的x轴和z轴（这里假定y轴为up）方向不远的一两个点，和目标点相减得到切线和副切线方向，通过叉乘得到目标点的法线。亦或是采样其他点后通过中心差分法求得目标点的法线。\n\n## 阴影\n仅仅通过法线来渲染地形的明部和暗部是不够的，我们还需要计算地形投射在地表上的阴影。地形的阴影计算原理非常简单，就是将地形上渲染的目标点，沿着光源方向进行射线检测，如果和地形相交的话，那该点就是处于阴影之下。理想情况下，射线检测的距离当然是实际上光源和地形上的点的距离，但是往往由于性能的原因，我们需要缩短这个距离。*实际的检测距离可以结合当前点的高度以及地形可能的最高位置进行计算*。\n\n在判断当前点处于阴影的时候，计算最终颜色的时候需要再乘以一个阴影的系数。\n![](shadertoy_oc11_hardshadow.png)\n\n为了提升效果，我们通常不希望阴影的边缘非常生硬，而是希望有一种柔软的过度，这种更加符合现实的表现。实现这种软阴影的方法可能有很多种，这里采用的是Inigo教程的一种方法。\n\n上面提到判定阴影是通过从地形上面的点向光源方向做射线检测得到的，如果和地形相交则该点处于阴影当中，若不相交，则需要再取一个值，这值是地形向着光源方向移动距离t长度的位置，它和地形高度的差值d和距离t的比值的最小值，乘以某个常数X（10~32等等，可以自己尝试合适的范围）后经过smoothstep限制在（0,1）范围内。这个值作为阴影系数放入光照计算后就可以得到不错的软阴影效果。\n![](calc_soft_shadow.png)\n\n通过下面的对比图我们可以看到，在加入了软阴影计算后，地形阴影的边缘有了一种较为平滑的过度，显得没那么生硬了。想要更改软阴影的表现的话可以通过修改常数X。\n![](shadertoy_terrain.png)\n\n# 结语\n好了，我们已经得到了一个基础的程序化生成地形的效果了，但是它看起来还是有些单调。地形的深度表现、天空、云彩等等应该如何表现呢？\n\n无需着急，我们将会在后面的文章中对它进行进一步的优化。\n\n## 参考资料\nhttps://thebookofshaders.com/13/?lan=ch\nhttps://iquilezles.org/articles/morenoise\nhttps://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g\n","source":"_posts/ProceduralTerrainGeneration.md","raw":"---\ntitle: 程序化地形生成-1\ndate: 2024-10-11 22:59:27\ncategories: \n\t- 技术漫谈\ntags: [3D, render, 渲染, 编程, 程序化生成]\n\t\nindex_img: /2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain.png\nbanner_img: /2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain.png\n---\n\n[ShaderToy](https://www.shadertoy.com/)是一个很有趣的网站，它上面有着非常多的渲染案例分享，最近一段时间我也是沉迷了。在看了不少大佬的作品之后，不禁手痒。前一段时间看了Inigo大佬的一个[教程案例](https://www.shadertoy.com/view/4ttSWf)，想着把这个效果自己来实现一次，因此就有了今天的这篇文章。\n\n我最终的成品也放到了shadertoy上面，有兴趣的同学可以一起讨论参考一下。看起来还不错对吧，虽然还有不少地方需要完善，但这个demo已经实现了我心中的大部分效果，包括无限的基于噪音的地形生成、地形阴影、雾气、云等等。\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n那么下面，就让我来一步步说明这个demo的实现过程吧。\n\n# 基础知识\n## 在ST上渲染地形\n对ShaderToy上运行的Shader代码，对应着可编程渲染管线的片段着色器(或者叫像素着色器)。片段着色器主要是是图形光栅化后的像素信息，所以渲染3D场景需要进行一些额外的步骤。\n\nShaderToy的程序一般是这样的：\n```c\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n\t...\n}\n```\n**fragColor**是输出，代表这这个像素的最终颜色；**fragCoord**是输入，代表这个像素点的xy坐标。ShaderToy提供了固定变量**iResolution**用来表示整个屏幕的xy的分辨率。\n\n为了渲染3D物体，我们需要采用ray cast/marching的方法，构建一个相机的位置作为光线射出的起点**ro**，再根据当前像素点的坐标和ro的差获得光线射出的方向**rd**。\n```c\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n    vec2 uv = fragCoord / iResolution.xy;\n\t// 以屏幕中心为（0,0）\n    uv = uv * 2.0 - 1.0;\n\t// 缩放x，在画面拉伸的时候保证比例正确\n    uv.x *= iResolution.x/iResolution.y;\n\t// 原点位置\n    vec3 ro = vec3(0, 0, -1);\n    // 射线方向\n    vec3 rd = normalize(vec3(uv, 2));\n\n\tfragColor = rayMarching(ro, rd);\n}\n```\n\n## 和地形相交\n在shadertoy中渲染3D物体，一般是使用raymarching方法配合SDFs来渲染3D的物体。SDF（Signed Distance Field）是一种物体的隐式表达，用于存储和计算点到图形表面的最近距离。经由一个起点和一个方向，可以用SDF来达到低消耗的射线检测效果。\n\n这里可以参考Inigo对SDF的介绍的介绍：https://iquilezles.org/articles/distfunctions/\n\n地形的渲染也是类似的，我们通过ray marching方法来找到距离地形最近的点，以此来获取地形的形状。但是和SDF不同的是，我们无法很轻易的判断射线当前距离地形的最近距离，尤其是当我们的地形完全是通过噪音来随机生成的时候，这变成了一个不可能完成的任务。所以在判断地形相交的时候，只能回归到笨办法，一步一步慢慢的往前“挪”，*若当前的顶点在地形之下，而之前的一个迭代在地形之上的话*，那我们就找到了击中地表的区间段。\n![射线和地表相交](https://iquilezles.org/articles/terrainmarching/gfx02.png)\n``` c\nbool rayMarch(vec3 ro, vec3 rd, out float hit_t)\n{\n\tconst float dt = 0.01f;\n\tconst float min_t = 1e-3;\n\tconst float max_t = 1e3;\n\tfor(float t = min_t; t < max_t; t+=dt)\n\t{\n\t\tconst vec3 p = ro+rd*t;\n\t\tif(p.y < f(p.x, p.z));\n\t\t{\n\t\t\t// 取中间点减小误差\n\t\t\thit_t = t - 0.5f*dt;\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n```\n这个方法简单易懂，但显而易见在性能上并不是最优的，尤其是涉及到范围很大的地形的时候，dt的值如果取得太小，那么渲染完成一个场景的时间将会非常的长，消耗巨大；而若是dt的值取得太大，则很有可能会出现取值错误的情况。\n\n当场景距离我们足够远的时候，由于透视的原因，近大远小，远处的场景精度对于观察者来说是越来越不重要了，因此dt的值可以随着光线步近而逐渐组建增大，动态变化。在合适的dt取值和变化曲线下，能够满足精度和性能的要求。Inigo给出的方法是类似这样的：\n```c\n//其他和上方代码一致\nfor(float t = min_t; t<max_t; t+=dt)\n{\n    const vec3 p = ro+rd*t;\n    const float h = f(p.xz);\n    if(p.y<h)\n    {\n        hit_t = t - 0.5f*dt;\n        return true;\n    }\n    dt=0.01f*t;\n}\nreturn false;\n```\nt的起始值和dt的增长倍数可以自己尝试选择一个合适的值。\n\n另外，如果我们能对最终渲染的效果有所了解的话，可以通过过滤掉很多不需要做射线检测的情况来极大的提升性能。如果我们最终的效果是一个在空中的相机，天空和地面占据画面各一半的话，那么上半部分的画面（通过rd.y>0判断）是可以完全跳过射线检测的。或者通过增加min_t的值来减少前期昂贵且不必要的性能消耗。\n\n在相交点的取值上，也可以进一步优化。原来仅仅是取两次光线步近的平均值，我们可以额外获取两次步近时位置的地形高度，用高度变化的连线和光线步近的线段做相交的判定取交点。这样得到的值将会更加精确。\n```c\n//其他和上方代码一致\nfloat lh = 0.0f;\nfloat ly = 0.0f;\nfor(float t = min_t; t<max_t; t+=dt)\n{\n    const vec3 p = ro+rd*t;\n    const float h = f(p.xz);\n    if(p.y<h)\n    {\n        // 计算两个线段的相交点\n        hit_t = t - dt + dt*(lh-ly)/(p.y-ly-h+lh);\n        return true;\n    }\n    dt=0.01f*t;\n    lh = h;\n    ly = p.y;\n}\nreturn false;\n```\n至此，我们就可以在ShaderToy渲染出地形了。\n\n# 地形生成\n## 生成的基础：噪音\n当我们提到噪音，往往会很生活化的把噪音和声音连接起来，从声学的角度来说是正确的。噪音其实可以用来表示所有通过振幅（amplitude）和频率（frequency）描述的波动，它可以是声音，它可以是辐射，也可以是其他的任意一种波动。\n\n在数学课上，我们学过正弦、余弦等三角函数，sin和cos其实就是一种噪音的表现方式。\n```c\nfloat amplitude = 1.0;\nfloat frequencey = 1.0;\nfloat y = amplitude * sin(frequency * x);\n```\n就像上面的代码所示，通过改变amplitude和frequency，我们可以改变sin波形的状态。\n\n噪音在很多程序化生成算法中都有着举足轻重的地位。\n\n## 分形布朗运动\n噪音是一种波，它是可以相互叠加的。两个相同的sin波形叠加会形成振幅更加强大的sin波形，而频率相差π/2的两个sin波形叠加后会相互抵消。\n\n在地形随机生成中，为了最终的结果噪音有着更好的随机性和更好的细节，将会循环多次计算噪音，循环的次数为我们称之为octave。每次循环的同一个噪音以一定倍数（lacunarity）升高频率，同时以一定比例（gain）降低振幅，最终将每个噪音计算的结果叠加得到一个最终的噪音，这个噪音的生成技术叫做“分形布朗运动”（fractal brownian motion，fbm）。\n\n下面是分形布朗运动的一个简单的代码演示：\n```c\nfloat fbm(vec2 uv, float frequency, float amplitude, int octave)\n{\n\tfloat lacunarity = 2.0;\n\tfloat gain = 0.5;\n\tfloat noise_val = 0.0;\n\tfloat amp = amplitude;\n\tfor(int index = 0; index < octave; ++index)\n\t{\n\t\tnose_val += noiseInterpolate(uv * frequency) * amp;\n\t\tamp *= gain;\n\t\tfrequency *= lacunarity;\n\t}\n\t\n\treturn noise_val;\n}\n```\n其中noiseInterpolate可以是perlin noise或者是simplex noise等任意一种噪音算法。\ndemo中的地形生成和云层的生成，也使用了该技术。关于FBM除了上面简单的使用还有很多其他的变种，这里我们就不扩展了，后面有机会的话可以专门介绍一下。\n\n## 地形的基础表现\n这里我将地形部分拆解出来。demo的地形计算使用了perlin noise，octave数量达到了11。更多的octave数量会给地形带来更多的细节，但是一般来说后面的效果收益会越来越少。下方是octave数量分布为5和11下的地形的形状对比。\n![](shadertoy_oc5_noshadow.png)\n![](shadertoy_oc11_noshadow.png)\n\n除了每次叠加噪音会进行频率和振幅的变化，为了获得更好的随机性，以及进一步减少噪音可能出现的重复pattern，可以将噪音进行旋转（也就是将传入的uv或者是坐标乘以一个默认的旋转矩阵）后再叠加到原来的噪音上。\n\n我们也需要地形的法线来和光源结合，渲染出地形的明暗部分。获得法线的方法有很多种，可以采样当前计算的地形上点的x轴和z轴（这里假定y轴为up）方向不远的一两个点，和目标点相减得到切线和副切线方向，通过叉乘得到目标点的法线。亦或是采样其他点后通过中心差分法求得目标点的法线。\n\n## 阴影\n仅仅通过法线来渲染地形的明部和暗部是不够的，我们还需要计算地形投射在地表上的阴影。地形的阴影计算原理非常简单，就是将地形上渲染的目标点，沿着光源方向进行射线检测，如果和地形相交的话，那该点就是处于阴影之下。理想情况下，射线检测的距离当然是实际上光源和地形上的点的距离，但是往往由于性能的原因，我们需要缩短这个距离。*实际的检测距离可以结合当前点的高度以及地形可能的最高位置进行计算*。\n\n在判断当前点处于阴影的时候，计算最终颜色的时候需要再乘以一个阴影的系数。\n![](shadertoy_oc11_hardshadow.png)\n\n为了提升效果，我们通常不希望阴影的边缘非常生硬，而是希望有一种柔软的过度，这种更加符合现实的表现。实现这种软阴影的方法可能有很多种，这里采用的是Inigo教程的一种方法。\n\n上面提到判定阴影是通过从地形上面的点向光源方向做射线检测得到的，如果和地形相交则该点处于阴影当中，若不相交，则需要再取一个值，这值是地形向着光源方向移动距离t长度的位置，它和地形高度的差值d和距离t的比值的最小值，乘以某个常数X（10~32等等，可以自己尝试合适的范围）后经过smoothstep限制在（0,1）范围内。这个值作为阴影系数放入光照计算后就可以得到不错的软阴影效果。\n![](calc_soft_shadow.png)\n\n通过下面的对比图我们可以看到，在加入了软阴影计算后，地形阴影的边缘有了一种较为平滑的过度，显得没那么生硬了。想要更改软阴影的表现的话可以通过修改常数X。\n![](shadertoy_terrain.png)\n\n# 结语\n好了，我们已经得到了一个基础的程序化生成地形的效果了，但是它看起来还是有些单调。地形的深度表现、天空、云彩等等应该如何表现呢？\n\n无需着急，我们将会在后面的文章中对它进行进一步的优化。\n\n## 参考资料\nhttps://thebookofshaders.com/13/?lan=ch\nhttps://iquilezles.org/articles/morenoise\nhttps://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g\n","slug":"ProceduralTerrainGeneration","published":1,"updated":"2024-10-15T14:31:06.374Z","comments":1,"layout":"post","photos":[],"_id":"cm34lv4qc0001y05705f2e1jt","content":"<p><a href=\"https://www.shadertoy.com/\">ShaderToy</a>是一个很有趣的网站，它上面有着非常多的渲染案例分享，最近一段时间我也是沉迷了。在看了不少大佬的作品之后，不禁手痒。前一段时间看了Inigo大佬的一个<a href=\"https://www.shadertoy.com/view/4ttSWf\">教程案例</a>，想着把这个效果自己来实现一次，因此就有了今天的这篇文章。</p>\n<p>我最终的成品也放到了shadertoy上面，有兴趣的同学可以一起讨论参考一下。看起来还不错对吧，虽然还有不少地方需要完善，但这个demo已经实现了我心中的大部分效果，包括无限的基于噪音的地形生成、地形阴影、雾气、云等等。</p>\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>那么下面，就让我来一步步说明这个demo的实现过程吧。</p>\n<h1 id=\"基础知识\"><a href=\"#基础知识\" class=\"headerlink\" title=\"基础知识\"></a>基础知识</h1><h2 id=\"在ST上渲染地形\"><a href=\"#在ST上渲染地形\" class=\"headerlink\" title=\"在ST上渲染地形\"></a>在ST上渲染地形</h2><p>对ShaderToy上运行的Shader代码，对应着可编程渲染管线的片段着色器(或者叫像素着色器)。片段着色器主要是是图形光栅化后的像素信息，所以渲染3D场景需要进行一些额外的步骤。</p>\n<p>ShaderToy的程序一般是这样的：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title function_\">mainImage</span><span class=\"hljs-params\">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>\t...<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><strong>fragColor</strong>是输出，代表这这个像素的最终颜色；<strong>fragCoord</strong>是输入，代表这个像素点的xy坐标。ShaderToy提供了固定变量<strong>iResolution</strong>用来表示整个屏幕的xy的分辨率。</p>\n<p>为了渲染3D物体，我们需要采用ray cast&#x2F;marching的方法，构建一个相机的位置作为光线射出的起点<strong>ro</strong>，再根据当前像素点的坐标和ro的差获得光线射出的方向<strong>rd</strong>。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title function_\">mainImage</span><span class=\"hljs-params\">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>    vec2 uv = fragCoord / iResolution.xy;<br>\t<span class=\"hljs-comment\">// 以屏幕中心为（0,0）</span><br>    uv = uv * <span class=\"hljs-number\">2.0</span> - <span class=\"hljs-number\">1.0</span>;<br>\t<span class=\"hljs-comment\">// 缩放x，在画面拉伸的时候保证比例正确</span><br>    uv.x *= iResolution.x/iResolution.y;<br>\t<span class=\"hljs-comment\">// 原点位置</span><br>    vec3 ro = vec3(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">-1</span>);<br>    <span class=\"hljs-comment\">// 射线方向</span><br>    vec3 rd = normalize(vec3(uv, <span class=\"hljs-number\">2</span>));<br><br>\tfragColor = rayMarching(ro, rd);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"和地形相交\"><a href=\"#和地形相交\" class=\"headerlink\" title=\"和地形相交\"></a>和地形相交</h2><p>在shadertoy中渲染3D物体，一般是使用raymarching方法配合SDFs来渲染3D的物体。SDF（Signed Distance Field）是一种物体的隐式表达，用于存储和计算点到图形表面的最近距离。经由一个起点和一个方向，可以用SDF来达到低消耗的射线检测效果。</p>\n<p>这里可以参考Inigo对SDF的介绍的介绍：<a href=\"https://iquilezles.org/articles/distfunctions/\">https://iquilezles.org/articles/distfunctions/</a></p>\n<p>地形的渲染也是类似的，我们通过ray marching方法来找到距离地形最近的点，以此来获取地形的形状。但是和SDF不同的是，我们无法很轻易的判断射线当前距离地形的最近距离，尤其是当我们的地形完全是通过噪音来随机生成的时候，这变成了一个不可能完成的任务。所以在判断地形相交的时候，只能回归到笨办法，一步一步慢慢的往前“挪”，<em>若当前的顶点在地形之下，而之前的一个迭代在地形之上的话</em>，那我们就找到了击中地表的区间段。<br><img src=\"https://iquilezles.org/articles/terrainmarching/gfx02.png\" alt=\"射线和地表相交\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title function_\">rayMarch</span><span class=\"hljs-params\">(vec3 ro, vec3 rd, out <span class=\"hljs-type\">float</span> <span class=\"hljs-type\">hit_t</span>)</span><br>&#123;<br>\t<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> dt = <span class=\"hljs-number\">0.01f</span>;<br>\t<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> <span class=\"hljs-type\">min_t</span> = <span class=\"hljs-number\">1e-3</span>;<br>\t<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> <span class=\"hljs-type\">max_t</span> = <span class=\"hljs-number\">1e3</span>;<br>\t<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">float</span> t = <span class=\"hljs-type\">min_t</span>; t &lt; <span class=\"hljs-type\">max_t</span>; t+=dt)<br>\t&#123;<br>\t\t<span class=\"hljs-type\">const</span> vec3 p = ro+rd*t;<br>\t\t<span class=\"hljs-keyword\">if</span>(p.y &lt; f(p.x, p.z));<br>\t\t&#123;<br>\t\t\t<span class=\"hljs-comment\">// 取中间点减小误差</span><br>\t\t\t<span class=\"hljs-type\">hit_t</span> = t - <span class=\"hljs-number\">0.5f</span>*dt;<br>\t\t\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>这个方法简单易懂，但显而易见在性能上并不是最优的，尤其是涉及到范围很大的地形的时候，dt的值如果取得太小，那么渲染完成一个场景的时间将会非常的长，消耗巨大；而若是dt的值取得太大，则很有可能会出现取值错误的情况。</p>\n<p>当场景距离我们足够远的时候，由于透视的原因，近大远小，远处的场景精度对于观察者来说是越来越不重要了，因此dt的值可以随着光线步近而逐渐组建增大，动态变化。在合适的dt取值和变化曲线下，能够满足精度和性能的要求。Inigo给出的方法是类似这样的：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-comment\">//其他和上方代码一致</span><br><span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">float</span> t = <span class=\"hljs-type\">min_t</span>; t&lt;<span class=\"hljs-type\">max_t</span>; t+=dt)<br>&#123;<br>    <span class=\"hljs-type\">const</span> vec3 p = ro+rd*t;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> h = f(p.xz);<br>    <span class=\"hljs-keyword\">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class=\"hljs-type\">hit_t</span> = t - <span class=\"hljs-number\">0.5f</span>*dt;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>    dt=<span class=\"hljs-number\">0.01f</span>*t;<br>&#125;<br><span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br></code></pre></td></tr></table></figure>\n<p>t的起始值和dt的增长倍数可以自己尝试选择一个合适的值。</p>\n<p>另外，如果我们能对最终渲染的效果有所了解的话，可以通过过滤掉很多不需要做射线检测的情况来极大的提升性能。如果我们最终的效果是一个在空中的相机，天空和地面占据画面各一半的话，那么上半部分的画面（通过rd.y&gt;0判断）是可以完全跳过射线检测的。或者通过增加min_t的值来减少前期昂贵且不必要的性能消耗。</p>\n<p>在相交点的取值上，也可以进一步优化。原来仅仅是取两次光线步近的平均值，我们可以额外获取两次步近时位置的地形高度，用高度变化的连线和光线步近的线段做相交的判定取交点。这样得到的值将会更加精确。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-comment\">//其他和上方代码一致</span><br><span class=\"hljs-type\">float</span> lh = <span class=\"hljs-number\">0.0f</span>;<br><span class=\"hljs-type\">float</span> ly = <span class=\"hljs-number\">0.0f</span>;<br><span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">float</span> t = <span class=\"hljs-type\">min_t</span>; t&lt;<span class=\"hljs-type\">max_t</span>; t+=dt)<br>&#123;<br>    <span class=\"hljs-type\">const</span> vec3 p = ro+rd*t;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> h = f(p.xz);<br>    <span class=\"hljs-keyword\">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class=\"hljs-comment\">// 计算两个线段的相交点</span><br>        <span class=\"hljs-type\">hit_t</span> = t - dt + dt*(lh-ly)/(p.y-ly-h+lh);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>    dt=<span class=\"hljs-number\">0.01f</span>*t;<br>    lh = h;<br>    ly = p.y;<br>&#125;<br><span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br></code></pre></td></tr></table></figure>\n<p>至此，我们就可以在ShaderToy渲染出地形了。</p>\n<h1 id=\"地形生成\"><a href=\"#地形生成\" class=\"headerlink\" title=\"地形生成\"></a>地形生成</h1><h2 id=\"生成的基础：噪音\"><a href=\"#生成的基础：噪音\" class=\"headerlink\" title=\"生成的基础：噪音\"></a>生成的基础：噪音</h2><p>当我们提到噪音，往往会很生活化的把噪音和声音连接起来，从声学的角度来说是正确的。噪音其实可以用来表示所有通过振幅（amplitude）和频率（frequency）描述的波动，它可以是声音，它可以是辐射，也可以是其他的任意一种波动。</p>\n<p>在数学课上，我们学过正弦、余弦等三角函数，sin和cos其实就是一种噪音的表现方式。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">float</span> amplitude = <span class=\"hljs-number\">1.0</span>;<br><span class=\"hljs-type\">float</span> frequencey = <span class=\"hljs-number\">1.0</span>;<br><span class=\"hljs-type\">float</span> y = amplitude * <span class=\"hljs-built_in\">sin</span>(frequency * x);<br></code></pre></td></tr></table></figure>\n<p>就像上面的代码所示，通过改变amplitude和frequency，我们可以改变sin波形的状态。</p>\n<p>噪音在很多程序化生成算法中都有着举足轻重的地位。</p>\n<h2 id=\"分形布朗运动\"><a href=\"#分形布朗运动\" class=\"headerlink\" title=\"分形布朗运动\"></a>分形布朗运动</h2><p>噪音是一种波，它是可以相互叠加的。两个相同的sin波形叠加会形成振幅更加强大的sin波形，而频率相差π&#x2F;2的两个sin波形叠加后会相互抵消。</p>\n<p>在地形随机生成中，为了最终的结果噪音有着更好的随机性和更好的细节，将会循环多次计算噪音，循环的次数为我们称之为octave。每次循环的同一个噪音以一定倍数（lacunarity）升高频率，同时以一定比例（gain）降低振幅，最终将每个噪音计算的结果叠加得到一个最终的噪音，这个噪音的生成技术叫做“分形布朗运动”（fractal brownian motion，fbm）。</p>\n<p>下面是分形布朗运动的一个简单的代码演示：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">float</span> <span class=\"hljs-title function_\">fbm</span><span class=\"hljs-params\">(vec2 uv, <span class=\"hljs-type\">float</span> frequency, <span class=\"hljs-type\">float</span> amplitude, <span class=\"hljs-type\">int</span> octave)</span><br>&#123;<br>\t<span class=\"hljs-type\">float</span> lacunarity = <span class=\"hljs-number\">2.0</span>;<br>\t<span class=\"hljs-type\">float</span> gain = <span class=\"hljs-number\">0.5</span>;<br>\t<span class=\"hljs-type\">float</span> noise_val = <span class=\"hljs-number\">0.0</span>;<br>\t<span class=\"hljs-type\">float</span> amp = amplitude;<br>\t<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> index = <span class=\"hljs-number\">0</span>; index &lt; octave; ++index)<br>\t&#123;<br>\t\tnose_val += noiseInterpolate(uv * frequency) * amp;<br>\t\tamp *= gain;<br>\t\tfrequency *= lacunarity;<br>\t&#125;<br>\t<br>\t<span class=\"hljs-keyword\">return</span> noise_val;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>其中noiseInterpolate可以是perlin noise或者是simplex noise等任意一种噪音算法。<br>demo中的地形生成和云层的生成，也使用了该技术。关于FBM除了上面简单的使用还有很多其他的变种，这里我们就不扩展了，后面有机会的话可以专门介绍一下。</p>\n<h2 id=\"地形的基础表现\"><a href=\"#地形的基础表现\" class=\"headerlink\" title=\"地形的基础表现\"></a>地形的基础表现</h2><p>这里我将地形部分拆解出来。demo的地形计算使用了perlin noise，octave数量达到了11。更多的octave数量会给地形带来更多的细节，但是一般来说后面的效果收益会越来越少。下方是octave数量分布为5和11下的地形的形状对比。<br><img src=\"/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc5_noshadow.png\"><br><img src=\"/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_noshadow.png\"></p>\n<p>除了每次叠加噪音会进行频率和振幅的变化，为了获得更好的随机性，以及进一步减少噪音可能出现的重复pattern，可以将噪音进行旋转（也就是将传入的uv或者是坐标乘以一个默认的旋转矩阵）后再叠加到原来的噪音上。</p>\n<p>我们也需要地形的法线来和光源结合，渲染出地形的明暗部分。获得法线的方法有很多种，可以采样当前计算的地形上点的x轴和z轴（这里假定y轴为up）方向不远的一两个点，和目标点相减得到切线和副切线方向，通过叉乘得到目标点的法线。亦或是采样其他点后通过中心差分法求得目标点的法线。</p>\n<h2 id=\"阴影\"><a href=\"#阴影\" class=\"headerlink\" title=\"阴影\"></a>阴影</h2><p>仅仅通过法线来渲染地形的明部和暗部是不够的，我们还需要计算地形投射在地表上的阴影。地形的阴影计算原理非常简单，就是将地形上渲染的目标点，沿着光源方向进行射线检测，如果和地形相交的话，那该点就是处于阴影之下。理想情况下，射线检测的距离当然是实际上光源和地形上的点的距离，但是往往由于性能的原因，我们需要缩短这个距离。<em>实际的检测距离可以结合当前点的高度以及地形可能的最高位置进行计算</em>。</p>\n<p>在判断当前点处于阴影的时候，计算最终颜色的时候需要再乘以一个阴影的系数。<br><img src=\"/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_hardshadow.png\"></p>\n<p>为了提升效果，我们通常不希望阴影的边缘非常生硬，而是希望有一种柔软的过度，这种更加符合现实的表现。实现这种软阴影的方法可能有很多种，这里采用的是Inigo教程的一种方法。</p>\n<p>上面提到判定阴影是通过从地形上面的点向光源方向做射线检测得到的，如果和地形相交则该点处于阴影当中，若不相交，则需要再取一个值，这值是地形向着光源方向移动距离t长度的位置，它和地形高度的差值d和距离t的比值的最小值，乘以某个常数X（10~32等等，可以自己尝试合适的范围）后经过smoothstep限制在（0,1）范围内。这个值作为阴影系数放入光照计算后就可以得到不错的软阴影效果。<br><img src=\"/2024/10/11/ProceduralTerrainGeneration/calc_soft_shadow.png\"></p>\n<p>通过下面的对比图我们可以看到，在加入了软阴影计算后，地形阴影的边缘有了一种较为平滑的过度，显得没那么生硬了。想要更改软阴影的表现的话可以通过修改常数X。<br><img src=\"/2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain.png\"></p>\n<h1 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h1><p>好了，我们已经得到了一个基础的程序化生成地形的效果了，但是它看起来还是有些单调。地形的深度表现、天空、云彩等等应该如何表现呢？</p>\n<p>无需着急，我们将会在后面的文章中对它进行进一步的优化。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://thebookofshaders.com/13/?lan=ch\">https://thebookofshaders.com/13/?lan=ch</a><br><a href=\"https://iquilezles.org/articles/morenoise\">https://iquilezles.org/articles/morenoise</a><br><a href=\"https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g\">https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g</a></p>\n","excerpt":"","more":"<p><a href=\"https://www.shadertoy.com/\">ShaderToy</a>是一个很有趣的网站，它上面有着非常多的渲染案例分享，最近一段时间我也是沉迷了。在看了不少大佬的作品之后，不禁手痒。前一段时间看了Inigo大佬的一个<a href=\"https://www.shadertoy.com/view/4ttSWf\">教程案例</a>，想着把这个效果自己来实现一次，因此就有了今天的这篇文章。</p>\n<p>我最终的成品也放到了shadertoy上面，有兴趣的同学可以一起讨论参考一下。看起来还不错对吧，虽然还有不少地方需要完善，但这个demo已经实现了我心中的大部分效果，包括无限的基于噪音的地形生成、地形阴影、雾气、云等等。</p>\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>那么下面，就让我来一步步说明这个demo的实现过程吧。</p>\n<h1 id=\"基础知识\"><a href=\"#基础知识\" class=\"headerlink\" title=\"基础知识\"></a>基础知识</h1><h2 id=\"在ST上渲染地形\"><a href=\"#在ST上渲染地形\" class=\"headerlink\" title=\"在ST上渲染地形\"></a>在ST上渲染地形</h2><p>对ShaderToy上运行的Shader代码，对应着可编程渲染管线的片段着色器(或者叫像素着色器)。片段着色器主要是是图形光栅化后的像素信息，所以渲染3D场景需要进行一些额外的步骤。</p>\n<p>ShaderToy的程序一般是这样的：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title function_\">mainImage</span><span class=\"hljs-params\">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>\t...<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><strong>fragColor</strong>是输出，代表这这个像素的最终颜色；<strong>fragCoord</strong>是输入，代表这个像素点的xy坐标。ShaderToy提供了固定变量<strong>iResolution</strong>用来表示整个屏幕的xy的分辨率。</p>\n<p>为了渲染3D物体，我们需要采用ray cast&#x2F;marching的方法，构建一个相机的位置作为光线射出的起点<strong>ro</strong>，再根据当前像素点的坐标和ro的差获得光线射出的方向<strong>rd</strong>。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title function_\">mainImage</span><span class=\"hljs-params\">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>    vec2 uv = fragCoord / iResolution.xy;<br>\t<span class=\"hljs-comment\">// 以屏幕中心为（0,0）</span><br>    uv = uv * <span class=\"hljs-number\">2.0</span> - <span class=\"hljs-number\">1.0</span>;<br>\t<span class=\"hljs-comment\">// 缩放x，在画面拉伸的时候保证比例正确</span><br>    uv.x *= iResolution.x/iResolution.y;<br>\t<span class=\"hljs-comment\">// 原点位置</span><br>    vec3 ro = vec3(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">-1</span>);<br>    <span class=\"hljs-comment\">// 射线方向</span><br>    vec3 rd = normalize(vec3(uv, <span class=\"hljs-number\">2</span>));<br><br>\tfragColor = rayMarching(ro, rd);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"和地形相交\"><a href=\"#和地形相交\" class=\"headerlink\" title=\"和地形相交\"></a>和地形相交</h2><p>在shadertoy中渲染3D物体，一般是使用raymarching方法配合SDFs来渲染3D的物体。SDF（Signed Distance Field）是一种物体的隐式表达，用于存储和计算点到图形表面的最近距离。经由一个起点和一个方向，可以用SDF来达到低消耗的射线检测效果。</p>\n<p>这里可以参考Inigo对SDF的介绍的介绍：<a href=\"https://iquilezles.org/articles/distfunctions/\">https://iquilezles.org/articles/distfunctions/</a></p>\n<p>地形的渲染也是类似的，我们通过ray marching方法来找到距离地形最近的点，以此来获取地形的形状。但是和SDF不同的是，我们无法很轻易的判断射线当前距离地形的最近距离，尤其是当我们的地形完全是通过噪音来随机生成的时候，这变成了一个不可能完成的任务。所以在判断地形相交的时候，只能回归到笨办法，一步一步慢慢的往前“挪”，<em>若当前的顶点在地形之下，而之前的一个迭代在地形之上的话</em>，那我们就找到了击中地表的区间段。<br><img src=\"https://iquilezles.org/articles/terrainmarching/gfx02.png\" alt=\"射线和地表相交\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">bool</span> <span class=\"hljs-title function_\">rayMarch</span><span class=\"hljs-params\">(vec3 ro, vec3 rd, out <span class=\"hljs-type\">float</span> <span class=\"hljs-type\">hit_t</span>)</span><br>&#123;<br>\t<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> dt = <span class=\"hljs-number\">0.01f</span>;<br>\t<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> <span class=\"hljs-type\">min_t</span> = <span class=\"hljs-number\">1e-3</span>;<br>\t<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> <span class=\"hljs-type\">max_t</span> = <span class=\"hljs-number\">1e3</span>;<br>\t<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">float</span> t = <span class=\"hljs-type\">min_t</span>; t &lt; <span class=\"hljs-type\">max_t</span>; t+=dt)<br>\t&#123;<br>\t\t<span class=\"hljs-type\">const</span> vec3 p = ro+rd*t;<br>\t\t<span class=\"hljs-keyword\">if</span>(p.y &lt; f(p.x, p.z));<br>\t\t&#123;<br>\t\t\t<span class=\"hljs-comment\">// 取中间点减小误差</span><br>\t\t\t<span class=\"hljs-type\">hit_t</span> = t - <span class=\"hljs-number\">0.5f</span>*dt;<br>\t\t\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>\t\t&#125;<br>\t&#125;<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>这个方法简单易懂，但显而易见在性能上并不是最优的，尤其是涉及到范围很大的地形的时候，dt的值如果取得太小，那么渲染完成一个场景的时间将会非常的长，消耗巨大；而若是dt的值取得太大，则很有可能会出现取值错误的情况。</p>\n<p>当场景距离我们足够远的时候，由于透视的原因，近大远小，远处的场景精度对于观察者来说是越来越不重要了，因此dt的值可以随着光线步近而逐渐组建增大，动态变化。在合适的dt取值和变化曲线下，能够满足精度和性能的要求。Inigo给出的方法是类似这样的：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-comment\">//其他和上方代码一致</span><br><span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">float</span> t = <span class=\"hljs-type\">min_t</span>; t&lt;<span class=\"hljs-type\">max_t</span>; t+=dt)<br>&#123;<br>    <span class=\"hljs-type\">const</span> vec3 p = ro+rd*t;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> h = f(p.xz);<br>    <span class=\"hljs-keyword\">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class=\"hljs-type\">hit_t</span> = t - <span class=\"hljs-number\">0.5f</span>*dt;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>    dt=<span class=\"hljs-number\">0.01f</span>*t;<br>&#125;<br><span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br></code></pre></td></tr></table></figure>\n<p>t的起始值和dt的增长倍数可以自己尝试选择一个合适的值。</p>\n<p>另外，如果我们能对最终渲染的效果有所了解的话，可以通过过滤掉很多不需要做射线检测的情况来极大的提升性能。如果我们最终的效果是一个在空中的相机，天空和地面占据画面各一半的话，那么上半部分的画面（通过rd.y&gt;0判断）是可以完全跳过射线检测的。或者通过增加min_t的值来减少前期昂贵且不必要的性能消耗。</p>\n<p>在相交点的取值上，也可以进一步优化。原来仅仅是取两次光线步近的平均值，我们可以额外获取两次步近时位置的地形高度，用高度变化的连线和光线步近的线段做相交的判定取交点。这样得到的值将会更加精确。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-comment\">//其他和上方代码一致</span><br><span class=\"hljs-type\">float</span> lh = <span class=\"hljs-number\">0.0f</span>;<br><span class=\"hljs-type\">float</span> ly = <span class=\"hljs-number\">0.0f</span>;<br><span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">float</span> t = <span class=\"hljs-type\">min_t</span>; t&lt;<span class=\"hljs-type\">max_t</span>; t+=dt)<br>&#123;<br>    <span class=\"hljs-type\">const</span> vec3 p = ro+rd*t;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">float</span> h = f(p.xz);<br>    <span class=\"hljs-keyword\">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class=\"hljs-comment\">// 计算两个线段的相交点</span><br>        <span class=\"hljs-type\">hit_t</span> = t - dt + dt*(lh-ly)/(p.y-ly-h+lh);<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>    dt=<span class=\"hljs-number\">0.01f</span>*t;<br>    lh = h;<br>    ly = p.y;<br>&#125;<br><span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br></code></pre></td></tr></table></figure>\n<p>至此，我们就可以在ShaderToy渲染出地形了。</p>\n<h1 id=\"地形生成\"><a href=\"#地形生成\" class=\"headerlink\" title=\"地形生成\"></a>地形生成</h1><h2 id=\"生成的基础：噪音\"><a href=\"#生成的基础：噪音\" class=\"headerlink\" title=\"生成的基础：噪音\"></a>生成的基础：噪音</h2><p>当我们提到噪音，往往会很生活化的把噪音和声音连接起来，从声学的角度来说是正确的。噪音其实可以用来表示所有通过振幅（amplitude）和频率（frequency）描述的波动，它可以是声音，它可以是辐射，也可以是其他的任意一种波动。</p>\n<p>在数学课上，我们学过正弦、余弦等三角函数，sin和cos其实就是一种噪音的表现方式。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">float</span> amplitude = <span class=\"hljs-number\">1.0</span>;<br><span class=\"hljs-type\">float</span> frequencey = <span class=\"hljs-number\">1.0</span>;<br><span class=\"hljs-type\">float</span> y = amplitude * <span class=\"hljs-built_in\">sin</span>(frequency * x);<br></code></pre></td></tr></table></figure>\n<p>就像上面的代码所示，通过改变amplitude和frequency，我们可以改变sin波形的状态。</p>\n<p>噪音在很多程序化生成算法中都有着举足轻重的地位。</p>\n<h2 id=\"分形布朗运动\"><a href=\"#分形布朗运动\" class=\"headerlink\" title=\"分形布朗运动\"></a>分形布朗运动</h2><p>噪音是一种波，它是可以相互叠加的。两个相同的sin波形叠加会形成振幅更加强大的sin波形，而频率相差π&#x2F;2的两个sin波形叠加后会相互抵消。</p>\n<p>在地形随机生成中，为了最终的结果噪音有着更好的随机性和更好的细节，将会循环多次计算噪音，循环的次数为我们称之为octave。每次循环的同一个噪音以一定倍数（lacunarity）升高频率，同时以一定比例（gain）降低振幅，最终将每个噪音计算的结果叠加得到一个最终的噪音，这个噪音的生成技术叫做“分形布朗运动”（fractal brownian motion，fbm）。</p>\n<p>下面是分形布朗运动的一个简单的代码演示：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-type\">float</span> <span class=\"hljs-title function_\">fbm</span><span class=\"hljs-params\">(vec2 uv, <span class=\"hljs-type\">float</span> frequency, <span class=\"hljs-type\">float</span> amplitude, <span class=\"hljs-type\">int</span> octave)</span><br>&#123;<br>\t<span class=\"hljs-type\">float</span> lacunarity = <span class=\"hljs-number\">2.0</span>;<br>\t<span class=\"hljs-type\">float</span> gain = <span class=\"hljs-number\">0.5</span>;<br>\t<span class=\"hljs-type\">float</span> noise_val = <span class=\"hljs-number\">0.0</span>;<br>\t<span class=\"hljs-type\">float</span> amp = amplitude;<br>\t<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> index = <span class=\"hljs-number\">0</span>; index &lt; octave; ++index)<br>\t&#123;<br>\t\tnose_val += noiseInterpolate(uv * frequency) * amp;<br>\t\tamp *= gain;<br>\t\tfrequency *= lacunarity;<br>\t&#125;<br>\t<br>\t<span class=\"hljs-keyword\">return</span> noise_val;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>其中noiseInterpolate可以是perlin noise或者是simplex noise等任意一种噪音算法。<br>demo中的地形生成和云层的生成，也使用了该技术。关于FBM除了上面简单的使用还有很多其他的变种，这里我们就不扩展了，后面有机会的话可以专门介绍一下。</p>\n<h2 id=\"地形的基础表现\"><a href=\"#地形的基础表现\" class=\"headerlink\" title=\"地形的基础表现\"></a>地形的基础表现</h2><p>这里我将地形部分拆解出来。demo的地形计算使用了perlin noise，octave数量达到了11。更多的octave数量会给地形带来更多的细节，但是一般来说后面的效果收益会越来越少。下方是octave数量分布为5和11下的地形的形状对比。<br><img src=\"/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc5_noshadow.png\"><br><img src=\"/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_noshadow.png\"></p>\n<p>除了每次叠加噪音会进行频率和振幅的变化，为了获得更好的随机性，以及进一步减少噪音可能出现的重复pattern，可以将噪音进行旋转（也就是将传入的uv或者是坐标乘以一个默认的旋转矩阵）后再叠加到原来的噪音上。</p>\n<p>我们也需要地形的法线来和光源结合，渲染出地形的明暗部分。获得法线的方法有很多种，可以采样当前计算的地形上点的x轴和z轴（这里假定y轴为up）方向不远的一两个点，和目标点相减得到切线和副切线方向，通过叉乘得到目标点的法线。亦或是采样其他点后通过中心差分法求得目标点的法线。</p>\n<h2 id=\"阴影\"><a href=\"#阴影\" class=\"headerlink\" title=\"阴影\"></a>阴影</h2><p>仅仅通过法线来渲染地形的明部和暗部是不够的，我们还需要计算地形投射在地表上的阴影。地形的阴影计算原理非常简单，就是将地形上渲染的目标点，沿着光源方向进行射线检测，如果和地形相交的话，那该点就是处于阴影之下。理想情况下，射线检测的距离当然是实际上光源和地形上的点的距离，但是往往由于性能的原因，我们需要缩短这个距离。<em>实际的检测距离可以结合当前点的高度以及地形可能的最高位置进行计算</em>。</p>\n<p>在判断当前点处于阴影的时候，计算最终颜色的时候需要再乘以一个阴影的系数。<br><img src=\"/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_hardshadow.png\"></p>\n<p>为了提升效果，我们通常不希望阴影的边缘非常生硬，而是希望有一种柔软的过度，这种更加符合现实的表现。实现这种软阴影的方法可能有很多种，这里采用的是Inigo教程的一种方法。</p>\n<p>上面提到判定阴影是通过从地形上面的点向光源方向做射线检测得到的，如果和地形相交则该点处于阴影当中，若不相交，则需要再取一个值，这值是地形向着光源方向移动距离t长度的位置，它和地形高度的差值d和距离t的比值的最小值，乘以某个常数X（10~32等等，可以自己尝试合适的范围）后经过smoothstep限制在（0,1）范围内。这个值作为阴影系数放入光照计算后就可以得到不错的软阴影效果。<br><img src=\"/2024/10/11/ProceduralTerrainGeneration/calc_soft_shadow.png\"></p>\n<p>通过下面的对比图我们可以看到，在加入了软阴影计算后，地形阴影的边缘有了一种较为平滑的过度，显得没那么生硬了。想要更改软阴影的表现的话可以通过修改常数X。<br><img src=\"/2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain.png\"></p>\n<h1 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h1><p>好了，我们已经得到了一个基础的程序化生成地形的效果了，但是它看起来还是有些单调。地形的深度表现、天空、云彩等等应该如何表现呢？</p>\n<p>无需着急，我们将会在后面的文章中对它进行进一步的优化。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://thebookofshaders.com/13/?lan=ch\">https://thebookofshaders.com/13/?lan=ch</a><br><a href=\"https://iquilezles.org/articles/morenoise\">https://iquilezles.org/articles/morenoise</a><br><a href=\"https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g\">https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g</a></p>\n"},{"title":"程序化地形生成-2","date":"2024-11-04T13:50:18.000Z","index_img":"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_all_cloud.png","banner_img":"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_all_cloud.png","_content":"\n距离上一篇将程序化地形生成的[教程](https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/)也已经过去了一段时间了。前段时间一直有其他事情需要忙，现在终于有时间继续之前未完成的工作了。\n\n# 丰富地形\n上一篇教程我们已经创建出了绵延的山脉，如下图所示：\n![上次渲染的结果](terrain_no_grass.png)\n看起来似乎是有那么点意思了，但是这样的山脉效果还是太单调了。\n\n接下来我们就计划丰富一下这个场景。\n\n## 增加绿植\n我们场景中的山光秃秃的，很像是沙漠，也很像火星上的地貌。\n\n我想给场景增加一些层次，一些生机，因此我打算将山的一部分渲染为绿植部分。\n\n那么如何确定哪些部分是绿植，哪些部分是裸露的山体呢？根据地形表面的法线可以做一个简单的判定：法线的y分量越大，也就是面向上的分量越大，表明这个面更平，因此有绿植是更合适的；反正则表明这个面更加陡峭，更适合作为山体表现。\n\n```glsl\nvec3 dirt_color = vec3(0.8549, 0.5255, 0.3098);\nvec3 grass_color = vec3(0.3137, 0.5412, 0.0157);\n// ..\n\nif(rd.y < 0.05 && rayMarchingTerrain(ro, rd, maxt, res_t))\n{\n    vec3 height_pos = ro+res_t*rd;\n\n    // calculate normla\n    vec3 normal = getNormal(height_pos);\n    float grass_ratio = smoothstep(0.7, 0.98, normal.y);\n    vec3 ground_color = mix(dirt_color, grass_color, grass_ratio);\n}\n\n```\n\n上面是一段实例代码，我们预先设定山体和绿植的颜色，在光线步进山体的时候，获取normal，根据法线的y方向的大小（也可以用dot来判定）做smoothstep取一个合适的值作为当前平面草地的比例，最后混合山体和草地的比例。得到的结果如下：\n\n![增加绿植](terrain_with_grass.png)\n这样一来场景的丰富程度一下子就提升了。\n\n# 天空\n现在最终结果还是挺奇怪的，很大一部分的原因是场景的背景还是黑咕隆咚的。我们的大场景急需增加天空的部分。\n\n## 天空的颜色\n天空的颜色我之前有写过一个[教程](https://ruochenhua.github.io/2024/10/15/single-scatter-atmosphere/)，是利用单次散射的方法来计算天空大气的颜色。当然这个方法在这依然是可用的。\n\n不过如果你说，我不想用那么复杂的方法，只想快速出效果呢？那也是很简单，给地形光线步近没有结果的像素设定为蓝色就行了，哈哈。\n\n如果想再复杂一点，可以做一个小细节的优化。也就是在晴朗的情况下，一般靠近地平线的天的蓝色是更加浅的，所以在给天空像素上色的时候，可以根据当前像素的方向的y值作为判定，在深蓝色和浅蓝色做线性插值。\n\n```glsl\nvec3 low_sky_blue = vec3(0.5137, 0.7804, 0.9608);\nvec3 high_sky_blue = vec3(0.3216, 0.4706, 0.9725);\n\nvec3 sky_color = mix(low_sky_blue, high_sky_blue, clamp(rd.y, 0.0, 1.0));\n```\n\n![增加天空](terrain_with_sky.png)\n\n## 雾气增强层次感\n在增加了天空之后，我们的渲染结果有了很显著的提升，终于像室外的场景了。\n\n不过仔细看后，还是觉得怪怪的，远处的山和天空根本不在一个图层上；山的远近层次感也不足，远处的山太清晰了。\n\n这是因为缺少雾气的结果，雾气能够很好的增加大场景体量感，能够很好的处理场景和天空衔接的感觉。\n\n增加雾气也十分简单，仅需根据地形光线步近的结果的大小（也就是地形离相机的距离）来计算一个比例，根据这个比例来做场景颜色和雾气颜色的插值即可。\n\n```glsl\n// cal fog density, different between r,g,b so the fog has a blue hue\nvec3 calcFog(float dist)\n{    \n    return exp(-5e-3*dist*vec3(1,2,4));\n}\n\n// ...\nvec3 fog_amount = calcFog(res_t);\ncolor = mix(vec3(0.7),color, fog_amount);\n```\n上面这段便是雾气的计算过程。雾气的比例通过**exp(-5e-3*dist*vec3(1,2,4))**计算，得到的雾的比例用于最终颜色的线性插值。\n\n![增加雾气](terrain_with_sky_fog.png)\n有了雾气的加持，我们场景的大体量感就有了，层次感也明显了很多。\n关于雾气的更多内容，可以参考Inigo大神的[这篇文章](https://iquilezles.org/articles/fog/)。\n\n## 漫反射光照细节\n接下来我想优化一下场景整体的漫反射细节。\n\n当前的渲染结果其实是有加一个默认的环境光**vec3(0.1)**的，主要是之前的场景太黑了。这是个临时的处理，把这个环境光去掉。\n![去掉写死的环境光补偿](terrain_with_sky_fog_less_ambient.png)\n\n好了，我们再来看一下我们的场景。有没有感觉山体的阴影部分有点太黑了？是的，在现实世界中，处于阴影的场景，在大白天也会被场景的漫反射光给提亮的，这种一片漆黑的感觉是有些难看。所以接下来我们来增加一些场景中应该有的漫反射光。\n\n首先山体之间是会有漫反射光的影响的，也就是阴影部分的山体会被不在阴影的其他山的漫反射光照亮。当然这种影响我们是无法实时计算的，要计算的东西实在是太多了。但是可以通过一个很简单的方式来提单：我们计算当前点的发现和指向光源方向的点乘，当这个结果大于0的时候，用这个乘积乘以一个小的光照并加到原本的颜色上。\n\n```glsl\ncolor += (max(0.0, dot(-light_dir, normal))*ground_color/10.0);\n```\n\n![增加地形的漫反射光](terrain_with_sky_fog_diffuse_from_mountain.png)\n\n加完地形的漫反射光后，天空其实也有各个方向的漫反射的光会影响地形的亮度。天空的漫反射光可以通过地形法线的y分量和天空颜色的一部分来计算，示例代码如下：\n```glsl\ncolor += (normal.y + 1.0)/2.0*low_sky_blue/10.0;\n```\n\n![增加天空的漫反射光](terrain_with_sky_fog_diffuse_from_sky.png)\n\n增加了这些漫反射细节，场景的真实度进一步得到了提升。\n\n# 云朵\n有了天空，再给天空上增加云的话会进一步增加场景的丰富度，下面就来介绍我给这个场景添加的两部分云的计算。\n\n## 高层云\n我给这个场景添加了两种云，高层云是我想模拟在高度很高的地方，云层看起来不厚并且相对静态的感觉。\n\n高层云的纹理也是利用perlin noise来计算，由于高层的云没有厚实感其实用2D的perlin noise也足够了。\n\n另外需要注意的是，云的纹理需要根据远近来做处理。远处的云的纹理如果太清晰的话在最终效果上会显得太过于密集。下面是高层云的示例代码：\n```glsl\n// 高层云的高度\nfloat top_sky_plane = 3000.;\n\nvec3 getSkyColor(vec3 ro, vec3 rd)\n{    \n    vec3 hit_sky;\n    hit_sky.y = top_sky_plane;\n        \n    hit_sky.xz = ro.xz + rd.xz * (top_sky_plane - ro.y)/rd.y;    \n    \n    //降低远处云的密度，看起来效果更好\n    float hit_dist = distance(hit_sky, ro);\n    float cloud_density_percentage = 1.0;\n    if(hit_dist > cloud_view_distance)\n    {\n        cloud_density_percentage *= exp(-(hit_dist - cloud_view_distance)/ cloud_view_distance);\n    }    \n\n    // 根据云层采样点的远近处理云层的密度\n    float cloud_density = smoothstep(getCloudDensity(hit_sky.xz/150.0, 3), -0.99, 1.9)*cloud_density_percentage * 0.5;\n    float res_t;\n\n    // sky color    \n    vec3 sky_color = mix(low_sky_blue, high_sky_blue, clamp(rd.y, 0.0, 1.0));\n    vec3 cloud_color = vec3(1.);\n    // 根据云层密度得到最终的高层云和天空颜色\n    return mix(sky_color, cloud_color, cloud_density);\n}\n```\n\n![增加天空高层云](terrain_with_high_cloud.png)\n\n增加了高层云之后，天空就显得不那么单调了。\n\n## 体积云\n最后就是体积云了，体积云的部分我不会在这里详细讨论，这是一个可以讨论的比较深的话题。我这个场景的体积云效果也并不是很理想，这里仅作为一个最后的点缀，在山峰上增加一点点动态效果。\n\n体积云的效果其实也是在一定区域内进行多个点的采样而来，这个区域内利用FBM来实现云的动态的随机效果。在这个场景内我使用了SDF来圈定体积云的范围，并且给SDF增加了随机现状来获取更好的随机效果。\n\n```glsl\nfloat scene(in vec3 pos)\n{    \n    vec3 cloud_pos = vec3(0.0, 5.0, 15.0);\n    \n    vec3 filter_pos = vec3(pos.x, pos.y+iTime, pos.z+iTime);\n    pos -= cloud_pos;\n    float rst = -(rm_box(pos)) + fbm_cloud(pos * 0.1+iTime*0.3, 5);\n    rst = rst / 25.0 * max(fbm_cloud(filter_pos*0.1, 1) - 1.2, 0.0); \n    return rst;\n}\n\nfloat max_cloud_dist = 80.;\nvec4 renderMidClouds(vec3 ro, vec3 rd)\n{    \n    vec4 res = vec4(0.0);\n    float depth = 0.0;    \n    \n    int sample_count = 64;\n    float dt = max_cloud_dist / float(sample_count);\n    \n    for(int i = 0; i < sample_count; ++i)\n    {\n        vec3 p = ro + depth*rd;\n        float density = scene(p);\n        if(density > 0.0)\n        {\n            float diffuse = clamp((scene(p) - scene(p + 0.3*light_dir))/0.3, 0.0, 1.0);\n            vec3 lin = vec3(0.8, 0.8, 0.8) * 1.1 + 0.8 * vec3(0.9333, 0.702, 0.5255)*diffuse;\n            vec4 color = vec4(mix(vec3(1.0), vec3(0.0), density), density);\n            color.rgb *= color.a;\n\n            res += color * (1.0 - res.a);\n        }\n\n        depth+=dt;\n    }\n\n    return res;\n}\n```\n\n![增加体积云](terrain_with_all_cloud.png)\n\n\n# 最终效果\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n以上便是我如何实现这个场景的简单介绍了。这是我初次尝试在ShaderToy上渲染大场景，也是第一次将整个步骤拆解讲解，可能还是会有不少地方讲的不过仔细和通透，也有些遗漏。\n\n后面我还是会继续尝试创作和讲解，希望能给人带来帮助，也有助于巩固我所学的知识。","source":"_posts/ProceduralTerrainGeneration2.md","raw":"---\ntitle: 程序化地形生成-2\ndate: 2024-11-04 21:50:18\ncategories: \n\t- 技术漫谈\ntags: [3D, render, 渲染, 编程, 程序化生成]\n\t\nindex_img: /2024/11/04/ProceduralTerrainGeneration2/terrain_with_all_cloud.png\nbanner_img: /2024/11/04/ProceduralTerrainGeneration2/terrain_with_all_cloud.png\n---\n\n距离上一篇将程序化地形生成的[教程](https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/)也已经过去了一段时间了。前段时间一直有其他事情需要忙，现在终于有时间继续之前未完成的工作了。\n\n# 丰富地形\n上一篇教程我们已经创建出了绵延的山脉，如下图所示：\n![上次渲染的结果](terrain_no_grass.png)\n看起来似乎是有那么点意思了，但是这样的山脉效果还是太单调了。\n\n接下来我们就计划丰富一下这个场景。\n\n## 增加绿植\n我们场景中的山光秃秃的，很像是沙漠，也很像火星上的地貌。\n\n我想给场景增加一些层次，一些生机，因此我打算将山的一部分渲染为绿植部分。\n\n那么如何确定哪些部分是绿植，哪些部分是裸露的山体呢？根据地形表面的法线可以做一个简单的判定：法线的y分量越大，也就是面向上的分量越大，表明这个面更平，因此有绿植是更合适的；反正则表明这个面更加陡峭，更适合作为山体表现。\n\n```glsl\nvec3 dirt_color = vec3(0.8549, 0.5255, 0.3098);\nvec3 grass_color = vec3(0.3137, 0.5412, 0.0157);\n// ..\n\nif(rd.y < 0.05 && rayMarchingTerrain(ro, rd, maxt, res_t))\n{\n    vec3 height_pos = ro+res_t*rd;\n\n    // calculate normla\n    vec3 normal = getNormal(height_pos);\n    float grass_ratio = smoothstep(0.7, 0.98, normal.y);\n    vec3 ground_color = mix(dirt_color, grass_color, grass_ratio);\n}\n\n```\n\n上面是一段实例代码，我们预先设定山体和绿植的颜色，在光线步进山体的时候，获取normal，根据法线的y方向的大小（也可以用dot来判定）做smoothstep取一个合适的值作为当前平面草地的比例，最后混合山体和草地的比例。得到的结果如下：\n\n![增加绿植](terrain_with_grass.png)\n这样一来场景的丰富程度一下子就提升了。\n\n# 天空\n现在最终结果还是挺奇怪的，很大一部分的原因是场景的背景还是黑咕隆咚的。我们的大场景急需增加天空的部分。\n\n## 天空的颜色\n天空的颜色我之前有写过一个[教程](https://ruochenhua.github.io/2024/10/15/single-scatter-atmosphere/)，是利用单次散射的方法来计算天空大气的颜色。当然这个方法在这依然是可用的。\n\n不过如果你说，我不想用那么复杂的方法，只想快速出效果呢？那也是很简单，给地形光线步近没有结果的像素设定为蓝色就行了，哈哈。\n\n如果想再复杂一点，可以做一个小细节的优化。也就是在晴朗的情况下，一般靠近地平线的天的蓝色是更加浅的，所以在给天空像素上色的时候，可以根据当前像素的方向的y值作为判定，在深蓝色和浅蓝色做线性插值。\n\n```glsl\nvec3 low_sky_blue = vec3(0.5137, 0.7804, 0.9608);\nvec3 high_sky_blue = vec3(0.3216, 0.4706, 0.9725);\n\nvec3 sky_color = mix(low_sky_blue, high_sky_blue, clamp(rd.y, 0.0, 1.0));\n```\n\n![增加天空](terrain_with_sky.png)\n\n## 雾气增强层次感\n在增加了天空之后，我们的渲染结果有了很显著的提升，终于像室外的场景了。\n\n不过仔细看后，还是觉得怪怪的，远处的山和天空根本不在一个图层上；山的远近层次感也不足，远处的山太清晰了。\n\n这是因为缺少雾气的结果，雾气能够很好的增加大场景体量感，能够很好的处理场景和天空衔接的感觉。\n\n增加雾气也十分简单，仅需根据地形光线步近的结果的大小（也就是地形离相机的距离）来计算一个比例，根据这个比例来做场景颜色和雾气颜色的插值即可。\n\n```glsl\n// cal fog density, different between r,g,b so the fog has a blue hue\nvec3 calcFog(float dist)\n{    \n    return exp(-5e-3*dist*vec3(1,2,4));\n}\n\n// ...\nvec3 fog_amount = calcFog(res_t);\ncolor = mix(vec3(0.7),color, fog_amount);\n```\n上面这段便是雾气的计算过程。雾气的比例通过**exp(-5e-3*dist*vec3(1,2,4))**计算，得到的雾的比例用于最终颜色的线性插值。\n\n![增加雾气](terrain_with_sky_fog.png)\n有了雾气的加持，我们场景的大体量感就有了，层次感也明显了很多。\n关于雾气的更多内容，可以参考Inigo大神的[这篇文章](https://iquilezles.org/articles/fog/)。\n\n## 漫反射光照细节\n接下来我想优化一下场景整体的漫反射细节。\n\n当前的渲染结果其实是有加一个默认的环境光**vec3(0.1)**的，主要是之前的场景太黑了。这是个临时的处理，把这个环境光去掉。\n![去掉写死的环境光补偿](terrain_with_sky_fog_less_ambient.png)\n\n好了，我们再来看一下我们的场景。有没有感觉山体的阴影部分有点太黑了？是的，在现实世界中，处于阴影的场景，在大白天也会被场景的漫反射光给提亮的，这种一片漆黑的感觉是有些难看。所以接下来我们来增加一些场景中应该有的漫反射光。\n\n首先山体之间是会有漫反射光的影响的，也就是阴影部分的山体会被不在阴影的其他山的漫反射光照亮。当然这种影响我们是无法实时计算的，要计算的东西实在是太多了。但是可以通过一个很简单的方式来提单：我们计算当前点的发现和指向光源方向的点乘，当这个结果大于0的时候，用这个乘积乘以一个小的光照并加到原本的颜色上。\n\n```glsl\ncolor += (max(0.0, dot(-light_dir, normal))*ground_color/10.0);\n```\n\n![增加地形的漫反射光](terrain_with_sky_fog_diffuse_from_mountain.png)\n\n加完地形的漫反射光后，天空其实也有各个方向的漫反射的光会影响地形的亮度。天空的漫反射光可以通过地形法线的y分量和天空颜色的一部分来计算，示例代码如下：\n```glsl\ncolor += (normal.y + 1.0)/2.0*low_sky_blue/10.0;\n```\n\n![增加天空的漫反射光](terrain_with_sky_fog_diffuse_from_sky.png)\n\n增加了这些漫反射细节，场景的真实度进一步得到了提升。\n\n# 云朵\n有了天空，再给天空上增加云的话会进一步增加场景的丰富度，下面就来介绍我给这个场景添加的两部分云的计算。\n\n## 高层云\n我给这个场景添加了两种云，高层云是我想模拟在高度很高的地方，云层看起来不厚并且相对静态的感觉。\n\n高层云的纹理也是利用perlin noise来计算，由于高层的云没有厚实感其实用2D的perlin noise也足够了。\n\n另外需要注意的是，云的纹理需要根据远近来做处理。远处的云的纹理如果太清晰的话在最终效果上会显得太过于密集。下面是高层云的示例代码：\n```glsl\n// 高层云的高度\nfloat top_sky_plane = 3000.;\n\nvec3 getSkyColor(vec3 ro, vec3 rd)\n{    \n    vec3 hit_sky;\n    hit_sky.y = top_sky_plane;\n        \n    hit_sky.xz = ro.xz + rd.xz * (top_sky_plane - ro.y)/rd.y;    \n    \n    //降低远处云的密度，看起来效果更好\n    float hit_dist = distance(hit_sky, ro);\n    float cloud_density_percentage = 1.0;\n    if(hit_dist > cloud_view_distance)\n    {\n        cloud_density_percentage *= exp(-(hit_dist - cloud_view_distance)/ cloud_view_distance);\n    }    \n\n    // 根据云层采样点的远近处理云层的密度\n    float cloud_density = smoothstep(getCloudDensity(hit_sky.xz/150.0, 3), -0.99, 1.9)*cloud_density_percentage * 0.5;\n    float res_t;\n\n    // sky color    \n    vec3 sky_color = mix(low_sky_blue, high_sky_blue, clamp(rd.y, 0.0, 1.0));\n    vec3 cloud_color = vec3(1.);\n    // 根据云层密度得到最终的高层云和天空颜色\n    return mix(sky_color, cloud_color, cloud_density);\n}\n```\n\n![增加天空高层云](terrain_with_high_cloud.png)\n\n增加了高层云之后，天空就显得不那么单调了。\n\n## 体积云\n最后就是体积云了，体积云的部分我不会在这里详细讨论，这是一个可以讨论的比较深的话题。我这个场景的体积云效果也并不是很理想，这里仅作为一个最后的点缀，在山峰上增加一点点动态效果。\n\n体积云的效果其实也是在一定区域内进行多个点的采样而来，这个区域内利用FBM来实现云的动态的随机效果。在这个场景内我使用了SDF来圈定体积云的范围，并且给SDF增加了随机现状来获取更好的随机效果。\n\n```glsl\nfloat scene(in vec3 pos)\n{    \n    vec3 cloud_pos = vec3(0.0, 5.0, 15.0);\n    \n    vec3 filter_pos = vec3(pos.x, pos.y+iTime, pos.z+iTime);\n    pos -= cloud_pos;\n    float rst = -(rm_box(pos)) + fbm_cloud(pos * 0.1+iTime*0.3, 5);\n    rst = rst / 25.0 * max(fbm_cloud(filter_pos*0.1, 1) - 1.2, 0.0); \n    return rst;\n}\n\nfloat max_cloud_dist = 80.;\nvec4 renderMidClouds(vec3 ro, vec3 rd)\n{    \n    vec4 res = vec4(0.0);\n    float depth = 0.0;    \n    \n    int sample_count = 64;\n    float dt = max_cloud_dist / float(sample_count);\n    \n    for(int i = 0; i < sample_count; ++i)\n    {\n        vec3 p = ro + depth*rd;\n        float density = scene(p);\n        if(density > 0.0)\n        {\n            float diffuse = clamp((scene(p) - scene(p + 0.3*light_dir))/0.3, 0.0, 1.0);\n            vec3 lin = vec3(0.8, 0.8, 0.8) * 1.1 + 0.8 * vec3(0.9333, 0.702, 0.5255)*diffuse;\n            vec4 color = vec4(mix(vec3(1.0), vec3(0.0), density), density);\n            color.rgb *= color.a;\n\n            res += color * (1.0 - res.a);\n        }\n\n        depth+=dt;\n    }\n\n    return res;\n}\n```\n\n![增加体积云](terrain_with_all_cloud.png)\n\n\n# 最终效果\n\n<iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n以上便是我如何实现这个场景的简单介绍了。这是我初次尝试在ShaderToy上渲染大场景，也是第一次将整个步骤拆解讲解，可能还是会有不少地方讲的不过仔细和通透，也有些遗漏。\n\n后面我还是会继续尝试创作和讲解，希望能给人带来帮助，也有助于巩固我所学的知识。","slug":"ProceduralTerrainGeneration2","published":1,"updated":"2024-11-05T15:29:34.319Z","_id":"cm34lv4qh000fy057gau26780","comments":1,"layout":"post","photos":[],"content":"<p>距离上一篇将程序化地形生成的<a href=\"https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/\">教程</a>也已经过去了一段时间了。前段时间一直有其他事情需要忙，现在终于有时间继续之前未完成的工作了。</p>\n<h1 id=\"丰富地形\"><a href=\"#丰富地形\" class=\"headerlink\" title=\"丰富地形\"></a>丰富地形</h1><p>上一篇教程我们已经创建出了绵延的山脉，如下图所示：<br><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_no_grass.png\" alt=\"上次渲染的结果\"><br>看起来似乎是有那么点意思了，但是这样的山脉效果还是太单调了。</p>\n<p>接下来我们就计划丰富一下这个场景。</p>\n<h2 id=\"增加绿植\"><a href=\"#增加绿植\" class=\"headerlink\" title=\"增加绿植\"></a>增加绿植</h2><p>我们场景中的山光秃秃的，很像是沙漠，也很像火星上的地貌。</p>\n<p>我想给场景增加一些层次，一些生机，因此我打算将山的一部分渲染为绿植部分。</p>\n<p>那么如何确定哪些部分是绿植，哪些部分是裸露的山体呢？根据地形表面的法线可以做一个简单的判定：法线的y分量越大，也就是面向上的分量越大，表明这个面更平，因此有绿植是更合适的；反正则表明这个面更加陡峭，更适合作为山体表现。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">vec3</span> dirt_color = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.8549</span>, <span class=\"hljs-number\">0.5255</span>, <span class=\"hljs-number\">0.3098</span>);<br><span class=\"hljs-type\">vec3</span> grass_color = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.3137</span>, <span class=\"hljs-number\">0.5412</span>, <span class=\"hljs-number\">0.0157</span>);<br><span class=\"hljs-comment\">// ..</span><br><br><span class=\"hljs-keyword\">if</span>(rd.y &lt; <span class=\"hljs-number\">0.05</span> &amp;&amp; rayMarchingTerrain(ro, rd, maxt, res_t))<br>&#123;<br>    <span class=\"hljs-type\">vec3</span> height_pos = ro+res_t*rd;<br><br>    <span class=\"hljs-comment\">// calculate normla</span><br>    <span class=\"hljs-type\">vec3</span> normal = getNormal(height_pos);<br>    <span class=\"hljs-type\">float</span> grass_ratio = <span class=\"hljs-built_in\">smoothstep</span>(<span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.98</span>, normal.y);<br>    <span class=\"hljs-type\">vec3</span> ground_color = <span class=\"hljs-built_in\">mix</span>(dirt_color, grass_color, grass_ratio);<br>&#125;<br><br></code></pre></td></tr></table></figure>\n\n<p>上面是一段实例代码，我们预先设定山体和绿植的颜色，在光线步进山体的时候，获取normal，根据法线的y方向的大小（也可以用dot来判定）做smoothstep取一个合适的值作为当前平面草地的比例，最后混合山体和草地的比例。得到的结果如下：</p>\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_grass.png\" alt=\"增加绿植\"><br>这样一来场景的丰富程度一下子就提升了。</p>\n<h1 id=\"天空\"><a href=\"#天空\" class=\"headerlink\" title=\"天空\"></a>天空</h1><p>现在最终结果还是挺奇怪的，很大一部分的原因是场景的背景还是黑咕隆咚的。我们的大场景急需增加天空的部分。</p>\n<h2 id=\"天空的颜色\"><a href=\"#天空的颜色\" class=\"headerlink\" title=\"天空的颜色\"></a>天空的颜色</h2><p>天空的颜色我之前有写过一个<a href=\"https://ruochenhua.github.io/2024/10/15/single-scatter-atmosphere/\">教程</a>，是利用单次散射的方法来计算天空大气的颜色。当然这个方法在这依然是可用的。</p>\n<p>不过如果你说，我不想用那么复杂的方法，只想快速出效果呢？那也是很简单，给地形光线步近没有结果的像素设定为蓝色就行了，哈哈。</p>\n<p>如果想再复杂一点，可以做一个小细节的优化。也就是在晴朗的情况下，一般靠近地平线的天的蓝色是更加浅的，所以在给天空像素上色的时候，可以根据当前像素的方向的y值作为判定，在深蓝色和浅蓝色做线性插值。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">vec3</span> low_sky_blue = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.5137</span>, <span class=\"hljs-number\">0.7804</span>, <span class=\"hljs-number\">0.9608</span>);<br><span class=\"hljs-type\">vec3</span> high_sky_blue = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.3216</span>, <span class=\"hljs-number\">0.4706</span>, <span class=\"hljs-number\">0.9725</span>);<br><br><span class=\"hljs-type\">vec3</span> sky_color = <span class=\"hljs-built_in\">mix</span>(low_sky_blue, high_sky_blue, <span class=\"hljs-built_in\">clamp</span>(rd.y, <span class=\"hljs-number\">0.0</span>, <span class=\"hljs-number\">1.0</span>));<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky.png\" alt=\"增加天空\"></p>\n<h2 id=\"雾气增强层次感\"><a href=\"#雾气增强层次感\" class=\"headerlink\" title=\"雾气增强层次感\"></a>雾气增强层次感</h2><p>在增加了天空之后，我们的渲染结果有了很显著的提升，终于像室外的场景了。</p>\n<p>不过仔细看后，还是觉得怪怪的，远处的山和天空根本不在一个图层上；山的远近层次感也不足，远处的山太清晰了。</p>\n<p>这是因为缺少雾气的结果，雾气能够很好的增加大场景体量感，能够很好的处理场景和天空衔接的感觉。</p>\n<p>增加雾气也十分简单，仅需根据地形光线步近的结果的大小（也就是地形离相机的距离）来计算一个比例，根据这个比例来做场景颜色和雾气颜色的插值即可。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// cal fog density, different between r,g,b so the fog has a blue hue</span><br><span class=\"hljs-type\">vec3</span> calcFog(<span class=\"hljs-type\">float</span> dist)<br>&#123;    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">exp</span>(<span class=\"hljs-number\">-5e-3</span>*dist*<span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">4</span>));<br>&#125;<br><br><span class=\"hljs-comment\">// ...</span><br><span class=\"hljs-type\">vec3</span> fog_amount = calcFog(res_t);<br>color = <span class=\"hljs-built_in\">mix</span>(<span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.7</span>),color, fog_amount);<br></code></pre></td></tr></table></figure>\n<p>上面这段便是雾气的计算过程。雾气的比例通过*<em>exp(-5e-3</em>dist*vec3(1,2,4))**计算，得到的雾的比例用于最终颜色的线性插值。</p>\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog.png\" alt=\"增加雾气\"><br>有了雾气的加持，我们场景的大体量感就有了，层次感也明显了很多。<br>关于雾气的更多内容，可以参考Inigo大神的<a href=\"https://iquilezles.org/articles/fog/\">这篇文章</a>。</p>\n<h2 id=\"漫反射光照细节\"><a href=\"#漫反射光照细节\" class=\"headerlink\" title=\"漫反射光照细节\"></a>漫反射光照细节</h2><p>接下来我想优化一下场景整体的漫反射细节。</p>\n<p>当前的渲染结果其实是有加一个默认的环境光**vec3(0.1)**的，主要是之前的场景太黑了。这是个临时的处理，把这个环境光去掉。<br><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_less_ambient.png\" alt=\"去掉写死的环境光补偿\"></p>\n<p>好了，我们再来看一下我们的场景。有没有感觉山体的阴影部分有点太黑了？是的，在现实世界中，处于阴影的场景，在大白天也会被场景的漫反射光给提亮的，这种一片漆黑的感觉是有些难看。所以接下来我们来增加一些场景中应该有的漫反射光。</p>\n<p>首先山体之间是会有漫反射光的影响的，也就是阴影部分的山体会被不在阴影的其他山的漫反射光照亮。当然这种影响我们是无法实时计算的，要计算的东西实在是太多了。但是可以通过一个很简单的方式来提单：我们计算当前点的发现和指向光源方向的点乘，当这个结果大于0的时候，用这个乘积乘以一个小的光照并加到原本的颜色上。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\">color += (<span class=\"hljs-built_in\">max</span>(<span class=\"hljs-number\">0.0</span>, <span class=\"hljs-built_in\">dot</span>(-light_dir, normal))*ground_color/<span class=\"hljs-number\">10.0</span>);<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_mountain.png\" alt=\"增加地形的漫反射光\"></p>\n<p>加完地形的漫反射光后，天空其实也有各个方向的漫反射的光会影响地形的亮度。天空的漫反射光可以通过地形法线的y分量和天空颜色的一部分来计算，示例代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\">color += (normal.y + <span class=\"hljs-number\">1.0</span>)/<span class=\"hljs-number\">2.0</span>*low_sky_blue/<span class=\"hljs-number\">10.0</span>;<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_sky.png\" alt=\"增加天空的漫反射光\"></p>\n<p>增加了这些漫反射细节，场景的真实度进一步得到了提升。</p>\n<h1 id=\"云朵\"><a href=\"#云朵\" class=\"headerlink\" title=\"云朵\"></a>云朵</h1><p>有了天空，再给天空上增加云的话会进一步增加场景的丰富度，下面就来介绍我给这个场景添加的两部分云的计算。</p>\n<h2 id=\"高层云\"><a href=\"#高层云\" class=\"headerlink\" title=\"高层云\"></a>高层云</h2><p>我给这个场景添加了两种云，高层云是我想模拟在高度很高的地方，云层看起来不厚并且相对静态的感觉。</p>\n<p>高层云的纹理也是利用perlin noise来计算，由于高层的云没有厚实感其实用2D的perlin noise也足够了。</p>\n<p>另外需要注意的是，云的纹理需要根据远近来做处理。远处的云的纹理如果太清晰的话在最终效果上会显得太过于密集。下面是高层云的示例代码：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 高层云的高度</span><br><span class=\"hljs-type\">float</span> top_sky_plane = <span class=\"hljs-number\">3000.</span>;<br><br><span class=\"hljs-type\">vec3</span> getSkyColor(<span class=\"hljs-type\">vec3</span> ro, <span class=\"hljs-type\">vec3</span> rd)<br>&#123;    <br>    <span class=\"hljs-type\">vec3</span> hit_sky;<br>    hit_sky.y = top_sky_plane;<br>        <br>    hit_sky.xz = ro.xz + rd.xz * (top_sky_plane - ro.y)/rd.y;    <br>    <br>    <span class=\"hljs-comment\">//降低远处云的密度，看起来效果更好</span><br>    <span class=\"hljs-type\">float</span> hit_dist = <span class=\"hljs-built_in\">distance</span>(hit_sky, ro);<br>    <span class=\"hljs-type\">float</span> cloud_density_percentage = <span class=\"hljs-number\">1.0</span>;<br>    <span class=\"hljs-keyword\">if</span>(hit_dist &gt; cloud_view_distance)<br>    &#123;<br>        cloud_density_percentage *= <span class=\"hljs-built_in\">exp</span>(-(hit_dist - cloud_view_distance)/ cloud_view_distance);<br>    &#125;    <br><br>    <span class=\"hljs-comment\">// 根据云层采样点的远近处理云层的密度</span><br>    <span class=\"hljs-type\">float</span> cloud_density = <span class=\"hljs-built_in\">smoothstep</span>(getCloudDensity(hit_sky.xz/<span class=\"hljs-number\">150.0</span>, <span class=\"hljs-number\">3</span>), <span class=\"hljs-number\">-0.99</span>, <span class=\"hljs-number\">1.9</span>)*cloud_density_percentage * <span class=\"hljs-number\">0.5</span>;<br>    <span class=\"hljs-type\">float</span> res_t;<br><br>    <span class=\"hljs-comment\">// sky color    </span><br>    <span class=\"hljs-type\">vec3</span> sky_color = <span class=\"hljs-built_in\">mix</span>(low_sky_blue, high_sky_blue, <span class=\"hljs-built_in\">clamp</span>(rd.y, <span class=\"hljs-number\">0.0</span>, <span class=\"hljs-number\">1.0</span>));<br>    <span class=\"hljs-type\">vec3</span> cloud_color = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">1.</span>);<br>    <span class=\"hljs-comment\">// 根据云层密度得到最终的高层云和天空颜色</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">mix</span>(sky_color, cloud_color, cloud_density);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_high_cloud.png\" alt=\"增加天空高层云\"></p>\n<p>增加了高层云之后，天空就显得不那么单调了。</p>\n<h2 id=\"体积云\"><a href=\"#体积云\" class=\"headerlink\" title=\"体积云\"></a>体积云</h2><p>最后就是体积云了，体积云的部分我不会在这里详细讨论，这是一个可以讨论的比较深的话题。我这个场景的体积云效果也并不是很理想，这里仅作为一个最后的点缀，在山峰上增加一点点动态效果。</p>\n<p>体积云的效果其实也是在一定区域内进行多个点的采样而来，这个区域内利用FBM来实现云的动态的随机效果。在这个场景内我使用了SDF来圈定体积云的范围，并且给SDF增加了随机现状来获取更好的随机效果。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">float</span> scene(<span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec3</span> pos)<br>&#123;    <br>    <span class=\"hljs-type\">vec3</span> cloud_pos = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.0</span>, <span class=\"hljs-number\">5.0</span>, <span class=\"hljs-number\">15.0</span>);<br>    <br>    <span class=\"hljs-type\">vec3</span> filter_pos = <span class=\"hljs-type\">vec3</span>(pos.x, pos.y+iTime, pos.z+iTime);<br>    pos -= cloud_pos;<br>    <span class=\"hljs-type\">float</span> rst = -(rm_box(pos)) + fbm_cloud(pos * <span class=\"hljs-number\">0.1</span>+iTime*<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">5</span>);<br>    rst = rst / <span class=\"hljs-number\">25.0</span> * <span class=\"hljs-built_in\">max</span>(fbm_cloud(filter_pos*<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">1</span>) - <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">0.0</span>); <br>    <span class=\"hljs-keyword\">return</span> rst;<br>&#125;<br><br><span class=\"hljs-type\">float</span> max_cloud_dist = <span class=\"hljs-number\">80.</span>;<br><span class=\"hljs-type\">vec4</span> renderMidClouds(<span class=\"hljs-type\">vec3</span> ro, <span class=\"hljs-type\">vec3</span> rd)<br>&#123;    <br>    <span class=\"hljs-type\">vec4</span> res = <span class=\"hljs-type\">vec4</span>(<span class=\"hljs-number\">0.0</span>);<br>    <span class=\"hljs-type\">float</span> depth = <span class=\"hljs-number\">0.0</span>;    <br>    <br>    <span class=\"hljs-type\">int</span> sample_count = <span class=\"hljs-number\">64</span>;<br>    <span class=\"hljs-type\">float</span> dt = max_cloud_dist / <span class=\"hljs-type\">float</span>(sample_count);<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; sample_count; ++i)<br>    &#123;<br>        <span class=\"hljs-type\">vec3</span> p = ro + depth*rd;<br>        <span class=\"hljs-type\">float</span> density = scene(p);<br>        <span class=\"hljs-keyword\">if</span>(density &gt; <span class=\"hljs-number\">0.0</span>)<br>        &#123;<br>            <span class=\"hljs-type\">float</span> diffuse = <span class=\"hljs-built_in\">clamp</span>((scene(p) - scene(p + <span class=\"hljs-number\">0.3</span>*light_dir))/<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.0</span>, <span class=\"hljs-number\">1.0</span>);<br>            <span class=\"hljs-type\">vec3</span> lin = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.8</span>) * <span class=\"hljs-number\">1.1</span> + <span class=\"hljs-number\">0.8</span> * <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.9333</span>, <span class=\"hljs-number\">0.702</span>, <span class=\"hljs-number\">0.5255</span>)*diffuse;<br>            <span class=\"hljs-type\">vec4</span> color = <span class=\"hljs-type\">vec4</span>(<span class=\"hljs-built_in\">mix</span>(<span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">1.0</span>), <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.0</span>), density), density);<br>            color.rgb *= color.a;<br><br>            res += color * (<span class=\"hljs-number\">1.0</span> - res.a);<br>        &#125;<br><br>        depth+=dt;<br>    &#125;<br><br>    <span class=\"hljs-keyword\">return</span> res;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_all_cloud.png\" alt=\"增加体积云\"></p>\n<h1 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果\"></a>最终效果</h1><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>以上便是我如何实现这个场景的简单介绍了。这是我初次尝试在ShaderToy上渲染大场景，也是第一次将整个步骤拆解讲解，可能还是会有不少地方讲的不过仔细和通透，也有些遗漏。</p>\n<p>后面我还是会继续尝试创作和讲解，希望能给人带来帮助，也有助于巩固我所学的知识。</p>\n","excerpt":"","more":"<p>距离上一篇将程序化地形生成的<a href=\"https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/\">教程</a>也已经过去了一段时间了。前段时间一直有其他事情需要忙，现在终于有时间继续之前未完成的工作了。</p>\n<h1 id=\"丰富地形\"><a href=\"#丰富地形\" class=\"headerlink\" title=\"丰富地形\"></a>丰富地形</h1><p>上一篇教程我们已经创建出了绵延的山脉，如下图所示：<br><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_no_grass.png\" alt=\"上次渲染的结果\"><br>看起来似乎是有那么点意思了，但是这样的山脉效果还是太单调了。</p>\n<p>接下来我们就计划丰富一下这个场景。</p>\n<h2 id=\"增加绿植\"><a href=\"#增加绿植\" class=\"headerlink\" title=\"增加绿植\"></a>增加绿植</h2><p>我们场景中的山光秃秃的，很像是沙漠，也很像火星上的地貌。</p>\n<p>我想给场景增加一些层次，一些生机，因此我打算将山的一部分渲染为绿植部分。</p>\n<p>那么如何确定哪些部分是绿植，哪些部分是裸露的山体呢？根据地形表面的法线可以做一个简单的判定：法线的y分量越大，也就是面向上的分量越大，表明这个面更平，因此有绿植是更合适的；反正则表明这个面更加陡峭，更适合作为山体表现。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">vec3</span> dirt_color = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.8549</span>, <span class=\"hljs-number\">0.5255</span>, <span class=\"hljs-number\">0.3098</span>);<br><span class=\"hljs-type\">vec3</span> grass_color = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.3137</span>, <span class=\"hljs-number\">0.5412</span>, <span class=\"hljs-number\">0.0157</span>);<br><span class=\"hljs-comment\">// ..</span><br><br><span class=\"hljs-keyword\">if</span>(rd.y &lt; <span class=\"hljs-number\">0.05</span> &amp;&amp; rayMarchingTerrain(ro, rd, maxt, res_t))<br>&#123;<br>    <span class=\"hljs-type\">vec3</span> height_pos = ro+res_t*rd;<br><br>    <span class=\"hljs-comment\">// calculate normla</span><br>    <span class=\"hljs-type\">vec3</span> normal = getNormal(height_pos);<br>    <span class=\"hljs-type\">float</span> grass_ratio = <span class=\"hljs-built_in\">smoothstep</span>(<span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.98</span>, normal.y);<br>    <span class=\"hljs-type\">vec3</span> ground_color = <span class=\"hljs-built_in\">mix</span>(dirt_color, grass_color, grass_ratio);<br>&#125;<br><br></code></pre></td></tr></table></figure>\n\n<p>上面是一段实例代码，我们预先设定山体和绿植的颜色，在光线步进山体的时候，获取normal，根据法线的y方向的大小（也可以用dot来判定）做smoothstep取一个合适的值作为当前平面草地的比例，最后混合山体和草地的比例。得到的结果如下：</p>\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_grass.png\" alt=\"增加绿植\"><br>这样一来场景的丰富程度一下子就提升了。</p>\n<h1 id=\"天空\"><a href=\"#天空\" class=\"headerlink\" title=\"天空\"></a>天空</h1><p>现在最终结果还是挺奇怪的，很大一部分的原因是场景的背景还是黑咕隆咚的。我们的大场景急需增加天空的部分。</p>\n<h2 id=\"天空的颜色\"><a href=\"#天空的颜色\" class=\"headerlink\" title=\"天空的颜色\"></a>天空的颜色</h2><p>天空的颜色我之前有写过一个<a href=\"https://ruochenhua.github.io/2024/10/15/single-scatter-atmosphere/\">教程</a>，是利用单次散射的方法来计算天空大气的颜色。当然这个方法在这依然是可用的。</p>\n<p>不过如果你说，我不想用那么复杂的方法，只想快速出效果呢？那也是很简单，给地形光线步近没有结果的像素设定为蓝色就行了，哈哈。</p>\n<p>如果想再复杂一点，可以做一个小细节的优化。也就是在晴朗的情况下，一般靠近地平线的天的蓝色是更加浅的，所以在给天空像素上色的时候，可以根据当前像素的方向的y值作为判定，在深蓝色和浅蓝色做线性插值。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">vec3</span> low_sky_blue = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.5137</span>, <span class=\"hljs-number\">0.7804</span>, <span class=\"hljs-number\">0.9608</span>);<br><span class=\"hljs-type\">vec3</span> high_sky_blue = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.3216</span>, <span class=\"hljs-number\">0.4706</span>, <span class=\"hljs-number\">0.9725</span>);<br><br><span class=\"hljs-type\">vec3</span> sky_color = <span class=\"hljs-built_in\">mix</span>(low_sky_blue, high_sky_blue, <span class=\"hljs-built_in\">clamp</span>(rd.y, <span class=\"hljs-number\">0.0</span>, <span class=\"hljs-number\">1.0</span>));<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky.png\" alt=\"增加天空\"></p>\n<h2 id=\"雾气增强层次感\"><a href=\"#雾气增强层次感\" class=\"headerlink\" title=\"雾气增强层次感\"></a>雾气增强层次感</h2><p>在增加了天空之后，我们的渲染结果有了很显著的提升，终于像室外的场景了。</p>\n<p>不过仔细看后，还是觉得怪怪的，远处的山和天空根本不在一个图层上；山的远近层次感也不足，远处的山太清晰了。</p>\n<p>这是因为缺少雾气的结果，雾气能够很好的增加大场景体量感，能够很好的处理场景和天空衔接的感觉。</p>\n<p>增加雾气也十分简单，仅需根据地形光线步近的结果的大小（也就是地形离相机的距离）来计算一个比例，根据这个比例来做场景颜色和雾气颜色的插值即可。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// cal fog density, different between r,g,b so the fog has a blue hue</span><br><span class=\"hljs-type\">vec3</span> calcFog(<span class=\"hljs-type\">float</span> dist)<br>&#123;    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">exp</span>(<span class=\"hljs-number\">-5e-3</span>*dist*<span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">4</span>));<br>&#125;<br><br><span class=\"hljs-comment\">// ...</span><br><span class=\"hljs-type\">vec3</span> fog_amount = calcFog(res_t);<br>color = <span class=\"hljs-built_in\">mix</span>(<span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.7</span>),color, fog_amount);<br></code></pre></td></tr></table></figure>\n<p>上面这段便是雾气的计算过程。雾气的比例通过*<em>exp(-5e-3</em>dist*vec3(1,2,4))**计算，得到的雾的比例用于最终颜色的线性插值。</p>\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog.png\" alt=\"增加雾气\"><br>有了雾气的加持，我们场景的大体量感就有了，层次感也明显了很多。<br>关于雾气的更多内容，可以参考Inigo大神的<a href=\"https://iquilezles.org/articles/fog/\">这篇文章</a>。</p>\n<h2 id=\"漫反射光照细节\"><a href=\"#漫反射光照细节\" class=\"headerlink\" title=\"漫反射光照细节\"></a>漫反射光照细节</h2><p>接下来我想优化一下场景整体的漫反射细节。</p>\n<p>当前的渲染结果其实是有加一个默认的环境光**vec3(0.1)**的，主要是之前的场景太黑了。这是个临时的处理，把这个环境光去掉。<br><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_less_ambient.png\" alt=\"去掉写死的环境光补偿\"></p>\n<p>好了，我们再来看一下我们的场景。有没有感觉山体的阴影部分有点太黑了？是的，在现实世界中，处于阴影的场景，在大白天也会被场景的漫反射光给提亮的，这种一片漆黑的感觉是有些难看。所以接下来我们来增加一些场景中应该有的漫反射光。</p>\n<p>首先山体之间是会有漫反射光的影响的，也就是阴影部分的山体会被不在阴影的其他山的漫反射光照亮。当然这种影响我们是无法实时计算的，要计算的东西实在是太多了。但是可以通过一个很简单的方式来提单：我们计算当前点的发现和指向光源方向的点乘，当这个结果大于0的时候，用这个乘积乘以一个小的光照并加到原本的颜色上。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\">color += (<span class=\"hljs-built_in\">max</span>(<span class=\"hljs-number\">0.0</span>, <span class=\"hljs-built_in\">dot</span>(-light_dir, normal))*ground_color/<span class=\"hljs-number\">10.0</span>);<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_mountain.png\" alt=\"增加地形的漫反射光\"></p>\n<p>加完地形的漫反射光后，天空其实也有各个方向的漫反射的光会影响地形的亮度。天空的漫反射光可以通过地形法线的y分量和天空颜色的一部分来计算，示例代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\">color += (normal.y + <span class=\"hljs-number\">1.0</span>)/<span class=\"hljs-number\">2.0</span>*low_sky_blue/<span class=\"hljs-number\">10.0</span>;<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_sky.png\" alt=\"增加天空的漫反射光\"></p>\n<p>增加了这些漫反射细节，场景的真实度进一步得到了提升。</p>\n<h1 id=\"云朵\"><a href=\"#云朵\" class=\"headerlink\" title=\"云朵\"></a>云朵</h1><p>有了天空，再给天空上增加云的话会进一步增加场景的丰富度，下面就来介绍我给这个场景添加的两部分云的计算。</p>\n<h2 id=\"高层云\"><a href=\"#高层云\" class=\"headerlink\" title=\"高层云\"></a>高层云</h2><p>我给这个场景添加了两种云，高层云是我想模拟在高度很高的地方，云层看起来不厚并且相对静态的感觉。</p>\n<p>高层云的纹理也是利用perlin noise来计算，由于高层的云没有厚实感其实用2D的perlin noise也足够了。</p>\n<p>另外需要注意的是，云的纹理需要根据远近来做处理。远处的云的纹理如果太清晰的话在最终效果上会显得太过于密集。下面是高层云的示例代码：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 高层云的高度</span><br><span class=\"hljs-type\">float</span> top_sky_plane = <span class=\"hljs-number\">3000.</span>;<br><br><span class=\"hljs-type\">vec3</span> getSkyColor(<span class=\"hljs-type\">vec3</span> ro, <span class=\"hljs-type\">vec3</span> rd)<br>&#123;    <br>    <span class=\"hljs-type\">vec3</span> hit_sky;<br>    hit_sky.y = top_sky_plane;<br>        <br>    hit_sky.xz = ro.xz + rd.xz * (top_sky_plane - ro.y)/rd.y;    <br>    <br>    <span class=\"hljs-comment\">//降低远处云的密度，看起来效果更好</span><br>    <span class=\"hljs-type\">float</span> hit_dist = <span class=\"hljs-built_in\">distance</span>(hit_sky, ro);<br>    <span class=\"hljs-type\">float</span> cloud_density_percentage = <span class=\"hljs-number\">1.0</span>;<br>    <span class=\"hljs-keyword\">if</span>(hit_dist &gt; cloud_view_distance)<br>    &#123;<br>        cloud_density_percentage *= <span class=\"hljs-built_in\">exp</span>(-(hit_dist - cloud_view_distance)/ cloud_view_distance);<br>    &#125;    <br><br>    <span class=\"hljs-comment\">// 根据云层采样点的远近处理云层的密度</span><br>    <span class=\"hljs-type\">float</span> cloud_density = <span class=\"hljs-built_in\">smoothstep</span>(getCloudDensity(hit_sky.xz/<span class=\"hljs-number\">150.0</span>, <span class=\"hljs-number\">3</span>), <span class=\"hljs-number\">-0.99</span>, <span class=\"hljs-number\">1.9</span>)*cloud_density_percentage * <span class=\"hljs-number\">0.5</span>;<br>    <span class=\"hljs-type\">float</span> res_t;<br><br>    <span class=\"hljs-comment\">// sky color    </span><br>    <span class=\"hljs-type\">vec3</span> sky_color = <span class=\"hljs-built_in\">mix</span>(low_sky_blue, high_sky_blue, <span class=\"hljs-built_in\">clamp</span>(rd.y, <span class=\"hljs-number\">0.0</span>, <span class=\"hljs-number\">1.0</span>));<br>    <span class=\"hljs-type\">vec3</span> cloud_color = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">1.</span>);<br>    <span class=\"hljs-comment\">// 根据云层密度得到最终的高层云和天空颜色</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">mix</span>(sky_color, cloud_color, cloud_density);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_high_cloud.png\" alt=\"增加天空高层云\"></p>\n<p>增加了高层云之后，天空就显得不那么单调了。</p>\n<h2 id=\"体积云\"><a href=\"#体积云\" class=\"headerlink\" title=\"体积云\"></a>体积云</h2><p>最后就是体积云了，体积云的部分我不会在这里详细讨论，这是一个可以讨论的比较深的话题。我这个场景的体积云效果也并不是很理想，这里仅作为一个最后的点缀，在山峰上增加一点点动态效果。</p>\n<p>体积云的效果其实也是在一定区域内进行多个点的采样而来，这个区域内利用FBM来实现云的动态的随机效果。在这个场景内我使用了SDF来圈定体积云的范围，并且给SDF增加了随机现状来获取更好的随机效果。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">float</span> scene(<span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec3</span> pos)<br>&#123;    <br>    <span class=\"hljs-type\">vec3</span> cloud_pos = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.0</span>, <span class=\"hljs-number\">5.0</span>, <span class=\"hljs-number\">15.0</span>);<br>    <br>    <span class=\"hljs-type\">vec3</span> filter_pos = <span class=\"hljs-type\">vec3</span>(pos.x, pos.y+iTime, pos.z+iTime);<br>    pos -= cloud_pos;<br>    <span class=\"hljs-type\">float</span> rst = -(rm_box(pos)) + fbm_cloud(pos * <span class=\"hljs-number\">0.1</span>+iTime*<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">5</span>);<br>    rst = rst / <span class=\"hljs-number\">25.0</span> * <span class=\"hljs-built_in\">max</span>(fbm_cloud(filter_pos*<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">1</span>) - <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">0.0</span>); <br>    <span class=\"hljs-keyword\">return</span> rst;<br>&#125;<br><br><span class=\"hljs-type\">float</span> max_cloud_dist = <span class=\"hljs-number\">80.</span>;<br><span class=\"hljs-type\">vec4</span> renderMidClouds(<span class=\"hljs-type\">vec3</span> ro, <span class=\"hljs-type\">vec3</span> rd)<br>&#123;    <br>    <span class=\"hljs-type\">vec4</span> res = <span class=\"hljs-type\">vec4</span>(<span class=\"hljs-number\">0.0</span>);<br>    <span class=\"hljs-type\">float</span> depth = <span class=\"hljs-number\">0.0</span>;    <br>    <br>    <span class=\"hljs-type\">int</span> sample_count = <span class=\"hljs-number\">64</span>;<br>    <span class=\"hljs-type\">float</span> dt = max_cloud_dist / <span class=\"hljs-type\">float</span>(sample_count);<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; sample_count; ++i)<br>    &#123;<br>        <span class=\"hljs-type\">vec3</span> p = ro + depth*rd;<br>        <span class=\"hljs-type\">float</span> density = scene(p);<br>        <span class=\"hljs-keyword\">if</span>(density &gt; <span class=\"hljs-number\">0.0</span>)<br>        &#123;<br>            <span class=\"hljs-type\">float</span> diffuse = <span class=\"hljs-built_in\">clamp</span>((scene(p) - scene(p + <span class=\"hljs-number\">0.3</span>*light_dir))/<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.0</span>, <span class=\"hljs-number\">1.0</span>);<br>            <span class=\"hljs-type\">vec3</span> lin = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.8</span>) * <span class=\"hljs-number\">1.1</span> + <span class=\"hljs-number\">0.8</span> * <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.9333</span>, <span class=\"hljs-number\">0.702</span>, <span class=\"hljs-number\">0.5255</span>)*diffuse;<br>            <span class=\"hljs-type\">vec4</span> color = <span class=\"hljs-type\">vec4</span>(<span class=\"hljs-built_in\">mix</span>(<span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">1.0</span>), <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.0</span>), density), density);<br>            color.rgb *= color.a;<br><br>            res += color * (<span class=\"hljs-number\">1.0</span> - res.a);<br>        &#125;<br><br>        depth+=dt;<br>    &#125;<br><br>    <span class=\"hljs-keyword\">return</span> res;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/11/04/ProceduralTerrainGeneration2/terrain_with_all_cloud.png\" alt=\"增加体积云\"></p>\n<h1 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果\"></a>最终效果</h1><iframe width=\"640\" height=\"360\" frameborder=\"0\" src=\"https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false\" allowfullscreen></iframe>\n\n<p>以上便是我如何实现这个场景的简单介绍了。这是我初次尝试在ShaderToy上渲染大场景，也是第一次将整个步骤拆解讲解，可能还是会有不少地方讲的不过仔细和通透，也有些遗漏。</p>\n<p>后面我还是会继续尝试创作和讲解，希望能给人带来帮助，也有助于巩固我所学的知识。</p>\n"},{"title":"个人博客启动","date":"2024-10-09T15:33:59.000Z","_content":"\n晚上好。\n\n还是打算在个人的github.io继续更新自己的技术博客了。[原网站](qrc-eye.com)本来是打算用于和朋友一起写点东西上去的，结果现在倒是变成了只有我自己的碎碎念，着实不太好。\n\n最近一段时间会尽快的将我的部分文章搬运过来，一些琐碎的文章暂时就不管了。\n\n","source":"_posts/StartMyBlog.md","raw":"---\ntitle: 个人博客启动\ndate: 2024-10-09 23:33:59\ncategory: 生活杂谈\ntags: 生活\n---\n\n晚上好。\n\n还是打算在个人的github.io继续更新自己的技术博客了。[原网站](qrc-eye.com)本来是打算用于和朋友一起写点东西上去的，结果现在倒是变成了只有我自己的碎碎念，着实不太好。\n\n最近一段时间会尽快的将我的部分文章搬运过来，一些琐碎的文章暂时就不管了。\n\n","slug":"StartMyBlog","published":1,"updated":"2024-10-10T14:58:34.819Z","comments":1,"layout":"post","photos":[],"_id":"cm34lv4qi000gy057gbxk779v","content":"<p>晚上好。</p>\n<p>还是打算在个人的github.io继续更新自己的技术博客了。<a href=\"qrc-eye.com\">原网站</a>本来是打算用于和朋友一起写点东西上去的，结果现在倒是变成了只有我自己的碎碎念，着实不太好。</p>\n<p>最近一段时间会尽快的将我的部分文章搬运过来，一些琐碎的文章暂时就不管了。</p>\n","excerpt":"","more":"<p>晚上好。</p>\n<p>还是打算在个人的github.io继续更新自己的技术博客了。<a href=\"qrc-eye.com\">原网站</a>本来是打算用于和朋友一起写点东西上去的，结果现在倒是变成了只有我自己的碎碎念，着实不太好。</p>\n<p>最近一段时间会尽快的将我的部分文章搬运过来，一些琐碎的文章暂时就不管了。</p>\n"},{"title":"级联阴影贴图实现","date":"2024-10-13T09:06:53.000Z","index_img":"/2024/10/13/cascade-shadow-map/sm_far.png","banner_img":"/2024/10/13/cascade-shadow-map/sm_far.png","_content":"\n# 阴影贴图的局限\n阴影贴图（shadow map）是3D场景中实现阴影效果的基础手段，它通过预先将光线方向的场景深度存储到贴图中，在渲染的时候取每个场景中的点到光源的距离和深度贴图作比较，来判定该点是否在阴影当中。\n\n但是在较大的场景中，使用阴影贴图会有几个明显的不足：\n\n1. 阴影贴图只能覆盖部分场景，在渲染较大的场景的时候（如大世界），远处的场景基本上无法被阴影贴图所覆盖。\n2. 贴图的分辨率是有限的，太大的分辨率会对性能造成非常大的影响。但是在覆盖较大场景的时候，贴图分辨率不足会导致阴影模糊，效果不佳。\n3. 阴影贴图的实现一开始其实并没有考虑玩家相机的视椎体，也就是说在玩家没有看的地方也会渲染阴影贴图，这对渲染资源来说显然是个浪费。\n\nKongEngine计划在后面接入大地形的渲染，借此机会接入了级联阴影贴图的能力。\n实现方法参考了[LearnOpenGL的教程](https://learnopengl.com/Guest-Articles/2021/CSM)。\n\n\n# 级联阴影贴图的实现\n级联阴影贴图的基本概念包括如下几点：\n\n1. 将玩家的视椎体划分为几段，每一段视椎体构建一张阴影贴图覆盖，这个阴影贴图完美贴合从光源方向投射到这段视椎体中心点的正交投影。\n2. 和模型LOD的理念类似，离相机近的阴影贴图需要采用较高精度，而离相机远的阴影贴图可以使用低精度。\n3. 将多级阴影贴图传入最后的光照计算着色器，根据每个点所处视椎体的分段不同采用对应不同的阴影贴图计算光照。\n\n听起来挺简单的对吧，那我们一步一步来。\n\n## 视椎体分段\n上面说到我们需要将视椎体分为几段，在每一段视椎体覆盖一张阴影贴图，并计算出这张贴图的从光源方向看向视椎体中心点的正交投影的矩阵，也就是Light projection matrix和Light view matrix。这个矩阵需要紧密贴合这段视椎体，为此我们需要得到视椎体的顶点的世界坐标，得到顶点的min、max和视椎体的中心点。\n\n我们从相机的视椎体出发，当处于视椎体范围上的顶点的世界坐标经过projection矩阵和view矩阵转换后，xyz都会被映射到[-1,1]范围的屏幕空间坐标。矩阵转换是可逆的，也就是说取屏幕空间坐标为[-1, 1]边界的八个顶点，经过视椎体的projection矩阵和view矩阵的逆矩阵转换后，就能得到边界顶点的世界空间坐标。在代码里面的实现如下：\n\n```c++\nstd::vector<glm::vec4> CDirectionalLightComponent::GetFrustumCornersWorldSpace(const glm::mat4& proj_view)\n{\n    const auto inv = glm::inverse(proj_view);\n\n    // 顶点的世界坐标在projection和view matrix的转换下的坐标范围是[-1,1]\n    // 那么将在[-1,1]这个边界的八个顶点坐标乘以projection和view matrix的逆矩阵则可以得到视锥体边界的顶点的世界坐标\n    vector<vec4> frustum_corners;\n    for(unsigned int i = 0; i < 2; i++)\n    {\n        for(unsigned int j = 0; j < 2; j++)\n        {\n            for(unsigned int k = 0; k < 2; k++)\n            {\n                const vec4 pt = inv * vec4(2.0f*i-1.0f,2.0f*j-1.0f,2.0f*k-1.0f, 1.0f);\n                frustum_corners.push_back(pt / pt.w);\n            }\n        }   \n    }\n    \n    return frustum_corners;\n}\n```\n\n我们得到了视椎体角落的顶点世界坐标，我们希望阴影贴图能够如下图一般贴合每一段视椎体。那么我们需要计算视椎体的中心顶点坐标，中心顶点在计算view矩阵的时候需要用到；我们需要计算在xyz轴上顶点坐标的最大和最小值，这些数值在计算projection矩阵的时候会被用到。\n\n![级联阴影贴图由远及近](https://learnopengl.com/img/guest/2021/CSM/frustum_fitting.png)\n\n计算中心点的代码十分简单，将视椎体角落的坐标相加后再除以数量即可，代码如下：\n\n``` c++\nvec3 center = vec3(0.0f);\nfor(const auto& v : corners)\n{\n    center += vec3(v);\n}\ncenter /= corners.size();   // 获取视锥体的中心点\n\nconst auto light_view = lookAt(center-light_dir, center, vec3(0.0f, 1.0f, 0.0f));\n```\n\n计算贴合视椎体的范围则是比较并记录各个顶点在xyz轴的最大值和最小值，方法如下。这里提一下在z轴方向和一个参数z_mult进行了处理，其意义是阴影的投射源是有可能在视椎体范围之外的，如果不考虑这一部分的影响的话可能在阴影过度的时候会非常生硬，并且丢掉一些本来该显示的阴影导致渲染错误。\n\n``` c++\nfloat min_x = std::numeric_limits<float>::max();\nfloat min_y = std::numeric_limits<float>::max();\nfloat min_z = std::numeric_limits<float>::max();\nfloat max_x = std::numeric_limits<float>::lowest();\nfloat max_y = std::numeric_limits<float>::lowest();\nfloat max_z = std::numeric_limits<float>::lowest();\nfor (const auto& v : corners)\n{\n    const auto trf = light_view * v;\n    min_x = std::min(min_x, trf.x);\n    max_x = std::max(max_x, trf.x);\n    min_y = std::min(min_y, trf.y);\n    max_y = std::max(max_y, trf.y);\n    min_z = std::min(min_z, trf.z);\n    max_z = std::max(max_z, trf.z);\n}\nconstexpr float z_mult = 10.0f;\nif (min_z < 0)\n{\n    min_z *= z_mult;\n}\nelse\n{\n    min_z /= z_mult;\n}\nif (max_z < 0)\n{\n    max_z /= z_mult;\n}\nelse\n{\n    max_z *= z_mult;\n}\n\nconst mat4 light_projection = ortho(min_x, max_x, min_y, max_y, min_z, max_z);\n```\n\n## 计算级联阴影贴图\n一般的阴影贴图我们采用的是GL_TEXTURE_2D，而级联阴影贴图我们需要传入多张贴图，因此对应的贴图类型会变为GL_TEXTURE_2D_ARRAY。\n\n``` c++\nglGenTextures(1, &csm_texture);\nglBindTexture(GL_TEXTURE_2D_ARRAY, csm_texture);\nglTexImage3D(GL_TEXTURE_2D_ARRAY, 0, GL_DEPTH_COMPONENT32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, (int)csm_distances.size()+1, 0, GL_DEPTH_COMPONENT, GL_FLOAT, nullptr);\nglTexParameteri(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\nglTexParameteri(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\nglTexParameteri(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);\nglTexParameteri(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER);\nglTexParameterfv(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_BORDER_COLOR, border_color);\n\nglBindFramebuffer(GL_FRAMEBUFFER, shadowmap_fbo);\nglFramebufferTexture(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, csm_texture, 0);\nglDrawBuffer(GL_NONE);\nglReadBuffer(GL_NONE);\nglBindFramebuffer(GL_FRAMEBUFFER, 0);\n```\n\n除此之外，我们需要一次性渲染多张贴图，我们参考点光源阴影贴图使用geometry shader的做法，将顶点映射到不同的视椎体分段的光源的投影。代码如下：\n\n``` glsl\n#version 450 compatibility\nlayout(triangles, invocations = 6) in;\nlayout(triangle_strip, max_vertices = 3) out;\n\nuniform mat4 light_space_matrix[16];\n\n\nvoid main()\n{\n\tfor (int i = 0; i < 3; ++i)\n\t{\n\t\tgl_Position = light_space_matrix[gl_InvocationID] * gl_in[i].gl_Position;\n\t\tgl_Layer = gl_InvocationID;\n\t\tEmitVertex();\n\t}\n\tEndPrimitive();\n} \n```\n\n这里新增的**invocations = 6**代表了这个Shader可以被实例化，每个实例同时平行进行运算，实例的个数为6。内置的**gl_InvocationID**代表了当前处理的是哪一个实例，我们将其赋值到**gl_Layer**。其余的阴影贴图渲染步骤和普通的阴影贴图类似。\n\n下面几张图所示展示的，就是从近到远的几个级联阴影贴图的表现：\n![](csm_near.png)\n![](csm_mid.png)\n![](csm_far.png)\n\n## 使用级联阴影贴图\n级联阴影贴图的使用和阴影贴图是类似的，由于传入给光照Shader的是GL_TEXTURE_2D_ARRAY，需要使用vec3来索引贴图数据的，vec3的z值代表的是Layer索引。\n\nLayer代表的是使用哪一个视椎体分段的阴影贴图，取决于当前像素和相机的距离。取得对应的Layer参数后带入texcoord的z值读取对应的阴影贴图的值。示例代码如下：\n\n``` glsl\n// 计算阴影\nfloat ShadowCalculation_DirLight(vec4 frag_world_pos, vec3 to_light_dir, vec3 in_normal)\n{\n    // 获取像素和相机的距离，也就是view转换后的z值\n    vec4 frag_pos_view_space = matrix_ubo.view * frag_world_pos;\n    float depthValue = abs(frag_pos_view_space.z);\n\n    // 根据距离和每段视椎体分段的距离区间，获取Layer值\n    int layer = -1;\n    for (int i = 0; i < csm_level_count; ++i)\n    {\n        if (depthValue < csm_distances[i])\n        {\n            layer = i;\n            break;\n        }\n    }\n    if (layer == -1)\n    {\n        layer = csm_level_count;\n    }\n    // 下面的和应用普通阴影贴图的一致\n    // 转换到-1,1的范围，再转到0,1的范围\n    vec4 frag_pos_light_space = light_space_matrices[layer] * frag_world_pos;\n    // perform perspective divide\n    vec3 proj_coord = frag_pos_light_space.xyz / frag_pos_light_space.w;\n    // transform to [0,1] range\n    proj_coord = proj_coord * 0.5 + 0.5;\n\n    // get depth of current fragment from light's perspective\n    float current_depth = proj_coord.z;\n\n    // keep the shadow at 0.0 when outside the far_plane region of the light's frustum.\n    if (current_depth > 1.0)\n    {\n        return 0.0;\n    }\n\n    // PCF\n    float shadow = 0.0;\n    vec2 texel_size = 1.0 / vec2(textureSize(shadow_map, 0));\n    for(int x = -1; x <= 1; ++x)\n    {\n        for(int y = -1; y <= 1; ++y)\n        {\n            float pcf_depth = texture(shadow_map, vec3(proj_coord.xy + vec2(x, y) * texel_size, layer)).r;\n            shadow += current_depth > pcf_depth ? 1.0 : 0.0;\n        }\n    }\n    shadow /= 9.0;\n        \n    return shadow;\n}\n```\n\n# 效果对比\n## 原先的阴影贴图\n原先的阴影贴图只能覆盖有限的场景：\n![](sm_near.png)\n\n提升覆盖范围后，阴影的质量则会出现下降：\n![](sm_far.png)\n\n## 级联阴影贴图\n采用级联阴影贴图可以覆盖很大的场景，并且在可控的性能消耗下仍然有不错的显示智联。\n![](csm_result.png)\n","source":"_posts/cascade-shadow-map.md","raw":"---\ntitle: 级联阴影贴图实现\ndate: 2024-10-13 17:06:53\ncategories: \n\t- 技术漫谈\ntags: [3D, render, 渲染, 编程]\nindex_img: /2024/10/13/cascade-shadow-map/sm_far.png\nbanner_img: /2024/10/13/cascade-shadow-map/sm_far.png\n---\n\n# 阴影贴图的局限\n阴影贴图（shadow map）是3D场景中实现阴影效果的基础手段，它通过预先将光线方向的场景深度存储到贴图中，在渲染的时候取每个场景中的点到光源的距离和深度贴图作比较，来判定该点是否在阴影当中。\n\n但是在较大的场景中，使用阴影贴图会有几个明显的不足：\n\n1. 阴影贴图只能覆盖部分场景，在渲染较大的场景的时候（如大世界），远处的场景基本上无法被阴影贴图所覆盖。\n2. 贴图的分辨率是有限的，太大的分辨率会对性能造成非常大的影响。但是在覆盖较大场景的时候，贴图分辨率不足会导致阴影模糊，效果不佳。\n3. 阴影贴图的实现一开始其实并没有考虑玩家相机的视椎体，也就是说在玩家没有看的地方也会渲染阴影贴图，这对渲染资源来说显然是个浪费。\n\nKongEngine计划在后面接入大地形的渲染，借此机会接入了级联阴影贴图的能力。\n实现方法参考了[LearnOpenGL的教程](https://learnopengl.com/Guest-Articles/2021/CSM)。\n\n\n# 级联阴影贴图的实现\n级联阴影贴图的基本概念包括如下几点：\n\n1. 将玩家的视椎体划分为几段，每一段视椎体构建一张阴影贴图覆盖，这个阴影贴图完美贴合从光源方向投射到这段视椎体中心点的正交投影。\n2. 和模型LOD的理念类似，离相机近的阴影贴图需要采用较高精度，而离相机远的阴影贴图可以使用低精度。\n3. 将多级阴影贴图传入最后的光照计算着色器，根据每个点所处视椎体的分段不同采用对应不同的阴影贴图计算光照。\n\n听起来挺简单的对吧，那我们一步一步来。\n\n## 视椎体分段\n上面说到我们需要将视椎体分为几段，在每一段视椎体覆盖一张阴影贴图，并计算出这张贴图的从光源方向看向视椎体中心点的正交投影的矩阵，也就是Light projection matrix和Light view matrix。这个矩阵需要紧密贴合这段视椎体，为此我们需要得到视椎体的顶点的世界坐标，得到顶点的min、max和视椎体的中心点。\n\n我们从相机的视椎体出发，当处于视椎体范围上的顶点的世界坐标经过projection矩阵和view矩阵转换后，xyz都会被映射到[-1,1]范围的屏幕空间坐标。矩阵转换是可逆的，也就是说取屏幕空间坐标为[-1, 1]边界的八个顶点，经过视椎体的projection矩阵和view矩阵的逆矩阵转换后，就能得到边界顶点的世界空间坐标。在代码里面的实现如下：\n\n```c++\nstd::vector<glm::vec4> CDirectionalLightComponent::GetFrustumCornersWorldSpace(const glm::mat4& proj_view)\n{\n    const auto inv = glm::inverse(proj_view);\n\n    // 顶点的世界坐标在projection和view matrix的转换下的坐标范围是[-1,1]\n    // 那么将在[-1,1]这个边界的八个顶点坐标乘以projection和view matrix的逆矩阵则可以得到视锥体边界的顶点的世界坐标\n    vector<vec4> frustum_corners;\n    for(unsigned int i = 0; i < 2; i++)\n    {\n        for(unsigned int j = 0; j < 2; j++)\n        {\n            for(unsigned int k = 0; k < 2; k++)\n            {\n                const vec4 pt = inv * vec4(2.0f*i-1.0f,2.0f*j-1.0f,2.0f*k-1.0f, 1.0f);\n                frustum_corners.push_back(pt / pt.w);\n            }\n        }   \n    }\n    \n    return frustum_corners;\n}\n```\n\n我们得到了视椎体角落的顶点世界坐标，我们希望阴影贴图能够如下图一般贴合每一段视椎体。那么我们需要计算视椎体的中心顶点坐标，中心顶点在计算view矩阵的时候需要用到；我们需要计算在xyz轴上顶点坐标的最大和最小值，这些数值在计算projection矩阵的时候会被用到。\n\n![级联阴影贴图由远及近](https://learnopengl.com/img/guest/2021/CSM/frustum_fitting.png)\n\n计算中心点的代码十分简单，将视椎体角落的坐标相加后再除以数量即可，代码如下：\n\n``` c++\nvec3 center = vec3(0.0f);\nfor(const auto& v : corners)\n{\n    center += vec3(v);\n}\ncenter /= corners.size();   // 获取视锥体的中心点\n\nconst auto light_view = lookAt(center-light_dir, center, vec3(0.0f, 1.0f, 0.0f));\n```\n\n计算贴合视椎体的范围则是比较并记录各个顶点在xyz轴的最大值和最小值，方法如下。这里提一下在z轴方向和一个参数z_mult进行了处理，其意义是阴影的投射源是有可能在视椎体范围之外的，如果不考虑这一部分的影响的话可能在阴影过度的时候会非常生硬，并且丢掉一些本来该显示的阴影导致渲染错误。\n\n``` c++\nfloat min_x = std::numeric_limits<float>::max();\nfloat min_y = std::numeric_limits<float>::max();\nfloat min_z = std::numeric_limits<float>::max();\nfloat max_x = std::numeric_limits<float>::lowest();\nfloat max_y = std::numeric_limits<float>::lowest();\nfloat max_z = std::numeric_limits<float>::lowest();\nfor (const auto& v : corners)\n{\n    const auto trf = light_view * v;\n    min_x = std::min(min_x, trf.x);\n    max_x = std::max(max_x, trf.x);\n    min_y = std::min(min_y, trf.y);\n    max_y = std::max(max_y, trf.y);\n    min_z = std::min(min_z, trf.z);\n    max_z = std::max(max_z, trf.z);\n}\nconstexpr float z_mult = 10.0f;\nif (min_z < 0)\n{\n    min_z *= z_mult;\n}\nelse\n{\n    min_z /= z_mult;\n}\nif (max_z < 0)\n{\n    max_z /= z_mult;\n}\nelse\n{\n    max_z *= z_mult;\n}\n\nconst mat4 light_projection = ortho(min_x, max_x, min_y, max_y, min_z, max_z);\n```\n\n## 计算级联阴影贴图\n一般的阴影贴图我们采用的是GL_TEXTURE_2D，而级联阴影贴图我们需要传入多张贴图，因此对应的贴图类型会变为GL_TEXTURE_2D_ARRAY。\n\n``` c++\nglGenTextures(1, &csm_texture);\nglBindTexture(GL_TEXTURE_2D_ARRAY, csm_texture);\nglTexImage3D(GL_TEXTURE_2D_ARRAY, 0, GL_DEPTH_COMPONENT32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, (int)csm_distances.size()+1, 0, GL_DEPTH_COMPONENT, GL_FLOAT, nullptr);\nglTexParameteri(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\nglTexParameteri(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\nglTexParameteri(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);\nglTexParameteri(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER);\nglTexParameterfv(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_BORDER_COLOR, border_color);\n\nglBindFramebuffer(GL_FRAMEBUFFER, shadowmap_fbo);\nglFramebufferTexture(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, csm_texture, 0);\nglDrawBuffer(GL_NONE);\nglReadBuffer(GL_NONE);\nglBindFramebuffer(GL_FRAMEBUFFER, 0);\n```\n\n除此之外，我们需要一次性渲染多张贴图，我们参考点光源阴影贴图使用geometry shader的做法，将顶点映射到不同的视椎体分段的光源的投影。代码如下：\n\n``` glsl\n#version 450 compatibility\nlayout(triangles, invocations = 6) in;\nlayout(triangle_strip, max_vertices = 3) out;\n\nuniform mat4 light_space_matrix[16];\n\n\nvoid main()\n{\n\tfor (int i = 0; i < 3; ++i)\n\t{\n\t\tgl_Position = light_space_matrix[gl_InvocationID] * gl_in[i].gl_Position;\n\t\tgl_Layer = gl_InvocationID;\n\t\tEmitVertex();\n\t}\n\tEndPrimitive();\n} \n```\n\n这里新增的**invocations = 6**代表了这个Shader可以被实例化，每个实例同时平行进行运算，实例的个数为6。内置的**gl_InvocationID**代表了当前处理的是哪一个实例，我们将其赋值到**gl_Layer**。其余的阴影贴图渲染步骤和普通的阴影贴图类似。\n\n下面几张图所示展示的，就是从近到远的几个级联阴影贴图的表现：\n![](csm_near.png)\n![](csm_mid.png)\n![](csm_far.png)\n\n## 使用级联阴影贴图\n级联阴影贴图的使用和阴影贴图是类似的，由于传入给光照Shader的是GL_TEXTURE_2D_ARRAY，需要使用vec3来索引贴图数据的，vec3的z值代表的是Layer索引。\n\nLayer代表的是使用哪一个视椎体分段的阴影贴图，取决于当前像素和相机的距离。取得对应的Layer参数后带入texcoord的z值读取对应的阴影贴图的值。示例代码如下：\n\n``` glsl\n// 计算阴影\nfloat ShadowCalculation_DirLight(vec4 frag_world_pos, vec3 to_light_dir, vec3 in_normal)\n{\n    // 获取像素和相机的距离，也就是view转换后的z值\n    vec4 frag_pos_view_space = matrix_ubo.view * frag_world_pos;\n    float depthValue = abs(frag_pos_view_space.z);\n\n    // 根据距离和每段视椎体分段的距离区间，获取Layer值\n    int layer = -1;\n    for (int i = 0; i < csm_level_count; ++i)\n    {\n        if (depthValue < csm_distances[i])\n        {\n            layer = i;\n            break;\n        }\n    }\n    if (layer == -1)\n    {\n        layer = csm_level_count;\n    }\n    // 下面的和应用普通阴影贴图的一致\n    // 转换到-1,1的范围，再转到0,1的范围\n    vec4 frag_pos_light_space = light_space_matrices[layer] * frag_world_pos;\n    // perform perspective divide\n    vec3 proj_coord = frag_pos_light_space.xyz / frag_pos_light_space.w;\n    // transform to [0,1] range\n    proj_coord = proj_coord * 0.5 + 0.5;\n\n    // get depth of current fragment from light's perspective\n    float current_depth = proj_coord.z;\n\n    // keep the shadow at 0.0 when outside the far_plane region of the light's frustum.\n    if (current_depth > 1.0)\n    {\n        return 0.0;\n    }\n\n    // PCF\n    float shadow = 0.0;\n    vec2 texel_size = 1.0 / vec2(textureSize(shadow_map, 0));\n    for(int x = -1; x <= 1; ++x)\n    {\n        for(int y = -1; y <= 1; ++y)\n        {\n            float pcf_depth = texture(shadow_map, vec3(proj_coord.xy + vec2(x, y) * texel_size, layer)).r;\n            shadow += current_depth > pcf_depth ? 1.0 : 0.0;\n        }\n    }\n    shadow /= 9.0;\n        \n    return shadow;\n}\n```\n\n# 效果对比\n## 原先的阴影贴图\n原先的阴影贴图只能覆盖有限的场景：\n![](sm_near.png)\n\n提升覆盖范围后，阴影的质量则会出现下降：\n![](sm_far.png)\n\n## 级联阴影贴图\n采用级联阴影贴图可以覆盖很大的场景，并且在可控的性能消耗下仍然有不错的显示智联。\n![](csm_result.png)\n","slug":"cascade-shadow-map","published":1,"updated":"2024-10-15T14:31:53.649Z","comments":1,"layout":"post","photos":[],"_id":"cm34lv4qi000iy057a2o18zgj","content":"<h1 id=\"阴影贴图的局限\"><a href=\"#阴影贴图的局限\" class=\"headerlink\" title=\"阴影贴图的局限\"></a>阴影贴图的局限</h1><p>阴影贴图（shadow map）是3D场景中实现阴影效果的基础手段，它通过预先将光线方向的场景深度存储到贴图中，在渲染的时候取每个场景中的点到光源的距离和深度贴图作比较，来判定该点是否在阴影当中。</p>\n<p>但是在较大的场景中，使用阴影贴图会有几个明显的不足：</p>\n<ol>\n<li>阴影贴图只能覆盖部分场景，在渲染较大的场景的时候（如大世界），远处的场景基本上无法被阴影贴图所覆盖。</li>\n<li>贴图的分辨率是有限的，太大的分辨率会对性能造成非常大的影响。但是在覆盖较大场景的时候，贴图分辨率不足会导致阴影模糊，效果不佳。</li>\n<li>阴影贴图的实现一开始其实并没有考虑玩家相机的视椎体，也就是说在玩家没有看的地方也会渲染阴影贴图，这对渲染资源来说显然是个浪费。</li>\n</ol>\n<p>KongEngine计划在后面接入大地形的渲染，借此机会接入了级联阴影贴图的能力。<br>实现方法参考了<a href=\"https://learnopengl.com/Guest-Articles/2021/CSM\">LearnOpenGL的教程</a>。</p>\n<h1 id=\"级联阴影贴图的实现\"><a href=\"#级联阴影贴图的实现\" class=\"headerlink\" title=\"级联阴影贴图的实现\"></a>级联阴影贴图的实现</h1><p>级联阴影贴图的基本概念包括如下几点：</p>\n<ol>\n<li>将玩家的视椎体划分为几段，每一段视椎体构建一张阴影贴图覆盖，这个阴影贴图完美贴合从光源方向投射到这段视椎体中心点的正交投影。</li>\n<li>和模型LOD的理念类似，离相机近的阴影贴图需要采用较高精度，而离相机远的阴影贴图可以使用低精度。</li>\n<li>将多级阴影贴图传入最后的光照计算着色器，根据每个点所处视椎体的分段不同采用对应不同的阴影贴图计算光照。</li>\n</ol>\n<p>听起来挺简单的对吧，那我们一步一步来。</p>\n<h2 id=\"视椎体分段\"><a href=\"#视椎体分段\" class=\"headerlink\" title=\"视椎体分段\"></a>视椎体分段</h2><p>上面说到我们需要将视椎体分为几段，在每一段视椎体覆盖一张阴影贴图，并计算出这张贴图的从光源方向看向视椎体中心点的正交投影的矩阵，也就是Light projection matrix和Light view matrix。这个矩阵需要紧密贴合这段视椎体，为此我们需要得到视椎体的顶点的世界坐标，得到顶点的min、max和视椎体的中心点。</p>\n<p>我们从相机的视椎体出发，当处于视椎体范围上的顶点的世界坐标经过projection矩阵和view矩阵转换后，xyz都会被映射到[-1,1]范围的屏幕空间坐标。矩阵转换是可逆的，也就是说取屏幕空间坐标为[-1, 1]边界的八个顶点，经过视椎体的projection矩阵和view矩阵的逆矩阵转换后，就能得到边界顶点的世界空间坐标。在代码里面的实现如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">std::vector&lt;glm::vec4&gt; <span class=\"hljs-title\">CDirectionalLightComponent::GetFrustumCornersWorldSpace</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> glm::mat4&amp; proj_view)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> inv = glm::<span class=\"hljs-built_in\">inverse</span>(proj_view);<br><br>    <span class=\"hljs-comment\">// 顶点的世界坐标在projection和view matrix的转换下的坐标范围是[-1,1]</span><br>    <span class=\"hljs-comment\">// 那么将在[-1,1]这个边界的八个顶点坐标乘以projection和view matrix的逆矩阵则可以得到视锥体边界的顶点的世界坐标</span><br>    vector&lt;vec4&gt; frustum_corners;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">unsigned</span> <span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">2</span>; i++)<br>    &#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">unsigned</span> <span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; <span class=\"hljs-number\">2</span>; j++)<br>        &#123;<br>            <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">unsigned</span> <span class=\"hljs-type\">int</span> k = <span class=\"hljs-number\">0</span>; k &lt; <span class=\"hljs-number\">2</span>; k++)<br>            &#123;<br>                <span class=\"hljs-type\">const</span> vec4 pt = inv * <span class=\"hljs-built_in\">vec4</span>(<span class=\"hljs-number\">2.0f</span>*i<span class=\"hljs-number\">-1.0f</span>,<span class=\"hljs-number\">2.0f</span>*j<span class=\"hljs-number\">-1.0f</span>,<span class=\"hljs-number\">2.0f</span>*k<span class=\"hljs-number\">-1.0f</span>, <span class=\"hljs-number\">1.0f</span>);<br>                frustum_corners.<span class=\"hljs-built_in\">push_back</span>(pt / pt.w);<br>            &#125;<br>        &#125;   <br>    &#125;<br>    <br>    <span class=\"hljs-keyword\">return</span> frustum_corners;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>我们得到了视椎体角落的顶点世界坐标，我们希望阴影贴图能够如下图一般贴合每一段视椎体。那么我们需要计算视椎体的中心顶点坐标，中心顶点在计算view矩阵的时候需要用到；我们需要计算在xyz轴上顶点坐标的最大和最小值，这些数值在计算projection矩阵的时候会被用到。</p>\n<p><img src=\"https://learnopengl.com/img/guest/2021/CSM/frustum_fitting.png\" alt=\"级联阴影贴图由远及近\"></p>\n<p>计算中心点的代码十分简单，将视椎体角落的坐标相加后再除以数量即可，代码如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\">vec3 center = <span class=\"hljs-built_in\">vec3</span>(<span class=\"hljs-number\">0.0f</span>);<br><span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span>&amp; v : corners)<br>&#123;<br>    center += <span class=\"hljs-built_in\">vec3</span>(v);<br>&#125;<br>center /= corners.<span class=\"hljs-built_in\">size</span>();   <span class=\"hljs-comment\">// 获取视锥体的中心点</span><br><br><span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> light_view = <span class=\"hljs-built_in\">lookAt</span>(center-light_dir, center, <span class=\"hljs-built_in\">vec3</span>(<span class=\"hljs-number\">0.0f</span>, <span class=\"hljs-number\">1.0f</span>, <span class=\"hljs-number\">0.0f</span>));<br></code></pre></td></tr></table></figure>\n\n<p>计算贴合视椎体的范围则是比较并记录各个顶点在xyz轴的最大值和最小值，方法如下。这里提一下在z轴方向和一个参数z_mult进行了处理，其意义是阴影的投射源是有可能在视椎体范围之外的，如果不考虑这一部分的影响的话可能在阴影过度的时候会非常生硬，并且丢掉一些本来该显示的阴影导致渲染错误。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-type\">float</span> min_x = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">max</span>();<br><span class=\"hljs-type\">float</span> min_y = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">max</span>();<br><span class=\"hljs-type\">float</span> min_z = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">max</span>();<br><span class=\"hljs-type\">float</span> max_x = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">lowest</span>();<br><span class=\"hljs-type\">float</span> max_y = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">lowest</span>();<br><span class=\"hljs-type\">float</span> max_z = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">lowest</span>();<br><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span>&amp; v : corners)<br>&#123;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> trf = light_view * v;<br>    min_x = std::<span class=\"hljs-built_in\">min</span>(min_x, trf.x);<br>    max_x = std::<span class=\"hljs-built_in\">max</span>(max_x, trf.x);<br>    min_y = std::<span class=\"hljs-built_in\">min</span>(min_y, trf.y);<br>    max_y = std::<span class=\"hljs-built_in\">max</span>(max_y, trf.y);<br>    min_z = std::<span class=\"hljs-built_in\">min</span>(min_z, trf.z);<br>    max_z = std::<span class=\"hljs-built_in\">max</span>(max_z, trf.z);<br>&#125;<br><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">float</span> z_mult = <span class=\"hljs-number\">10.0f</span>;<br><span class=\"hljs-keyword\">if</span> (min_z &lt; <span class=\"hljs-number\">0</span>)<br>&#123;<br>    min_z *= z_mult;<br>&#125;<br><span class=\"hljs-keyword\">else</span><br>&#123;<br>    min_z /= z_mult;<br>&#125;<br><span class=\"hljs-keyword\">if</span> (max_z &lt; <span class=\"hljs-number\">0</span>)<br>&#123;<br>    max_z /= z_mult;<br>&#125;<br><span class=\"hljs-keyword\">else</span><br>&#123;<br>    max_z *= z_mult;<br>&#125;<br><br><span class=\"hljs-type\">const</span> mat4 light_projection = <span class=\"hljs-built_in\">ortho</span>(min_x, max_x, min_y, max_y, min_z, max_z);<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"计算级联阴影贴图\"><a href=\"#计算级联阴影贴图\" class=\"headerlink\" title=\"计算级联阴影贴图\"></a>计算级联阴影贴图</h2><p>一般的阴影贴图我们采用的是GL_TEXTURE_2D，而级联阴影贴图我们需要传入多张贴图，因此对应的贴图类型会变为GL_TEXTURE_2D_ARRAY。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;csm_texture);<br><span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D_ARRAY, csm_texture);<br><span class=\"hljs-built_in\">glTexImage3D</span>(GL_TEXTURE_2D_ARRAY, <span class=\"hljs-number\">0</span>, GL_DEPTH_COMPONENT32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, (<span class=\"hljs-type\">int</span>)csm_distances.<span class=\"hljs-built_in\">size</span>()<span class=\"hljs-number\">+1</span>, <span class=\"hljs-number\">0</span>, GL_DEPTH_COMPONENT, GL_FLOAT, <span class=\"hljs-literal\">nullptr</span>);<br><span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);<br><span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER);<br><span class=\"hljs-built_in\">glTexParameterfv</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_BORDER_COLOR, border_color);<br><br><span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_FRAMEBUFFER, shadowmap_fbo);<br><span class=\"hljs-built_in\">glFramebufferTexture</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, csm_texture, <span class=\"hljs-number\">0</span>);<br><span class=\"hljs-built_in\">glDrawBuffer</span>(GL_NONE);<br><span class=\"hljs-built_in\">glReadBuffer</span>(GL_NONE);<br><span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class=\"hljs-number\">0</span>);<br></code></pre></td></tr></table></figure>\n\n<p>除此之外，我们需要一次性渲染多张贴图，我们参考点光源阴影贴图使用geometry shader的做法，将顶点映射到不同的视椎体分段的光源的投影。代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-meta\">#version 450 compatibility</span><br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">triangles</span>, <span class=\"hljs-keyword\">invocations</span> = <span class=\"hljs-number\">6</span>) <span class=\"hljs-keyword\">in</span>;<br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">triangle_strip</span>, <span class=\"hljs-keyword\">max_vertices</span> = <span class=\"hljs-number\">3</span>) <span class=\"hljs-keyword\">out</span>;<br><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">mat4</span> light_space_matrix[<span class=\"hljs-number\">16</span>];<br><br><br><span class=\"hljs-type\">void</span> main()<br>&#123;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i)<br>\t&#123;<br>\t\t<span class=\"hljs-built_in\">gl_Position</span> = light_space_matrix[<span class=\"hljs-built_in\">gl_InvocationID</span>] * <span class=\"hljs-built_in\">gl_in</span>[i].<span class=\"hljs-built_in\">gl_Position</span>;<br>\t\t<span class=\"hljs-built_in\">gl_Layer</span> = <span class=\"hljs-built_in\">gl_InvocationID</span>;<br>\t\t<span class=\"hljs-built_in\">EmitVertex</span>();<br>\t&#125;<br>\t<span class=\"hljs-built_in\">EndPrimitive</span>();<br>&#125; <br></code></pre></td></tr></table></figure>\n\n<p>这里新增的<strong>invocations &#x3D; 6</strong>代表了这个Shader可以被实例化，每个实例同时平行进行运算，实例的个数为6。内置的<strong>gl_InvocationID</strong>代表了当前处理的是哪一个实例，我们将其赋值到<strong>gl_Layer</strong>。其余的阴影贴图渲染步骤和普通的阴影贴图类似。</p>\n<p>下面几张图所示展示的，就是从近到远的几个级联阴影贴图的表现：<br><img src=\"/2024/10/13/cascade-shadow-map/csm_near.png\"><br><img src=\"/2024/10/13/cascade-shadow-map/csm_mid.png\"><br><img src=\"/2024/10/13/cascade-shadow-map/csm_far.png\"></p>\n<h2 id=\"使用级联阴影贴图\"><a href=\"#使用级联阴影贴图\" class=\"headerlink\" title=\"使用级联阴影贴图\"></a>使用级联阴影贴图</h2><p>级联阴影贴图的使用和阴影贴图是类似的，由于传入给光照Shader的是GL_TEXTURE_2D_ARRAY，需要使用vec3来索引贴图数据的，vec3的z值代表的是Layer索引。</p>\n<p>Layer代表的是使用哪一个视椎体分段的阴影贴图，取决于当前像素和相机的距离。取得对应的Layer参数后带入texcoord的z值读取对应的阴影贴图的值。示例代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 计算阴影</span><br><span class=\"hljs-type\">float</span> ShadowCalculation_DirLight(<span class=\"hljs-type\">vec4</span> frag_world_pos, <span class=\"hljs-type\">vec3</span> to_light_dir, <span class=\"hljs-type\">vec3</span> in_normal)<br>&#123;<br>    <span class=\"hljs-comment\">// 获取像素和相机的距离，也就是view转换后的z值</span><br>    <span class=\"hljs-type\">vec4</span> frag_pos_view_space = matrix_ubo.view * frag_world_pos;<br>    <span class=\"hljs-type\">float</span> depthValue = <span class=\"hljs-built_in\">abs</span>(frag_pos_view_space.z);<br><br>    <span class=\"hljs-comment\">// 根据距离和每段视椎体分段的距离区间，获取Layer值</span><br>    <span class=\"hljs-type\">int</span> layer = <span class=\"hljs-number\">-1</span>;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; csm_level_count; ++i)<br>    &#123;<br>        <span class=\"hljs-keyword\">if</span> (depthValue &lt; csm_distances[i])<br>        &#123;<br>            layer = i;<br>            <span class=\"hljs-keyword\">break</span>;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span> (layer == <span class=\"hljs-number\">-1</span>)<br>    &#123;<br>        layer = csm_level_count;<br>    &#125;<br>    <span class=\"hljs-comment\">// 下面的和应用普通阴影贴图的一致</span><br>    <span class=\"hljs-comment\">// 转换到-1,1的范围，再转到0,1的范围</span><br>    <span class=\"hljs-type\">vec4</span> frag_pos_light_space = light_space_matrices[layer] * frag_world_pos;<br>    <span class=\"hljs-comment\">// perform perspective divide</span><br>    <span class=\"hljs-type\">vec3</span> proj_coord = frag_pos_light_space.xyz / frag_pos_light_space.w;<br>    <span class=\"hljs-comment\">// transform to [0,1] range</span><br>    proj_coord = proj_coord * <span class=\"hljs-number\">0.5</span> + <span class=\"hljs-number\">0.5</span>;<br><br>    <span class=\"hljs-comment\">// get depth of current fragment from light&#x27;s perspective</span><br>    <span class=\"hljs-type\">float</span> current_depth = proj_coord.z;<br><br>    <span class=\"hljs-comment\">// keep the shadow at 0.0 when outside the far_plane region of the light&#x27;s frustum.</span><br>    <span class=\"hljs-keyword\">if</span> (current_depth &gt; <span class=\"hljs-number\">1.0</span>)<br>    &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0.0</span>;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// PCF</span><br>    <span class=\"hljs-type\">float</span> shadow = <span class=\"hljs-number\">0.0</span>;<br>    <span class=\"hljs-type\">vec2</span> texel_size = <span class=\"hljs-number\">1.0</span> / <span class=\"hljs-type\">vec2</span>(<span class=\"hljs-built_in\">textureSize</span>(shadow_map, <span class=\"hljs-number\">0</span>));<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> x = <span class=\"hljs-number\">-1</span>; x &lt;= <span class=\"hljs-number\">1</span>; ++x)<br>    &#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> y = <span class=\"hljs-number\">-1</span>; y &lt;= <span class=\"hljs-number\">1</span>; ++y)<br>        &#123;<br>            <span class=\"hljs-type\">float</span> pcf_depth = <span class=\"hljs-built_in\">texture</span>(shadow_map, <span class=\"hljs-type\">vec3</span>(proj_coord.xy + <span class=\"hljs-type\">vec2</span>(x, y) * texel_size, layer)).r;<br>            shadow += current_depth &gt; pcf_depth ? <span class=\"hljs-number\">1.0</span> : <span class=\"hljs-number\">0.0</span>;<br>        &#125;<br>    &#125;<br>    shadow /= <span class=\"hljs-number\">9.0</span>;<br>        <br>    <span class=\"hljs-keyword\">return</span> shadow;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"效果对比\"><a href=\"#效果对比\" class=\"headerlink\" title=\"效果对比\"></a>效果对比</h1><h2 id=\"原先的阴影贴图\"><a href=\"#原先的阴影贴图\" class=\"headerlink\" title=\"原先的阴影贴图\"></a>原先的阴影贴图</h2><p>原先的阴影贴图只能覆盖有限的场景：<br><img src=\"/2024/10/13/cascade-shadow-map/sm_near.png\"></p>\n<p>提升覆盖范围后，阴影的质量则会出现下降：<br><img src=\"/2024/10/13/cascade-shadow-map/sm_far.png\"></p>\n<h2 id=\"级联阴影贴图\"><a href=\"#级联阴影贴图\" class=\"headerlink\" title=\"级联阴影贴图\"></a>级联阴影贴图</h2><p>采用级联阴影贴图可以覆盖很大的场景，并且在可控的性能消耗下仍然有不错的显示智联。<br><img src=\"/2024/10/13/cascade-shadow-map/csm_result.png\"></p>\n","excerpt":"","more":"<h1 id=\"阴影贴图的局限\"><a href=\"#阴影贴图的局限\" class=\"headerlink\" title=\"阴影贴图的局限\"></a>阴影贴图的局限</h1><p>阴影贴图（shadow map）是3D场景中实现阴影效果的基础手段，它通过预先将光线方向的场景深度存储到贴图中，在渲染的时候取每个场景中的点到光源的距离和深度贴图作比较，来判定该点是否在阴影当中。</p>\n<p>但是在较大的场景中，使用阴影贴图会有几个明显的不足：</p>\n<ol>\n<li>阴影贴图只能覆盖部分场景，在渲染较大的场景的时候（如大世界），远处的场景基本上无法被阴影贴图所覆盖。</li>\n<li>贴图的分辨率是有限的，太大的分辨率会对性能造成非常大的影响。但是在覆盖较大场景的时候，贴图分辨率不足会导致阴影模糊，效果不佳。</li>\n<li>阴影贴图的实现一开始其实并没有考虑玩家相机的视椎体，也就是说在玩家没有看的地方也会渲染阴影贴图，这对渲染资源来说显然是个浪费。</li>\n</ol>\n<p>KongEngine计划在后面接入大地形的渲染，借此机会接入了级联阴影贴图的能力。<br>实现方法参考了<a href=\"https://learnopengl.com/Guest-Articles/2021/CSM\">LearnOpenGL的教程</a>。</p>\n<h1 id=\"级联阴影贴图的实现\"><a href=\"#级联阴影贴图的实现\" class=\"headerlink\" title=\"级联阴影贴图的实现\"></a>级联阴影贴图的实现</h1><p>级联阴影贴图的基本概念包括如下几点：</p>\n<ol>\n<li>将玩家的视椎体划分为几段，每一段视椎体构建一张阴影贴图覆盖，这个阴影贴图完美贴合从光源方向投射到这段视椎体中心点的正交投影。</li>\n<li>和模型LOD的理念类似，离相机近的阴影贴图需要采用较高精度，而离相机远的阴影贴图可以使用低精度。</li>\n<li>将多级阴影贴图传入最后的光照计算着色器，根据每个点所处视椎体的分段不同采用对应不同的阴影贴图计算光照。</li>\n</ol>\n<p>听起来挺简单的对吧，那我们一步一步来。</p>\n<h2 id=\"视椎体分段\"><a href=\"#视椎体分段\" class=\"headerlink\" title=\"视椎体分段\"></a>视椎体分段</h2><p>上面说到我们需要将视椎体分为几段，在每一段视椎体覆盖一张阴影贴图，并计算出这张贴图的从光源方向看向视椎体中心点的正交投影的矩阵，也就是Light projection matrix和Light view matrix。这个矩阵需要紧密贴合这段视椎体，为此我们需要得到视椎体的顶点的世界坐标，得到顶点的min、max和视椎体的中心点。</p>\n<p>我们从相机的视椎体出发，当处于视椎体范围上的顶点的世界坐标经过projection矩阵和view矩阵转换后，xyz都会被映射到[-1,1]范围的屏幕空间坐标。矩阵转换是可逆的，也就是说取屏幕空间坐标为[-1, 1]边界的八个顶点，经过视椎体的projection矩阵和view矩阵的逆矩阵转换后，就能得到边界顶点的世界空间坐标。在代码里面的实现如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">std::vector&lt;glm::vec4&gt; <span class=\"hljs-title\">CDirectionalLightComponent::GetFrustumCornersWorldSpace</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> glm::mat4&amp; proj_view)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> inv = glm::<span class=\"hljs-built_in\">inverse</span>(proj_view);<br><br>    <span class=\"hljs-comment\">// 顶点的世界坐标在projection和view matrix的转换下的坐标范围是[-1,1]</span><br>    <span class=\"hljs-comment\">// 那么将在[-1,1]这个边界的八个顶点坐标乘以projection和view matrix的逆矩阵则可以得到视锥体边界的顶点的世界坐标</span><br>    vector&lt;vec4&gt; frustum_corners;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">unsigned</span> <span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">2</span>; i++)<br>    &#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">unsigned</span> <span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; <span class=\"hljs-number\">2</span>; j++)<br>        &#123;<br>            <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">unsigned</span> <span class=\"hljs-type\">int</span> k = <span class=\"hljs-number\">0</span>; k &lt; <span class=\"hljs-number\">2</span>; k++)<br>            &#123;<br>                <span class=\"hljs-type\">const</span> vec4 pt = inv * <span class=\"hljs-built_in\">vec4</span>(<span class=\"hljs-number\">2.0f</span>*i<span class=\"hljs-number\">-1.0f</span>,<span class=\"hljs-number\">2.0f</span>*j<span class=\"hljs-number\">-1.0f</span>,<span class=\"hljs-number\">2.0f</span>*k<span class=\"hljs-number\">-1.0f</span>, <span class=\"hljs-number\">1.0f</span>);<br>                frustum_corners.<span class=\"hljs-built_in\">push_back</span>(pt / pt.w);<br>            &#125;<br>        &#125;   <br>    &#125;<br>    <br>    <span class=\"hljs-keyword\">return</span> frustum_corners;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>我们得到了视椎体角落的顶点世界坐标，我们希望阴影贴图能够如下图一般贴合每一段视椎体。那么我们需要计算视椎体的中心顶点坐标，中心顶点在计算view矩阵的时候需要用到；我们需要计算在xyz轴上顶点坐标的最大和最小值，这些数值在计算projection矩阵的时候会被用到。</p>\n<p><img src=\"https://learnopengl.com/img/guest/2021/CSM/frustum_fitting.png\" alt=\"级联阴影贴图由远及近\"></p>\n<p>计算中心点的代码十分简单，将视椎体角落的坐标相加后再除以数量即可，代码如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\">vec3 center = <span class=\"hljs-built_in\">vec3</span>(<span class=\"hljs-number\">0.0f</span>);<br><span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span>&amp; v : corners)<br>&#123;<br>    center += <span class=\"hljs-built_in\">vec3</span>(v);<br>&#125;<br>center /= corners.<span class=\"hljs-built_in\">size</span>();   <span class=\"hljs-comment\">// 获取视锥体的中心点</span><br><br><span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> light_view = <span class=\"hljs-built_in\">lookAt</span>(center-light_dir, center, <span class=\"hljs-built_in\">vec3</span>(<span class=\"hljs-number\">0.0f</span>, <span class=\"hljs-number\">1.0f</span>, <span class=\"hljs-number\">0.0f</span>));<br></code></pre></td></tr></table></figure>\n\n<p>计算贴合视椎体的范围则是比较并记录各个顶点在xyz轴的最大值和最小值，方法如下。这里提一下在z轴方向和一个参数z_mult进行了处理，其意义是阴影的投射源是有可能在视椎体范围之外的，如果不考虑这一部分的影响的话可能在阴影过度的时候会非常生硬，并且丢掉一些本来该显示的阴影导致渲染错误。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-type\">float</span> min_x = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">max</span>();<br><span class=\"hljs-type\">float</span> min_y = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">max</span>();<br><span class=\"hljs-type\">float</span> min_z = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">max</span>();<br><span class=\"hljs-type\">float</span> max_x = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">lowest</span>();<br><span class=\"hljs-type\">float</span> max_y = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">lowest</span>();<br><span class=\"hljs-type\">float</span> max_z = std::numeric_limits&lt;<span class=\"hljs-type\">float</span>&gt;::<span class=\"hljs-built_in\">lowest</span>();<br><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span>&amp; v : corners)<br>&#123;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> trf = light_view * v;<br>    min_x = std::<span class=\"hljs-built_in\">min</span>(min_x, trf.x);<br>    max_x = std::<span class=\"hljs-built_in\">max</span>(max_x, trf.x);<br>    min_y = std::<span class=\"hljs-built_in\">min</span>(min_y, trf.y);<br>    max_y = std::<span class=\"hljs-built_in\">max</span>(max_y, trf.y);<br>    min_z = std::<span class=\"hljs-built_in\">min</span>(min_z, trf.z);<br>    max_z = std::<span class=\"hljs-built_in\">max</span>(max_z, trf.z);<br>&#125;<br><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">float</span> z_mult = <span class=\"hljs-number\">10.0f</span>;<br><span class=\"hljs-keyword\">if</span> (min_z &lt; <span class=\"hljs-number\">0</span>)<br>&#123;<br>    min_z *= z_mult;<br>&#125;<br><span class=\"hljs-keyword\">else</span><br>&#123;<br>    min_z /= z_mult;<br>&#125;<br><span class=\"hljs-keyword\">if</span> (max_z &lt; <span class=\"hljs-number\">0</span>)<br>&#123;<br>    max_z /= z_mult;<br>&#125;<br><span class=\"hljs-keyword\">else</span><br>&#123;<br>    max_z *= z_mult;<br>&#125;<br><br><span class=\"hljs-type\">const</span> mat4 light_projection = <span class=\"hljs-built_in\">ortho</span>(min_x, max_x, min_y, max_y, min_z, max_z);<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"计算级联阴影贴图\"><a href=\"#计算级联阴影贴图\" class=\"headerlink\" title=\"计算级联阴影贴图\"></a>计算级联阴影贴图</h2><p>一般的阴影贴图我们采用的是GL_TEXTURE_2D，而级联阴影贴图我们需要传入多张贴图，因此对应的贴图类型会变为GL_TEXTURE_2D_ARRAY。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;csm_texture);<br><span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D_ARRAY, csm_texture);<br><span class=\"hljs-built_in\">glTexImage3D</span>(GL_TEXTURE_2D_ARRAY, <span class=\"hljs-number\">0</span>, GL_DEPTH_COMPONENT32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, (<span class=\"hljs-type\">int</span>)csm_distances.<span class=\"hljs-built_in\">size</span>()<span class=\"hljs-number\">+1</span>, <span class=\"hljs-number\">0</span>, GL_DEPTH_COMPONENT, GL_FLOAT, <span class=\"hljs-literal\">nullptr</span>);<br><span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);<br><span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER);<br><span class=\"hljs-built_in\">glTexParameterfv</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_BORDER_COLOR, border_color);<br><br><span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_FRAMEBUFFER, shadowmap_fbo);<br><span class=\"hljs-built_in\">glFramebufferTexture</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, csm_texture, <span class=\"hljs-number\">0</span>);<br><span class=\"hljs-built_in\">glDrawBuffer</span>(GL_NONE);<br><span class=\"hljs-built_in\">glReadBuffer</span>(GL_NONE);<br><span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class=\"hljs-number\">0</span>);<br></code></pre></td></tr></table></figure>\n\n<p>除此之外，我们需要一次性渲染多张贴图，我们参考点光源阴影贴图使用geometry shader的做法，将顶点映射到不同的视椎体分段的光源的投影。代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-meta\">#version 450 compatibility</span><br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">triangles</span>, <span class=\"hljs-keyword\">invocations</span> = <span class=\"hljs-number\">6</span>) <span class=\"hljs-keyword\">in</span>;<br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">triangle_strip</span>, <span class=\"hljs-keyword\">max_vertices</span> = <span class=\"hljs-number\">3</span>) <span class=\"hljs-keyword\">out</span>;<br><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">mat4</span> light_space_matrix[<span class=\"hljs-number\">16</span>];<br><br><br><span class=\"hljs-type\">void</span> main()<br>&#123;<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">3</span>; ++i)<br>\t&#123;<br>\t\t<span class=\"hljs-built_in\">gl_Position</span> = light_space_matrix[<span class=\"hljs-built_in\">gl_InvocationID</span>] * <span class=\"hljs-built_in\">gl_in</span>[i].<span class=\"hljs-built_in\">gl_Position</span>;<br>\t\t<span class=\"hljs-built_in\">gl_Layer</span> = <span class=\"hljs-built_in\">gl_InvocationID</span>;<br>\t\t<span class=\"hljs-built_in\">EmitVertex</span>();<br>\t&#125;<br>\t<span class=\"hljs-built_in\">EndPrimitive</span>();<br>&#125; <br></code></pre></td></tr></table></figure>\n\n<p>这里新增的<strong>invocations &#x3D; 6</strong>代表了这个Shader可以被实例化，每个实例同时平行进行运算，实例的个数为6。内置的<strong>gl_InvocationID</strong>代表了当前处理的是哪一个实例，我们将其赋值到<strong>gl_Layer</strong>。其余的阴影贴图渲染步骤和普通的阴影贴图类似。</p>\n<p>下面几张图所示展示的，就是从近到远的几个级联阴影贴图的表现：<br><img src=\"/2024/10/13/cascade-shadow-map/csm_near.png\"><br><img src=\"/2024/10/13/cascade-shadow-map/csm_mid.png\"><br><img src=\"/2024/10/13/cascade-shadow-map/csm_far.png\"></p>\n<h2 id=\"使用级联阴影贴图\"><a href=\"#使用级联阴影贴图\" class=\"headerlink\" title=\"使用级联阴影贴图\"></a>使用级联阴影贴图</h2><p>级联阴影贴图的使用和阴影贴图是类似的，由于传入给光照Shader的是GL_TEXTURE_2D_ARRAY，需要使用vec3来索引贴图数据的，vec3的z值代表的是Layer索引。</p>\n<p>Layer代表的是使用哪一个视椎体分段的阴影贴图，取决于当前像素和相机的距离。取得对应的Layer参数后带入texcoord的z值读取对应的阴影贴图的值。示例代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 计算阴影</span><br><span class=\"hljs-type\">float</span> ShadowCalculation_DirLight(<span class=\"hljs-type\">vec4</span> frag_world_pos, <span class=\"hljs-type\">vec3</span> to_light_dir, <span class=\"hljs-type\">vec3</span> in_normal)<br>&#123;<br>    <span class=\"hljs-comment\">// 获取像素和相机的距离，也就是view转换后的z值</span><br>    <span class=\"hljs-type\">vec4</span> frag_pos_view_space = matrix_ubo.view * frag_world_pos;<br>    <span class=\"hljs-type\">float</span> depthValue = <span class=\"hljs-built_in\">abs</span>(frag_pos_view_space.z);<br><br>    <span class=\"hljs-comment\">// 根据距离和每段视椎体分段的距离区间，获取Layer值</span><br>    <span class=\"hljs-type\">int</span> layer = <span class=\"hljs-number\">-1</span>;<br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; csm_level_count; ++i)<br>    &#123;<br>        <span class=\"hljs-keyword\">if</span> (depthValue &lt; csm_distances[i])<br>        &#123;<br>            layer = i;<br>            <span class=\"hljs-keyword\">break</span>;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span> (layer == <span class=\"hljs-number\">-1</span>)<br>    &#123;<br>        layer = csm_level_count;<br>    &#125;<br>    <span class=\"hljs-comment\">// 下面的和应用普通阴影贴图的一致</span><br>    <span class=\"hljs-comment\">// 转换到-1,1的范围，再转到0,1的范围</span><br>    <span class=\"hljs-type\">vec4</span> frag_pos_light_space = light_space_matrices[layer] * frag_world_pos;<br>    <span class=\"hljs-comment\">// perform perspective divide</span><br>    <span class=\"hljs-type\">vec3</span> proj_coord = frag_pos_light_space.xyz / frag_pos_light_space.w;<br>    <span class=\"hljs-comment\">// transform to [0,1] range</span><br>    proj_coord = proj_coord * <span class=\"hljs-number\">0.5</span> + <span class=\"hljs-number\">0.5</span>;<br><br>    <span class=\"hljs-comment\">// get depth of current fragment from light&#x27;s perspective</span><br>    <span class=\"hljs-type\">float</span> current_depth = proj_coord.z;<br><br>    <span class=\"hljs-comment\">// keep the shadow at 0.0 when outside the far_plane region of the light&#x27;s frustum.</span><br>    <span class=\"hljs-keyword\">if</span> (current_depth &gt; <span class=\"hljs-number\">1.0</span>)<br>    &#123;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0.0</span>;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// PCF</span><br>    <span class=\"hljs-type\">float</span> shadow = <span class=\"hljs-number\">0.0</span>;<br>    <span class=\"hljs-type\">vec2</span> texel_size = <span class=\"hljs-number\">1.0</span> / <span class=\"hljs-type\">vec2</span>(<span class=\"hljs-built_in\">textureSize</span>(shadow_map, <span class=\"hljs-number\">0</span>));<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> x = <span class=\"hljs-number\">-1</span>; x &lt;= <span class=\"hljs-number\">1</span>; ++x)<br>    &#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> y = <span class=\"hljs-number\">-1</span>; y &lt;= <span class=\"hljs-number\">1</span>; ++y)<br>        &#123;<br>            <span class=\"hljs-type\">float</span> pcf_depth = <span class=\"hljs-built_in\">texture</span>(shadow_map, <span class=\"hljs-type\">vec3</span>(proj_coord.xy + <span class=\"hljs-type\">vec2</span>(x, y) * texel_size, layer)).r;<br>            shadow += current_depth &gt; pcf_depth ? <span class=\"hljs-number\">1.0</span> : <span class=\"hljs-number\">0.0</span>;<br>        &#125;<br>    &#125;<br>    shadow /= <span class=\"hljs-number\">9.0</span>;<br>        <br>    <span class=\"hljs-keyword\">return</span> shadow;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"效果对比\"><a href=\"#效果对比\" class=\"headerlink\" title=\"效果对比\"></a>效果对比</h1><h2 id=\"原先的阴影贴图\"><a href=\"#原先的阴影贴图\" class=\"headerlink\" title=\"原先的阴影贴图\"></a>原先的阴影贴图</h2><p>原先的阴影贴图只能覆盖有限的场景：<br><img src=\"/2024/10/13/cascade-shadow-map/sm_near.png\"></p>\n<p>提升覆盖范围后，阴影的质量则会出现下降：<br><img src=\"/2024/10/13/cascade-shadow-map/sm_far.png\"></p>\n<h2 id=\"级联阴影贴图\"><a href=\"#级联阴影贴图\" class=\"headerlink\" title=\"级联阴影贴图\"></a>级联阴影贴图</h2><p>采用级联阴影贴图可以覆盖很大的场景，并且在可控的性能消耗下仍然有不错的显示智联。<br><img src=\"/2024/10/13/cascade-shadow-map/csm_result.png\"></p>\n"},{"title":"延迟渲染实现","date":"2024-10-19T09:18:41.000Z","index_img":"/2024/10/19/defer-render/defer_render_banner.png","banner_img":"/2024/10/19/defer-render/defer_render_banner.png","_content":"\n\n想要在Kong引擎里面实现的场景慢慢复杂了起来，光源和模型的数量从原先的十以内的数量增长到几十甚至几百的数量级，是时候接入延迟渲染的方法了。\n\n# 延迟渲染\n\n\n**延迟渲染**（Defer Rendering），或者**延迟着色法**（Defer Shading），是区别于**正向渲染**（Forward Shading）的一种计算场景光照的方式。\n\n正向渲染方法就是遍历场景中的每一个模型，计算一个模型的光照表现后再继续下一个模型的计算，根据深度测试的结果更新屏幕上最终像素显示的颜色。这种方法是很容易让人理解并实现的。但是当场景中的光照和模型数量变多的时候，模型重叠的区域会进行不必要的光照计算（被挡住的模型像素区域最终会被前面的模型遮挡，但是这篇被挡住的区域还是被计算了光照），而光照计算一般来说是渲染消耗的大头，这部分时间就被浪费了。\n\n而延迟渲染的想法则是将光照计算分成两部分。第一个部分叫做<strong>几何处理阶段</strong>（Geometry Pass），它先将光照计算所需要的模型信息（顶点位置、法线、颜色、材质属性等等）先渲染到多张贴图上（消耗低），经由深度检测保留最终在屏幕上显示的模型部分的这些信息。\n\n<!-- wp:image {\"sizeSlug\":\"large\",\"align\":\"center\"} -->\n<figure class=\"wp-block-image aligncenter size-large\"><img src=\"https://learnopengl-cn.github.io/img/05/08/deferred_g_buffer.png\" alt=\"\"/></figure>\n<!-- /wp:image -->\n\n\n第二部分叫做<strong>光照处理阶段</strong>（Lighting Pass），根据几何处理阶段保存的信息再去进行光照计算，这样就不会将算力浪费在计算被遮挡的模型部分的光照了，从而优化渲染的性能，也有赋予了能够更加方便的实现某些效果的能力（如SSAO）。\n\n<!-- wp:image {\"sizeSlug\":\"large\",\"align\":\"center\"} -->\n<figure class=\"wp-block-image aligncenter size-large\"><img src=\"https://learnopengl-cn.github.io/img/05/08/deferred_overview.png\" alt=\"\"/></figure>\n<!-- /wp:image -->\n\n# G缓冲\nG缓冲(G-buffer)是对所有用来储存光照相关的数据，并在最后的光照处理阶段中使用的所有纹理的总称。它是我们计算最终渲染输出中的缓存和中转站，为了实现延迟渲染，G-buffer中会包含如下几张纹理的数据：模型顶点位置数据；模型法线数据；模型漫反射颜色数据；材质数据（ao，roughness，metallic）等等。有了这些数据则能够实现Kong引擎的PBR光照计算，初始化G-buffer的代码如下：\n\n```c++\nvoid DeferBuffer::GenerateDeferRenderTextures(int width, int height)\n{\n\tglBindFramebuffer(GL_FRAMEBUFFER, g_buffer_);\n\n\t// 将当前视野的数据用贴图缓存\n\t// 位置数据\n\tglGenTextures(1, &g_position_);\n\tglBindTexture(GL_TEXTURE_2D, g_position_);\n\tglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA32F, width, height, 0, GL_RGBA, GL_FLOAT, NULL);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);\n\tglFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, g_position_, 0);\n\n\t// 法线数据\n\tglGenTextures(1, &g_normal_);\n\tglBindTexture(GL_TEXTURE_2D, g_normal_);\n\tglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA32F, width, height, 0, GL_RGBA, GL_FLOAT, NULL);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\tglFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, g_normal_, 0);\n\n\t// 顶点颜色数据\n\tglGenTextures(1, &g_albedo_);\n\tglBindTexture(GL_TEXTURE_2D, g_albedo_);\n\tglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, width, height, 0, GL_RGBA, GL_UNSIGNED_INT, NULL);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\tglFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, g_albedo_, 0);\n\n\t// orm数据（ao，roughness，metallic）\n\tglGenTextures(1, &g_orm_);\n\tglBindTexture(GL_TEXTURE_2D, g_orm_);\n\tglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, width, height, 0, GL_RGBA, GL_UNSIGNED_INT, NULL);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\tglFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT3, GL_TEXTURE_2D, g_orm_, 0);\n\n\t// 生成renderbuffer\n\tglGenRenderbuffers(1, &g_rbo_);\n\tglBindRenderbuffer(GL_RENDERBUFFER, g_rbo_);\n\tglRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, width, height);\n\tglFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, g_rbo_);\n\tglEnable(GL_DEPTH_TEST);\n\t\n\tunsigned int attachments[4] = {GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3};\n\tglDrawBuffers(4, attachments);\n\tglBindFramebuffer(GL_FRAMEBUFFER, 0);\n}\n```\n\n\n可以从上面的代码看到，我们利用了多渲染目标（multiple render targets）可以一次处理并输出到多个缓冲（GL_COLOR_ATTACHMENT0到3）。简化的几何处理着色器示例代码如下：\n\n```glsl\n// defer_geometry_pass.frag\nlayout(location = 0) out vec4 gPosition;\nlayout(location = 1) out vec4 gNormal;\nlayout(location = 2) out vec4 gAlbedo;\nlayout(location = 3) out vec4 gORM;\n\nin vec4 frag_pos;\nin vec3 frag_normal;\nin vec2 frag_uv;\n\nuniform vec4 albedo;    // color\nuniform float metallic;\nuniform float roughness;\nuniform float ao;\n\nvoid main()\n{\n    // 深度信息存储到position贴图的w值中\n    gPosition = frag_pos;\n    gNormal = vec4(frag_normal, 1.0);\n    gAlbedo = albedo;\n    gORM = vec4(ao, roughness, metallic, 1.0);\n}\n```\n\n上方的代码将我们所需要的世界坐标下的顶点坐标信息、法线信息、漫反射颜色和材质信息输出到了四张贴图。带着这四张贴图的信息，我们进入下一个阶段，光照处理阶段。下面是个简化的光照处理着色器代码：\n\n```glsl\nvoid main()\n{\n    vec3 frag_pos = texture(position_texture, TexCoords).xyz;\n    vec3 frag_normal = texture(normal_texture, TexCoords).rgb;\n    vec4 env_albedo = texture(albedo_texture, TexCoords);\n\n    vec3 orm = texture(orm_texture, TexCoords).rgb;\n    float ao = orm.x;\n    float env_roughness = orm.y;\n    float env_metallic = orm.z;\n\n    vec3 view = normalize(cam_pos - frag_pos);  //to_view\n\n    vec3 light_color = CalcLight(light_info, frag_normal, view,  frag_pos, material);\n\n    vec3 color = ambient + light_color;\n    FragColor = vec4(color, 1.0);\n}\n```\n\n# 结合延迟和正向渲染\n\n延迟渲染实现起来其实还是比较简单明了的，但是需要注意的是，有些材质并不能通过延迟渲染实现，比如说半透明这种需要进行alpha混合的材质，因此就会出现需要结合延迟渲染和正向渲染的情况。\n\n\n结合延迟渲染和正向渲染的时候，一般来说是先处理延迟渲染的部分。在处理完延迟渲染后，将延迟渲染的G-buffer的深度缓冲复制到最后输出屏幕的深度缓冲上（我这里最后会继续后处理，所以是会输出到后处理的FrameBuffer上）。如此一来，正向渲染的物体才可以和延迟渲染的场景有正确的深度遮挡结合，否则会出现正向渲染的物体永远在上的情况。实例代码如下所示：\n\n```c++\n// 需要将延迟渲染的深度缓冲复制到后面的后处理buffer上\nglBindFramebuffer(GL_READ_FRAMEBUFFER, defer_buffer_.g_buffer_);\nglBindFramebuffer(GL_DRAW_FRAMEBUFFER, post_process.GetScreenFrameBuffer());\nglBlitFramebuffer(0, 0, window_size.x, window_size.y, 0, 0, window_size.x, window_size.y, GL_DEPTH_BUFFER_BIT, \nGL_NEAREST);\n```\n\n# 延迟渲染的效能提升\n之前提过，延迟渲染最大的好处之一便是能够提升渲染的效率，这里大概做一个粗略的测试。下方是一个包含着1000个人物模型和200个点光源的场景，如果按照正常的正向渲染，这个场景在我的笔记本上的帧率大概在35左右：\n\n![非延迟渲染](no_defer_render.png)\n\n当使用延迟渲染的情况下，该场景的帧率可以提升到170左右：\n\n![延迟渲染](defer_render.png)\n\n当然上方这是个比较极端的场景，实际场景上可能不会有这么复杂的光源，以及模型可能不会像测试场景这样重叠，所以差距可能不会像测试场景那般明显。但是一般来说延迟渲染对渲染场景的性能提升会是比较客观的。\n\n## 基于延迟渲染的延伸\n延迟渲染的好处之一不仅仅体现在性能上，由于延迟渲染将很多有用的信息存储下来，基于延迟渲染我们可以实现非常多其他的效果。比如说屏幕空间环境光遮蔽SSAO（如下图）以及屏幕空间反射SSR等等，我计划在后面的文章详细介绍一下。\n\n![SSAO效果](ssao.png)\n","source":"_posts/defer-render.md","raw":"---\ntitle: 延迟渲染实现\ndate: 2024-10-19 17:18:41\ncategories: \n\t- 技术漫谈\ntags: [3D, render, 渲染, 编程]\nindex_img: /2024/10/19/defer-render/defer_render_banner.png\nbanner_img: /2024/10/19/defer-render/defer_render_banner.png\n---\n\n\n想要在Kong引擎里面实现的场景慢慢复杂了起来，光源和模型的数量从原先的十以内的数量增长到几十甚至几百的数量级，是时候接入延迟渲染的方法了。\n\n# 延迟渲染\n\n\n**延迟渲染**（Defer Rendering），或者**延迟着色法**（Defer Shading），是区别于**正向渲染**（Forward Shading）的一种计算场景光照的方式。\n\n正向渲染方法就是遍历场景中的每一个模型，计算一个模型的光照表现后再继续下一个模型的计算，根据深度测试的结果更新屏幕上最终像素显示的颜色。这种方法是很容易让人理解并实现的。但是当场景中的光照和模型数量变多的时候，模型重叠的区域会进行不必要的光照计算（被挡住的模型像素区域最终会被前面的模型遮挡，但是这篇被挡住的区域还是被计算了光照），而光照计算一般来说是渲染消耗的大头，这部分时间就被浪费了。\n\n而延迟渲染的想法则是将光照计算分成两部分。第一个部分叫做<strong>几何处理阶段</strong>（Geometry Pass），它先将光照计算所需要的模型信息（顶点位置、法线、颜色、材质属性等等）先渲染到多张贴图上（消耗低），经由深度检测保留最终在屏幕上显示的模型部分的这些信息。\n\n<!-- wp:image {\"sizeSlug\":\"large\",\"align\":\"center\"} -->\n<figure class=\"wp-block-image aligncenter size-large\"><img src=\"https://learnopengl-cn.github.io/img/05/08/deferred_g_buffer.png\" alt=\"\"/></figure>\n<!-- /wp:image -->\n\n\n第二部分叫做<strong>光照处理阶段</strong>（Lighting Pass），根据几何处理阶段保存的信息再去进行光照计算，这样就不会将算力浪费在计算被遮挡的模型部分的光照了，从而优化渲染的性能，也有赋予了能够更加方便的实现某些效果的能力（如SSAO）。\n\n<!-- wp:image {\"sizeSlug\":\"large\",\"align\":\"center\"} -->\n<figure class=\"wp-block-image aligncenter size-large\"><img src=\"https://learnopengl-cn.github.io/img/05/08/deferred_overview.png\" alt=\"\"/></figure>\n<!-- /wp:image -->\n\n# G缓冲\nG缓冲(G-buffer)是对所有用来储存光照相关的数据，并在最后的光照处理阶段中使用的所有纹理的总称。它是我们计算最终渲染输出中的缓存和中转站，为了实现延迟渲染，G-buffer中会包含如下几张纹理的数据：模型顶点位置数据；模型法线数据；模型漫反射颜色数据；材质数据（ao，roughness，metallic）等等。有了这些数据则能够实现Kong引擎的PBR光照计算，初始化G-buffer的代码如下：\n\n```c++\nvoid DeferBuffer::GenerateDeferRenderTextures(int width, int height)\n{\n\tglBindFramebuffer(GL_FRAMEBUFFER, g_buffer_);\n\n\t// 将当前视野的数据用贴图缓存\n\t// 位置数据\n\tglGenTextures(1, &g_position_);\n\tglBindTexture(GL_TEXTURE_2D, g_position_);\n\tglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA32F, width, height, 0, GL_RGBA, GL_FLOAT, NULL);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);\n\tglFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, g_position_, 0);\n\n\t// 法线数据\n\tglGenTextures(1, &g_normal_);\n\tglBindTexture(GL_TEXTURE_2D, g_normal_);\n\tglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA32F, width, height, 0, GL_RGBA, GL_FLOAT, NULL);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\tglFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, g_normal_, 0);\n\n\t// 顶点颜色数据\n\tglGenTextures(1, &g_albedo_);\n\tglBindTexture(GL_TEXTURE_2D, g_albedo_);\n\tglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, width, height, 0, GL_RGBA, GL_UNSIGNED_INT, NULL);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\tglFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, g_albedo_, 0);\n\n\t// orm数据（ao，roughness，metallic）\n\tglGenTextures(1, &g_orm_);\n\tglBindTexture(GL_TEXTURE_2D, g_orm_);\n\tglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, width, height, 0, GL_RGBA, GL_UNSIGNED_INT, NULL);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\tglFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT3, GL_TEXTURE_2D, g_orm_, 0);\n\n\t// 生成renderbuffer\n\tglGenRenderbuffers(1, &g_rbo_);\n\tglBindRenderbuffer(GL_RENDERBUFFER, g_rbo_);\n\tglRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, width, height);\n\tglFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, g_rbo_);\n\tglEnable(GL_DEPTH_TEST);\n\t\n\tunsigned int attachments[4] = {GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3};\n\tglDrawBuffers(4, attachments);\n\tglBindFramebuffer(GL_FRAMEBUFFER, 0);\n}\n```\n\n\n可以从上面的代码看到，我们利用了多渲染目标（multiple render targets）可以一次处理并输出到多个缓冲（GL_COLOR_ATTACHMENT0到3）。简化的几何处理着色器示例代码如下：\n\n```glsl\n// defer_geometry_pass.frag\nlayout(location = 0) out vec4 gPosition;\nlayout(location = 1) out vec4 gNormal;\nlayout(location = 2) out vec4 gAlbedo;\nlayout(location = 3) out vec4 gORM;\n\nin vec4 frag_pos;\nin vec3 frag_normal;\nin vec2 frag_uv;\n\nuniform vec4 albedo;    // color\nuniform float metallic;\nuniform float roughness;\nuniform float ao;\n\nvoid main()\n{\n    // 深度信息存储到position贴图的w值中\n    gPosition = frag_pos;\n    gNormal = vec4(frag_normal, 1.0);\n    gAlbedo = albedo;\n    gORM = vec4(ao, roughness, metallic, 1.0);\n}\n```\n\n上方的代码将我们所需要的世界坐标下的顶点坐标信息、法线信息、漫反射颜色和材质信息输出到了四张贴图。带着这四张贴图的信息，我们进入下一个阶段，光照处理阶段。下面是个简化的光照处理着色器代码：\n\n```glsl\nvoid main()\n{\n    vec3 frag_pos = texture(position_texture, TexCoords).xyz;\n    vec3 frag_normal = texture(normal_texture, TexCoords).rgb;\n    vec4 env_albedo = texture(albedo_texture, TexCoords);\n\n    vec3 orm = texture(orm_texture, TexCoords).rgb;\n    float ao = orm.x;\n    float env_roughness = orm.y;\n    float env_metallic = orm.z;\n\n    vec3 view = normalize(cam_pos - frag_pos);  //to_view\n\n    vec3 light_color = CalcLight(light_info, frag_normal, view,  frag_pos, material);\n\n    vec3 color = ambient + light_color;\n    FragColor = vec4(color, 1.0);\n}\n```\n\n# 结合延迟和正向渲染\n\n延迟渲染实现起来其实还是比较简单明了的，但是需要注意的是，有些材质并不能通过延迟渲染实现，比如说半透明这种需要进行alpha混合的材质，因此就会出现需要结合延迟渲染和正向渲染的情况。\n\n\n结合延迟渲染和正向渲染的时候，一般来说是先处理延迟渲染的部分。在处理完延迟渲染后，将延迟渲染的G-buffer的深度缓冲复制到最后输出屏幕的深度缓冲上（我这里最后会继续后处理，所以是会输出到后处理的FrameBuffer上）。如此一来，正向渲染的物体才可以和延迟渲染的场景有正确的深度遮挡结合，否则会出现正向渲染的物体永远在上的情况。实例代码如下所示：\n\n```c++\n// 需要将延迟渲染的深度缓冲复制到后面的后处理buffer上\nglBindFramebuffer(GL_READ_FRAMEBUFFER, defer_buffer_.g_buffer_);\nglBindFramebuffer(GL_DRAW_FRAMEBUFFER, post_process.GetScreenFrameBuffer());\nglBlitFramebuffer(0, 0, window_size.x, window_size.y, 0, 0, window_size.x, window_size.y, GL_DEPTH_BUFFER_BIT, \nGL_NEAREST);\n```\n\n# 延迟渲染的效能提升\n之前提过，延迟渲染最大的好处之一便是能够提升渲染的效率，这里大概做一个粗略的测试。下方是一个包含着1000个人物模型和200个点光源的场景，如果按照正常的正向渲染，这个场景在我的笔记本上的帧率大概在35左右：\n\n![非延迟渲染](no_defer_render.png)\n\n当使用延迟渲染的情况下，该场景的帧率可以提升到170左右：\n\n![延迟渲染](defer_render.png)\n\n当然上方这是个比较极端的场景，实际场景上可能不会有这么复杂的光源，以及模型可能不会像测试场景这样重叠，所以差距可能不会像测试场景那般明显。但是一般来说延迟渲染对渲染场景的性能提升会是比较客观的。\n\n## 基于延迟渲染的延伸\n延迟渲染的好处之一不仅仅体现在性能上，由于延迟渲染将很多有用的信息存储下来，基于延迟渲染我们可以实现非常多其他的效果。比如说屏幕空间环境光遮蔽SSAO（如下图）以及屏幕空间反射SSR等等，我计划在后面的文章详细介绍一下。\n\n![SSAO效果](ssao.png)\n","slug":"defer-render","published":1,"updated":"2024-10-19T09:43:16.358Z","comments":1,"layout":"post","photos":[],"_id":"cm34lv4qj000my0574r4r0g30","content":"<p>想要在Kong引擎里面实现的场景慢慢复杂了起来，光源和模型的数量从原先的十以内的数量增长到几十甚至几百的数量级，是时候接入延迟渲染的方法了。</p>\n<h1 id=\"延迟渲染\"><a href=\"#延迟渲染\" class=\"headerlink\" title=\"延迟渲染\"></a>延迟渲染</h1><p><strong>延迟渲染</strong>（Defer Rendering），或者<strong>延迟着色法</strong>（Defer Shading），是区别于<strong>正向渲染</strong>（Forward Shading）的一种计算场景光照的方式。</p>\n<p>正向渲染方法就是遍历场景中的每一个模型，计算一个模型的光照表现后再继续下一个模型的计算，根据深度测试的结果更新屏幕上最终像素显示的颜色。这种方法是很容易让人理解并实现的。但是当场景中的光照和模型数量变多的时候，模型重叠的区域会进行不必要的光照计算（被挡住的模型像素区域最终会被前面的模型遮挡，但是这篇被挡住的区域还是被计算了光照），而光照计算一般来说是渲染消耗的大头，这部分时间就被浪费了。</p>\n<p>而延迟渲染的想法则是将光照计算分成两部分。第一个部分叫做<strong>几何处理阶段</strong>（Geometry Pass），它先将光照计算所需要的模型信息（顶点位置、法线、颜色、材质属性等等）先渲染到多张贴图上（消耗低），经由深度检测保留最终在屏幕上显示的模型部分的这些信息。</p>\n<!-- wp:image {\"sizeSlug\":\"large\",\"align\":\"center\"} -->\n<figure class=\"wp-block-image aligncenter size-large\"><img src=\"https://learnopengl-cn.github.io/img/05/08/deferred_g_buffer.png\" alt=\"\"/></figure>\n<!-- /wp:image -->\n\n\n<p>第二部分叫做<strong>光照处理阶段</strong>（Lighting Pass），根据几何处理阶段保存的信息再去进行光照计算，这样就不会将算力浪费在计算被遮挡的模型部分的光照了，从而优化渲染的性能，也有赋予了能够更加方便的实现某些效果的能力（如SSAO）。</p>\n<!-- wp:image {\"sizeSlug\":\"large\",\"align\":\"center\"} -->\n<figure class=\"wp-block-image aligncenter size-large\"><img src=\"https://learnopengl-cn.github.io/img/05/08/deferred_overview.png\" alt=\"\"/></figure>\n<!-- /wp:image -->\n\n<h1 id=\"G缓冲\"><a href=\"#G缓冲\" class=\"headerlink\" title=\"G缓冲\"></a>G缓冲</h1><p>G缓冲(G-buffer)是对所有用来储存光照相关的数据，并在最后的光照处理阶段中使用的所有纹理的总称。它是我们计算最终渲染输出中的缓存和中转站，为了实现延迟渲染，G-buffer中会包含如下几张纹理的数据：模型顶点位置数据；模型法线数据；模型漫反射颜色数据；材质数据（ao，roughness，metallic）等等。有了这些数据则能够实现Kong引擎的PBR光照计算，初始化G-buffer的代码如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">DeferBuffer::GenerateDeferRenderTextures</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> width, <span class=\"hljs-type\">int</span> height)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_FRAMEBUFFER, g_buffer_);<br><br>\t<span class=\"hljs-comment\">// 将当前视野的数据用贴图缓存</span><br>\t<span class=\"hljs-comment\">// 位置数据</span><br>\t<span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;g_position_);<br>\t<span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D, g_position_);<br>\t<span class=\"hljs-built_in\">glTexImage2D</span>(GL_TEXTURE_2D, <span class=\"hljs-number\">0</span>, GL_RGBA32F, width, height, <span class=\"hljs-number\">0</span>, GL_RGBA, GL_FLOAT, <span class=\"hljs-literal\">NULL</span>);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br>\t<span class=\"hljs-built_in\">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, g_position_, <span class=\"hljs-number\">0</span>);<br><br>\t<span class=\"hljs-comment\">// 法线数据</span><br>\t<span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;g_normal_);<br>\t<span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D, g_normal_);<br>\t<span class=\"hljs-built_in\">glTexImage2D</span>(GL_TEXTURE_2D, <span class=\"hljs-number\">0</span>, GL_RGBA32F, width, height, <span class=\"hljs-number\">0</span>, GL_RGBA, GL_FLOAT, <span class=\"hljs-literal\">NULL</span>);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, g_normal_, <span class=\"hljs-number\">0</span>);<br><br>\t<span class=\"hljs-comment\">// 顶点颜色数据</span><br>\t<span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;g_albedo_);<br>\t<span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D, g_albedo_);<br>\t<span class=\"hljs-built_in\">glTexImage2D</span>(GL_TEXTURE_2D, <span class=\"hljs-number\">0</span>, GL_RGBA, width, height, <span class=\"hljs-number\">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class=\"hljs-literal\">NULL</span>);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, g_albedo_, <span class=\"hljs-number\">0</span>);<br><br>\t<span class=\"hljs-comment\">// orm数据（ao，roughness，metallic）</span><br>\t<span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;g_orm_);<br>\t<span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D, g_orm_);<br>\t<span class=\"hljs-built_in\">glTexImage2D</span>(GL_TEXTURE_2D, <span class=\"hljs-number\">0</span>, GL_RGBA, width, height, <span class=\"hljs-number\">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class=\"hljs-literal\">NULL</span>);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT3, GL_TEXTURE_2D, g_orm_, <span class=\"hljs-number\">0</span>);<br><br>\t<span class=\"hljs-comment\">// 生成renderbuffer</span><br>\t<span class=\"hljs-built_in\">glGenRenderbuffers</span>(<span class=\"hljs-number\">1</span>, &amp;g_rbo_);<br>\t<span class=\"hljs-built_in\">glBindRenderbuffer</span>(GL_RENDERBUFFER, g_rbo_);<br>\t<span class=\"hljs-built_in\">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, width, height);<br>\t<span class=\"hljs-built_in\">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, g_rbo_);<br>\t<span class=\"hljs-built_in\">glEnable</span>(GL_DEPTH_TEST);<br>\t<br>\t<span class=\"hljs-type\">unsigned</span> <span class=\"hljs-type\">int</span> attachments[<span class=\"hljs-number\">4</span>] = &#123;GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3&#125;;<br>\t<span class=\"hljs-built_in\">glDrawBuffers</span>(<span class=\"hljs-number\">4</span>, attachments);<br>\t<span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class=\"hljs-number\">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n\n<p>可以从上面的代码看到，我们利用了多渲染目标（multiple render targets）可以一次处理并输出到多个缓冲（GL_COLOR_ATTACHMENT0到3）。简化的几何处理着色器示例代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// defer_geometry_pass.frag</span><br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">location</span> = <span class=\"hljs-number\">0</span>) <span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> gPosition;<br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">location</span> = <span class=\"hljs-number\">1</span>) <span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> gNormal;<br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">location</span> = <span class=\"hljs-number\">2</span>) <span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> gAlbedo;<br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">location</span> = <span class=\"hljs-number\">3</span>) <span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> gORM;<br><br><span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec4</span> frag_pos;<br><span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec3</span> frag_normal;<br><span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec2</span> frag_uv;<br><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">vec4</span> albedo;    <span class=\"hljs-comment\">// color</span><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">float</span> metallic;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">float</span> roughness;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">float</span> ao;<br><br><span class=\"hljs-type\">void</span> main()<br>&#123;<br>    <span class=\"hljs-comment\">// 深度信息存储到position贴图的w值中</span><br>    gPosition = frag_pos;<br>    gNormal = <span class=\"hljs-type\">vec4</span>(frag_normal, <span class=\"hljs-number\">1.0</span>);<br>    gAlbedo = albedo;<br>    gORM = <span class=\"hljs-type\">vec4</span>(ao, roughness, metallic, <span class=\"hljs-number\">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>上方的代码将我们所需要的世界坐标下的顶点坐标信息、法线信息、漫反射颜色和材质信息输出到了四张贴图。带着这四张贴图的信息，我们进入下一个阶段，光照处理阶段。下面是个简化的光照处理着色器代码：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">void</span> main()<br>&#123;<br>    <span class=\"hljs-type\">vec3</span> frag_pos = <span class=\"hljs-built_in\">texture</span>(position_texture, TexCoords).xyz;<br>    <span class=\"hljs-type\">vec3</span> frag_normal = <span class=\"hljs-built_in\">texture</span>(normal_texture, TexCoords).rgb;<br>    <span class=\"hljs-type\">vec4</span> env_albedo = <span class=\"hljs-built_in\">texture</span>(albedo_texture, TexCoords);<br><br>    <span class=\"hljs-type\">vec3</span> orm = <span class=\"hljs-built_in\">texture</span>(orm_texture, TexCoords).rgb;<br>    <span class=\"hljs-type\">float</span> ao = orm.x;<br>    <span class=\"hljs-type\">float</span> env_roughness = orm.y;<br>    <span class=\"hljs-type\">float</span> env_metallic = orm.z;<br><br>    <span class=\"hljs-type\">vec3</span> view = <span class=\"hljs-built_in\">normalize</span>(cam_pos - frag_pos);  <span class=\"hljs-comment\">//to_view</span><br><br>    <span class=\"hljs-type\">vec3</span> light_color = CalcLight(light_info, frag_normal, view,  frag_pos, material);<br><br>    <span class=\"hljs-type\">vec3</span> color = ambient + light_color;<br>    FragColor = <span class=\"hljs-type\">vec4</span>(color, <span class=\"hljs-number\">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"结合延迟和正向渲染\"><a href=\"#结合延迟和正向渲染\" class=\"headerlink\" title=\"结合延迟和正向渲染\"></a>结合延迟和正向渲染</h1><p>延迟渲染实现起来其实还是比较简单明了的，但是需要注意的是，有些材质并不能通过延迟渲染实现，比如说半透明这种需要进行alpha混合的材质，因此就会出现需要结合延迟渲染和正向渲染的情况。</p>\n<p>结合延迟渲染和正向渲染的时候，一般来说是先处理延迟渲染的部分。在处理完延迟渲染后，将延迟渲染的G-buffer的深度缓冲复制到最后输出屏幕的深度缓冲上（我这里最后会继续后处理，所以是会输出到后处理的FrameBuffer上）。如此一来，正向渲染的物体才可以和延迟渲染的场景有正确的深度遮挡结合，否则会出现正向渲染的物体永远在上的情况。实例代码如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 需要将延迟渲染的深度缓冲复制到后面的后处理buffer上</span><br><span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_READ_FRAMEBUFFER, defer_buffer_.g_buffer_);<br><span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_DRAW_FRAMEBUFFER, post_process.<span class=\"hljs-built_in\">GetScreenFrameBuffer</span>());<br><span class=\"hljs-built_in\">glBlitFramebuffer</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, window_size.x, window_size.y, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, window_size.x, window_size.y, GL_DEPTH_BUFFER_BIT, <br>GL_NEAREST);<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"延迟渲染的效能提升\"><a href=\"#延迟渲染的效能提升\" class=\"headerlink\" title=\"延迟渲染的效能提升\"></a>延迟渲染的效能提升</h1><p>之前提过，延迟渲染最大的好处之一便是能够提升渲染的效率，这里大概做一个粗略的测试。下方是一个包含着1000个人物模型和200个点光源的场景，如果按照正常的正向渲染，这个场景在我的笔记本上的帧率大概在35左右：</p>\n<p><img src=\"/2024/10/19/defer-render/no_defer_render.png\" alt=\"非延迟渲染\"></p>\n<p>当使用延迟渲染的情况下，该场景的帧率可以提升到170左右：</p>\n<p><img src=\"/2024/10/19/defer-render/defer_render.png\" alt=\"延迟渲染\"></p>\n<p>当然上方这是个比较极端的场景，实际场景上可能不会有这么复杂的光源，以及模型可能不会像测试场景这样重叠，所以差距可能不会像测试场景那般明显。但是一般来说延迟渲染对渲染场景的性能提升会是比较客观的。</p>\n<h2 id=\"基于延迟渲染的延伸\"><a href=\"#基于延迟渲染的延伸\" class=\"headerlink\" title=\"基于延迟渲染的延伸\"></a>基于延迟渲染的延伸</h2><p>延迟渲染的好处之一不仅仅体现在性能上，由于延迟渲染将很多有用的信息存储下来，基于延迟渲染我们可以实现非常多其他的效果。比如说屏幕空间环境光遮蔽SSAO（如下图）以及屏幕空间反射SSR等等，我计划在后面的文章详细介绍一下。</p>\n<p><img src=\"/2024/10/19/defer-render/ssao.png\" alt=\"SSAO效果\"></p>\n","excerpt":"","more":"<p>想要在Kong引擎里面实现的场景慢慢复杂了起来，光源和模型的数量从原先的十以内的数量增长到几十甚至几百的数量级，是时候接入延迟渲染的方法了。</p>\n<h1 id=\"延迟渲染\"><a href=\"#延迟渲染\" class=\"headerlink\" title=\"延迟渲染\"></a>延迟渲染</h1><p><strong>延迟渲染</strong>（Defer Rendering），或者<strong>延迟着色法</strong>（Defer Shading），是区别于<strong>正向渲染</strong>（Forward Shading）的一种计算场景光照的方式。</p>\n<p>正向渲染方法就是遍历场景中的每一个模型，计算一个模型的光照表现后再继续下一个模型的计算，根据深度测试的结果更新屏幕上最终像素显示的颜色。这种方法是很容易让人理解并实现的。但是当场景中的光照和模型数量变多的时候，模型重叠的区域会进行不必要的光照计算（被挡住的模型像素区域最终会被前面的模型遮挡，但是这篇被挡住的区域还是被计算了光照），而光照计算一般来说是渲染消耗的大头，这部分时间就被浪费了。</p>\n<p>而延迟渲染的想法则是将光照计算分成两部分。第一个部分叫做<strong>几何处理阶段</strong>（Geometry Pass），它先将光照计算所需要的模型信息（顶点位置、法线、颜色、材质属性等等）先渲染到多张贴图上（消耗低），经由深度检测保留最终在屏幕上显示的模型部分的这些信息。</p>\n<!-- wp:image {\"sizeSlug\":\"large\",\"align\":\"center\"} -->\n<figure class=\"wp-block-image aligncenter size-large\"><img src=\"https://learnopengl-cn.github.io/img/05/08/deferred_g_buffer.png\" alt=\"\"/></figure>\n<!-- /wp:image -->\n\n\n<p>第二部分叫做<strong>光照处理阶段</strong>（Lighting Pass），根据几何处理阶段保存的信息再去进行光照计算，这样就不会将算力浪费在计算被遮挡的模型部分的光照了，从而优化渲染的性能，也有赋予了能够更加方便的实现某些效果的能力（如SSAO）。</p>\n<!-- wp:image {\"sizeSlug\":\"large\",\"align\":\"center\"} -->\n<figure class=\"wp-block-image aligncenter size-large\"><img src=\"https://learnopengl-cn.github.io/img/05/08/deferred_overview.png\" alt=\"\"/></figure>\n<!-- /wp:image -->\n\n<h1 id=\"G缓冲\"><a href=\"#G缓冲\" class=\"headerlink\" title=\"G缓冲\"></a>G缓冲</h1><p>G缓冲(G-buffer)是对所有用来储存光照相关的数据，并在最后的光照处理阶段中使用的所有纹理的总称。它是我们计算最终渲染输出中的缓存和中转站，为了实现延迟渲染，G-buffer中会包含如下几张纹理的数据：模型顶点位置数据；模型法线数据；模型漫反射颜色数据；材质数据（ao，roughness，metallic）等等。有了这些数据则能够实现Kong引擎的PBR光照计算，初始化G-buffer的代码如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">DeferBuffer::GenerateDeferRenderTextures</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span> width, <span class=\"hljs-type\">int</span> height)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_FRAMEBUFFER, g_buffer_);<br><br>\t<span class=\"hljs-comment\">// 将当前视野的数据用贴图缓存</span><br>\t<span class=\"hljs-comment\">// 位置数据</span><br>\t<span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;g_position_);<br>\t<span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D, g_position_);<br>\t<span class=\"hljs-built_in\">glTexImage2D</span>(GL_TEXTURE_2D, <span class=\"hljs-number\">0</span>, GL_RGBA32F, width, height, <span class=\"hljs-number\">0</span>, GL_RGBA, GL_FLOAT, <span class=\"hljs-literal\">NULL</span>);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br>\t<span class=\"hljs-built_in\">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, g_position_, <span class=\"hljs-number\">0</span>);<br><br>\t<span class=\"hljs-comment\">// 法线数据</span><br>\t<span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;g_normal_);<br>\t<span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D, g_normal_);<br>\t<span class=\"hljs-built_in\">glTexImage2D</span>(GL_TEXTURE_2D, <span class=\"hljs-number\">0</span>, GL_RGBA32F, width, height, <span class=\"hljs-number\">0</span>, GL_RGBA, GL_FLOAT, <span class=\"hljs-literal\">NULL</span>);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, g_normal_, <span class=\"hljs-number\">0</span>);<br><br>\t<span class=\"hljs-comment\">// 顶点颜色数据</span><br>\t<span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;g_albedo_);<br>\t<span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D, g_albedo_);<br>\t<span class=\"hljs-built_in\">glTexImage2D</span>(GL_TEXTURE_2D, <span class=\"hljs-number\">0</span>, GL_RGBA, width, height, <span class=\"hljs-number\">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class=\"hljs-literal\">NULL</span>);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, g_albedo_, <span class=\"hljs-number\">0</span>);<br><br>\t<span class=\"hljs-comment\">// orm数据（ao，roughness，metallic）</span><br>\t<span class=\"hljs-built_in\">glGenTextures</span>(<span class=\"hljs-number\">1</span>, &amp;g_orm_);<br>\t<span class=\"hljs-built_in\">glBindTexture</span>(GL_TEXTURE_2D, g_orm_);<br>\t<span class=\"hljs-built_in\">glTexImage2D</span>(GL_TEXTURE_2D, <span class=\"hljs-number\">0</span>, GL_RGBA, width, height, <span class=\"hljs-number\">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class=\"hljs-literal\">NULL</span>);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br>\t<span class=\"hljs-built_in\">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT3, GL_TEXTURE_2D, g_orm_, <span class=\"hljs-number\">0</span>);<br><br>\t<span class=\"hljs-comment\">// 生成renderbuffer</span><br>\t<span class=\"hljs-built_in\">glGenRenderbuffers</span>(<span class=\"hljs-number\">1</span>, &amp;g_rbo_);<br>\t<span class=\"hljs-built_in\">glBindRenderbuffer</span>(GL_RENDERBUFFER, g_rbo_);<br>\t<span class=\"hljs-built_in\">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, width, height);<br>\t<span class=\"hljs-built_in\">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, g_rbo_);<br>\t<span class=\"hljs-built_in\">glEnable</span>(GL_DEPTH_TEST);<br>\t<br>\t<span class=\"hljs-type\">unsigned</span> <span class=\"hljs-type\">int</span> attachments[<span class=\"hljs-number\">4</span>] = &#123;GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3&#125;;<br>\t<span class=\"hljs-built_in\">glDrawBuffers</span>(<span class=\"hljs-number\">4</span>, attachments);<br>\t<span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class=\"hljs-number\">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n\n<p>可以从上面的代码看到，我们利用了多渲染目标（multiple render targets）可以一次处理并输出到多个缓冲（GL_COLOR_ATTACHMENT0到3）。简化的几何处理着色器示例代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// defer_geometry_pass.frag</span><br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">location</span> = <span class=\"hljs-number\">0</span>) <span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> gPosition;<br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">location</span> = <span class=\"hljs-number\">1</span>) <span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> gNormal;<br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">location</span> = <span class=\"hljs-number\">2</span>) <span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> gAlbedo;<br><span class=\"hljs-keyword\">layout</span>(<span class=\"hljs-keyword\">location</span> = <span class=\"hljs-number\">3</span>) <span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> gORM;<br><br><span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec4</span> frag_pos;<br><span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec3</span> frag_normal;<br><span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec2</span> frag_uv;<br><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">vec4</span> albedo;    <span class=\"hljs-comment\">// color</span><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">float</span> metallic;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">float</span> roughness;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">float</span> ao;<br><br><span class=\"hljs-type\">void</span> main()<br>&#123;<br>    <span class=\"hljs-comment\">// 深度信息存储到position贴图的w值中</span><br>    gPosition = frag_pos;<br>    gNormal = <span class=\"hljs-type\">vec4</span>(frag_normal, <span class=\"hljs-number\">1.0</span>);<br>    gAlbedo = albedo;<br>    gORM = <span class=\"hljs-type\">vec4</span>(ao, roughness, metallic, <span class=\"hljs-number\">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>上方的代码将我们所需要的世界坐标下的顶点坐标信息、法线信息、漫反射颜色和材质信息输出到了四张贴图。带着这四张贴图的信息，我们进入下一个阶段，光照处理阶段。下面是个简化的光照处理着色器代码：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">void</span> main()<br>&#123;<br>    <span class=\"hljs-type\">vec3</span> frag_pos = <span class=\"hljs-built_in\">texture</span>(position_texture, TexCoords).xyz;<br>    <span class=\"hljs-type\">vec3</span> frag_normal = <span class=\"hljs-built_in\">texture</span>(normal_texture, TexCoords).rgb;<br>    <span class=\"hljs-type\">vec4</span> env_albedo = <span class=\"hljs-built_in\">texture</span>(albedo_texture, TexCoords);<br><br>    <span class=\"hljs-type\">vec3</span> orm = <span class=\"hljs-built_in\">texture</span>(orm_texture, TexCoords).rgb;<br>    <span class=\"hljs-type\">float</span> ao = orm.x;<br>    <span class=\"hljs-type\">float</span> env_roughness = orm.y;<br>    <span class=\"hljs-type\">float</span> env_metallic = orm.z;<br><br>    <span class=\"hljs-type\">vec3</span> view = <span class=\"hljs-built_in\">normalize</span>(cam_pos - frag_pos);  <span class=\"hljs-comment\">//to_view</span><br><br>    <span class=\"hljs-type\">vec3</span> light_color = CalcLight(light_info, frag_normal, view,  frag_pos, material);<br><br>    <span class=\"hljs-type\">vec3</span> color = ambient + light_color;<br>    FragColor = <span class=\"hljs-type\">vec4</span>(color, <span class=\"hljs-number\">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"结合延迟和正向渲染\"><a href=\"#结合延迟和正向渲染\" class=\"headerlink\" title=\"结合延迟和正向渲染\"></a>结合延迟和正向渲染</h1><p>延迟渲染实现起来其实还是比较简单明了的，但是需要注意的是，有些材质并不能通过延迟渲染实现，比如说半透明这种需要进行alpha混合的材质，因此就会出现需要结合延迟渲染和正向渲染的情况。</p>\n<p>结合延迟渲染和正向渲染的时候，一般来说是先处理延迟渲染的部分。在处理完延迟渲染后，将延迟渲染的G-buffer的深度缓冲复制到最后输出屏幕的深度缓冲上（我这里最后会继续后处理，所以是会输出到后处理的FrameBuffer上）。如此一来，正向渲染的物体才可以和延迟渲染的场景有正确的深度遮挡结合，否则会出现正向渲染的物体永远在上的情况。实例代码如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">// 需要将延迟渲染的深度缓冲复制到后面的后处理buffer上</span><br><span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_READ_FRAMEBUFFER, defer_buffer_.g_buffer_);<br><span class=\"hljs-built_in\">glBindFramebuffer</span>(GL_DRAW_FRAMEBUFFER, post_process.<span class=\"hljs-built_in\">GetScreenFrameBuffer</span>());<br><span class=\"hljs-built_in\">glBlitFramebuffer</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, window_size.x, window_size.y, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, window_size.x, window_size.y, GL_DEPTH_BUFFER_BIT, <br>GL_NEAREST);<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"延迟渲染的效能提升\"><a href=\"#延迟渲染的效能提升\" class=\"headerlink\" title=\"延迟渲染的效能提升\"></a>延迟渲染的效能提升</h1><p>之前提过，延迟渲染最大的好处之一便是能够提升渲染的效率，这里大概做一个粗略的测试。下方是一个包含着1000个人物模型和200个点光源的场景，如果按照正常的正向渲染，这个场景在我的笔记本上的帧率大概在35左右：</p>\n<p><img src=\"/2024/10/19/defer-render/no_defer_render.png\" alt=\"非延迟渲染\"></p>\n<p>当使用延迟渲染的情况下，该场景的帧率可以提升到170左右：</p>\n<p><img src=\"/2024/10/19/defer-render/defer_render.png\" alt=\"延迟渲染\"></p>\n<p>当然上方这是个比较极端的场景，实际场景上可能不会有这么复杂的光源，以及模型可能不会像测试场景这样重叠，所以差距可能不会像测试场景那般明显。但是一般来说延迟渲染对渲染场景的性能提升会是比较客观的。</p>\n<h2 id=\"基于延迟渲染的延伸\"><a href=\"#基于延迟渲染的延伸\" class=\"headerlink\" title=\"基于延迟渲染的延伸\"></a>基于延迟渲染的延伸</h2><p>延迟渲染的好处之一不仅仅体现在性能上，由于延迟渲染将很多有用的信息存储下来，基于延迟渲染我们可以实现非常多其他的效果。比如说屏幕空间环境光遮蔽SSAO（如下图）以及屏幕空间反射SSR等等，我计划在后面的文章详细介绍一下。</p>\n<p><img src=\"/2024/10/19/defer-render/ssao.png\" alt=\"SSAO效果\"></p>\n"},{"title":"景深的简单实现","date":"2024-10-28T14:11:58.000Z","index_img":"/2024/10/28/depth-of-field/game1.jpg","banner_img":"/2024/10/28/depth-of-field/game1.jpg","_content":"\n# 关于景深\n景深是一个常在摄像领域出现的词，它一般指的是沿着摄像机或其他成像器的拍摄方向上，能够取得清晰图像的成像所测定的被摄物体前后距离范围。用大白话就是说，拥有浅景深的成像器拍摄出来的效果，是只有焦点附近的图像是清晰的，其他地方的图像都是模糊的；而拥有大景深则可以在离焦点很远的地方也能有清晰的图像。\n\n![一张浅景深的照片](dof_butterfly.JPG)\n\n有了景深效果的图像可以有重点的突出核心想要表达的内容，不仅仅在摄影摄像的领域有非常多的应用，在游戏领域内也是应用广泛，可以表现出很独特的风格化美术效果（如八方旅人的浅景深效果）。\n\n![八方旅人](game1.jpg)\n\n下面我来介绍一种基础的景深效果实现，这个方法也在最近接入了[KongEngine](https://github.com/ruochenhua/KongEngine)\n\n\n# 渲染散景\n浅景深的主要应用是通过调整不同焦距上物体的成像清晰程度来突出渲染画面的重点。清晰的部分我们已经掌握了，就是正常的将场景渲染出来，那不清晰的部分（或者叫做散景）也有不少的实现方式，一般是通过模糊算法来实现。\n\n模糊的算法有很多种，比如box blur，gaussian blur等等，效果最好的是扩张模糊(dilate blur)，这也是我们会采取的方法。\n\n## 扩张模糊（dilate blur)\n扩张模糊它的主要方式，是在给定一个模糊的窗口下，取得这个窗口下的最亮的颜色记录下来，然后将这个最亮的颜色扩张到整个窗口。这样一来经过扩张模糊的画面会有一种亮晶晶，并且很柔和的效果，很适合作为散景的表现效果。\n\ndilate blur的计算也比较简单，首先我们定义此次blur的窗口大小已经采样的间隔大小。\n\n``` glsl\n// 窗口的大小，数值越大扩散越大，消耗越高 \nint size = 5;\t\n// 采样间隔的大小，数值越大扩散越大，效果降低\nfloat separation = 1.0;\n```\n\n在定义了窗口的尺寸之后，我们在窗口的范围内记录最亮的像素颜色，并保存下来。**窗口的形状不限**，可以是矩形，或者圆形。我们这里实现采取圆形的窗口。\n\n``` glsl\n// 渲染场景的尺寸\nvec2 tex_size = vec2(textureSize(scene_texture, 0).xy);\n// 获取场景的原本颜色\nFragColor = texture(scene_texture, TexCoords);\n\nif(size <= 0) return;\nfloat mx = 0.0;\nvec4 cmx = FragColor;\n\nfor(int i = -size; i <= size; ++i)\n{\n\tfor(int j = -size; j <= size; ++j)\n\t{\n\t\t// dilate的形状可以多样，如圆形，矩形等等，根据采样点的形状来决定\n\t\t// 这里使用圆形的dilate\n\t\tif(distance(vec2(i,j), vec2(0)) > size) continue;\n\n\t\t// 采样区域内点的颜色，不要越界出去了\n\t\tvec2 sample_coord = TexCoords + vec2(i, j)*separation/tex_size;\n\t\tif(sample_coord.x > 1.0 || sample_coord.x < 0.0 || sample_coord.y > 1.0 || sample_coord.y < 0.0)\n\t\t\t\tcontinue;\n\n\t\t// 拿到采样点\n\t\tvec4 c = texture(scene_texture, sample_coord);\n\n\t\t// 和目标颜色做点乘，得到一个灰度值\n\t\tfloat mxt = dot(c.rgb, vec3(0.3, 0.59, 0.11));\n\n\t\t// 保存区域内灰度值最大的颜色\n\t\tif(mxt > mx)\n\t\t{\n\t\t\tmx = mxt;\n\t\t\tcmx = c;\n\t\t}\n\t}\n}\n```\n\n这里我们计算最亮区域的方式是通过和一个目标颜色**(0.3, 0.59, 0.11)**来做点乘，当然也可以通过和其他的目标颜色，或者其他的方式来实现。\n\n最后，我们得到窗口区域内最亮的颜色，我们的最终颜色是原本颜色和最亮颜色的差值。\n```glsl\n// 模糊采样的颜色和原始颜色的mix上下限\nfloat min_threshold = 0.1;\nfloat max_threshold = 0.3;\n\n// 最终颜色是原来颜色和区域内灰度值最大的采样颜色的混合，有上下限做限制\nFragColor.rgb = mix(FragColor.rgb, cmx.rgb, smoothstep(min_threshold, max_threshold, mx));\n```\n这里我们还是采用了一个上下限，尽量控制增亮的程度。\n\n## 散景的效果\n这里给出经过扩张模糊得到的散景效果。下面这张图是扩张模糊之前的效果。\n![扩张模糊前](dilate_before.png)\n下面这张图是扩张模糊之后的效果。\n![扩张模糊后](dilate_after.png)\n\n当然在实际的场景中，我们可能不会开这么大的扩散效果，此处只是作为对比。\n\n# 结合场景\n好了，现在我们有原本场景的渲染效果和扩散后的效果，实现最终的景深效果需要将这两者结合起来。我们需要一种方法来决定画面上哪些部分是需要采用清晰的图像，哪些是采用模糊的图像。\n\n为了实现这个效果我们需要获得画面上每个点的深度，或者每个点的实际世界坐标。幸运的是，我们在实现[延迟渲染](https://ruochenhua.github.io/2024/10/19/defer-render/)的时候已经将这些存放到缓冲中去了，接下来就是实现景深效果了。\n\n最终的代码如下：\n``` glsl\nout vec4 FragColor;\nin vec2 TexCoords;\n\nuniform sampler2D scene_texture;\nuniform sampler2D dilate_texture;\nuniform sampler2D position_texture;\n\n// 焦点距离\nuniform float focus_distance = 3.0;\nuniform vec2 focus_threshold;\n// 景深的上下限\nfloat min_dist = focus_threshold.x;\nfloat max_dist = focus_threshold.y;\n\nvoid main()\n{\n    vec4 focus_color = texture(scene_texture, TexCoords);\n    vec4 out_of_focus_color = texture(dilate_texture, TexCoords);\n    vec3 scene_position = texture(position_texture, TexCoords).xyz; \n    \n\t// 这里采用了画面每个点的世界坐标和相机的距离作为判定模糊的标准\n\t// 当然用深度信息也是可以的，性能上也更好，这里为了代码展示更好理解\n    vec3 cam_pos = matrix_ubo.cam_pos.xyz;\n\t\n    float blur_amout = smoothstep(min_dist, max_dist, abs(focus_distance - distance(scene_position, cam_pos)));\n    \n\t// 最后的颜色是焦距内和散景的混合\n    FragColor = mix(focus_color, out_of_focus_color, blur_amout);\n}\n```\n\n这段代码理解起来应该没有什么太大的难度。\n\n# 最终效果\n这里展示一下最终的效果。\n\n![近焦点](dof_near.png)\n![远焦点](dof_far.png)\n\n上面两张图分别展示了不同焦点的景深的表现结果。可以明显看到不同景深效果的加入可以很容易的将画面上想要着重表达出来的部分勾勒出来。优秀的散景效果也能给画面增加不少美感（虽然我这个测试场景也没有什么美感可言...）。","source":"_posts/depth-of-field.md","raw":"---\ntitle: 景深的简单实现\ndate: 2024-10-28 22:11:58\ncategories: \n\t- 技术漫谈\ntags: [3D, render, 渲染, 编程]\nindex_img: /2024/10/28/depth-of-field/game1.jpg\nbanner_img: /2024/10/28/depth-of-field/game1.jpg\n---\n\n# 关于景深\n景深是一个常在摄像领域出现的词，它一般指的是沿着摄像机或其他成像器的拍摄方向上，能够取得清晰图像的成像所测定的被摄物体前后距离范围。用大白话就是说，拥有浅景深的成像器拍摄出来的效果，是只有焦点附近的图像是清晰的，其他地方的图像都是模糊的；而拥有大景深则可以在离焦点很远的地方也能有清晰的图像。\n\n![一张浅景深的照片](dof_butterfly.JPG)\n\n有了景深效果的图像可以有重点的突出核心想要表达的内容，不仅仅在摄影摄像的领域有非常多的应用，在游戏领域内也是应用广泛，可以表现出很独特的风格化美术效果（如八方旅人的浅景深效果）。\n\n![八方旅人](game1.jpg)\n\n下面我来介绍一种基础的景深效果实现，这个方法也在最近接入了[KongEngine](https://github.com/ruochenhua/KongEngine)\n\n\n# 渲染散景\n浅景深的主要应用是通过调整不同焦距上物体的成像清晰程度来突出渲染画面的重点。清晰的部分我们已经掌握了，就是正常的将场景渲染出来，那不清晰的部分（或者叫做散景）也有不少的实现方式，一般是通过模糊算法来实现。\n\n模糊的算法有很多种，比如box blur，gaussian blur等等，效果最好的是扩张模糊(dilate blur)，这也是我们会采取的方法。\n\n## 扩张模糊（dilate blur)\n扩张模糊它的主要方式，是在给定一个模糊的窗口下，取得这个窗口下的最亮的颜色记录下来，然后将这个最亮的颜色扩张到整个窗口。这样一来经过扩张模糊的画面会有一种亮晶晶，并且很柔和的效果，很适合作为散景的表现效果。\n\ndilate blur的计算也比较简单，首先我们定义此次blur的窗口大小已经采样的间隔大小。\n\n``` glsl\n// 窗口的大小，数值越大扩散越大，消耗越高 \nint size = 5;\t\n// 采样间隔的大小，数值越大扩散越大，效果降低\nfloat separation = 1.0;\n```\n\n在定义了窗口的尺寸之后，我们在窗口的范围内记录最亮的像素颜色，并保存下来。**窗口的形状不限**，可以是矩形，或者圆形。我们这里实现采取圆形的窗口。\n\n``` glsl\n// 渲染场景的尺寸\nvec2 tex_size = vec2(textureSize(scene_texture, 0).xy);\n// 获取场景的原本颜色\nFragColor = texture(scene_texture, TexCoords);\n\nif(size <= 0) return;\nfloat mx = 0.0;\nvec4 cmx = FragColor;\n\nfor(int i = -size; i <= size; ++i)\n{\n\tfor(int j = -size; j <= size; ++j)\n\t{\n\t\t// dilate的形状可以多样，如圆形，矩形等等，根据采样点的形状来决定\n\t\t// 这里使用圆形的dilate\n\t\tif(distance(vec2(i,j), vec2(0)) > size) continue;\n\n\t\t// 采样区域内点的颜色，不要越界出去了\n\t\tvec2 sample_coord = TexCoords + vec2(i, j)*separation/tex_size;\n\t\tif(sample_coord.x > 1.0 || sample_coord.x < 0.0 || sample_coord.y > 1.0 || sample_coord.y < 0.0)\n\t\t\t\tcontinue;\n\n\t\t// 拿到采样点\n\t\tvec4 c = texture(scene_texture, sample_coord);\n\n\t\t// 和目标颜色做点乘，得到一个灰度值\n\t\tfloat mxt = dot(c.rgb, vec3(0.3, 0.59, 0.11));\n\n\t\t// 保存区域内灰度值最大的颜色\n\t\tif(mxt > mx)\n\t\t{\n\t\t\tmx = mxt;\n\t\t\tcmx = c;\n\t\t}\n\t}\n}\n```\n\n这里我们计算最亮区域的方式是通过和一个目标颜色**(0.3, 0.59, 0.11)**来做点乘，当然也可以通过和其他的目标颜色，或者其他的方式来实现。\n\n最后，我们得到窗口区域内最亮的颜色，我们的最终颜色是原本颜色和最亮颜色的差值。\n```glsl\n// 模糊采样的颜色和原始颜色的mix上下限\nfloat min_threshold = 0.1;\nfloat max_threshold = 0.3;\n\n// 最终颜色是原来颜色和区域内灰度值最大的采样颜色的混合，有上下限做限制\nFragColor.rgb = mix(FragColor.rgb, cmx.rgb, smoothstep(min_threshold, max_threshold, mx));\n```\n这里我们还是采用了一个上下限，尽量控制增亮的程度。\n\n## 散景的效果\n这里给出经过扩张模糊得到的散景效果。下面这张图是扩张模糊之前的效果。\n![扩张模糊前](dilate_before.png)\n下面这张图是扩张模糊之后的效果。\n![扩张模糊后](dilate_after.png)\n\n当然在实际的场景中，我们可能不会开这么大的扩散效果，此处只是作为对比。\n\n# 结合场景\n好了，现在我们有原本场景的渲染效果和扩散后的效果，实现最终的景深效果需要将这两者结合起来。我们需要一种方法来决定画面上哪些部分是需要采用清晰的图像，哪些是采用模糊的图像。\n\n为了实现这个效果我们需要获得画面上每个点的深度，或者每个点的实际世界坐标。幸运的是，我们在实现[延迟渲染](https://ruochenhua.github.io/2024/10/19/defer-render/)的时候已经将这些存放到缓冲中去了，接下来就是实现景深效果了。\n\n最终的代码如下：\n``` glsl\nout vec4 FragColor;\nin vec2 TexCoords;\n\nuniform sampler2D scene_texture;\nuniform sampler2D dilate_texture;\nuniform sampler2D position_texture;\n\n// 焦点距离\nuniform float focus_distance = 3.0;\nuniform vec2 focus_threshold;\n// 景深的上下限\nfloat min_dist = focus_threshold.x;\nfloat max_dist = focus_threshold.y;\n\nvoid main()\n{\n    vec4 focus_color = texture(scene_texture, TexCoords);\n    vec4 out_of_focus_color = texture(dilate_texture, TexCoords);\n    vec3 scene_position = texture(position_texture, TexCoords).xyz; \n    \n\t// 这里采用了画面每个点的世界坐标和相机的距离作为判定模糊的标准\n\t// 当然用深度信息也是可以的，性能上也更好，这里为了代码展示更好理解\n    vec3 cam_pos = matrix_ubo.cam_pos.xyz;\n\t\n    float blur_amout = smoothstep(min_dist, max_dist, abs(focus_distance - distance(scene_position, cam_pos)));\n    \n\t// 最后的颜色是焦距内和散景的混合\n    FragColor = mix(focus_color, out_of_focus_color, blur_amout);\n}\n```\n\n这段代码理解起来应该没有什么太大的难度。\n\n# 最终效果\n这里展示一下最终的效果。\n\n![近焦点](dof_near.png)\n![远焦点](dof_far.png)\n\n上面两张图分别展示了不同焦点的景深的表现结果。可以明显看到不同景深效果的加入可以很容易的将画面上想要着重表达出来的部分勾勒出来。优秀的散景效果也能给画面增加不少美感（虽然我这个测试场景也没有什么美感可言...）。","slug":"depth-of-field","published":1,"updated":"2024-10-28T15:19:19.418Z","comments":1,"layout":"post","photos":[],"_id":"cm34lv4qj000py0576os04ic7","content":"<h1 id=\"关于景深\"><a href=\"#关于景深\" class=\"headerlink\" title=\"关于景深\"></a>关于景深</h1><p>景深是一个常在摄像领域出现的词，它一般指的是沿着摄像机或其他成像器的拍摄方向上，能够取得清晰图像的成像所测定的被摄物体前后距离范围。用大白话就是说，拥有浅景深的成像器拍摄出来的效果，是只有焦点附近的图像是清晰的，其他地方的图像都是模糊的；而拥有大景深则可以在离焦点很远的地方也能有清晰的图像。</p>\n<p><img src=\"/2024/10/28/depth-of-field/dof_butterfly.JPG\" alt=\"一张浅景深的照片\"></p>\n<p>有了景深效果的图像可以有重点的突出核心想要表达的内容，不仅仅在摄影摄像的领域有非常多的应用，在游戏领域内也是应用广泛，可以表现出很独特的风格化美术效果（如八方旅人的浅景深效果）。</p>\n<p><img src=\"/2024/10/28/depth-of-field/game1.jpg\" alt=\"八方旅人\"></p>\n<p>下面我来介绍一种基础的景深效果实现，这个方法也在最近接入了<a href=\"https://github.com/ruochenhua/KongEngine\">KongEngine</a></p>\n<h1 id=\"渲染散景\"><a href=\"#渲染散景\" class=\"headerlink\" title=\"渲染散景\"></a>渲染散景</h1><p>浅景深的主要应用是通过调整不同焦距上物体的成像清晰程度来突出渲染画面的重点。清晰的部分我们已经掌握了，就是正常的将场景渲染出来，那不清晰的部分（或者叫做散景）也有不少的实现方式，一般是通过模糊算法来实现。</p>\n<p>模糊的算法有很多种，比如box blur，gaussian blur等等，效果最好的是扩张模糊(dilate blur)，这也是我们会采取的方法。</p>\n<h2 id=\"扩张模糊（dilate-blur\"><a href=\"#扩张模糊（dilate-blur\" class=\"headerlink\" title=\"扩张模糊（dilate blur)\"></a>扩张模糊（dilate blur)</h2><p>扩张模糊它的主要方式，是在给定一个模糊的窗口下，取得这个窗口下的最亮的颜色记录下来，然后将这个最亮的颜色扩张到整个窗口。这样一来经过扩张模糊的画面会有一种亮晶晶，并且很柔和的效果，很适合作为散景的表现效果。</p>\n<p>dilate blur的计算也比较简单，首先我们定义此次blur的窗口大小已经采样的间隔大小。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 窗口的大小，数值越大扩散越大，消耗越高 </span><br><span class=\"hljs-type\">int</span> size = <span class=\"hljs-number\">5</span>;\t<br><span class=\"hljs-comment\">// 采样间隔的大小，数值越大扩散越大，效果降低</span><br><span class=\"hljs-type\">float</span> separation = <span class=\"hljs-number\">1.0</span>;<br></code></pre></td></tr></table></figure>\n\n<p>在定义了窗口的尺寸之后，我们在窗口的范围内记录最亮的像素颜色，并保存下来。<strong>窗口的形状不限</strong>，可以是矩形，或者圆形。我们这里实现采取圆形的窗口。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 渲染场景的尺寸</span><br><span class=\"hljs-type\">vec2</span> tex_size = <span class=\"hljs-type\">vec2</span>(<span class=\"hljs-built_in\">textureSize</span>(scene_texture, <span class=\"hljs-number\">0</span>).xy);<br><span class=\"hljs-comment\">// 获取场景的原本颜色</span><br>FragColor = <span class=\"hljs-built_in\">texture</span>(scene_texture, TexCoords);<br><br><span class=\"hljs-keyword\">if</span>(size &lt;= <span class=\"hljs-number\">0</span>) <span class=\"hljs-keyword\">return</span>;<br><span class=\"hljs-type\">float</span> mx = <span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-type\">vec4</span> cmx = FragColor;<br><br><span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = -size; i &lt;= size; ++i)<br>&#123;<br>\t<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> j = -size; j &lt;= size; ++j)<br>\t&#123;<br>\t\t<span class=\"hljs-comment\">// dilate的形状可以多样，如圆形，矩形等等，根据采样点的形状来决定</span><br>\t\t<span class=\"hljs-comment\">// 这里使用圆形的dilate</span><br>\t\t<span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">distance</span>(<span class=\"hljs-type\">vec2</span>(i,j), <span class=\"hljs-type\">vec2</span>(<span class=\"hljs-number\">0</span>)) &gt; size) <span class=\"hljs-keyword\">continue</span>;<br><br>\t\t<span class=\"hljs-comment\">// 采样区域内点的颜色，不要越界出去了</span><br>\t\t<span class=\"hljs-type\">vec2</span> sample_coord = TexCoords + <span class=\"hljs-type\">vec2</span>(i, j)*separation/tex_size;<br>\t\t<span class=\"hljs-keyword\">if</span>(sample_coord.x &gt; <span class=\"hljs-number\">1.0</span> || sample_coord.x &lt; <span class=\"hljs-number\">0.0</span> || sample_coord.y &gt; <span class=\"hljs-number\">1.0</span> || sample_coord.y &lt; <span class=\"hljs-number\">0.0</span>)<br>\t\t\t\t<span class=\"hljs-keyword\">continue</span>;<br><br>\t\t<span class=\"hljs-comment\">// 拿到采样点</span><br>\t\t<span class=\"hljs-type\">vec4</span> c = <span class=\"hljs-built_in\">texture</span>(scene_texture, sample_coord);<br><br>\t\t<span class=\"hljs-comment\">// 和目标颜色做点乘，得到一个灰度值</span><br>\t\t<span class=\"hljs-type\">float</span> mxt = <span class=\"hljs-built_in\">dot</span>(c.rgb, <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.59</span>, <span class=\"hljs-number\">0.11</span>));<br><br>\t\t<span class=\"hljs-comment\">// 保存区域内灰度值最大的颜色</span><br>\t\t<span class=\"hljs-keyword\">if</span>(mxt &gt; mx)<br>\t\t&#123;<br>\t\t\tmx = mxt;<br>\t\t\tcmx = c;<br>\t\t&#125;<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>这里我们计算最亮区域的方式是通过和一个目标颜色**(0.3, 0.59, 0.11)**来做点乘，当然也可以通过和其他的目标颜色，或者其他的方式来实现。</p>\n<p>最后，我们得到窗口区域内最亮的颜色，我们的最终颜色是原本颜色和最亮颜色的差值。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 模糊采样的颜色和原始颜色的mix上下限</span><br><span class=\"hljs-type\">float</span> min_threshold = <span class=\"hljs-number\">0.1</span>;<br><span class=\"hljs-type\">float</span> max_threshold = <span class=\"hljs-number\">0.3</span>;<br><br><span class=\"hljs-comment\">// 最终颜色是原来颜色和区域内灰度值最大的采样颜色的混合，有上下限做限制</span><br>FragColor.rgb = <span class=\"hljs-built_in\">mix</span>(FragColor.rgb, cmx.rgb, <span class=\"hljs-built_in\">smoothstep</span>(min_threshold, max_threshold, mx));<br></code></pre></td></tr></table></figure>\n<p>这里我们还是采用了一个上下限，尽量控制增亮的程度。</p>\n<h2 id=\"散景的效果\"><a href=\"#散景的效果\" class=\"headerlink\" title=\"散景的效果\"></a>散景的效果</h2><p>这里给出经过扩张模糊得到的散景效果。下面这张图是扩张模糊之前的效果。<br><img src=\"/2024/10/28/depth-of-field/dilate_before.png\" alt=\"扩张模糊前\"><br>下面这张图是扩张模糊之后的效果。<br><img src=\"/2024/10/28/depth-of-field/dilate_after.png\" alt=\"扩张模糊后\"></p>\n<p>当然在实际的场景中，我们可能不会开这么大的扩散效果，此处只是作为对比。</p>\n<h1 id=\"结合场景\"><a href=\"#结合场景\" class=\"headerlink\" title=\"结合场景\"></a>结合场景</h1><p>好了，现在我们有原本场景的渲染效果和扩散后的效果，实现最终的景深效果需要将这两者结合起来。我们需要一种方法来决定画面上哪些部分是需要采用清晰的图像，哪些是采用模糊的图像。</p>\n<p>为了实现这个效果我们需要获得画面上每个点的深度，或者每个点的实际世界坐标。幸运的是，我们在实现<a href=\"https://ruochenhua.github.io/2024/10/19/defer-render/\">延迟渲染</a>的时候已经将这些存放到缓冲中去了，接下来就是实现景深效果了。</p>\n<p>最终的代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> FragColor;<br><span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec2</span> TexCoords;<br><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">sampler2D</span> scene_texture;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">sampler2D</span> dilate_texture;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">sampler2D</span> position_texture;<br><br><span class=\"hljs-comment\">// 焦点距离</span><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">float</span> focus_distance = <span class=\"hljs-number\">3.0</span>;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">vec2</span> focus_threshold;<br><span class=\"hljs-comment\">// 景深的上下限</span><br><span class=\"hljs-type\">float</span> min_dist = focus_threshold.x;<br><span class=\"hljs-type\">float</span> max_dist = focus_threshold.y;<br><br><span class=\"hljs-type\">void</span> main()<br>&#123;<br>    <span class=\"hljs-type\">vec4</span> focus_color = <span class=\"hljs-built_in\">texture</span>(scene_texture, TexCoords);<br>    <span class=\"hljs-type\">vec4</span> out_of_focus_color = <span class=\"hljs-built_in\">texture</span>(dilate_texture, TexCoords);<br>    <span class=\"hljs-type\">vec3</span> scene_position = <span class=\"hljs-built_in\">texture</span>(position_texture, TexCoords).xyz; <br>    <br>\t<span class=\"hljs-comment\">// 这里采用了画面每个点的世界坐标和相机的距离作为判定模糊的标准</span><br>\t<span class=\"hljs-comment\">// 当然用深度信息也是可以的，性能上也更好，这里为了代码展示更好理解</span><br>    <span class=\"hljs-type\">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br>\t<br>    <span class=\"hljs-type\">float</span> blur_amout = <span class=\"hljs-built_in\">smoothstep</span>(min_dist, max_dist, <span class=\"hljs-built_in\">abs</span>(focus_distance - <span class=\"hljs-built_in\">distance</span>(scene_position, cam_pos)));<br>    <br>\t<span class=\"hljs-comment\">// 最后的颜色是焦距内和散景的混合</span><br>    FragColor = <span class=\"hljs-built_in\">mix</span>(focus_color, out_of_focus_color, blur_amout);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>这段代码理解起来应该没有什么太大的难度。</p>\n<h1 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果\"></a>最终效果</h1><p>这里展示一下最终的效果。</p>\n<p><img src=\"/2024/10/28/depth-of-field/dof_near.png\" alt=\"近焦点\"><br><img src=\"/2024/10/28/depth-of-field/dof_far.png\" alt=\"远焦点\"></p>\n<p>上面两张图分别展示了不同焦点的景深的表现结果。可以明显看到不同景深效果的加入可以很容易的将画面上想要着重表达出来的部分勾勒出来。优秀的散景效果也能给画面增加不少美感（虽然我这个测试场景也没有什么美感可言…）。</p>\n","excerpt":"","more":"<h1 id=\"关于景深\"><a href=\"#关于景深\" class=\"headerlink\" title=\"关于景深\"></a>关于景深</h1><p>景深是一个常在摄像领域出现的词，它一般指的是沿着摄像机或其他成像器的拍摄方向上，能够取得清晰图像的成像所测定的被摄物体前后距离范围。用大白话就是说，拥有浅景深的成像器拍摄出来的效果，是只有焦点附近的图像是清晰的，其他地方的图像都是模糊的；而拥有大景深则可以在离焦点很远的地方也能有清晰的图像。</p>\n<p><img src=\"/2024/10/28/depth-of-field/dof_butterfly.JPG\" alt=\"一张浅景深的照片\"></p>\n<p>有了景深效果的图像可以有重点的突出核心想要表达的内容，不仅仅在摄影摄像的领域有非常多的应用，在游戏领域内也是应用广泛，可以表现出很独特的风格化美术效果（如八方旅人的浅景深效果）。</p>\n<p><img src=\"/2024/10/28/depth-of-field/game1.jpg\" alt=\"八方旅人\"></p>\n<p>下面我来介绍一种基础的景深效果实现，这个方法也在最近接入了<a href=\"https://github.com/ruochenhua/KongEngine\">KongEngine</a></p>\n<h1 id=\"渲染散景\"><a href=\"#渲染散景\" class=\"headerlink\" title=\"渲染散景\"></a>渲染散景</h1><p>浅景深的主要应用是通过调整不同焦距上物体的成像清晰程度来突出渲染画面的重点。清晰的部分我们已经掌握了，就是正常的将场景渲染出来，那不清晰的部分（或者叫做散景）也有不少的实现方式，一般是通过模糊算法来实现。</p>\n<p>模糊的算法有很多种，比如box blur，gaussian blur等等，效果最好的是扩张模糊(dilate blur)，这也是我们会采取的方法。</p>\n<h2 id=\"扩张模糊（dilate-blur\"><a href=\"#扩张模糊（dilate-blur\" class=\"headerlink\" title=\"扩张模糊（dilate blur)\"></a>扩张模糊（dilate blur)</h2><p>扩张模糊它的主要方式，是在给定一个模糊的窗口下，取得这个窗口下的最亮的颜色记录下来，然后将这个最亮的颜色扩张到整个窗口。这样一来经过扩张模糊的画面会有一种亮晶晶，并且很柔和的效果，很适合作为散景的表现效果。</p>\n<p>dilate blur的计算也比较简单，首先我们定义此次blur的窗口大小已经采样的间隔大小。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 窗口的大小，数值越大扩散越大，消耗越高 </span><br><span class=\"hljs-type\">int</span> size = <span class=\"hljs-number\">5</span>;\t<br><span class=\"hljs-comment\">// 采样间隔的大小，数值越大扩散越大，效果降低</span><br><span class=\"hljs-type\">float</span> separation = <span class=\"hljs-number\">1.0</span>;<br></code></pre></td></tr></table></figure>\n\n<p>在定义了窗口的尺寸之后，我们在窗口的范围内记录最亮的像素颜色，并保存下来。<strong>窗口的形状不限</strong>，可以是矩形，或者圆形。我们这里实现采取圆形的窗口。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 渲染场景的尺寸</span><br><span class=\"hljs-type\">vec2</span> tex_size = <span class=\"hljs-type\">vec2</span>(<span class=\"hljs-built_in\">textureSize</span>(scene_texture, <span class=\"hljs-number\">0</span>).xy);<br><span class=\"hljs-comment\">// 获取场景的原本颜色</span><br>FragColor = <span class=\"hljs-built_in\">texture</span>(scene_texture, TexCoords);<br><br><span class=\"hljs-keyword\">if</span>(size &lt;= <span class=\"hljs-number\">0</span>) <span class=\"hljs-keyword\">return</span>;<br><span class=\"hljs-type\">float</span> mx = <span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-type\">vec4</span> cmx = FragColor;<br><br><span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> i = -size; i &lt;= size; ++i)<br>&#123;<br>\t<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-type\">int</span> j = -size; j &lt;= size; ++j)<br>\t&#123;<br>\t\t<span class=\"hljs-comment\">// dilate的形状可以多样，如圆形，矩形等等，根据采样点的形状来决定</span><br>\t\t<span class=\"hljs-comment\">// 这里使用圆形的dilate</span><br>\t\t<span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">distance</span>(<span class=\"hljs-type\">vec2</span>(i,j), <span class=\"hljs-type\">vec2</span>(<span class=\"hljs-number\">0</span>)) &gt; size) <span class=\"hljs-keyword\">continue</span>;<br><br>\t\t<span class=\"hljs-comment\">// 采样区域内点的颜色，不要越界出去了</span><br>\t\t<span class=\"hljs-type\">vec2</span> sample_coord = TexCoords + <span class=\"hljs-type\">vec2</span>(i, j)*separation/tex_size;<br>\t\t<span class=\"hljs-keyword\">if</span>(sample_coord.x &gt; <span class=\"hljs-number\">1.0</span> || sample_coord.x &lt; <span class=\"hljs-number\">0.0</span> || sample_coord.y &gt; <span class=\"hljs-number\">1.0</span> || sample_coord.y &lt; <span class=\"hljs-number\">0.0</span>)<br>\t\t\t\t<span class=\"hljs-keyword\">continue</span>;<br><br>\t\t<span class=\"hljs-comment\">// 拿到采样点</span><br>\t\t<span class=\"hljs-type\">vec4</span> c = <span class=\"hljs-built_in\">texture</span>(scene_texture, sample_coord);<br><br>\t\t<span class=\"hljs-comment\">// 和目标颜色做点乘，得到一个灰度值</span><br>\t\t<span class=\"hljs-type\">float</span> mxt = <span class=\"hljs-built_in\">dot</span>(c.rgb, <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.59</span>, <span class=\"hljs-number\">0.11</span>));<br><br>\t\t<span class=\"hljs-comment\">// 保存区域内灰度值最大的颜色</span><br>\t\t<span class=\"hljs-keyword\">if</span>(mxt &gt; mx)<br>\t\t&#123;<br>\t\t\tmx = mxt;<br>\t\t\tcmx = c;<br>\t\t&#125;<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>这里我们计算最亮区域的方式是通过和一个目标颜色**(0.3, 0.59, 0.11)**来做点乘，当然也可以通过和其他的目标颜色，或者其他的方式来实现。</p>\n<p>最后，我们得到窗口区域内最亮的颜色，我们的最终颜色是原本颜色和最亮颜色的差值。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 模糊采样的颜色和原始颜色的mix上下限</span><br><span class=\"hljs-type\">float</span> min_threshold = <span class=\"hljs-number\">0.1</span>;<br><span class=\"hljs-type\">float</span> max_threshold = <span class=\"hljs-number\">0.3</span>;<br><br><span class=\"hljs-comment\">// 最终颜色是原来颜色和区域内灰度值最大的采样颜色的混合，有上下限做限制</span><br>FragColor.rgb = <span class=\"hljs-built_in\">mix</span>(FragColor.rgb, cmx.rgb, <span class=\"hljs-built_in\">smoothstep</span>(min_threshold, max_threshold, mx));<br></code></pre></td></tr></table></figure>\n<p>这里我们还是采用了一个上下限，尽量控制增亮的程度。</p>\n<h2 id=\"散景的效果\"><a href=\"#散景的效果\" class=\"headerlink\" title=\"散景的效果\"></a>散景的效果</h2><p>这里给出经过扩张模糊得到的散景效果。下面这张图是扩张模糊之前的效果。<br><img src=\"/2024/10/28/depth-of-field/dilate_before.png\" alt=\"扩张模糊前\"><br>下面这张图是扩张模糊之后的效果。<br><img src=\"/2024/10/28/depth-of-field/dilate_after.png\" alt=\"扩张模糊后\"></p>\n<p>当然在实际的场景中，我们可能不会开这么大的扩散效果，此处只是作为对比。</p>\n<h1 id=\"结合场景\"><a href=\"#结合场景\" class=\"headerlink\" title=\"结合场景\"></a>结合场景</h1><p>好了，现在我们有原本场景的渲染效果和扩散后的效果，实现最终的景深效果需要将这两者结合起来。我们需要一种方法来决定画面上哪些部分是需要采用清晰的图像，哪些是采用模糊的图像。</p>\n<p>为了实现这个效果我们需要获得画面上每个点的深度，或者每个点的实际世界坐标。幸运的是，我们在实现<a href=\"https://ruochenhua.github.io/2024/10/19/defer-render/\">延迟渲染</a>的时候已经将这些存放到缓冲中去了，接下来就是实现景深效果了。</p>\n<p>最终的代码如下：</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-keyword\">out</span> <span class=\"hljs-type\">vec4</span> FragColor;<br><span class=\"hljs-keyword\">in</span> <span class=\"hljs-type\">vec2</span> TexCoords;<br><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">sampler2D</span> scene_texture;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">sampler2D</span> dilate_texture;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">sampler2D</span> position_texture;<br><br><span class=\"hljs-comment\">// 焦点距离</span><br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">float</span> focus_distance = <span class=\"hljs-number\">3.0</span>;<br><span class=\"hljs-keyword\">uniform</span> <span class=\"hljs-type\">vec2</span> focus_threshold;<br><span class=\"hljs-comment\">// 景深的上下限</span><br><span class=\"hljs-type\">float</span> min_dist = focus_threshold.x;<br><span class=\"hljs-type\">float</span> max_dist = focus_threshold.y;<br><br><span class=\"hljs-type\">void</span> main()<br>&#123;<br>    <span class=\"hljs-type\">vec4</span> focus_color = <span class=\"hljs-built_in\">texture</span>(scene_texture, TexCoords);<br>    <span class=\"hljs-type\">vec4</span> out_of_focus_color = <span class=\"hljs-built_in\">texture</span>(dilate_texture, TexCoords);<br>    <span class=\"hljs-type\">vec3</span> scene_position = <span class=\"hljs-built_in\">texture</span>(position_texture, TexCoords).xyz; <br>    <br>\t<span class=\"hljs-comment\">// 这里采用了画面每个点的世界坐标和相机的距离作为判定模糊的标准</span><br>\t<span class=\"hljs-comment\">// 当然用深度信息也是可以的，性能上也更好，这里为了代码展示更好理解</span><br>    <span class=\"hljs-type\">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br>\t<br>    <span class=\"hljs-type\">float</span> blur_amout = <span class=\"hljs-built_in\">smoothstep</span>(min_dist, max_dist, <span class=\"hljs-built_in\">abs</span>(focus_distance - <span class=\"hljs-built_in\">distance</span>(scene_position, cam_pos)));<br>    <br>\t<span class=\"hljs-comment\">// 最后的颜色是焦距内和散景的混合</span><br>    FragColor = <span class=\"hljs-built_in\">mix</span>(focus_color, out_of_focus_color, blur_amout);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>这段代码理解起来应该没有什么太大的难度。</p>\n<h1 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果\"></a>最终效果</h1><p>这里展示一下最终的效果。</p>\n<p><img src=\"/2024/10/28/depth-of-field/dof_near.png\" alt=\"近焦点\"><br><img src=\"/2024/10/28/depth-of-field/dof_far.png\" alt=\"远焦点\"></p>\n<p>上面两张图分别展示了不同焦点的景深的表现结果。可以明显看到不同景深效果的加入可以很容易的将画面上想要着重表达出来的部分勾勒出来。优秀的散景效果也能给画面增加不少美感（虽然我这个测试场景也没有什么美感可言…）。</p>\n"},{"title":"基于单次散射的天空大气渲染方法","date":"2024-10-15T14:03:02.000Z","index_img":"/2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.png","banner_img":"/2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.png","_content":"\n\n最近KongEngine实现了IBL(Image Based Lighting)，可以将HDR环境贴图映射作为3D场景的环境。\n\n![KongEngine的IBL效果](kong-screen-shot.png)\n\n在实现了IBL之后我又产生了一个想法，能否实现类似UE中的大气环境的渲染效果呢？我尝试去寻找答案，发现如果要完全复刻UE中的效果确实需要一定的功夫的，但是最基础的天空大气渲染并没有想象中那么复杂，于是我便花了点时间在KongEngine中实现了这个功能。\n\n![KongEngine天空大气效果](single-scatter-atmosphere.png)\n\n我打算将这个方法的基础思想和实现在此简单记录一下。\n\n# 单次散射模型\n星球的大气层是一种参与性介质，和在真空环境不同，光在大气层中传播的时候会因为大气中的微小颗粒（水、灰尘等等）发生散射（折射、反射）和吸收等情况。因此我们看向空中的一个点的时候，这个点的颜色是光经过多次散射得到的结果。\n\n光到达我们眼睛之前经过多少次反射和折射是不一定的，在实时渲染的需求下计算太多次光的变化显然也是不显示的。最简单的方法，是使用单次散射模型：我们假定光在进入我们眼睛之前，有且只发生了一次散射。光一般在第一次散射的时候，还会有最多的能量剩余，后面的多次散射能力相对少，对最后效果的呈现也影响不大，因此这种模型可以在保证性能的情况下，还有不错的效果。\n\n![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_02.png)\n\n除了散射，光在传播的时候会被大气吸收。一般来说，如果在一个均匀的介质中传播的话，光的被吸收的部分和介质的密度，以及传播的路径长度正相关。放到单散射模型的例子中，就是需要计算光在散射前和散射后的路径上，被吸收了多少能量。\n![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_07.png)\n\n按照上面的图，假设相机在A点，观察方向为AB，其中有一束光在P点发生散射后沿着PA进入相机。如果我们知道了光线损耗和距离相关的公式，那么似乎是只要计算出CP和PA的长度，在带入公式后就可以得到光该路径上传播后的最终能量了。\n\n![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_10a.png)\n\n但是对于大气层来说，它的密度并不是均匀的，而是和大气层距离地面的高度相关。所以在计算CP段光线损耗的时候，我们需要将这段距离分为多个小段，每个小段的损耗公式带入对应平均高度，在最后将所有结果相加才。小段划分的越密集，则结果越准确。\n\n如果我们还要考虑大气中的其他因素，比如说大气中的云层，在这些区域中光的损耗就不仅仅是和高度相关了。\n\n另外一点就是，当我们考虑AB方向的光线时，它的最终效果，是在大气层内的所有AB连线上面的点的散射结果的总和（P0、P1、P2...Pn），因此我们也同样的需要对AB线段进行分段采样并将结果叠加。AB线段上的每一个采样结果按照上面所描述的计算单一P点的方式。\n\n![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_08a.png)\n\n以上便是大气单次散射模型的基本思路。\n\n# 散射的计算\n之前我们提到了计算光的散射，这里我们介绍一下散射的相关计算。会提及一些公式，但是不会做过多的数学推导工作，对推导过程感兴趣的可以看一下文章中的参考资料。\n\n一般来说，天空大气的散射主要包括两种，分别是**瑞利散射**和**米氏散射**。\n\n - 瑞利散射是当光线通过介质中的微小颗粒或分子时发生的散射现象。由于颗粒或分子的尺寸远小于光的波长，不同波长的光线会以不同的角度散射，一个最经典的案例就是因为蓝色的波长是较短的，所以蓝色很容易发生瑞利散射，导致天空呈现蓝色。\n - 米氏散射则一般由空气中含有的较大颗粒的介质，如气溶胶、灰尘、水滴等引起。和瑞利散射不同的是，米氏散射和光的波长关系并不大。\n ![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_13.png)\n\n那么根据前面的模型思路，光在P点上发生了散射，其中一部分能量沿着PA方向进入相机的实现。获取这一部分能量的计算函数被称之为<strong>相位函数（Phase Function）</strong>。相位函数是用来描述，当光线发生散射的情况时，某个方向（一般是和原光线方向的夹角）占原光线的能量的比例。瑞利散射和米氏散射的相位函数是不同的，同一种散射的相位函数也会有不同的方法进行拟合，这里我不想去做过多的公式推导的工作，有兴趣的可以去查看[参考资料](https://patapom.com/topics/Revision2013/Revision%202013%20-%20Real-time%20Volumetric%20Rendering%20Course%20Notes.pdf)的推导过程。\n\n下方是瑞利散射的相位函数，theta是原光线方向和目标方向的夹角：\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mtable displaystyle=\"true\" columnalign=\"right left right\" columnspacing=\"0em 2em\" rowspacing=\"3pt\">\n    <mtr>\n      <mtd>\n        <mi>P</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>&#x3B8;</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mtd>        \n      <mtd>\n        <mi></mi>\n        <mo>=</mo>\n        <mfrac>\n          <mn>3</mn>\n          <mrow>\n            <mn>16</mn>\n            <mi>&#x3C0;</mi>\n          </mrow>\n        </mfrac>\n        <mo stretchy=\"false\">(</mo>\n        <mn>1</mn>\n        <mo>+</mo>\n        <mi>c</mi>\n        <mi>o</mi>\n        <msup>\n          <mi>s</mi>\n          <mn>2</mn>\n        </msup>\n        <mi>&#x3B8;</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mtd>\n    </mtr>\n  </mtable>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n下方是米氏散射的相位函数，这里使用的是[Henyey-Greenstein函数](https://omlc.org/classroom/ece532/class3/hg.html)来近似。\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">  <mi>P</mi>  <mo stretchy=\"false\">(</mo>  <mi>&#x3B8;</mi>  <mo stretchy=\"false\">)</mo>  <mo>=</mo>  <mfrac>    <mrow>      <mn>1</mn>      <mo>&#x2212;</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>    <mrow>      <mn>4</mn>      <mi>&#x3C0;</mi>      <mo stretchy=\"false\">(</mo>      <mn>1</mn>      <mo>+</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>      <mo>&#x2212;</mo>      <mn>2</mn>      <mi>g</mi>      <mi>c</mi>      <mi>o</mi>      <mi>s</mi>      <mo stretchy=\"false\">(</mo>      <mi>&#x3B8;</mi>      <mo stretchy=\"false\">)</mo>      <msup>        <mo stretchy=\"false\">)</mo>        <mrow>          <mn>3</mn>          <mrow>            <mo>/</mo>          </mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>  </mfrac></math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>好了，现在我们知道了如何计算光线在P点的散射行为。剩下的工作就是需要计算光线在传播过程的损耗了。这一部分的计算方法称之为<strong>衰减系数</strong>，或者<strong>消光系数</strong>。消光系数中的一部分，需要对光线在传播的路线的长度和空气密度进行积分。在程序中的表示就是将光的传播路径分为小段，将每一小段的长度和平均密度（或者小段中点的介质密度）相乘而得到，这个结果我们称之为<strong>光学距离（Optical Depth）</strong>。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>衰减系数的计算公式如下，红色部分代表的是在海拔为h的散射系数。他可以分解为在海平面上的散射系数乘以在海拔h的介质密度。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"#00AAFF\">\n    <mi>T</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>P</mi>\n    <mi>A</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n<mstyle mathcolor=\"#00AA00\">\n  <mi>exp</mi>\n</mstyle>\n  <mrow data-mjx-texclass=\"ORD\">\n    <mo>&#x2212;</mo>\n    <msubsup>\n      <mo data-mjx-texclass=\"OP\">&#x222B;</mo>\n      <mi>P</mi>\n      <mi>A</mi>\n    </msubsup>\n    <mrow data-mjx-texclass=\"ORD\">\n      <mstyle mathcolor=\"Red\">\n        <mi>&#x3B2;</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>&#x3BB;</mi>\n        <mo>,</mo>\n        <mi>h</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mstyle>\n    </mrow>\n    <mi>d</mi>\n    <mi>s</mi>\n  </mrow>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>分解出来后得到的结果如下，其中红色的部分代表的意思是在海平面的散射系数，是一个常量，黄色部分代表了在海拔为h的介质的密度。这个公式的积分便是针对AP路线上的介质密度，其结果也就是光学距离。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"#00AAFF\">\n    <mi>T</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>P</mi>\n    <mi>A</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n    <mstyle mathcolor=\"#00AA00\">\n      <mi>exp</mi>\n    </mstyle>\n  <mrow data-mjx-texclass=\"ORD\">\n    <mo>&#x2212;</mo>\n    <mstyle mathcolor=\"Red\">\n      <mi>&#x3B2;</mi>\n      <mo stretchy=\"false\">(</mo>\n      <mi>&#x3BB;</mi>\n      <mo stretchy=\"false\">)</mo>\n    </mstyle>\n    <msubsup>\n      <mo data-mjx-texclass=\"OP\">&#x222B;</mo>\n      <mi>P</mi>\n      <mi>A</mi>\n    </msubsup>\n    <mrow data-mjx-texclass=\"ORD\">\n      <mstyle mathcolor=\"Gold\">\n        <mi>&#x3C1;</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>h</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mstyle>\n    </mrow>\n    <mi>d</mi>\n    <mi>s</mi>\n  </mrow>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>介质密度的计算公式如下，其中H代表的是一个基准海拔，是一个常量。不同散射的基准海拔有所不同，瑞利散射的基准海拔是*8500*，而米氏散射的基准海拔是*1200*。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"Gold\">\n    <mi>&#x3C1;</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>h</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n  <mi>exp</mi>\n  <mo stretchy=\"false\">(</mo>\n  <mo>&#x2212;</mo>\n  <mfrac>\n    <mi>h</mi>\n    <mi>H</mi>\n  </mfrac>\n  <mo stretchy=\"false\">)</mo>\n</math>\n<!-- /wp:html -->\n\n自此，我们关于单次散射的天空大气渲染方法的基本预备知识已经了解的差不多了，接下来介绍shader的相关代码。\n\n\n# Shader代码\n首先，为了计算AB、PC等视线和光线在大气层内的传播距离，我们需要一个函数来计算射线和球体的相交情况。\n\n```glsl\nvec2 ray_sphere_intersection(vec3 ray_origin, vec3 ray_direction, vec3 sphere_center, float sphere_radius)\n{\n    // ray-sphere intersection that assumes\n    float a = dot(ray_direction, ray_direction);\n    vec3 oc = ray_origin - sphere_center;\n    float b = 2.0 * dot(ray_direction, oc);\n    float c = dot(oc, oc) - (sphere_radius * sphere_radius);\n    float d = (b*b) - 4.0*a*c;\n\n    // 返回击中结果，y小于x代表无结果\n    if (d < 0.0) return vec2(1e10,-1e10);\n    // 击中的话有两个相同或者不同的结果\n    return vec2(\n        (-b - sqrt(d))/(2.0*a),\n        (-b + sqrt(d))/(2.0*a)\n    );\n}\n```\n\n<!-- wp:paragraph -->\n<p>好了，那有了这个辅助公式，我们正式开始计算大气的颜色。首先，按照之前的理论，我们要计算视线向量在大气层内的长度，所以我们对射线方向和大气层，以及射线方向和星球表面做射线检测。得到视线在大气层内的长度后，根据我们预设的想要采样的步数（iSteps），计算出每次采样的长度ds。</p>\n<!-- /wp:paragraph -->\n\n```glsl\nray_dir = normalize(ray_dir);\n\n// 视线和大气层大小的尺寸的射线检测\n// x为大气入射点的距离、y为大气出射点的距离（x==y代表光线和大气球体相切，x>y代表光线不经过大气）\nvec2 atmos_hit = ray_sphere_intersection(ray_origin, ray_dir, rAtmos);\n// 未击中，返回0\nif (atmos_hit.x > atmos_hit.y) return vec3(0,0,0);\n\n    // 视线和星球做射线检测，取得近处的检测结果（远处的那个光被星球本体遮挡）\nvec2 planet_hit = ray_sphere_intersection(ray_origin, ray_dir, planet_radius);\nfloat light_distance = atmos_hit.y;\n\n// hit the planet\nif(planet_hit.x < planet_hit.y && planet_hit.x > 0.1)\n{\n    light_distance = planet_hit.x;\n}\n\n// light sample length\nfloat ds = light_distance / float(iSteps);\n```\n\n<!-- wp:paragraph -->\n<p>那么接下来，便是进入采样的循环。循环有两层，外面的循环是计算<strong>视线方向上的每个采样点的光能量</strong>，而计算这个点的光能量也需要一个循环，这个循环是用于采样该点和光源之间的连线在大气层内的线段（也就是之前图片的PC段）的光学距离。根据前面提到的公式，光学距离乘以海平面的散射系数便可以得到光的衰减系数，因此jSteps循环可以得到光线在进入大气层后，传播到达视线上的采样点（P0、P1...Pn点）的衰减所剩下的能量。</p>\n<!-- /wp:paragraph -->\n\n``` glsl\n// Initialize the primary ray time.\nfloat iTime = 0.0;\n\n// Initialize accumulators for Rayleigh and Mie scattering.\nvec3 total_scatter_rlh = vec3(0,0,0);\nvec3 total_scatter_mie = vec3(0,0,0);\n\n// Initialize optical depth accumulators for the primary ray.\nfloat total_od_rlh = 0.0;\nfloat total_od_mie = 0.0;\n\n// 对每个视线上的采样点循环\nfor (int i = 0; i < iSteps; i++) {\n    // 获取到采样点的位置\n    vec3 iPos = ray_origin + ray_dir * (iTime + ds * 0.5);\n\n    // 在当前点向太阳的位置做射线检测，以大气的半径为球体。.y是代表大气的出射点，j_steps代表采样数\n    float jStepSize = ray_sphere_intersection(iPos, pSun, rAtmos).y / float(jSteps);\n\n    float jTime = 0.0;\n    float jOdRlh = 0.0;\n    float jOdMie = 0.0;\n\n    // 在当前采样到大气入射点的距离上，采样计算\n    for (int j = 0; j < jSteps; j++) {\n        // 计算采样点到光源的衰减\n        vec3 jPos = iPos + pSun * (jTime + jStepSize * 0.5);\n\n        float jHeight = length(jPos-planet_center) - planet_radius;\n\n        // Accumulate the optical depth.\n        jOdRlh += get_atmos_density(jHeight, scale_height_rlh) * jStepSize;\n        jOdMie += get_atmos_density(jHeight, scale_height_mie) * jStepSize;\n\n        // Increment the secondary ray time.\n        jTime += jStepSize;\n    }\n\n    // 观察点和星球表面距离\n    float surface_height = length(iPos-planet_center) - planet_radius;\n\n    // 计算这一步的散射的光学深度结果\n    float od_step_rlh = get_atmos_density(surface_height, scale_height_rlh) * ds;\n    float od_step_mie = get_atmos_density(surface_height, scale_height_mie) * ds;\n    \n    total_od_rlh += od_step_rlh;\n    total_od_mie += od_step_mie;\n\n    // 计算衰减系数，光在经过一定距离后衰减剩下来的比例。\n    vec3 attn = exp(-(kMie * (total_od_mie + jOdMie) + kRlh * (total_od_rlh + jOdRlh)));\n\n    // Accumulate scattering.\n    total_scatter_rlh += od_step_rlh * attn;\n    total_scatter_mie += od_step_mie * attn;\n\n    // Increment the primary ray time.\n    iTime += ds;\n}\n```\n\n<!-- wp:paragraph -->\n<p>计算瑞利散射和米氏散射的大气密度的代码如下所示，其中scale_height在计算瑞利散射的时候带入的是8500，米氏散射则带入1200。</p>\n<!-- /wp:paragraph -->\n\n```glsl\n// 获取大气密度\n// 传入位置离海平面的高度，以及散射的相关基准高度\n// 大气中任意一点的散射系数的计算，简化拆解为散射在海平面的散射系数，乘以基于海平面高度的该散射的大气密度计算公式\nfloat get_atmos_density(float height_to_sea_level, float scale_height)\n{\n    return exp(-height_to_sea_level / scale_height);\n}\n```\n\n<!-- wp:paragraph -->\n<p>将iSteps循环的结果累加起来，我们便得到了视线上（AB）的每个采样点的光能量传播到达相机（A点）经过衰减的能量的和。那么还剩一个部分，就是光在P点进行散射的时候，光也损失掉了一部分能量，这个过程可以通过乘以米氏散射和瑞利散射的相位函数来计算。因为每个采样点P的结果都需要乘以相位函数，所以我们可以将它提取到最外面，乘以光的能量的总和即可。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>不过需要注意的是，前面的公式提到了，相位函数是和光线入射方向和目标方向的夹角相关的，所以如果我们<strong>默认太阳光源是平行光</strong>的话，这个夹角对每个采样点来说是一样的，所以可以将相位函数提取到最外层。如果认为这个夹角对每个采样点不一样的话，那也许还是应该老老实实在计算每个采样点的光的时候单独去处理。</p>\n<!-- /wp:paragraph -->\n\n最终的结果除了乘以相位函数，还需要乘以海平面的散射系数，结果如下。</p>\n\n```glsl\n// 计算并返回最终颜色\n// iSun是光源（太阳）的颜色\nreturn iSun * (pRlh * kRlh * total_scatter_rlh + pMie * kMie * total_scatter_mie);\n```\n下面是得到的结果：\n\n<iframe src=\"single-scatter-atmosphere.mp4\" scrolling=\"no\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n\n# 参考资料\n- https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/\n- https://www.xianlongok.site/post/8e5d3b12/\n","source":"_posts/single-scatter-atmosphere.md","raw":"---\ntitle: 基于单次散射的天空大气渲染方法\ndate: 2024-10-15 22:03:02\ncategories: \n\t- 技术漫谈\ntags: [3D, render, 渲染, 编程]\n\nindex_img: /2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.png\nbanner_img: /2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.png\n---\n\n\n最近KongEngine实现了IBL(Image Based Lighting)，可以将HDR环境贴图映射作为3D场景的环境。\n\n![KongEngine的IBL效果](kong-screen-shot.png)\n\n在实现了IBL之后我又产生了一个想法，能否实现类似UE中的大气环境的渲染效果呢？我尝试去寻找答案，发现如果要完全复刻UE中的效果确实需要一定的功夫的，但是最基础的天空大气渲染并没有想象中那么复杂，于是我便花了点时间在KongEngine中实现了这个功能。\n\n![KongEngine天空大气效果](single-scatter-atmosphere.png)\n\n我打算将这个方法的基础思想和实现在此简单记录一下。\n\n# 单次散射模型\n星球的大气层是一种参与性介质，和在真空环境不同，光在大气层中传播的时候会因为大气中的微小颗粒（水、灰尘等等）发生散射（折射、反射）和吸收等情况。因此我们看向空中的一个点的时候，这个点的颜色是光经过多次散射得到的结果。\n\n光到达我们眼睛之前经过多少次反射和折射是不一定的，在实时渲染的需求下计算太多次光的变化显然也是不显示的。最简单的方法，是使用单次散射模型：我们假定光在进入我们眼睛之前，有且只发生了一次散射。光一般在第一次散射的时候，还会有最多的能量剩余，后面的多次散射能力相对少，对最后效果的呈现也影响不大，因此这种模型可以在保证性能的情况下，还有不错的效果。\n\n![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_02.png)\n\n除了散射，光在传播的时候会被大气吸收。一般来说，如果在一个均匀的介质中传播的话，光的被吸收的部分和介质的密度，以及传播的路径长度正相关。放到单散射模型的例子中，就是需要计算光在散射前和散射后的路径上，被吸收了多少能量。\n![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_07.png)\n\n按照上面的图，假设相机在A点，观察方向为AB，其中有一束光在P点发生散射后沿着PA进入相机。如果我们知道了光线损耗和距离相关的公式，那么似乎是只要计算出CP和PA的长度，在带入公式后就可以得到光该路径上传播后的最终能量了。\n\n![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_10a.png)\n\n但是对于大气层来说，它的密度并不是均匀的，而是和大气层距离地面的高度相关。所以在计算CP段光线损耗的时候，我们需要将这段距离分为多个小段，每个小段的损耗公式带入对应平均高度，在最后将所有结果相加才。小段划分的越密集，则结果越准确。\n\n如果我们还要考虑大气中的其他因素，比如说大气中的云层，在这些区域中光的损耗就不仅仅是和高度相关了。\n\n另外一点就是，当我们考虑AB方向的光线时，它的最终效果，是在大气层内的所有AB连线上面的点的散射结果的总和（P0、P1、P2...Pn），因此我们也同样的需要对AB线段进行分段采样并将结果叠加。AB线段上的每一个采样结果按照上面所描述的计算单一P点的方式。\n\n![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_08a.png)\n\n以上便是大气单次散射模型的基本思路。\n\n# 散射的计算\n之前我们提到了计算光的散射，这里我们介绍一下散射的相关计算。会提及一些公式，但是不会做过多的数学推导工作，对推导过程感兴趣的可以看一下文章中的参考资料。\n\n一般来说，天空大气的散射主要包括两种，分别是**瑞利散射**和**米氏散射**。\n\n - 瑞利散射是当光线通过介质中的微小颗粒或分子时发生的散射现象。由于颗粒或分子的尺寸远小于光的波长，不同波长的光线会以不同的角度散射，一个最经典的案例就是因为蓝色的波长是较短的，所以蓝色很容易发生瑞利散射，导致天空呈现蓝色。\n - 米氏散射则一般由空气中含有的较大颗粒的介质，如气溶胶、灰尘、水滴等引起。和瑞利散射不同的是，米氏散射和光的波长关系并不大。\n ![](https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_13.png)\n\n那么根据前面的模型思路，光在P点上发生了散射，其中一部分能量沿着PA方向进入相机的实现。获取这一部分能量的计算函数被称之为<strong>相位函数（Phase Function）</strong>。相位函数是用来描述，当光线发生散射的情况时，某个方向（一般是和原光线方向的夹角）占原光线的能量的比例。瑞利散射和米氏散射的相位函数是不同的，同一种散射的相位函数也会有不同的方法进行拟合，这里我不想去做过多的公式推导的工作，有兴趣的可以去查看[参考资料](https://patapom.com/topics/Revision2013/Revision%202013%20-%20Real-time%20Volumetric%20Rendering%20Course%20Notes.pdf)的推导过程。\n\n下方是瑞利散射的相位函数，theta是原光线方向和目标方向的夹角：\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mtable displaystyle=\"true\" columnalign=\"right left right\" columnspacing=\"0em 2em\" rowspacing=\"3pt\">\n    <mtr>\n      <mtd>\n        <mi>P</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>&#x3B8;</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mtd>        \n      <mtd>\n        <mi></mi>\n        <mo>=</mo>\n        <mfrac>\n          <mn>3</mn>\n          <mrow>\n            <mn>16</mn>\n            <mi>&#x3C0;</mi>\n          </mrow>\n        </mfrac>\n        <mo stretchy=\"false\">(</mo>\n        <mn>1</mn>\n        <mo>+</mo>\n        <mi>c</mi>\n        <mi>o</mi>\n        <msup>\n          <mi>s</mi>\n          <mn>2</mn>\n        </msup>\n        <mi>&#x3B8;</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mtd>\n    </mtr>\n  </mtable>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n下方是米氏散射的相位函数，这里使用的是[Henyey-Greenstein函数](https://omlc.org/classroom/ece532/class3/hg.html)来近似。\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">  <mi>P</mi>  <mo stretchy=\"false\">(</mo>  <mi>&#x3B8;</mi>  <mo stretchy=\"false\">)</mo>  <mo>=</mo>  <mfrac>    <mrow>      <mn>1</mn>      <mo>&#x2212;</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>    <mrow>      <mn>4</mn>      <mi>&#x3C0;</mi>      <mo stretchy=\"false\">(</mo>      <mn>1</mn>      <mo>+</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>      <mo>&#x2212;</mo>      <mn>2</mn>      <mi>g</mi>      <mi>c</mi>      <mi>o</mi>      <mi>s</mi>      <mo stretchy=\"false\">(</mo>      <mi>&#x3B8;</mi>      <mo stretchy=\"false\">)</mo>      <msup>        <mo stretchy=\"false\">)</mo>        <mrow>          <mn>3</mn>          <mrow>            <mo>/</mo>          </mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>  </mfrac></math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>好了，现在我们知道了如何计算光线在P点的散射行为。剩下的工作就是需要计算光线在传播过程的损耗了。这一部分的计算方法称之为<strong>衰减系数</strong>，或者<strong>消光系数</strong>。消光系数中的一部分，需要对光线在传播的路线的长度和空气密度进行积分。在程序中的表示就是将光的传播路径分为小段，将每一小段的长度和平均密度（或者小段中点的介质密度）相乘而得到，这个结果我们称之为<strong>光学距离（Optical Depth）</strong>。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>衰减系数的计算公式如下，红色部分代表的是在海拔为h的散射系数。他可以分解为在海平面上的散射系数乘以在海拔h的介质密度。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"#00AAFF\">\n    <mi>T</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>P</mi>\n    <mi>A</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n<mstyle mathcolor=\"#00AA00\">\n  <mi>exp</mi>\n</mstyle>\n  <mrow data-mjx-texclass=\"ORD\">\n    <mo>&#x2212;</mo>\n    <msubsup>\n      <mo data-mjx-texclass=\"OP\">&#x222B;</mo>\n      <mi>P</mi>\n      <mi>A</mi>\n    </msubsup>\n    <mrow data-mjx-texclass=\"ORD\">\n      <mstyle mathcolor=\"Red\">\n        <mi>&#x3B2;</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>&#x3BB;</mi>\n        <mo>,</mo>\n        <mi>h</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mstyle>\n    </mrow>\n    <mi>d</mi>\n    <mi>s</mi>\n  </mrow>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>分解出来后得到的结果如下，其中红色的部分代表的意思是在海平面的散射系数，是一个常量，黄色部分代表了在海拔为h的介质的密度。这个公式的积分便是针对AP路线上的介质密度，其结果也就是光学距离。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"#00AAFF\">\n    <mi>T</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>P</mi>\n    <mi>A</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n    <mstyle mathcolor=\"#00AA00\">\n      <mi>exp</mi>\n    </mstyle>\n  <mrow data-mjx-texclass=\"ORD\">\n    <mo>&#x2212;</mo>\n    <mstyle mathcolor=\"Red\">\n      <mi>&#x3B2;</mi>\n      <mo stretchy=\"false\">(</mo>\n      <mi>&#x3BB;</mi>\n      <mo stretchy=\"false\">)</mo>\n    </mstyle>\n    <msubsup>\n      <mo data-mjx-texclass=\"OP\">&#x222B;</mo>\n      <mi>P</mi>\n      <mi>A</mi>\n    </msubsup>\n    <mrow data-mjx-texclass=\"ORD\">\n      <mstyle mathcolor=\"Gold\">\n        <mi>&#x3C1;</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>h</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mstyle>\n    </mrow>\n    <mi>d</mi>\n    <mi>s</mi>\n  </mrow>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>介质密度的计算公式如下，其中H代表的是一个基准海拔，是一个常量。不同散射的基准海拔有所不同，瑞利散射的基准海拔是*8500*，而米氏散射的基准海拔是*1200*。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"Gold\">\n    <mi>&#x3C1;</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>h</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n  <mi>exp</mi>\n  <mo stretchy=\"false\">(</mo>\n  <mo>&#x2212;</mo>\n  <mfrac>\n    <mi>h</mi>\n    <mi>H</mi>\n  </mfrac>\n  <mo stretchy=\"false\">)</mo>\n</math>\n<!-- /wp:html -->\n\n自此，我们关于单次散射的天空大气渲染方法的基本预备知识已经了解的差不多了，接下来介绍shader的相关代码。\n\n\n# Shader代码\n首先，为了计算AB、PC等视线和光线在大气层内的传播距离，我们需要一个函数来计算射线和球体的相交情况。\n\n```glsl\nvec2 ray_sphere_intersection(vec3 ray_origin, vec3 ray_direction, vec3 sphere_center, float sphere_radius)\n{\n    // ray-sphere intersection that assumes\n    float a = dot(ray_direction, ray_direction);\n    vec3 oc = ray_origin - sphere_center;\n    float b = 2.0 * dot(ray_direction, oc);\n    float c = dot(oc, oc) - (sphere_radius * sphere_radius);\n    float d = (b*b) - 4.0*a*c;\n\n    // 返回击中结果，y小于x代表无结果\n    if (d < 0.0) return vec2(1e10,-1e10);\n    // 击中的话有两个相同或者不同的结果\n    return vec2(\n        (-b - sqrt(d))/(2.0*a),\n        (-b + sqrt(d))/(2.0*a)\n    );\n}\n```\n\n<!-- wp:paragraph -->\n<p>好了，那有了这个辅助公式，我们正式开始计算大气的颜色。首先，按照之前的理论，我们要计算视线向量在大气层内的长度，所以我们对射线方向和大气层，以及射线方向和星球表面做射线检测。得到视线在大气层内的长度后，根据我们预设的想要采样的步数（iSteps），计算出每次采样的长度ds。</p>\n<!-- /wp:paragraph -->\n\n```glsl\nray_dir = normalize(ray_dir);\n\n// 视线和大气层大小的尺寸的射线检测\n// x为大气入射点的距离、y为大气出射点的距离（x==y代表光线和大气球体相切，x>y代表光线不经过大气）\nvec2 atmos_hit = ray_sphere_intersection(ray_origin, ray_dir, rAtmos);\n// 未击中，返回0\nif (atmos_hit.x > atmos_hit.y) return vec3(0,0,0);\n\n    // 视线和星球做射线检测，取得近处的检测结果（远处的那个光被星球本体遮挡）\nvec2 planet_hit = ray_sphere_intersection(ray_origin, ray_dir, planet_radius);\nfloat light_distance = atmos_hit.y;\n\n// hit the planet\nif(planet_hit.x < planet_hit.y && planet_hit.x > 0.1)\n{\n    light_distance = planet_hit.x;\n}\n\n// light sample length\nfloat ds = light_distance / float(iSteps);\n```\n\n<!-- wp:paragraph -->\n<p>那么接下来，便是进入采样的循环。循环有两层，外面的循环是计算<strong>视线方向上的每个采样点的光能量</strong>，而计算这个点的光能量也需要一个循环，这个循环是用于采样该点和光源之间的连线在大气层内的线段（也就是之前图片的PC段）的光学距离。根据前面提到的公式，光学距离乘以海平面的散射系数便可以得到光的衰减系数，因此jSteps循环可以得到光线在进入大气层后，传播到达视线上的采样点（P0、P1...Pn点）的衰减所剩下的能量。</p>\n<!-- /wp:paragraph -->\n\n``` glsl\n// Initialize the primary ray time.\nfloat iTime = 0.0;\n\n// Initialize accumulators for Rayleigh and Mie scattering.\nvec3 total_scatter_rlh = vec3(0,0,0);\nvec3 total_scatter_mie = vec3(0,0,0);\n\n// Initialize optical depth accumulators for the primary ray.\nfloat total_od_rlh = 0.0;\nfloat total_od_mie = 0.0;\n\n// 对每个视线上的采样点循环\nfor (int i = 0; i < iSteps; i++) {\n    // 获取到采样点的位置\n    vec3 iPos = ray_origin + ray_dir * (iTime + ds * 0.5);\n\n    // 在当前点向太阳的位置做射线检测，以大气的半径为球体。.y是代表大气的出射点，j_steps代表采样数\n    float jStepSize = ray_sphere_intersection(iPos, pSun, rAtmos).y / float(jSteps);\n\n    float jTime = 0.0;\n    float jOdRlh = 0.0;\n    float jOdMie = 0.0;\n\n    // 在当前采样到大气入射点的距离上，采样计算\n    for (int j = 0; j < jSteps; j++) {\n        // 计算采样点到光源的衰减\n        vec3 jPos = iPos + pSun * (jTime + jStepSize * 0.5);\n\n        float jHeight = length(jPos-planet_center) - planet_radius;\n\n        // Accumulate the optical depth.\n        jOdRlh += get_atmos_density(jHeight, scale_height_rlh) * jStepSize;\n        jOdMie += get_atmos_density(jHeight, scale_height_mie) * jStepSize;\n\n        // Increment the secondary ray time.\n        jTime += jStepSize;\n    }\n\n    // 观察点和星球表面距离\n    float surface_height = length(iPos-planet_center) - planet_radius;\n\n    // 计算这一步的散射的光学深度结果\n    float od_step_rlh = get_atmos_density(surface_height, scale_height_rlh) * ds;\n    float od_step_mie = get_atmos_density(surface_height, scale_height_mie) * ds;\n    \n    total_od_rlh += od_step_rlh;\n    total_od_mie += od_step_mie;\n\n    // 计算衰减系数，光在经过一定距离后衰减剩下来的比例。\n    vec3 attn = exp(-(kMie * (total_od_mie + jOdMie) + kRlh * (total_od_rlh + jOdRlh)));\n\n    // Accumulate scattering.\n    total_scatter_rlh += od_step_rlh * attn;\n    total_scatter_mie += od_step_mie * attn;\n\n    // Increment the primary ray time.\n    iTime += ds;\n}\n```\n\n<!-- wp:paragraph -->\n<p>计算瑞利散射和米氏散射的大气密度的代码如下所示，其中scale_height在计算瑞利散射的时候带入的是8500，米氏散射则带入1200。</p>\n<!-- /wp:paragraph -->\n\n```glsl\n// 获取大气密度\n// 传入位置离海平面的高度，以及散射的相关基准高度\n// 大气中任意一点的散射系数的计算，简化拆解为散射在海平面的散射系数，乘以基于海平面高度的该散射的大气密度计算公式\nfloat get_atmos_density(float height_to_sea_level, float scale_height)\n{\n    return exp(-height_to_sea_level / scale_height);\n}\n```\n\n<!-- wp:paragraph -->\n<p>将iSteps循环的结果累加起来，我们便得到了视线上（AB）的每个采样点的光能量传播到达相机（A点）经过衰减的能量的和。那么还剩一个部分，就是光在P点进行散射的时候，光也损失掉了一部分能量，这个过程可以通过乘以米氏散射和瑞利散射的相位函数来计算。因为每个采样点P的结果都需要乘以相位函数，所以我们可以将它提取到最外面，乘以光的能量的总和即可。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>不过需要注意的是，前面的公式提到了，相位函数是和光线入射方向和目标方向的夹角相关的，所以如果我们<strong>默认太阳光源是平行光</strong>的话，这个夹角对每个采样点来说是一样的，所以可以将相位函数提取到最外层。如果认为这个夹角对每个采样点不一样的话，那也许还是应该老老实实在计算每个采样点的光的时候单独去处理。</p>\n<!-- /wp:paragraph -->\n\n最终的结果除了乘以相位函数，还需要乘以海平面的散射系数，结果如下。</p>\n\n```glsl\n// 计算并返回最终颜色\n// iSun是光源（太阳）的颜色\nreturn iSun * (pRlh * kRlh * total_scatter_rlh + pMie * kMie * total_scatter_mie);\n```\n下面是得到的结果：\n\n<iframe src=\"single-scatter-atmosphere.mp4\" scrolling=\"no\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n\n# 参考资料\n- https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/\n- https://www.xianlongok.site/post/8e5d3b12/\n","slug":"single-scatter-atmosphere","published":1,"updated":"2024-10-15T14:31:41.794Z","comments":1,"layout":"post","photos":[],"_id":"cm34lv4qk000ry057fpdcb1oy","content":"<p>最近KongEngine实现了IBL(Image Based Lighting)，可以将HDR环境贴图映射作为3D场景的环境。</p>\n<p><img src=\"/2024/10/15/single-scatter-atmosphere/kong-screen-shot.png\" alt=\"KongEngine的IBL效果\"></p>\n<p>在实现了IBL之后我又产生了一个想法，能否实现类似UE中的大气环境的渲染效果呢？我尝试去寻找答案，发现如果要完全复刻UE中的效果确实需要一定的功夫的，但是最基础的天空大气渲染并没有想象中那么复杂，于是我便花了点时间在KongEngine中实现了这个功能。</p>\n<p><img src=\"/2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.png\" alt=\"KongEngine天空大气效果\"></p>\n<p>我打算将这个方法的基础思想和实现在此简单记录一下。</p>\n<h1 id=\"单次散射模型\"><a href=\"#单次散射模型\" class=\"headerlink\" title=\"单次散射模型\"></a>单次散射模型</h1><p>星球的大气层是一种参与性介质，和在真空环境不同，光在大气层中传播的时候会因为大气中的微小颗粒（水、灰尘等等）发生散射（折射、反射）和吸收等情况。因此我们看向空中的一个点的时候，这个点的颜色是光经过多次散射得到的结果。</p>\n<p>光到达我们眼睛之前经过多少次反射和折射是不一定的，在实时渲染的需求下计算太多次光的变化显然也是不显示的。最简单的方法，是使用单次散射模型：我们假定光在进入我们眼睛之前，有且只发生了一次散射。光一般在第一次散射的时候，还会有最多的能量剩余，后面的多次散射能力相对少，对最后效果的呈现也影响不大，因此这种模型可以在保证性能的情况下，还有不错的效果。</p>\n<p><img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_02.png\"></p>\n<p>除了散射，光在传播的时候会被大气吸收。一般来说，如果在一个均匀的介质中传播的话，光的被吸收的部分和介质的密度，以及传播的路径长度正相关。放到单散射模型的例子中，就是需要计算光在散射前和散射后的路径上，被吸收了多少能量。<br><img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_07.png\"></p>\n<p>按照上面的图，假设相机在A点，观察方向为AB，其中有一束光在P点发生散射后沿着PA进入相机。如果我们知道了光线损耗和距离相关的公式，那么似乎是只要计算出CP和PA的长度，在带入公式后就可以得到光该路径上传播后的最终能量了。</p>\n<p><img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_10a.png\"></p>\n<p>但是对于大气层来说，它的密度并不是均匀的，而是和大气层距离地面的高度相关。所以在计算CP段光线损耗的时候，我们需要将这段距离分为多个小段，每个小段的损耗公式带入对应平均高度，在最后将所有结果相加才。小段划分的越密集，则结果越准确。</p>\n<p>如果我们还要考虑大气中的其他因素，比如说大气中的云层，在这些区域中光的损耗就不仅仅是和高度相关了。</p>\n<p>另外一点就是，当我们考虑AB方向的光线时，它的最终效果，是在大气层内的所有AB连线上面的点的散射结果的总和（P0、P1、P2…Pn），因此我们也同样的需要对AB线段进行分段采样并将结果叠加。AB线段上的每一个采样结果按照上面所描述的计算单一P点的方式。</p>\n<p><img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_08a.png\"></p>\n<p>以上便是大气单次散射模型的基本思路。</p>\n<h1 id=\"散射的计算\"><a href=\"#散射的计算\" class=\"headerlink\" title=\"散射的计算\"></a>散射的计算</h1><p>之前我们提到了计算光的散射，这里我们介绍一下散射的相关计算。会提及一些公式，但是不会做过多的数学推导工作，对推导过程感兴趣的可以看一下文章中的参考资料。</p>\n<p>一般来说，天空大气的散射主要包括两种，分别是<strong>瑞利散射</strong>和<strong>米氏散射</strong>。</p>\n<ul>\n<li>瑞利散射是当光线通过介质中的微小颗粒或分子时发生的散射现象。由于颗粒或分子的尺寸远小于光的波长，不同波长的光线会以不同的角度散射，一个最经典的案例就是因为蓝色的波长是较短的，所以蓝色很容易发生瑞利散射，导致天空呈现蓝色。</li>\n<li>米氏散射则一般由空气中含有的较大颗粒的介质，如气溶胶、灰尘、水滴等引起。和瑞利散射不同的是，米氏散射和光的波长关系并不大。<br> <img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_13.png\"></li>\n</ul>\n<p>那么根据前面的模型思路，光在P点上发生了散射，其中一部分能量沿着PA方向进入相机的实现。获取这一部分能量的计算函数被称之为<strong>相位函数（Phase Function）</strong>。相位函数是用来描述，当光线发生散射的情况时，某个方向（一般是和原光线方向的夹角）占原光线的能量的比例。瑞利散射和米氏散射的相位函数是不同的，同一种散射的相位函数也会有不同的方法进行拟合，这里我不想去做过多的公式推导的工作，有兴趣的可以去查看<a href=\"https://patapom.com/topics/Revision2013/Revision%202013%20-%20Real-time%20Volumetric%20Rendering%20Course%20Notes.pdf\">参考资料</a>的推导过程。</p>\n<p>下方是瑞利散射的相位函数，theta是原光线方向和目标方向的夹角：</p>\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mtable displaystyle=\"true\" columnalign=\"right left right\" columnspacing=\"0em 2em\" rowspacing=\"3pt\">\n    <mtr>\n      <mtd>\n        <mi>P</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>&#x3B8;</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mtd>        \n      <mtd>\n        <mi></mi>\n        <mo>=</mo>\n        <mfrac>\n          <mn>3</mn>\n          <mrow>\n            <mn>16</mn>\n            <mi>&#x3C0;</mi>\n          </mrow>\n        </mfrac>\n        <mo stretchy=\"false\">(</mo>\n        <mn>1</mn>\n        <mo>+</mo>\n        <mi>c</mi>\n        <mi>o</mi>\n        <msup>\n          <mi>s</mi>\n          <mn>2</mn>\n        </msup>\n        <mi>&#x3B8;</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mtd>\n    </mtr>\n  </mtable>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>下方是米氏散射的相位函数，这里使用的是<a href=\"https://omlc.org/classroom/ece532/class3/hg.html\">Henyey-Greenstein函数</a>来近似。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<p><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">  <mi>P</mi>  <mo stretchy=\"false\">(</mo>  <mi>&#x3B8;</mi>  <mo stretchy=\"false\">)</mo>  <mo>&#x3D;</mo>  <mfrac>    <mrow>      <mn>1</mn>      <mo>&#x2212;</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>    <mrow>      <mn>4</mn>      <mi>&#x3C0;</mi>      <mo stretchy=\"false\">(</mo>      <mn>1</mn>      <mo>+</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>      <mo>&#x2212;</mo>      <mn>2</mn>      <mi>g</mi>      <mi>c</mi>      <mi>o</mi>      <mi>s</mi>      <mo stretchy=\"false\">(</mo>      <mi>&#x3B8;</mi>      <mo stretchy=\"false\">)</mo>      <msup>        <mo stretchy=\"false\">)</mo>        <mrow>          <mn>3</mn>          <mrow>            <mo>&#x2F;</mo>          </mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>  </mfrac></math></p>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>好了，现在我们知道了如何计算光线在P点的散射行为。剩下的工作就是需要计算光线在传播过程的损耗了。这一部分的计算方法称之为<strong>衰减系数</strong>，或者<strong>消光系数</strong>。消光系数中的一部分，需要对光线在传播的路线的长度和空气密度进行积分。在程序中的表示就是将光的传播路径分为小段，将每一小段的长度和平均密度（或者小段中点的介质密度）相乘而得到，这个结果我们称之为<strong>光学距离（Optical Depth）</strong>。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>衰减系数的计算公式如下，红色部分代表的是在海拔为h的散射系数。他可以分解为在海平面上的散射系数乘以在海拔h的介质密度。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"#00AAFF\">\n    <mi>T</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>P</mi>\n    <mi>A</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n<mstyle mathcolor=\"#00AA00\">\n  <mi>exp</mi>\n</mstyle>\n  <mrow data-mjx-texclass=\"ORD\">\n    <mo>&#x2212;</mo>\n    <msubsup>\n      <mo data-mjx-texclass=\"OP\">&#x222B;</mo>\n      <mi>P</mi>\n      <mi>A</mi>\n    </msubsup>\n    <mrow data-mjx-texclass=\"ORD\">\n      <mstyle mathcolor=\"Red\">\n        <mi>&#x3B2;</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>&#x3BB;</mi>\n        <mo>,</mo>\n        <mi>h</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mstyle>\n    </mrow>\n    <mi>d</mi>\n    <mi>s</mi>\n  </mrow>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>分解出来后得到的结果如下，其中红色的部分代表的意思是在海平面的散射系数，是一个常量，黄色部分代表了在海拔为h的介质的密度。这个公式的积分便是针对AP路线上的介质密度，其结果也就是光学距离。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"#00AAFF\">\n    <mi>T</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>P</mi>\n    <mi>A</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n    <mstyle mathcolor=\"#00AA00\">\n      <mi>exp</mi>\n    </mstyle>\n  <mrow data-mjx-texclass=\"ORD\">\n    <mo>&#x2212;</mo>\n    <mstyle mathcolor=\"Red\">\n      <mi>&#x3B2;</mi>\n      <mo stretchy=\"false\">(</mo>\n      <mi>&#x3BB;</mi>\n      <mo stretchy=\"false\">)</mo>\n    </mstyle>\n    <msubsup>\n      <mo data-mjx-texclass=\"OP\">&#x222B;</mo>\n      <mi>P</mi>\n      <mi>A</mi>\n    </msubsup>\n    <mrow data-mjx-texclass=\"ORD\">\n      <mstyle mathcolor=\"Gold\">\n        <mi>&#x3C1;</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>h</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mstyle>\n    </mrow>\n    <mi>d</mi>\n    <mi>s</mi>\n  </mrow>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>介质密度的计算公式如下，其中H代表的是一个基准海拔，是一个常量。不同散射的基准海拔有所不同，瑞利散射的基准海拔是*8500*，而米氏散射的基准海拔是*1200*。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"Gold\">\n    <mi>&#x3C1;</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>h</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n  <mi>exp</mi>\n  <mo stretchy=\"false\">(</mo>\n  <mo>&#x2212;</mo>\n  <mfrac>\n    <mi>h</mi>\n    <mi>H</mi>\n  </mfrac>\n  <mo stretchy=\"false\">)</mo>\n</math>\n<!-- /wp:html -->\n\n<p>自此，我们关于单次散射的天空大气渲染方法的基本预备知识已经了解的差不多了，接下来介绍shader的相关代码。</p>\n<h1 id=\"Shader代码\"><a href=\"#Shader代码\" class=\"headerlink\" title=\"Shader代码\"></a>Shader代码</h1><p>首先，为了计算AB、PC等视线和光线在大气层内的传播距离，我们需要一个函数来计算射线和球体的相交情况。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">vec2</span> ray_sphere_intersection(<span class=\"hljs-type\">vec3</span> ray_origin, <span class=\"hljs-type\">vec3</span> ray_direction, <span class=\"hljs-type\">vec3</span> sphere_center, <span class=\"hljs-type\">float</span> sphere_radius)<br>&#123;<br>    <span class=\"hljs-comment\">// ray-sphere intersection that assumes</span><br>    <span class=\"hljs-type\">float</span> a = <span class=\"hljs-built_in\">dot</span>(ray_direction, ray_direction);<br>    <span class=\"hljs-type\">vec3</span> oc = ray_origin - sphere_center;<br>    <span class=\"hljs-type\">float</span> b = <span class=\"hljs-number\">2.0</span> * <span class=\"hljs-built_in\">dot</span>(ray_direction, oc);<br>    <span class=\"hljs-type\">float</span> c = <span class=\"hljs-built_in\">dot</span>(oc, oc) - (sphere_radius * sphere_radius);<br>    <span class=\"hljs-type\">float</span> d = (b*b) - <span class=\"hljs-number\">4.0</span>*a*c;<br><br>    <span class=\"hljs-comment\">// 返回击中结果，y小于x代表无结果</span><br>    <span class=\"hljs-keyword\">if</span> (d &lt; <span class=\"hljs-number\">0.0</span>) <span class=\"hljs-keyword\">return</span> <span class=\"hljs-type\">vec2</span>(<span class=\"hljs-number\">1e10</span>,<span class=\"hljs-number\">-1e10</span>);<br>    <span class=\"hljs-comment\">// 击中的话有两个相同或者不同的结果</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-type\">vec2</span>(<br>        (-b - <span class=\"hljs-built_in\">sqrt</span>(d))/(<span class=\"hljs-number\">2.0</span>*a),<br>        (-b + <span class=\"hljs-built_in\">sqrt</span>(d))/(<span class=\"hljs-number\">2.0</span>*a)<br>    );<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<!-- wp:paragraph -->\n<p>好了，那有了这个辅助公式，我们正式开始计算大气的颜色。首先，按照之前的理论，我们要计算视线向量在大气层内的长度，所以我们对射线方向和大气层，以及射线方向和星球表面做射线检测。得到视线在大气层内的长度后，根据我们预设的想要采样的步数（iSteps），计算出每次采样的长度ds。</p>\n<!-- /wp:paragraph -->\n\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\">ray_dir = <span class=\"hljs-built_in\">normalize</span>(ray_dir);<br><br><span class=\"hljs-comment\">// 视线和大气层大小的尺寸的射线检测</span><br><span class=\"hljs-comment\">// x为大气入射点的距离、y为大气出射点的距离（x==y代表光线和大气球体相切，x&gt;y代表光线不经过大气）</span><br><span class=\"hljs-type\">vec2</span> atmos_hit = ray_sphere_intersection(ray_origin, ray_dir, rAtmos);<br><span class=\"hljs-comment\">// 未击中，返回0</span><br><span class=\"hljs-keyword\">if</span> (atmos_hit.x &gt; atmos_hit.y) <span class=\"hljs-keyword\">return</span> <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>);<br><br>    <span class=\"hljs-comment\">// 视线和星球做射线检测，取得近处的检测结果（远处的那个光被星球本体遮挡）</span><br><span class=\"hljs-type\">vec2</span> planet_hit = ray_sphere_intersection(ray_origin, ray_dir, planet_radius);<br><span class=\"hljs-type\">float</span> light_distance = atmos_hit.y;<br><br><span class=\"hljs-comment\">// hit the planet</span><br><span class=\"hljs-keyword\">if</span>(planet_hit.x &lt; planet_hit.y &amp;&amp; planet_hit.x &gt; <span class=\"hljs-number\">0.1</span>)<br>&#123;<br>    light_distance = planet_hit.x;<br>&#125;<br><br><span class=\"hljs-comment\">// light sample length</span><br><span class=\"hljs-type\">float</span> ds = light_distance / <span class=\"hljs-type\">float</span>(iSteps);<br></code></pre></td></tr></table></figure>\n\n<!-- wp:paragraph -->\n<p>那么接下来，便是进入采样的循环。循环有两层，外面的循环是计算<strong>视线方向上的每个采样点的光能量</strong>，而计算这个点的光能量也需要一个循环，这个循环是用于采样该点和光源之间的连线在大气层内的线段（也就是之前图片的PC段）的光学距离。根据前面提到的公式，光学距离乘以海平面的散射系数便可以得到光的衰减系数，因此jSteps循环可以得到光线在进入大气层后，传播到达视线上的采样点（P0、P1...Pn点）的衰减所剩下的能量。</p>\n<!-- /wp:paragraph -->\n\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// Initialize the primary ray time.</span><br><span class=\"hljs-type\">float</span> iTime = <span class=\"hljs-number\">0.0</span>;<br><br><span class=\"hljs-comment\">// Initialize accumulators for Rayleigh and Mie scattering.</span><br><span class=\"hljs-type\">vec3</span> total_scatter_rlh = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>);<br><span class=\"hljs-type\">vec3</span> total_scatter_mie = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>);<br><br><span class=\"hljs-comment\">// Initialize optical depth accumulators for the primary ray.</span><br><span class=\"hljs-type\">float</span> total_od_rlh = <span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-type\">float</span> total_od_mie = <span class=\"hljs-number\">0.0</span>;<br><br><span class=\"hljs-comment\">// 对每个视线上的采样点循环</span><br><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; iSteps; i++) &#123;<br>    <span class=\"hljs-comment\">// 获取到采样点的位置</span><br>    <span class=\"hljs-type\">vec3</span> iPos = ray_origin + ray_dir * (iTime + ds * <span class=\"hljs-number\">0.5</span>);<br><br>    <span class=\"hljs-comment\">// 在当前点向太阳的位置做射线检测，以大气的半径为球体。.y是代表大气的出射点，j_steps代表采样数</span><br>    <span class=\"hljs-type\">float</span> jStepSize = ray_sphere_intersection(iPos, pSun, rAtmos).y / <span class=\"hljs-type\">float</span>(jSteps);<br><br>    <span class=\"hljs-type\">float</span> jTime = <span class=\"hljs-number\">0.0</span>;<br>    <span class=\"hljs-type\">float</span> jOdRlh = <span class=\"hljs-number\">0.0</span>;<br>    <span class=\"hljs-type\">float</span> jOdMie = <span class=\"hljs-number\">0.0</span>;<br><br>    <span class=\"hljs-comment\">// 在当前采样到大气入射点的距离上，采样计算</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; jSteps; j++) &#123;<br>        <span class=\"hljs-comment\">// 计算采样点到光源的衰减</span><br>        <span class=\"hljs-type\">vec3</span> jPos = iPos + pSun * (jTime + jStepSize * <span class=\"hljs-number\">0.5</span>);<br><br>        <span class=\"hljs-type\">float</span> jHeight = <span class=\"hljs-built_in\">length</span>(jPos-planet_center) - planet_radius;<br><br>        <span class=\"hljs-comment\">// Accumulate the optical depth.</span><br>        jOdRlh += get_atmos_density(jHeight, scale_height_rlh) * jStepSize;<br>        jOdMie += get_atmos_density(jHeight, scale_height_mie) * jStepSize;<br><br>        <span class=\"hljs-comment\">// Increment the secondary ray time.</span><br>        jTime += jStepSize;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 观察点和星球表面距离</span><br>    <span class=\"hljs-type\">float</span> surface_height = <span class=\"hljs-built_in\">length</span>(iPos-planet_center) - planet_radius;<br><br>    <span class=\"hljs-comment\">// 计算这一步的散射的光学深度结果</span><br>    <span class=\"hljs-type\">float</span> od_step_rlh = get_atmos_density(surface_height, scale_height_rlh) * ds;<br>    <span class=\"hljs-type\">float</span> od_step_mie = get_atmos_density(surface_height, scale_height_mie) * ds;<br>    <br>    total_od_rlh += od_step_rlh;<br>    total_od_mie += od_step_mie;<br><br>    <span class=\"hljs-comment\">// 计算衰减系数，光在经过一定距离后衰减剩下来的比例。</span><br>    <span class=\"hljs-type\">vec3</span> attn = <span class=\"hljs-built_in\">exp</span>(-(kMie * (total_od_mie + jOdMie) + kRlh * (total_od_rlh + jOdRlh)));<br><br>    <span class=\"hljs-comment\">// Accumulate scattering.</span><br>    total_scatter_rlh += od_step_rlh * attn;<br>    total_scatter_mie += od_step_mie * attn;<br><br>    <span class=\"hljs-comment\">// Increment the primary ray time.</span><br>    iTime += ds;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<!-- wp:paragraph -->\n<p>计算瑞利散射和米氏散射的大气密度的代码如下所示，其中scale_height在计算瑞利散射的时候带入的是8500，米氏散射则带入1200。</p>\n<!-- /wp:paragraph -->\n\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 获取大气密度</span><br><span class=\"hljs-comment\">// 传入位置离海平面的高度，以及散射的相关基准高度</span><br><span class=\"hljs-comment\">// 大气中任意一点的散射系数的计算，简化拆解为散射在海平面的散射系数，乘以基于海平面高度的该散射的大气密度计算公式</span><br><span class=\"hljs-type\">float</span> get_atmos_density(<span class=\"hljs-type\">float</span> height_to_sea_level, <span class=\"hljs-type\">float</span> scale_height)<br>&#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">exp</span>(-height_to_sea_level / scale_height);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<!-- wp:paragraph -->\n<p>将iSteps循环的结果累加起来，我们便得到了视线上（AB）的每个采样点的光能量传播到达相机（A点）经过衰减的能量的和。那么还剩一个部分，就是光在P点进行散射的时候，光也损失掉了一部分能量，这个过程可以通过乘以米氏散射和瑞利散射的相位函数来计算。因为每个采样点P的结果都需要乘以相位函数，所以我们可以将它提取到最外面，乘以光的能量的总和即可。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>不过需要注意的是，前面的公式提到了，相位函数是和光线入射方向和目标方向的夹角相关的，所以如果我们<strong>默认太阳光源是平行光</strong>的话，这个夹角对每个采样点来说是一样的，所以可以将相位函数提取到最外层。如果认为这个夹角对每个采样点不一样的话，那也许还是应该老老实实在计算每个采样点的光的时候单独去处理。</p>\n<!-- /wp:paragraph -->\n\n<p>最终的结果除了乘以相位函数，还需要乘以海平面的散射系数，结果如下。</p></p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 计算并返回最终颜色</span><br><span class=\"hljs-comment\">// iSun是光源（太阳）的颜色</span><br><span class=\"hljs-keyword\">return</span> iSun * (pRlh * kRlh * total_scatter_rlh + pMie * kMie * total_scatter_mie);<br></code></pre></td></tr></table></figure>\n<p>下面是得到的结果：</p>\n<iframe src=\"single-scatter-atmosphere.mp4\" scrolling=\"no\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/\">https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/</a></li>\n<li><a href=\"https://www.xianlongok.site/post/8e5d3b12/\">https://www.xianlongok.site/post/8e5d3b12/</a></li>\n</ul>\n","excerpt":"","more":"<p>最近KongEngine实现了IBL(Image Based Lighting)，可以将HDR环境贴图映射作为3D场景的环境。</p>\n<p><img src=\"/2024/10/15/single-scatter-atmosphere/kong-screen-shot.png\" alt=\"KongEngine的IBL效果\"></p>\n<p>在实现了IBL之后我又产生了一个想法，能否实现类似UE中的大气环境的渲染效果呢？我尝试去寻找答案，发现如果要完全复刻UE中的效果确实需要一定的功夫的，但是最基础的天空大气渲染并没有想象中那么复杂，于是我便花了点时间在KongEngine中实现了这个功能。</p>\n<p><img src=\"/2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.png\" alt=\"KongEngine天空大气效果\"></p>\n<p>我打算将这个方法的基础思想和实现在此简单记录一下。</p>\n<h1 id=\"单次散射模型\"><a href=\"#单次散射模型\" class=\"headerlink\" title=\"单次散射模型\"></a>单次散射模型</h1><p>星球的大气层是一种参与性介质，和在真空环境不同，光在大气层中传播的时候会因为大气中的微小颗粒（水、灰尘等等）发生散射（折射、反射）和吸收等情况。因此我们看向空中的一个点的时候，这个点的颜色是光经过多次散射得到的结果。</p>\n<p>光到达我们眼睛之前经过多少次反射和折射是不一定的，在实时渲染的需求下计算太多次光的变化显然也是不显示的。最简单的方法，是使用单次散射模型：我们假定光在进入我们眼睛之前，有且只发生了一次散射。光一般在第一次散射的时候，还会有最多的能量剩余，后面的多次散射能力相对少，对最后效果的呈现也影响不大，因此这种模型可以在保证性能的情况下，还有不错的效果。</p>\n<p><img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_02.png\"></p>\n<p>除了散射，光在传播的时候会被大气吸收。一般来说，如果在一个均匀的介质中传播的话，光的被吸收的部分和介质的密度，以及传播的路径长度正相关。放到单散射模型的例子中，就是需要计算光在散射前和散射后的路径上，被吸收了多少能量。<br><img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_07.png\"></p>\n<p>按照上面的图，假设相机在A点，观察方向为AB，其中有一束光在P点发生散射后沿着PA进入相机。如果我们知道了光线损耗和距离相关的公式，那么似乎是只要计算出CP和PA的长度，在带入公式后就可以得到光该路径上传播后的最终能量了。</p>\n<p><img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_10a.png\"></p>\n<p>但是对于大气层来说，它的密度并不是均匀的，而是和大气层距离地面的高度相关。所以在计算CP段光线损耗的时候，我们需要将这段距离分为多个小段，每个小段的损耗公式带入对应平均高度，在最后将所有结果相加才。小段划分的越密集，则结果越准确。</p>\n<p>如果我们还要考虑大气中的其他因素，比如说大气中的云层，在这些区域中光的损耗就不仅仅是和高度相关了。</p>\n<p>另外一点就是，当我们考虑AB方向的光线时，它的最终效果，是在大气层内的所有AB连线上面的点的散射结果的总和（P0、P1、P2…Pn），因此我们也同样的需要对AB线段进行分段采样并将结果叠加。AB线段上的每一个采样结果按照上面所描述的计算单一P点的方式。</p>\n<p><img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_08a.png\"></p>\n<p>以上便是大气单次散射模型的基本思路。</p>\n<h1 id=\"散射的计算\"><a href=\"#散射的计算\" class=\"headerlink\" title=\"散射的计算\"></a>散射的计算</h1><p>之前我们提到了计算光的散射，这里我们介绍一下散射的相关计算。会提及一些公式，但是不会做过多的数学推导工作，对推导过程感兴趣的可以看一下文章中的参考资料。</p>\n<p>一般来说，天空大气的散射主要包括两种，分别是<strong>瑞利散射</strong>和<strong>米氏散射</strong>。</p>\n<ul>\n<li>瑞利散射是当光线通过介质中的微小颗粒或分子时发生的散射现象。由于颗粒或分子的尺寸远小于光的波长，不同波长的光线会以不同的角度散射，一个最经典的案例就是因为蓝色的波长是较短的，所以蓝色很容易发生瑞利散射，导致天空呈现蓝色。</li>\n<li>米氏散射则一般由空气中含有的较大颗粒的介质，如气溶胶、灰尘、水滴等引起。和瑞利散射不同的是，米氏散射和光的波长关系并不大。<br> <img src=\"https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_13.png\"></li>\n</ul>\n<p>那么根据前面的模型思路，光在P点上发生了散射，其中一部分能量沿着PA方向进入相机的实现。获取这一部分能量的计算函数被称之为<strong>相位函数（Phase Function）</strong>。相位函数是用来描述，当光线发生散射的情况时，某个方向（一般是和原光线方向的夹角）占原光线的能量的比例。瑞利散射和米氏散射的相位函数是不同的，同一种散射的相位函数也会有不同的方法进行拟合，这里我不想去做过多的公式推导的工作，有兴趣的可以去查看<a href=\"https://patapom.com/topics/Revision2013/Revision%202013%20-%20Real-time%20Volumetric%20Rendering%20Course%20Notes.pdf\">参考资料</a>的推导过程。</p>\n<p>下方是瑞利散射的相位函数，theta是原光线方向和目标方向的夹角：</p>\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mtable displaystyle=\"true\" columnalign=\"right left right\" columnspacing=\"0em 2em\" rowspacing=\"3pt\">\n    <mtr>\n      <mtd>\n        <mi>P</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>&#x3B8;</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mtd>        \n      <mtd>\n        <mi></mi>\n        <mo>=</mo>\n        <mfrac>\n          <mn>3</mn>\n          <mrow>\n            <mn>16</mn>\n            <mi>&#x3C0;</mi>\n          </mrow>\n        </mfrac>\n        <mo stretchy=\"false\">(</mo>\n        <mn>1</mn>\n        <mo>+</mo>\n        <mi>c</mi>\n        <mi>o</mi>\n        <msup>\n          <mi>s</mi>\n          <mn>2</mn>\n        </msup>\n        <mi>&#x3B8;</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mtd>\n    </mtr>\n  </mtable>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>下方是米氏散射的相位函数，这里使用的是<a href=\"https://omlc.org/classroom/ece532/class3/hg.html\">Henyey-Greenstein函数</a>来近似。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<p><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">  <mi>P</mi>  <mo stretchy=\"false\">(</mo>  <mi>&#x3B8;</mi>  <mo stretchy=\"false\">)</mo>  <mo>&#x3D;</mo>  <mfrac>    <mrow>      <mn>1</mn>      <mo>&#x2212;</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>    <mrow>      <mn>4</mn>      <mi>&#x3C0;</mi>      <mo stretchy=\"false\">(</mo>      <mn>1</mn>      <mo>+</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>      <mo>&#x2212;</mo>      <mn>2</mn>      <mi>g</mi>      <mi>c</mi>      <mi>o</mi>      <mi>s</mi>      <mo stretchy=\"false\">(</mo>      <mi>&#x3B8;</mi>      <mo stretchy=\"false\">)</mo>      <msup>        <mo stretchy=\"false\">)</mo>        <mrow>          <mn>3</mn>          <mrow>            <mo>&#x2F;</mo>          </mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>  </mfrac></math></p>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>好了，现在我们知道了如何计算光线在P点的散射行为。剩下的工作就是需要计算光线在传播过程的损耗了。这一部分的计算方法称之为<strong>衰减系数</strong>，或者<strong>消光系数</strong>。消光系数中的一部分，需要对光线在传播的路线的长度和空气密度进行积分。在程序中的表示就是将光的传播路径分为小段，将每一小段的长度和平均密度（或者小段中点的介质密度）相乘而得到，这个结果我们称之为<strong>光学距离（Optical Depth）</strong>。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>衰减系数的计算公式如下，红色部分代表的是在海拔为h的散射系数。他可以分解为在海平面上的散射系数乘以在海拔h的介质密度。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"#00AAFF\">\n    <mi>T</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>P</mi>\n    <mi>A</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n<mstyle mathcolor=\"#00AA00\">\n  <mi>exp</mi>\n</mstyle>\n  <mrow data-mjx-texclass=\"ORD\">\n    <mo>&#x2212;</mo>\n    <msubsup>\n      <mo data-mjx-texclass=\"OP\">&#x222B;</mo>\n      <mi>P</mi>\n      <mi>A</mi>\n    </msubsup>\n    <mrow data-mjx-texclass=\"ORD\">\n      <mstyle mathcolor=\"Red\">\n        <mi>&#x3B2;</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>&#x3BB;</mi>\n        <mo>,</mo>\n        <mi>h</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mstyle>\n    </mrow>\n    <mi>d</mi>\n    <mi>s</mi>\n  </mrow>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>分解出来后得到的结果如下，其中红色的部分代表的意思是在海平面的散射系数，是一个常量，黄色部分代表了在海拔为h的介质的密度。这个公式的积分便是针对AP路线上的介质密度，其结果也就是光学距离。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"#00AAFF\">\n    <mi>T</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>P</mi>\n    <mi>A</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n    <mstyle mathcolor=\"#00AA00\">\n      <mi>exp</mi>\n    </mstyle>\n  <mrow data-mjx-texclass=\"ORD\">\n    <mo>&#x2212;</mo>\n    <mstyle mathcolor=\"Red\">\n      <mi>&#x3B2;</mi>\n      <mo stretchy=\"false\">(</mo>\n      <mi>&#x3BB;</mi>\n      <mo stretchy=\"false\">)</mo>\n    </mstyle>\n    <msubsup>\n      <mo data-mjx-texclass=\"OP\">&#x222B;</mo>\n      <mi>P</mi>\n      <mi>A</mi>\n    </msubsup>\n    <mrow data-mjx-texclass=\"ORD\">\n      <mstyle mathcolor=\"Gold\">\n        <mi>&#x3C1;</mi>\n        <mo stretchy=\"false\">(</mo>\n        <mi>h</mi>\n        <mo stretchy=\"false\">)</mo>\n      </mstyle>\n    </mrow>\n    <mi>d</mi>\n    <mi>s</mi>\n  </mrow>\n</math>\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p>介质密度的计算公式如下，其中H代表的是一个基准海拔，是一个常量。不同散射的基准海拔有所不同，瑞利散射的基准海拔是*8500*，而米氏散射的基准海拔是*1200*。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:html -->\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n  <mstyle mathcolor=\"Gold\">\n    <mi>&#x3C1;</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>h</mi>\n    <mo stretchy=\"false\">)</mo>\n  </mstyle>\n  <mo>=</mo>\n  <mi>exp</mi>\n  <mo stretchy=\"false\">(</mo>\n  <mo>&#x2212;</mo>\n  <mfrac>\n    <mi>h</mi>\n    <mi>H</mi>\n  </mfrac>\n  <mo stretchy=\"false\">)</mo>\n</math>\n<!-- /wp:html -->\n\n<p>自此，我们关于单次散射的天空大气渲染方法的基本预备知识已经了解的差不多了，接下来介绍shader的相关代码。</p>\n<h1 id=\"Shader代码\"><a href=\"#Shader代码\" class=\"headerlink\" title=\"Shader代码\"></a>Shader代码</h1><p>首先，为了计算AB、PC等视线和光线在大气层内的传播距离，我们需要一个函数来计算射线和球体的相交情况。</p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-type\">vec2</span> ray_sphere_intersection(<span class=\"hljs-type\">vec3</span> ray_origin, <span class=\"hljs-type\">vec3</span> ray_direction, <span class=\"hljs-type\">vec3</span> sphere_center, <span class=\"hljs-type\">float</span> sphere_radius)<br>&#123;<br>    <span class=\"hljs-comment\">// ray-sphere intersection that assumes</span><br>    <span class=\"hljs-type\">float</span> a = <span class=\"hljs-built_in\">dot</span>(ray_direction, ray_direction);<br>    <span class=\"hljs-type\">vec3</span> oc = ray_origin - sphere_center;<br>    <span class=\"hljs-type\">float</span> b = <span class=\"hljs-number\">2.0</span> * <span class=\"hljs-built_in\">dot</span>(ray_direction, oc);<br>    <span class=\"hljs-type\">float</span> c = <span class=\"hljs-built_in\">dot</span>(oc, oc) - (sphere_radius * sphere_radius);<br>    <span class=\"hljs-type\">float</span> d = (b*b) - <span class=\"hljs-number\">4.0</span>*a*c;<br><br>    <span class=\"hljs-comment\">// 返回击中结果，y小于x代表无结果</span><br>    <span class=\"hljs-keyword\">if</span> (d &lt; <span class=\"hljs-number\">0.0</span>) <span class=\"hljs-keyword\">return</span> <span class=\"hljs-type\">vec2</span>(<span class=\"hljs-number\">1e10</span>,<span class=\"hljs-number\">-1e10</span>);<br>    <span class=\"hljs-comment\">// 击中的话有两个相同或者不同的结果</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-type\">vec2</span>(<br>        (-b - <span class=\"hljs-built_in\">sqrt</span>(d))/(<span class=\"hljs-number\">2.0</span>*a),<br>        (-b + <span class=\"hljs-built_in\">sqrt</span>(d))/(<span class=\"hljs-number\">2.0</span>*a)<br>    );<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<!-- wp:paragraph -->\n<p>好了，那有了这个辅助公式，我们正式开始计算大气的颜色。首先，按照之前的理论，我们要计算视线向量在大气层内的长度，所以我们对射线方向和大气层，以及射线方向和星球表面做射线检测。得到视线在大气层内的长度后，根据我们预设的想要采样的步数（iSteps），计算出每次采样的长度ds。</p>\n<!-- /wp:paragraph -->\n\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\">ray_dir = <span class=\"hljs-built_in\">normalize</span>(ray_dir);<br><br><span class=\"hljs-comment\">// 视线和大气层大小的尺寸的射线检测</span><br><span class=\"hljs-comment\">// x为大气入射点的距离、y为大气出射点的距离（x==y代表光线和大气球体相切，x&gt;y代表光线不经过大气）</span><br><span class=\"hljs-type\">vec2</span> atmos_hit = ray_sphere_intersection(ray_origin, ray_dir, rAtmos);<br><span class=\"hljs-comment\">// 未击中，返回0</span><br><span class=\"hljs-keyword\">if</span> (atmos_hit.x &gt; atmos_hit.y) <span class=\"hljs-keyword\">return</span> <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>);<br><br>    <span class=\"hljs-comment\">// 视线和星球做射线检测，取得近处的检测结果（远处的那个光被星球本体遮挡）</span><br><span class=\"hljs-type\">vec2</span> planet_hit = ray_sphere_intersection(ray_origin, ray_dir, planet_radius);<br><span class=\"hljs-type\">float</span> light_distance = atmos_hit.y;<br><br><span class=\"hljs-comment\">// hit the planet</span><br><span class=\"hljs-keyword\">if</span>(planet_hit.x &lt; planet_hit.y &amp;&amp; planet_hit.x &gt; <span class=\"hljs-number\">0.1</span>)<br>&#123;<br>    light_distance = planet_hit.x;<br>&#125;<br><br><span class=\"hljs-comment\">// light sample length</span><br><span class=\"hljs-type\">float</span> ds = light_distance / <span class=\"hljs-type\">float</span>(iSteps);<br></code></pre></td></tr></table></figure>\n\n<!-- wp:paragraph -->\n<p>那么接下来，便是进入采样的循环。循环有两层，外面的循环是计算<strong>视线方向上的每个采样点的光能量</strong>，而计算这个点的光能量也需要一个循环，这个循环是用于采样该点和光源之间的连线在大气层内的线段（也就是之前图片的PC段）的光学距离。根据前面提到的公式，光学距离乘以海平面的散射系数便可以得到光的衰减系数，因此jSteps循环可以得到光线在进入大气层后，传播到达视线上的采样点（P0、P1...Pn点）的衰减所剩下的能量。</p>\n<!-- /wp:paragraph -->\n\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// Initialize the primary ray time.</span><br><span class=\"hljs-type\">float</span> iTime = <span class=\"hljs-number\">0.0</span>;<br><br><span class=\"hljs-comment\">// Initialize accumulators for Rayleigh and Mie scattering.</span><br><span class=\"hljs-type\">vec3</span> total_scatter_rlh = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>);<br><span class=\"hljs-type\">vec3</span> total_scatter_mie = <span class=\"hljs-type\">vec3</span>(<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>);<br><br><span class=\"hljs-comment\">// Initialize optical depth accumulators for the primary ray.</span><br><span class=\"hljs-type\">float</span> total_od_rlh = <span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-type\">float</span> total_od_mie = <span class=\"hljs-number\">0.0</span>;<br><br><span class=\"hljs-comment\">// 对每个视线上的采样点循环</span><br><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; iSteps; i++) &#123;<br>    <span class=\"hljs-comment\">// 获取到采样点的位置</span><br>    <span class=\"hljs-type\">vec3</span> iPos = ray_origin + ray_dir * (iTime + ds * <span class=\"hljs-number\">0.5</span>);<br><br>    <span class=\"hljs-comment\">// 在当前点向太阳的位置做射线检测，以大气的半径为球体。.y是代表大气的出射点，j_steps代表采样数</span><br>    <span class=\"hljs-type\">float</span> jStepSize = ray_sphere_intersection(iPos, pSun, rAtmos).y / <span class=\"hljs-type\">float</span>(jSteps);<br><br>    <span class=\"hljs-type\">float</span> jTime = <span class=\"hljs-number\">0.0</span>;<br>    <span class=\"hljs-type\">float</span> jOdRlh = <span class=\"hljs-number\">0.0</span>;<br>    <span class=\"hljs-type\">float</span> jOdMie = <span class=\"hljs-number\">0.0</span>;<br><br>    <span class=\"hljs-comment\">// 在当前采样到大气入射点的距离上，采样计算</span><br>    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; jSteps; j++) &#123;<br>        <span class=\"hljs-comment\">// 计算采样点到光源的衰减</span><br>        <span class=\"hljs-type\">vec3</span> jPos = iPos + pSun * (jTime + jStepSize * <span class=\"hljs-number\">0.5</span>);<br><br>        <span class=\"hljs-type\">float</span> jHeight = <span class=\"hljs-built_in\">length</span>(jPos-planet_center) - planet_radius;<br><br>        <span class=\"hljs-comment\">// Accumulate the optical depth.</span><br>        jOdRlh += get_atmos_density(jHeight, scale_height_rlh) * jStepSize;<br>        jOdMie += get_atmos_density(jHeight, scale_height_mie) * jStepSize;<br><br>        <span class=\"hljs-comment\">// Increment the secondary ray time.</span><br>        jTime += jStepSize;<br>    &#125;<br><br>    <span class=\"hljs-comment\">// 观察点和星球表面距离</span><br>    <span class=\"hljs-type\">float</span> surface_height = <span class=\"hljs-built_in\">length</span>(iPos-planet_center) - planet_radius;<br><br>    <span class=\"hljs-comment\">// 计算这一步的散射的光学深度结果</span><br>    <span class=\"hljs-type\">float</span> od_step_rlh = get_atmos_density(surface_height, scale_height_rlh) * ds;<br>    <span class=\"hljs-type\">float</span> od_step_mie = get_atmos_density(surface_height, scale_height_mie) * ds;<br>    <br>    total_od_rlh += od_step_rlh;<br>    total_od_mie += od_step_mie;<br><br>    <span class=\"hljs-comment\">// 计算衰减系数，光在经过一定距离后衰减剩下来的比例。</span><br>    <span class=\"hljs-type\">vec3</span> attn = <span class=\"hljs-built_in\">exp</span>(-(kMie * (total_od_mie + jOdMie) + kRlh * (total_od_rlh + jOdRlh)));<br><br>    <span class=\"hljs-comment\">// Accumulate scattering.</span><br>    total_scatter_rlh += od_step_rlh * attn;<br>    total_scatter_mie += od_step_mie * attn;<br><br>    <span class=\"hljs-comment\">// Increment the primary ray time.</span><br>    iTime += ds;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<!-- wp:paragraph -->\n<p>计算瑞利散射和米氏散射的大气密度的代码如下所示，其中scale_height在计算瑞利散射的时候带入的是8500，米氏散射则带入1200。</p>\n<!-- /wp:paragraph -->\n\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 获取大气密度</span><br><span class=\"hljs-comment\">// 传入位置离海平面的高度，以及散射的相关基准高度</span><br><span class=\"hljs-comment\">// 大气中任意一点的散射系数的计算，简化拆解为散射在海平面的散射系数，乘以基于海平面高度的该散射的大气密度计算公式</span><br><span class=\"hljs-type\">float</span> get_atmos_density(<span class=\"hljs-type\">float</span> height_to_sea_level, <span class=\"hljs-type\">float</span> scale_height)<br>&#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">exp</span>(-height_to_sea_level / scale_height);<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<!-- wp:paragraph -->\n<p>将iSteps循环的结果累加起来，我们便得到了视线上（AB）的每个采样点的光能量传播到达相机（A点）经过衰减的能量的和。那么还剩一个部分，就是光在P点进行散射的时候，光也损失掉了一部分能量，这个过程可以通过乘以米氏散射和瑞利散射的相位函数来计算。因为每个采样点P的结果都需要乘以相位函数，所以我们可以将它提取到最外面，乘以光的能量的总和即可。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>不过需要注意的是，前面的公式提到了，相位函数是和光线入射方向和目标方向的夹角相关的，所以如果我们<strong>默认太阳光源是平行光</strong>的话，这个夹角对每个采样点来说是一样的，所以可以将相位函数提取到最外层。如果认为这个夹角对每个采样点不一样的话，那也许还是应该老老实实在计算每个采样点的光的时候单独去处理。</p>\n<!-- /wp:paragraph -->\n\n<p>最终的结果除了乘以相位函数，还需要乘以海平面的散射系数，结果如下。</p></p>\n<figure class=\"highlight glsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs glsl\"><span class=\"hljs-comment\">// 计算并返回最终颜色</span><br><span class=\"hljs-comment\">// iSun是光源（太阳）的颜色</span><br><span class=\"hljs-keyword\">return</span> iSun * (pRlh * kRlh * total_scatter_rlh + pMie * kMie * total_scatter_mie);<br></code></pre></td></tr></table></figure>\n<p>下面是得到的结果：</p>\n<iframe src=\"single-scatter-atmosphere.mp4\" scrolling=\"no\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/\">https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/</a></li>\n<li><a href=\"https://www.xianlongok.site/post/8e5d3b12/\">https://www.xianlongok.site/post/8e5d3b12/</a></li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/ProceduralTerrainGeneration/calc_soft_shadow.png","slug":"calc_soft_shadow.png","post":"cm34lv4qc0001y05705f2e1jt","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_oc11_hardshadow.png","slug":"shadertoy_oc11_hardshadow.png","post":"cm34lv4qc0001y05705f2e1jt","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_oc11_noshadow.png","slug":"shadertoy_oc11_noshadow.png","post":"cm34lv4qc0001y05705f2e1jt","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_oc5_noshadow.png","slug":"shadertoy_oc5_noshadow.png","post":"cm34lv4qc0001y05705f2e1jt","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_terrain.png","slug":"shadertoy_terrain.png","post":"cm34lv4qc0001y05705f2e1jt","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration/shadertoy_terrain_oct5.png","slug":"shadertoy_terrain_oct5.png","post":"cm34lv4qc0001y05705f2e1jt","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_no_grass.png","slug":"terrain_no_grass.png","post":"cm34lv4qh000fy057gau26780","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_all_cloud.png","slug":"terrain_with_all_cloud.png","post":"cm34lv4qh000fy057gau26780","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_grass.png","slug":"terrain_with_grass.png","post":"cm34lv4qh000fy057gau26780","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_high_cloud.png","slug":"terrain_with_high_cloud.png","post":"cm34lv4qh000fy057gau26780","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky.png","slug":"terrain_with_sky.png","post":"cm34lv4qh000fy057gau26780","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky_fog.png","slug":"terrain_with_sky_fog.png","post":"cm34lv4qh000fy057gau26780","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_mountain.png","slug":"terrain_with_sky_fog_diffuse_from_mountain.png","post":"cm34lv4qh000fy057gau26780","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_sky.png","slug":"terrain_with_sky_fog_diffuse_from_sky.png","post":"cm34lv4qh000fy057gau26780","modified":0,"renderable":0},{"_id":"source/_posts/ProceduralTerrainGeneration2/terrain_with_sky_fog_less_ambient.png","slug":"terrain_with_sky_fog_less_ambient.png","post":"cm34lv4qh000fy057gau26780","modified":0,"renderable":0},{"_id":"source/_posts/cascade-shadow-map/csm_far.png","slug":"csm_far.png","post":"cm34lv4qi000iy057a2o18zgj","modified":0,"renderable":0},{"_id":"source/_posts/cascade-shadow-map/csm_mid.png","slug":"csm_mid.png","post":"cm34lv4qi000iy057a2o18zgj","modified":0,"renderable":0},{"_id":"source/_posts/cascade-shadow-map/csm_near.png","slug":"csm_near.png","post":"cm34lv4qi000iy057a2o18zgj","modified":0,"renderable":0},{"_id":"source/_posts/cascade-shadow-map/csm_result.png","slug":"csm_result.png","post":"cm34lv4qi000iy057a2o18zgj","modified":0,"renderable":0},{"_id":"source/_posts/cascade-shadow-map/sm_far.png","slug":"sm_far.png","post":"cm34lv4qi000iy057a2o18zgj","modified":0,"renderable":0},{"_id":"source/_posts/cascade-shadow-map/sm_near.png","slug":"sm_near.png","post":"cm34lv4qi000iy057a2o18zgj","modified":0,"renderable":0},{"_id":"source/_posts/defer-render/defer_render.png","slug":"defer_render.png","post":"cm34lv4qj000my0574r4r0g30","modified":0,"renderable":0},{"_id":"source/_posts/defer-render/defer_render_banner.png","slug":"defer_render_banner.png","post":"cm34lv4qj000my0574r4r0g30","modified":0,"renderable":0},{"_id":"source/_posts/defer-render/no_defer_render.png","slug":"no_defer_render.png","post":"cm34lv4qj000my0574r4r0g30","modified":0,"renderable":0},{"_id":"source/_posts/defer-render/ssao.png","slug":"ssao.png","post":"cm34lv4qj000my0574r4r0g30","modified":0,"renderable":0},{"_id":"source/_posts/depth-of-field/dilate_after.png","slug":"dilate_after.png","post":"cm34lv4qj000py0576os04ic7","modified":0,"renderable":0},{"_id":"source/_posts/depth-of-field/dilate_before.png","slug":"dilate_before.png","post":"cm34lv4qj000py0576os04ic7","modified":0,"renderable":0},{"_id":"source/_posts/depth-of-field/dof_butterfly.JPG","slug":"dof_butterfly.JPG","post":"cm34lv4qj000py0576os04ic7","modified":0,"renderable":0},{"_id":"source/_posts/depth-of-field/dof_far.png","slug":"dof_far.png","post":"cm34lv4qj000py0576os04ic7","modified":0,"renderable":0},{"_id":"source/_posts/depth-of-field/dof_near.png","slug":"dof_near.png","post":"cm34lv4qj000py0576os04ic7","modified":0,"renderable":0},{"_id":"source/_posts/depth-of-field/game1.jpg","slug":"game1.jpg","post":"cm34lv4qj000py0576os04ic7","modified":0,"renderable":0},{"_id":"source/_posts/single-scatter-atmosphere/kong-screen-shot.png","slug":"kong-screen-shot.png","post":"cm34lv4qk000ry057fpdcb1oy","modified":0,"renderable":0},{"_id":"source/_posts/single-scatter-atmosphere/single-scatter-atmosphere.mp4","slug":"single-scatter-atmosphere.mp4","post":"cm34lv4qk000ry057fpdcb1oy","modified":0,"renderable":0},{"_id":"source/_posts/single-scatter-atmosphere/single-scatter-atmosphere.png","slug":"single-scatter-atmosphere.png","post":"cm34lv4qk000ry057fpdcb1oy","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cm34lv4qc0001y05705f2e1jt","category_id":"cm34lv4qe0003y0577mjbbi3q","_id":"cm34lv4qg0006y0576c0f6mdl"},{"post_id":"cm34lv4qh000fy057gau26780","category_id":"cm34lv4qe0003y0577mjbbi3q","_id":"cm34lv4qj000ny05787v4aof8"},{"post_id":"cm34lv4qi000iy057a2o18zgj","category_id":"cm34lv4qe0003y0577mjbbi3q","_id":"cm34lv4qk000sy057cebsd4a6"},{"post_id":"cm34lv4qj000my0574r4r0g30","category_id":"cm34lv4qe0003y0577mjbbi3q","_id":"cm34lv4qk000uy057calfhxre"},{"post_id":"cm34lv4qj000py0576os04ic7","category_id":"cm34lv4qe0003y0577mjbbi3q","_id":"cm34lv4qk000wy057egwr8z23"},{"post_id":"cm34lv4qi000gy057gbxk779v","category_id":"cm34lv4qj000jy057exu62lns","_id":"cm34lv4qk000yy05771vcgzvs"},{"post_id":"cm34lv4qk000ry057fpdcb1oy","category_id":"cm34lv4qe0003y0577mjbbi3q","_id":"cm34lv4qk0010y057d8qo1mk1"}],"PostTag":[{"post_id":"cm34lv4qc0001y05705f2e1jt","tag_id":"cm34lv4qf0004y057byja05it","_id":"cm34lv4qh000ay0578rn5a7sl"},{"post_id":"cm34lv4qc0001y05705f2e1jt","tag_id":"cm34lv4qf0005y0573vza9q91","_id":"cm34lv4qh000by05700k2capu"},{"post_id":"cm34lv4qc0001y05705f2e1jt","tag_id":"cm34lv4qg0007y05756etb4uv","_id":"cm34lv4qh000cy057cjfudwgn"},{"post_id":"cm34lv4qc0001y05705f2e1jt","tag_id":"cm34lv4qg0008y057afacaos4","_id":"cm34lv4qh000dy057d0yq8ws3"},{"post_id":"cm34lv4qc0001y05705f2e1jt","tag_id":"cm34lv4qg0009y057ayav02qt","_id":"cm34lv4qh000ey057caib2u2i"},{"post_id":"cm34lv4qh000fy057gau26780","tag_id":"cm34lv4qf0004y057byja05it","_id":"cm34lv4qi000hy057aamuazj6"},{"post_id":"cm34lv4qh000fy057gau26780","tag_id":"cm34lv4qf0005y0573vza9q91","_id":"cm34lv4qj000ly0574swhcdl6"},{"post_id":"cm34lv4qh000fy057gau26780","tag_id":"cm34lv4qg0007y05756etb4uv","_id":"cm34lv4qj000oy057av6tfgsy"},{"post_id":"cm34lv4qh000fy057gau26780","tag_id":"cm34lv4qg0008y057afacaos4","_id":"cm34lv4qk000qy0573hy57wqw"},{"post_id":"cm34lv4qh000fy057gau26780","tag_id":"cm34lv4qg0009y057ayav02qt","_id":"cm34lv4qk000ty057eldrc0at"},{"post_id":"cm34lv4qi000iy057a2o18zgj","tag_id":"cm34lv4qf0004y057byja05it","_id":"cm34lv4qk000vy057924afune"},{"post_id":"cm34lv4qi000iy057a2o18zgj","tag_id":"cm34lv4qf0005y0573vza9q91","_id":"cm34lv4qk000xy057e6ey10ii"},{"post_id":"cm34lv4qi000iy057a2o18zgj","tag_id":"cm34lv4qg0007y05756etb4uv","_id":"cm34lv4qk000zy0572kma1wy4"},{"post_id":"cm34lv4qi000iy057a2o18zgj","tag_id":"cm34lv4qg0008y057afacaos4","_id":"cm34lv4qk0011y057hyx97ulk"},{"post_id":"cm34lv4qj000my0574r4r0g30","tag_id":"cm34lv4qf0004y057byja05it","_id":"cm34lv4ql0012y0578oz9d2nb"},{"post_id":"cm34lv4qj000my0574r4r0g30","tag_id":"cm34lv4qf0005y0573vza9q91","_id":"cm34lv4ql0013y057b73yakfm"},{"post_id":"cm34lv4qj000my0574r4r0g30","tag_id":"cm34lv4qg0007y05756etb4uv","_id":"cm34lv4ql0014y0579grphz2z"},{"post_id":"cm34lv4qj000my0574r4r0g30","tag_id":"cm34lv4qg0008y057afacaos4","_id":"cm34lv4ql0015y057gdc6drwo"},{"post_id":"cm34lv4qj000py0576os04ic7","tag_id":"cm34lv4qf0004y057byja05it","_id":"cm34lv4ql0016y0575ay34si0"},{"post_id":"cm34lv4qj000py0576os04ic7","tag_id":"cm34lv4qf0005y0573vza9q91","_id":"cm34lv4ql0017y057hfcb1e10"},{"post_id":"cm34lv4qj000py0576os04ic7","tag_id":"cm34lv4qg0007y05756etb4uv","_id":"cm34lv4ql0018y0574jwgh561"},{"post_id":"cm34lv4qj000py0576os04ic7","tag_id":"cm34lv4qg0008y057afacaos4","_id":"cm34lv4ql0019y057ev2ubg91"},{"post_id":"cm34lv4qi000gy057gbxk779v","tag_id":"cm34lv4qj000ky057ammug7ye","_id":"cm34lv4ql001ay0570m586haz"},{"post_id":"cm34lv4qk000ry057fpdcb1oy","tag_id":"cm34lv4qf0004y057byja05it","_id":"cm34lv4ql001by05700mf47ks"},{"post_id":"cm34lv4qk000ry057fpdcb1oy","tag_id":"cm34lv4qf0005y0573vza9q91","_id":"cm34lv4ql001cy057cj369l62"},{"post_id":"cm34lv4qk000ry057fpdcb1oy","tag_id":"cm34lv4qg0007y05756etb4uv","_id":"cm34lv4ql001dy057012v93r5"},{"post_id":"cm34lv4qk000ry057fpdcb1oy","tag_id":"cm34lv4qg0008y057afacaos4","_id":"cm34lv4ql001ey0575rtp8m3j"}],"Tag":[{"name":"3D","_id":"cm34lv4qf0004y057byja05it"},{"name":"render","_id":"cm34lv4qf0005y0573vza9q91"},{"name":"渲染","_id":"cm34lv4qg0007y05756etb4uv"},{"name":"编程","_id":"cm34lv4qg0008y057afacaos4"},{"name":"程序化生成","_id":"cm34lv4qg0009y057ayav02qt"},{"name":"生活","_id":"cm34lv4qj000ky057ammug7ye"}]}}