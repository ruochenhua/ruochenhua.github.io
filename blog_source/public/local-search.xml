<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>屏幕空间反射</title>
    <link href="/2024/12/10/screen-space-reflection/"/>
    <url>/2024/12/10/screen-space-reflection/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是屏幕空间反射"><a href="#什么是屏幕空间反射" class="headerlink" title="什么是屏幕空间反射"></a>什么是屏幕空间反射</h1><p>在前面的文章的一些配图中，其实已经揭露了之前在<a href="https://github.com/ruochenhua/KongEngine">KongEngine</a>中实现的一个不小的功能点，就是<strong>屏幕空间反射（screen space reflection）</strong>。加入了屏幕空间反射能力之后，在一些光滑和带有反射材质的表面上，能够实现不错的反射效果。</p><p><img src="/2024/12/10/screen-space-reflection/screen-space-reflection-in-kong.png" alt="KongEngine中的屏幕空间反射效果"></p><p>屏幕空间反射（后简称<strong>SSR</strong>）是一种在实时渲染中用于模拟物体表面反射的成熟技术。SSR 的核心原理是在<strong>屏幕空间</strong>中进行光线追踪，以此计算反射效果，而无需像传统方法那样在世界空间或物体空间中进行复杂的光线与场景求交计算。它主要利用屏幕上已有的<strong>深度图</strong>和<strong>法线图</strong>等信息，通过对这些信息的分析和处理，确定反射光线的方向和位置，进而得到反射颜色。</p><p>因为SSR不错的效果表现和相对来说比较低的性能开销，使其被广泛的应用在各个实时渲染领域，包括游戏、虚拟现实、建筑可视化等等。当然SSR的效果其实还不够完美，有很多无法解决的问题，这个在后面也会提到。但是在大多数情况下它的效果都是足够的，属于一个很<strong>高性价比</strong>的方法。</p><h1 id="如何实现屏幕空间反射"><a href="#如何实现屏幕空间反射" class="headerlink" title="如何实现屏幕空间反射"></a>如何实现屏幕空间反射</h1><h2 id="屏幕空间反射的实现方法"><a href="#屏幕空间反射的实现方法" class="headerlink" title="屏幕空间反射的实现方法"></a>屏幕空间反射的实现方法</h2><p>简单概括一下SSR的实现方法：</p><ol><li>对于屏幕上的每个像素，先获取其<strong>深度值</strong>和<strong>法线向量</strong>。</li><li>结合相机参数和屏幕坐标计算出<strong>观察向量</strong>，进而得到<strong>反射向量</strong>。    </li><li>沿着反射向量在屏幕空间进行光线追踪，查找反射光线与场景中其他物体的相交点，以获取反射光线的颜色，最终将反射颜色与场景的原始颜色进行合成，得到带有反射效果的最终渲染结果。</li></ol><p>我们对于上面1、2两步应该已经不陌生了，毕竟我们在前面的文章就介绍了KongEngine接入<a href="https://ruochenhua.github.io/2024/10/19/defer-render/">延迟渲染</a>的能力，在G-Buffer中我们已经存储了屏幕空间的各种相关数据，包括深度值和法线向量。有了这些数据，按照第2点计算反射向量也是很顺理成章的事情。</p><p>对应的代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 将延迟渲染保存的数据传给SSR shader</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">CRender::SSReflectionRender</span><span class="hljs-params">()</span> <span class="hljs-type">const</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// scene normal：defer_buffer_.g_normal_</span><br><span class="hljs-comment">// scene reflection mask: defer_buffer_.g_orm_</span><br><span class="hljs-comment">// scene position: defer_buffer_.g_position_</span><br><span class="hljs-comment">// scene depth存在于normal贴图的w分量上</span><br>ssreflection_shader-&gt;<span class="hljs-built_in">Use</span>();<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, defer_buffer_.g_position_);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + <span class="hljs-number">1</span>);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, defer_buffer_.g_normal_);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + <span class="hljs-number">2</span>);<br><span class="hljs-comment">// 用给后处理的texture作为scene color</span><br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, post_process.screen_quad_texture[<span class="hljs-number">0</span>]);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + <span class="hljs-number">3</span>);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, defer_buffer_.g_orm_);<br><br>quad_shape-&gt;<span class="hljs-built_in">Draw</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>那么SSR的关键步骤，其实就在第三步，也是需要理解的重点部分。</p><h2 id="获得反射的颜色"><a href="#获得反射的颜色" class="headerlink" title="获得反射的颜色"></a>获得反射的颜色</h2><p><img src="/2024/12/10/screen-space-reflection/ssr-step3.gif" alt="SSR计算反射向量"></p><p>上面这张图大致描述了第3步的状态。图片中<strong>蓝色</strong>的向量代表了从相机向场景中的每个像素发射的观察向量，<strong>绿色</strong>的向量代表了场景中的法线向量，根据观察向量和法线向量，我们能够计算出反射向量，也就是图片中的<strong>红色</strong>向量。</p><p>我们需要得到的反射结果的颜色，基于反射向量和渲染场景中的其他物体的相交结果，这个是通过在<em>屏幕空间进行步近，判断步近后的坐标深度和深度缓存中存储的物体深度是否相交</em>来得到的。如果有相交结果，则该像素的反射颜色就是相交处的场景颜色，若超出步近范围（会预先设置一个步近长度或者步数的范围），则改点没有反射需要处理。</p><p><img src="/2024/12/10/screen-space-reflection/ssr-step4.gif" alt="反射向量步近"></p><p>这个原理是非常简单易懂的，下面是这段逻辑的大致代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec2</span> tex_size = <span class="hljs-built_in">textureSize</span>(scene_position, <span class="hljs-number">0</span>).xy;<br>    <span class="hljs-type">vec2</span> tex_uv = <span class="hljs-built_in">gl_FragCoord</span>.xy / tex_size;<br><br>    <span class="hljs-comment">// 材质相关的参数</span><br>    <span class="hljs-type">vec4</span> orm = <span class="hljs-built_in">texture</span>(orm_texture, TexCoords);<br>    <span class="hljs-type">float</span> roughness = orm.y;<br>    <span class="hljs-type">float</span> metallic = orm.z;<br>    <span class="hljs-comment">// 颜色信息</span><br>    <span class="hljs-type">vec4</span> s_color = <span class="hljs-built_in">texture</span>(scene_color, TexCoords);<br>    FragColor = s_color;<br><br>    <span class="hljs-comment">// 深度和法线</span><br>    <span class="hljs-type">vec4</span> normal_depth = <span class="hljs-built_in">texture</span>(scene_normal, TexCoords);<br>    <span class="hljs-type">vec3</span> world_normal = <span class="hljs-built_in">normalize</span>(normal_depth.xyz + randVec3(<span class="hljs-built_in">fract</span>(TexCoords.x*<span class="hljs-number">12.345</span>)*<span class="hljs-built_in">sin</span>(TexCoords.y)*<span class="hljs-number">9876.31</span>)*<span class="hljs-number">0.2</span>*roughness);<br><br>    ...<br><br>&#125;<br></code></pre></td></tr></table></figure><p>上面这段代码是将gbuffer中的信息读出来，包括前面讲到的几个部分。其中法线信息world_normal和材质的粗糙度做了一个随机方向的叠加，可以稍微增加反射效果的粗糙感。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br><br>    <span class="hljs-comment">// 远近平面</span><br>    <span class="hljs-type">vec2</span> near_far = matrix_ubo.near_far.xy;<br>    <span class="hljs-type">vec3</span> world_pos = <span class="hljs-built_in">texture</span>(scene_position, TexCoords).xyz;<br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br><br>    <span class="hljs-type">mat4</span> projection = matrix_ubo.projection;<br>    <span class="hljs-type">mat4</span> view = matrix_ubo.view;<br>    <span class="hljs-type">mat4</span> vp = projection * view;    <span class="hljs-comment">// 世界坐标到裁切坐标的转换矩阵</span><br><br>    <span class="hljs-type">vec3</span> view_dir = <span class="hljs-built_in">normalize</span>(world_pos-cam_pos);<br>    <span class="hljs-type">vec3</span> rd = <span class="hljs-built_in">normalize</span>(<span class="hljs-built_in">reflect</span>(view_dir, world_normal));<br>    <br>    <span class="hljs-type">float</span> resolution = <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-type">float</span> max_step_dist = <span class="hljs-number">5.0</span>;        <br>    <span class="hljs-type">vec3</span> start_pos_world = world_pos  + rd*<span class="hljs-number">0.1</span>;<br>    <span class="hljs-type">vec3</span> end_pos_world = world_pos + max_step_dist*rd;<br><br>    <span class="hljs-comment">// 在屏幕空间上的从起始点到结束点的坐标</span><br>    <span class="hljs-type">vec4</span> start_clip = vp * <span class="hljs-type">vec4</span>(start_pos_world, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-type">vec4</span> end_clip   = vp * <span class="hljs-type">vec4</span>(end_pos_world, <span class="hljs-number">1.0</span>);<br><br>    ...<br>&#125;<br><br></code></pre></td></tr></table></figure><p>在上面的代码，我们计算出了反射向量rd，同时也为步进设定了一个范围max_step_dist，得到了反射的步进区间，接下来就是进行步进的操作了。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br>    <br>    <span class="hljs-comment">// 步进的步数</span><br>    <span class="hljs-type">int</span> step_count = <span class="hljs-number">32</span>;<br>    <span class="hljs-type">int</span> sample_count = step_count;<br>    <span class="hljs-type">float</span> delta = <span class="hljs-number">1.0</span> / sample_count;   <span class="hljs-comment">// 如果sample count为10，则delta采样为总共的1/10</span><br><br>    <span class="hljs-type">vec4</span> reflect_color = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_count; i++)<br>    &#123;<br>        <span class="hljs-type">float</span> sample_t = i*delta;<br>        <br>        <span class="hljs-comment">// 步进到达处的屏幕空间uv</span><br>        <span class="hljs-type">vec2</span> uv = <span class="hljs-type">vec2</span>(<span class="hljs-number">0</span>);<br><br>        <span class="hljs-keyword">if</span>(campareDepth(start_clip, end_clip, start_pos_world, end_pos_world, sample_t, uv))<br>        &#123;<br>            reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);        <br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br><br>    FragColor = reflect_color*metallic;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上面的步进代码中，根据设定好的步进步数迭代，campareDepth函数中将当前位置的深度和深度缓存中的数据作对比，若当前深度大于缓存中的值，则代表击中并返回对应的屏幕空间贴图对应的uv值。</p><p>最后反射的颜色和金属度相乘，金属度越高的材质反射也是越高的。在场景渲染的最后，将反射颜色和场景实际的颜色结合，就得到了基本的反射效果了。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl">FragColor = <span class="hljs-built_in">texture</span>(scene_texture, TexCoords);<br><span class="hljs-type">vec4</span> reflection_color = <span class="hljs-built_in">texture</span>(reflection_texture, TexCoords);<br><br>FragColor.rgb += reflection_color.rgb * reflection_color.a;<br></code></pre></td></tr></table></figure><p><img src="/2024/12/10/screen-space-reflection/ssr_normal_s32.png" alt="SSR效果:sample数32"><br>上面是采样步数为32步时，得到的反射效果。可以看到反射效果确实出来了，但是条纹效果太过于明显。我们可以提高采样的精度，将sample的数量改为128后可以得到明显改善的结果，如下图。</p><p><img src="/2024/12/10/screen-space-reflection/ssr_normal_s128.png" alt="SSR效果：sample数128"></p><h1 id="屏幕空间反射的优化"><a href="#屏幕空间反射的优化" class="headerlink" title="屏幕空间反射的优化"></a>屏幕空间反射的优化</h1><p>现在我们已经有了基础的反射效果了，但是我们还是不满足不是吗。单纯提升采样精度确实能得到不错的效果，但是始终还是要考虑实际的性能的。那么有什么方法可以优化SSR的表现呢，下面会做一部分简单的介绍。</p><h2 id="粗晒和精筛"><a href="#粗晒和精筛" class="headerlink" title="粗晒和精筛"></a>粗晒和精筛</h2><p>在上面的采样处理中，我们通过步进迭代获取到了深度超过gbuffer中的深度的位置。为了弥补采样步数不足，我们可以将采样过程分为两部分：首先是粗筛，用较低的采样精度获取到大致的区间；然后再利用二分法或者其他方法在大致区间内进行二次筛选。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br><br>    <span class="hljs-type">float</span> sample_t = i*delta;<br>    <span class="hljs-comment">// 线性插值找到当前采样的屏幕空间的点</span><br>    <span class="hljs-type">vec2</span> uv = <span class="hljs-type">vec2</span>(<span class="hljs-number">0</span>);<br><br>    <span class="hljs-keyword">if</span>(campareDepth(start_clip, end_clip, start_pos_world, end_pos_world, sample_t, uv))<br>    &#123;<br>        reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);<br>        <span class="hljs-type">int</span> split_count = <span class="hljs-number">10</span>;<br>        <span class="hljs-type">float</span> i_divide_pos = <span class="hljs-number">0.5</span>;<br>        <span class="hljs-keyword">while</span>(split_count &gt; <span class="hljs-number">0</span>)<br>        &#123;<br>            <span class="hljs-keyword">if</span>(campareDepth(start_clip, end_clip, start_pos_world, end_pos_world, (<span class="hljs-type">float</span>(i)-i_divide_pos)*delta, uv))<br>            &#123;<br>                i_divide_pos += i_divide_pos*<span class="hljs-number">0.5</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span><br>            &#123;<br>                i_divide_pos -= i_divide_pos*<span class="hljs-number">0.5</span>;<br>            &#125;<br>            split_count--;<br>        &#125;<br><br>        reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);<br>        <span class="hljs-keyword">break</span>;<br>    &#125;<br><br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>下面是这种方法的结果，可以看到效果是稍微好了些，不过如果需要再进一步的话，还是避免不了要提升采样精度。<br><img src="/2024/12/10/screen-space-reflection/ssr_sample_twice.png" alt="SSR二次采样"></p><h2 id="屏幕空间步进"><a href="#屏幕空间步进" class="headerlink" title="屏幕空间步进"></a>屏幕空间步进</h2><p>目前比较常用的优化方法，是把三维空间做光线步近替换为在屏幕空间做光线步近。<br>传统的在三维空间做光线步近，很难避免采样不均的问题，如果我们是以三维空间的的步近长度作为采样依据的话，会出现下面的问题。其中蓝色小格子代表的是像素，红色的点对应的是每个采样点对应的像素位置。</p><p><img src="/2024/12/10/screen-space-reflection/ssr_over_sample.png" alt="SSR过采样"><br>当反射角度相对来说比较大，很容易出现非常多采样点对应同一个像素，进行了大量的重复运算。</p><p><img src="/2024/12/10/screen-space-reflection/ssr_under_sample.png" alt="SSR欠采样"></p><p>反射角度过小的时候，有很容易出现跳过中间某些像素的情况，出现了欠采样的情况。这也是我们上面的反射效果出现了带状的原因。</p><p>在<a href="https://jcgt.org/published/0003/04/04/">Efficient GPU Screen-Space Ray Tracing</a>这篇文章提出了在屏幕空间采样的观点。通过将采样点的选择放在屏幕空间，实现采样点连续且分布均匀的效果。每个采样点不会进行重复计算，也保证了性能的最优。<br><img src="/2024/12/10/screen-space-reflection/ssr_ss_sample.png" alt="SSR屏幕空间采样方法"></p><p>为了实现屏幕看见步近，代码需要做一些修改：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br><br>    <span class="hljs-type">vec3</span> start_pos_world = world_pos  + rd*<span class="hljs-number">0.1</span>;<br>    <span class="hljs-type">vec3</span> end_pos_world = world_pos + max_step_dist*rd;<br>    <span class="hljs-comment">// 在屏幕空间上的从起始点到结束点的坐标[0, resolution]</span><br>    <span class="hljs-type">vec4</span> start_clip = vp * <span class="hljs-type">vec4</span>(start_pos_world, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-type">vec4</span> end_clip   = vp * <span class="hljs-type">vec4</span>(end_pos_world, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-comment">// 在屏幕空间进行光线步进</span><br>    <span class="hljs-comment">// 起始点和结束点</span><br>    <span class="hljs-type">vec3</span> start_ndc  = start_clip.xyz / start_clip.w;<br>    <span class="hljs-type">vec3</span> end_ndc    = end_clip.xyz / end_clip.w;<br>    <span class="hljs-type">vec3</span> ndc_diff = end_ndc - start_ndc;<br><br>    <span class="hljs-comment">// ndc-&gt;屏幕坐标 [0, resolution.xy]</span><br>    <span class="hljs-type">vec3</span> start_screen  = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);<br>    start_screen.xy = (start_ndc.xy + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span> * tex_size;<br>    start_screen.z = (near_far.y - near_far.x) * <span class="hljs-number">0.5</span> * start_ndc.z + (near_far.x + near_far.y) * <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-type">vec3</span> end_screen    = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);    <br>    end_screen.xy = (end_ndc.xy + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span> * tex_size;<br>    end_screen.z = (near_far.y - near_far.x) * <span class="hljs-number">0.5</span> * end_ndc.z + (near_far.x + near_far.y) * <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-type">int</span> step_count = <span class="hljs-number">32</span>;<br><br>    <span class="hljs-type">vec3</span> screen_diff = end_screen - start_screen;<br>    <span class="hljs-type">int</span> sample_count = <span class="hljs-type">int</span>(<span class="hljs-built_in">max</span>(<span class="hljs-built_in">abs</span>(screen_diff.x), <span class="hljs-built_in">abs</span>(screen_diff.y)) * resolution) ; <span class="hljs-comment">// 大于1</span><br><br>    sample_count = <span class="hljs-built_in">min</span>(sample_count, <span class="hljs-number">64</span>);<br>    <span class="hljs-type">vec3</span> delta_screen = screen_diff / <span class="hljs-type">float</span>(sample_count);<br><br>    <span class="hljs-comment">// 如果sample count为10，则每次采样的前进的长度为总长度的1/10</span><br>    <span class="hljs-type">float</span> percentage_delta = <span class="hljs-number">1.0</span> / <span class="hljs-type">float</span>(sample_count);<br>    <span class="hljs-type">vec3</span> current_screen = start_screen;<br>    <span class="hljs-type">vec3</span> last_screen = current_screen;<br>    <span class="hljs-type">float</span> current_percentage = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> last_percentage = <span class="hljs-number">0.0</span>;<br><br>    ...<br><br></code></pre></td></tr></table></figure><p>使用屏幕空间步近，前面和原来的差不多，在获取步近的起始点和结束点的时候，需要将坐标转换为屏幕空间的坐标，也就是其中的current_screen和last_screen。</p><p>屏幕空间采样点数和<strong>采样的起始和结束位置的像素差值</strong>有关，所以和渲染输出的分辨率也是相关的。如果渲染分辨率越高，其对应所需要的采样点数可能也会增加，这里我们控制在64以内。当然如果起始点和结束点的像素差值较小，对应的采样点数也会变小，也就是对于距离相机很远的位置的采样会减少，在怎么不影响效果的情况下提升性能表现。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs glsl">    ...<br><br>    <span class="hljs-type">vec4</span> reflect_color = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_count; i++)<br>    &#123;<br>        <span class="hljs-comment">// 采样当前屏幕上的点对应场景世界空间坐标的位置</span><br>        <span class="hljs-type">vec2</span> uv = current_screen.xy / tex_size;<br><br>        <span class="hljs-comment">// 转换为贴图坐标，检查越界</span><br>        <span class="hljs-keyword">if</span>(uv.x &lt; <span class="hljs-number">0.0</span> || uv.y &lt; <span class="hljs-number">0.0</span> || uv.x &gt; <span class="hljs-number">1.0</span> || uv.y &gt; <span class="hljs-number">1.0</span>)<br>        &#123;<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>            <span class="hljs-comment">// 延迟渲染存储的屏幕对应的世界位置</span><br>            <span class="hljs-type">vec3</span> sample_world = <span class="hljs-built_in">texture</span>(scene_position, uv).xyz;<br>            <br>            <span class="hljs-type">vec4</span> sample_ndc = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">mix</span>(start_ndc, end_ndc, current_percentage), <span class="hljs-number">1.0</span>);<br>            <span class="hljs-keyword">if</span>(compareDepth(sample_ndc, uv))<br>            &#123;<br>                <span class="hljs-comment">// 初筛后再二分法检查</span><br>                <span class="hljs-type">int</span> split_count = <span class="hljs-number">5</span>;<br>                <span class="hljs-keyword">while</span>(split_count &gt; <span class="hljs-number">0</span>)<br>                &#123;<br>                    <span class="hljs-type">vec3</span> mid_screen = (last_screen + current_screen) * <span class="hljs-number">0.5</span>;<br>                    <span class="hljs-type">float</span> mid_percentage = (last_percentage + current_percentage) * <span class="hljs-number">0.5</span>;<br>                    <span class="hljs-type">vec4</span> mid_ndc = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">mix</span>(start_ndc, end_ndc, mid_percentage), <span class="hljs-number">1.0</span>);<br>                    uv = mid_screen.xy / tex_size;<br>                    <span class="hljs-keyword">if</span>(compareDepth(mid_ndc, uv))<br>                    &#123;<br>                        current_screen = mid_screen;<br>                    &#125;<br>                    <span class="hljs-keyword">else</span><br>                    &#123;<br>                        last_screen = mid_screen;<br>                    &#125;<br>                    split_count--;<br>                &#125;<br><br>                reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br><br>            last_screen = current_screen;<br>            last_percentage = current_percentage;<br>            current_screen += delta_screen;<br>            current_percentage += percentage_delta;<br>        &#125;<br>    &#125;<br><br>    FragColor = reflect_color*metallic;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><p>这里在屏幕空间采样还配合了之前的粗筛和精筛的方法，下面是使用屏幕空间采样的表现。可以看到条纹的状况被极大的缓解了。</p><p><img src="/2024/12/10/screen-space-reflection/ssr_result.png" alt="SSR屏幕空间采样结果"></p><p>应用在实际场景中，SSR的效果能比较明显的提升渲染质感。<br><img src="/2024/12/10/screen-space-reflection/ssr_mugshot.png" alt="SSR实际应用"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>SSR是一种计算场景的反射效果的算法，它基于屏幕空间已有的深度图和法线图等信息，通过计算反射向量，在屏幕空间中进行光线追踪，查找反射光线与场景中其他物体的相交点，获取相交点的颜色作为反射颜色，并与原始颜色合成得到最终渲染结果。</p><p>SSR的优点是计算效率相对较高，能实时反映场景中物体的变化，适用于复杂几何形状和不规则表面，适合大规模的动态场景，无需额外的镜头或几何体。</p><p>当然，SSR也有局限性，它只能反射屏幕上可见的物体，超出屏幕边界的内容无法被反射；反射的物体可能存在失真或错误，尤其是边缘区域；依赖屏幕分辨率，高分辨率下可能对性能有较大影响</p><h2 id="SSR的优化改进算法："><a href="#SSR的优化改进算法：" class="headerlink" title="SSR的优化改进算法："></a>SSR的优化改进算法：</h2><h3 id="SSSR（Spatially-Separated-Screen-Space-Reflection）"><a href="#SSSR（Spatially-Separated-Screen-Space-Reflection）" class="headerlink" title="SSSR（Spatially Separated Screen Space Reflection）"></a>SSSR（Spatially Separated Screen Space Reflection）</h3><p>原理：SSSR 是对传统 SSR 技术的一种改进。它主要是基于空间分离的思想来处理屏幕空间反射。传统 SSR 在处理反射时可能会受到屏幕空间限制和采样不足等问题的影响。SSSR 通过将屏幕空间划分为不同的区域，在这些区域内分别进行更精细的反射处理。</p><p>例如，它可以根据场景中物体的距离、重要性或者反射特性等因素，对空间进行划分。对于反射效果比较复杂或者重要的区域，分配更多的资源进行反射计算，而对于相对简单或者不重要的区域，则采用较为简略的计算方式。</p><p>优点：</p><ul><li>提高反射精度：通过对特定区域的精细处理，能够有效提高反射的精度。比如在处理具有高反射率的物体表面或者复杂的光照反射场景时，可以得到更真实、细腻的反射效果。</li><li>优化性能：与传统 SSR 相比，SSSR 能够更合理地分配计算资源。它避免了在整个屏幕空间进行统一标准的反射计算，从而在一定程度上减轻了计算负担，特别是在大规模复杂场景中，可以更好地平衡反射效果和性能。</li></ul><p>局限性：</p><ul><li>空间划分的复杂性：如何合理地划分空间是一个具有挑战性的问题。如果空间划分不合理，可能会导致反射效果出现不自然的边界或者遗漏重要的反射区域。</li><li>增加算法复杂度：空间划分和不同区域的分别处理增加了算法的复杂度。这可能会导致开发和调试的难度增加，并且在某些情况下，可能会引入新的错误或者视觉瑕疵。</li></ul><h3 id="Hi-z-SSR（Hierarchical-z-Screen-Space-Reflection）"><a href="#Hi-z-SSR（Hierarchical-z-Screen-Space-Reflection）" class="headerlink" title="Hi-z SSR（Hierarchical - z Screen Space Reflection）"></a>Hi-z SSR（Hierarchical - z Screen Space Reflection）</h3><p>原理：Hi - z SSR 是利用层次化的深度信息（Hierarchical-z）来改进 SSR。它构建了一个层次化的深度缓冲区，这个缓冲区可以更有效地存储和检索深度信息。在计算反射时，通过这个层次化的结构，可以快速地在不同层次的深度信息中进行搜索和采样。<br>例如，在较高层次的深度信息中，可以快速定位反射光线可能相交的大致区域，然后在较低层次的深度信息中进行更精细的搜索，就像在地图的不同比例尺中查找目标位置一样。这种层次化的搜索方式能够更高效地利用深度信息来计算反射。</p><p>优点：</p><ul><li>高效的深度搜索：层次化的深度搜索大大提高了反射光线与场景相交点的查找效率。尤其是在处理具有深度层次丰富的复杂场景时，能够快速定位反射位置，减少计算时间。</li><li>增强的反射范围：由于能够更好地利用深度信息，Hi-z SSR 可以在一定程度上缓解传统 SSR 中屏幕外反射难以处理的问题。它可以通过层次化的深度结构，对屏幕外部分场景的深度信息进行合理推测和利用，从而扩展反射的有效范围。</li></ul><p>局限性</p><ul><li><p>深度缓冲区的构建成本：构建层次化的深度缓冲区需要额外的存储空间和计算资源来生成和维护。这可能会在一些资源受限的场景或者硬件平台上带来一定的负担。</p></li><li><p>精度与性能的平衡：尽管 Hi-z SSR 提高了搜索效率，但在平衡反射精度和性能方面仍然是一个挑战。在某些情况下，过于追求效率可能会导致反射精度下降，而过度强调精度又可能会使性能开销过大。</p></li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html">https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html</a></p><p><a href="https://jcgt.org/published/0003/04/04/">https://jcgt.org/published/0003/04/04/</a></p><p><a href="https://blog.csdn.net/qjh5606/article/details/120102582?ops_request_misc=%257B%2522request%255Fid%2522%253A%25225a1434f7df5d388dc4166f4877eb172b%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=5a1434f7df5d388dc4166f4877eb172b&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-120102582-null-null.142%5Ev100%5Econtrol&utm_term=Efficient%20GPU%20Screen-Space%20Ray%20Tracing&spm=1018.2226.3001.4187">https://blog.csdn.net/qjh5606/article/details/120102582?ops_request_misc=%257B%2522request%255Fid%2522%253A%25225a1434f7df5d388dc4166f4877eb172b%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=5a1434f7df5d388dc4166f4877eb172b&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-120102582-null-null.142^v100^control&amp;utm_term=Efficient%20GPU%20Screen-Space%20Ray%20Tracing&amp;spm=1018.2226.3001.4187</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>软阴影的实现（PCF和PCSS）</title>
    <link href="/2024/12/08/soft-shadow/"/>
    <url>/2024/12/08/soft-shadow/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是软阴影"><a href="#什么是软阴影" class="headerlink" title="什么是软阴影"></a>什么是软阴影</h1><p>在3D中实现阴影最基础的方法是使用阴影贴图shadowmap，根据shadowmap中存储的信息来判定当前渲染的像素是否在阴影当中。</p><p>阴影贴图的方法很好理解，但是仅仅基于阴影贴图的阴影效果，在阴影的边缘会有锯齿的情况出现。这往往是由于阴影贴图的分辨率不够导致的，然而一味的提升阴影贴图的分辨率也不是方法，毕竟实时渲染的性能也是需要考虑的一个方面。</p><p>那么该如何在可接受的性能表现下实现软阴影的效果呢，下面详细介绍两种方法：Percentage Closer Filtering（PCF）以及Percentage Closer Soft Shadows（PCSS）。</p><h1 id="柔和阴影边缘-PCF"><a href="#柔和阴影边缘-PCF" class="headerlink" title="柔和阴影边缘-PCF"></a>柔和阴影边缘-PCF</h1><p>下面是一个普通的阴影效果：<br><img src="/2024/12/08/soft-shadow/normal-shadow.png" alt="普通的阴影效果"><br>这个阴影贴图的分辨率是2048，这是在<a href="https://ruochenhua.github.io/2024/10/13/cascade-shadow-map/">CSM</a>的最低一级的阴影效果。可以看到阴影边缘的锯齿感非常的强烈，同时由于采样精度的问题，模型的腿上也出现了不正确的阴影区域。最简单的方法就是通过提高阴影贴图的分辨率来缓解这个问题，但是显而易见这不是最好的解决方案，而Percentage Closer Filtering（后简称PCF）可以帮助我们解决这个问题。</p><h2 id="什么是PCF"><a href="#什么是PCF" class="headerlink" title="什么是PCF"></a>什么是PCF</h2><p>Percentage Closer Filtering（PCF）是一种在计算机图形学中用于生成软阴影的技术。它主要用于解决硬阴影（如简单的阴影映射产生的锐利阴影边缘）不符合真实场景光照效果的问题。</p><p>与简单的阴影映射不同，PCF 在判断像素是否在阴影中时，不是只比较单个点的深度。它会在像素点周围的一定区域内进行多次采样。例如，在一个以像素点为中心的小区域（通常是方形或圆形区域）内，对多个采样点进行深度比较。这些采样点的位置可以是均匀分布，也可以采用更复杂的分布方式，如泊松分布，以获得更自然的效果。</p><p>对于每个采样点，比较其深度和阴影图中的深度来判断是否在阴影中。然后统计在阴影中的采样点的比例。设采样点总数为<strong>N</strong>，处于阴影中的采样点数量为<strong>n</strong>，则阴影强度可以通过公式计算<strong>shadow&#x3D;n&#x2F;N</strong>得到。这个阴影强度用于确定像素最终的阴影效果。如果阴影强度为1，表示像素完全处于阴影中；如果阴影强度为0，表示像素完全不在阴影中；介于两者之间的值表示不同程度的软阴影效果。</p><h2 id="PCF的实现"><a href="#PCF的实现" class="headerlink" title="PCF的实现"></a>PCF的实现</h2><p>转换为代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> CalculatePCFShadow(<span class="hljs-type">float</span> current_depth, <span class="hljs-type">sampler2D</span> shadow_map,  <span class="hljs-type">vec2</span> uv, <span class="hljs-type">int</span> radius)<br>&#123;<br>    <span class="hljs-type">float</span> shadow = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">vec2</span> texel_size = <span class="hljs-number">1.0</span> / <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(shadow_map, <span class="hljs-number">0</span>));<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> x = -radius; x &lt;= radius; ++x)<br>    &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> y = -radius; y &lt;= radius; ++y)<br>        &#123;<br>            <span class="hljs-type">float</span> pcf_depth = <span class="hljs-built_in">texture</span>(shadow_map, <span class="hljs-type">vec2</span>(uv + <span class="hljs-type">vec2</span>(x, y) * texel_size)).r;<br>            shadow += current_depth &gt; pcf_depth ? <span class="hljs-number">1.0</span> : <span class="hljs-number">0.0</span>;<br>        &#125;<br>    &#125;<br>    shadow /= <span class="hljs-built_in">pow</span>((<span class="hljs-number">1</span>+radius*<span class="hljs-number">2</span>),<span class="hljs-number">2.0</span>);<br>    <span class="hljs-keyword">return</span> shadow;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我使用了矩形的采样区域，可以看到其实当采样区域的半径为1的时候，采样点个数为9，阴影边缘的锯齿感已经得到了明显的改善。模型腿上也没有出现错误的阴影区域，效果大大提升。</p><p><img src="/2024/12/08/soft-shadow/pcf-shadow-1.png" alt="PCF阴影，采样半径1"></p><p>当采样半径提升为3，采样点个数为49时，阴影的边缘软化效果更明显了，不过付出了5倍的性能消耗，提升确并没有非常明显。</p><p><img src="/2024/12/08/soft-shadow/pcf-shadow-3.png" alt="PCF阴影，采样半径3"> </p><h1 id="半影的产生-PCSS"><a href="#半影的产生-PCSS" class="headerlink" title="半影的产生-PCSS"></a>半影的产生-PCSS</h1><h2 id="什么是本影和半影"><a href="#什么是本影和半影" class="headerlink" title="什么是本影和半影"></a>什么是本影和半影</h2><p>在实际的场景中，我们观察阴影，会发现下面这种情况：</p><p><img src="/2024/12/08/soft-shadow/real_shadow.png" alt="现实阴影"><br>物体的深暗影子周围还有一片区域是浅浅的暗影。深暗影子的区域我们称之为“<strong>本影</strong>”，而浅暗影子的区域我们称之为“<strong>半影</strong>”。</p><p>这种现象在体积光照（或者区域光照）的情况下很容易出现。其原因是，很多光源是有范围的，如下图假设有一个光源的大小用L1到L2，光源的右边有一个物体。</p><p><img src="/2024/12/08/soft-shadow/umbra-principle.png" alt="本影和半影的原理"></p><p>光源最上点位L1的位置，照向物体的时候，产生的阴影范围是<strong>A区域</strong>以及下方的<strong>B区域</strong>，上方的<strong>B区域</strong>会被L1照亮；L2点产生的阴影范围是<strong>A区域</strong>和上方的<strong>B区域</strong>，下方的<strong>B区域</strong>会被L2照亮。所以我们可以看到，<strong>区域A</strong>是光源完全的光都会被挡住的区域，所以他的阴影是最深的，是为<strong>本影</strong>。而两个<strong>区域B</strong>是挡住了光源的部分区域，同时被光源的另外一部分照亮的，是为<strong>半影</strong>。</p><p><img src="/2024/12/08/soft-shadow/umbra-contrast.png" alt="本影和半影的对照区域"></p><h2 id="什么是PCSS"><a href="#什么是PCSS" class="headerlink" title="什么是PCSS"></a>什么是PCSS</h2><p>在弄明白什么是本影和半影之后，我们来介绍一下PCSS是什么。</p><p>Percentage Closer Soft Shadows（PCSS）即百分比渐近软阴影，是计算机图形学中用于生成更逼真软阴影的一种技术，它是在 Percentage Closer Filtering（PCF）基础上发展而来的。</p><p>在PCF的基础上，PCSS还额外考虑了光源、遮挡物和接收阴影的物体之间的几何关系，通过这些关系来调整用于计算阴影强度的采样区域大小。通过根据阴影的不同情况动态调整采样区域的大小，PCSS能生成更自然、更符合物理规律的软阴影。</p><p>这里是提出PCSS的<a href="https://developer.download.nvidia.com/shaderlibrary/docs/shadow_PCSS.pdf">论文</a>。</p><p>其原理总结起来就是根据采样一个区域内处于阴影的比例，来动态的调节这个区域对应的阴影的采样范围。</p><h2 id="PCSS的实现步骤"><a href="#PCSS的实现步骤" class="headerlink" title="PCSS的实现步骤"></a>PCSS的实现步骤</h2><p>PCSS的实现步骤如下：</p><p>首先，计算平均的遮挡物距离。在阴影图中，以当前像素点为中心，在一个初始的较小采样区域内查找深度值小于当前像素点深度的采样点，这些采样点对应的物体即为遮挡物。通过计算这些遮挡物采样点深度的平均值，得到平均遮挡物距离<strong>d_blocker</strong>。</p><p><img src="/2024/12/08/soft-shadow/get-d_blocker-1.png" alt="采样平均遮挡物距离1"></p><p>对应代码为：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> FindBlockerDepth(<span class="hljs-type">sampler2D</span> shadowmap, <span class="hljs-type">vec2</span> uv, <span class="hljs-type">float</span> d_receiver, <span class="hljs-type">float</span> radius)<br>&#123;<br>    <span class="hljs-type">float</span> blocker_depth_sum = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">int</span> blocker_count = <span class="hljs-number">0</span>;<br>    <br>    <span class="hljs-comment">// 以当前像素为中心,半径为radius的范围采样</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">float</span> y = -radius; y &lt;= radius; y++) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">float</span> x = -radius; x &lt;= radius; x++) &#123;<br>            <span class="hljs-type">vec2</span> <span class="hljs-keyword">offset</span> = <span class="hljs-type">vec2</span>(x, y) * <span class="hljs-number">1.0</span> / <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(shadowmap, <span class="hljs-number">0</span>));<br>            <span class="hljs-type">float</span> sampleDepth = TextureProjBilinear(shadowmap, uv + <span class="hljs-keyword">offset</span>);<br>            <span class="hljs-keyword">if</span> (sampleDepth &lt; d_receiver) &#123;<br>                blocker_depth_sum += sampleDepth;<br>                blocker_count++;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> blocker_count &gt; <span class="hljs-number">0</span>? blocker_depth_sum / <span class="hljs-type">float</span>(blocker_count) : <span class="hljs-number">0.0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中<strong>d_receiver</strong>为当前像素点到光源的深度值，这个值可以将当前像素点位置变换到光源的投影下得到，在处理阴影贴图的时候就需要拿到了。TextureProjBilinear是获取shadowmap深度值的方法，里面采用了双线性插值的方法，不过对PCSS来说不一定需要使用这个方法。</p><p>可以看到这个阶段，PCSS搜索了一个阴影贴图里面的区域（下图红色区域），记录下了这个区域的被阻挡范围的平均深度。</p><p><img src="/2024/12/08/soft-shadow/get-d_blocker-2.png" alt="采样平均遮挡物距离2"></p><p>然后根据这个范围，以及三角形相似原理，估算出半影半径。</p><p><img src="/2024/12/08/soft-shadow/penumbra.png" alt="计算半影半径"><br>其中d_receiver、d_blocker我们已知，W_light是光源的范围大小，可以根据实际情况来调整。用图上右方的公式，得出半影的采样范围W_penumbra。</p><p>代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 计算遮挡物范围半径（基于相似三角形原理）</span><br><span class="hljs-type">float</span> EstimateBlockerSearchRadius(<span class="hljs-type">vec2</span> uv, <span class="hljs-type">float</span> d_receiver, <span class="hljs-type">float</span> d_blocker, <span class="hljs-type">float</span> light_size)<br>&#123;<br>    <span class="hljs-keyword">if</span> (d_blocker == <span class="hljs-number">0.0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span>;<br>    <span class="hljs-keyword">return</span> (d_receiver - d_blocker) * (light_size / d_blocker);<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，根据估算出的半影半径，扩大采样区域，然后在这个更大的区域内进行采样，并按照 PCF 的方式计算阴影强度。这样，离光源较近或遮挡物较近的地方，半影半径较小，阴影较实；离光源较远或遮挡物较远的地方，半影半径较大，阴影较虚，从而实现了更自然的软阴影效果。</p><p>代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> shadow_sum = <span class="hljs-number">0.0</span>f;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> pcss_i = <span class="hljs-number">0</span>; pcss_i &lt; pcss_sample_count; pcss_i++)<br>&#123;<br>    <span class="hljs-comment">// 可以使用泊松采样盘等方法获取更自然的采样点位置，这里简单均匀采样</span><br>    <span class="hljs-type">vec2</span> <span class="hljs-keyword">offset</span> = <span class="hljs-type">vec2</span>(<span class="hljs-built_in">cos</span>(<span class="hljs-type">float</span>(pcss_i) * <span class="hljs-number">2.0</span> * <span class="hljs-number">3.1415926</span> / <span class="hljs-type">float</span>(pcss_sample_count)),<br>    <span class="hljs-built_in">sin</span>(<span class="hljs-type">float</span>(pcss_i) * <span class="hljs-number">2.0</span> * <span class="hljs-number">3.1415926</span> / <span class="hljs-type">float</span>(pcss_sample_count))) * blocker_radius;<br><br>    <span class="hljs-type">vec4</span> sampleLightSpacePos = <span class="hljs-type">vec4</span>(proj_coord.xy + <span class="hljs-keyword">offset</span>, proj_coord.z, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-type">float</span> sampleDepth = TextureProjBilinear(shadow_map, proj_coord.xy+<span class="hljs-keyword">offset</span>);<br>    shadow_sum += sampleDepth &lt; d_recv? <span class="hljs-number">1.0</span> : <span class="hljs-number">0.0</span>;<br>&#125;<br>shadow = shadow_sum / pcss_sample_count;<br></code></pre></td></tr></table></figure><h2 id="PCSS的效果"><a href="#PCSS的效果" class="headerlink" title="PCSS的效果"></a>PCSS的效果</h2><p>下面是PCSS开启和关闭的效果对比，其中PCSS关闭下PCF的采样半径是3：<br><img src="/2024/12/08/soft-shadow/PCSS_OFF.png" alt="PCSS关闭"></p><p><img src="/2024/12/08/soft-shadow/PCSS_ON.png" alt="PCSS开启"></p><p>可以看到开启了PCSS的效果后，遮挡物体的阴影区域，随着离遮挡物越来越远，出现了越来越明显的半影效果，效果更加自然和真实。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="Percentage-Closer-Filtering（PCF）的作用"><a href="#Percentage-Closer-Filtering（PCF）的作用" class="headerlink" title="Percentage Closer Filtering（PCF）的作用"></a>Percentage Closer Filtering（PCF）的作用</h2><ol><li><p>软阴影生成基础：PCF 是一种用于生成软阴影的基础技术。它基于阴影映射，在判断像素是否在阴影中时，不是只比较单个点的深度，而是在像素点周围一定区域内进行多次采样。</p></li><li><p>阴影强度计算：通过统计采样区域内处于阴影中的采样点比例来计算阴影强度。这种方式能有效避免硬阴影边缘的锯齿问题，使阴影边缘过渡更加自然，产生软阴影效果，提升了阴影的真实感。</p></li><li><p>平衡性能和效果：相对一些复杂的物理软阴影算法，PCF 较为简单，在性能和效果之间取得了较好的平衡，适用于实时渲染场景，如游戏。</p></li></ol><h2 id="Percentage-Closer-Soft-Shadows（PCSS）的作用"><a href="#Percentage-Closer-Soft-Shadows（PCSS）的作用" class="headerlink" title="Percentage Closer Soft Shadows（PCSS）的作用"></a>Percentage Closer Soft Shadows（PCSS）的作用</h2><ol><li><p>动态软阴影生成：PCSS 在 PCF 基础上进一步改进。它能够根据光源、遮挡物和接收阴影物体之间的几何关系动态调整采样区域的大小。</p></li><li><p>更自然的阴影过渡：通过计算平均遮挡物距离和估算半影半径，根据半影半径调整采样区域进行采样计算阴影强度。这样生成的软阴影更加符合物理规律，阴影从完全阴影到完全光照的过渡更加自然、真实，在需要高逼真度渲染的场景中能显著提升视觉质量。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>阴影</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>反射阴影贴图</title>
    <link href="/2024/11/24/reflective-shadow-map/"/>
    <url>/2024/11/24/reflective-shadow-map/</url>
    
    <content type="html"><![CDATA[<h1 id="反射阴影贴图简介"><a href="#反射阴影贴图简介" class="headerlink" title="反射阴影贴图简介"></a>反射阴影贴图简介</h1><p>反射阴影贴图（Reflective Shadow Map）是实现全局光照效果的一个非常经典的方法，它是在这篇<a href="https://users.soe.ucsc.edu/~pang/160/s13/proposal/mijallen/proposal/media/p203-dachsbacher.pdf">论文</a>中被提出。</p><h2 id="直接光照和间接光照"><a href="#直接光照和间接光照" class="headerlink" title="直接光照和间接光照"></a>直接光照和间接光照</h2><p>它的名字中带有“阴影贴图（Shadow Map）”几个字，所以乍看之下这个方法似乎是用来解决阴影问题，或者是提升阴影效果的。其实不然，它是用来解决<strong>间接光照</strong>的问题的方法。</p><p>在一般的场景中，光照可以大致分为两类：</p><ul><li>一类是直接光照，也就是物体被光源直接照亮的部分。这个类型的光照是比较好计算的，通过光源的入射角，物体表面的法线和材质，以及观察的方向等等，利用<strong>PBR</strong>的方法能够得到非常不错的效果，这个流程在KongEngine中已经基本实现了。</li><li>另外一个类型是间接光照，它代表的是光线经过一次甚至多次反射后照亮物体的部分。相对于直接光照，间接光照十分复杂，因为光线可能经过多次反射，想要实时的计算光的多次反射的完整路径是很难实现的。但是如果不包含间接光照的话，场景的真实度会大打折扣。在最基础的PBR渲染框架中，我们可以选择手动输入一个环境光照（Ambient Light）的颜色，可以简单的表现全局光照，但是真实性还是不够。</li></ul><p>反射阴影贴图（下面简称<strong>RSM</strong>）这个方法，就是用于解决实时模拟间接光照的问题。</p><h2 id="RSM算法基本介绍"><a href="#RSM算法基本介绍" class="headerlink" title="RSM算法基本介绍"></a>RSM算法基本介绍</h2><p>RSM的核心思想是将被光源直接照亮的区域再次作为光源进行光照计算，这就是光的一次反射。RSM只计算一次光反射，因为一般来说光的第一次反射的能量残留相对来说是最大的，对场景来说有较为显著的影响，后面的反射对场景影响较小，为了性能考量可以忽略。</p><p>那么怎么知道光照直接亮了哪些区域呢？其实非常简单，在参考实现阴影贴图（Shadow Map）的概念，从光源视角下进行渲染，不在阴影中的区域就是被光源直接照亮的。另外，由于光线在漫反射时会被照亮区域的材质所影响（比如说白色的光线从红色的墙反射会变成红色，因为其他颜色被吸收，同时不同粗糙度的物质反射方式也不一样），以及照亮区域的位置和法线也会影响计算光反射的方向，因此我们在计算阴影贴图的时候，还需要保存照亮区域的颜色、世界位置、法线等数据。</p><p>下面是需要记录的数据的截图，从左到右分别是：深度、位置坐标、法线、颜色。<br><img src="/2024/11/24/reflective-shadow-map/rsm_info.png" alt="光源方向记录的数据"></p><p>因此接下来光照计算可以分为以下几步：</p><ol><li>首先从光源的位置和方向渲染场景，将光源视角的信息（深度，世界位置，世界法线等等）缓存到buffer中。</li><li>计算光照直接对环境的影响。</li><li>将第一步缓存的光源保存的信息加入到场景中光照的计算，加上阴影（阴影贴图）和间接光照（反射阴影贴图）。</li></ol><h1 id="实现反射阴影贴图的步骤"><a href="#实现反射阴影贴图的步骤" class="headerlink" title="实现反射阴影贴图的步骤"></a>实现反射阴影贴图的步骤</h1><p>下面是在KongEngine中实现RSM的步骤。</p><h2 id="一些前期准备"><a href="#一些前期准备" class="headerlink" title="一些前期准备"></a>一些前期准备</h2><p>RSM需要将一些信息存储到buffer中，所以很首先需要设置新的缓冲。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glGenFramebuffers</span>(<span class="hljs-number">1</span>, &amp;rsm_fbo);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, rsm_fbo);<br><br><span class="hljs-comment">// 位置数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;rsm_world_position);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_position);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, rsm_world_position, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 法线数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;rsm_world_normal);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_normal);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, rsm_world_normal, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// flux数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;rsm_world_flux);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_flux);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, rsm_world_flux, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 生成renderbuffer</span><br><span class="hljs-built_in">glGenRenderbuffers</span>(<span class="hljs-number">1</span>, &amp;rsm_depth);<br><span class="hljs-built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, rsm_depth);<br><span class="hljs-built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, SHADOW_RESOLUTION, SHADOW_RESOLUTION);<br><span class="hljs-built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, rsm_depth);<br><span class="hljs-built_in">glEnable</span>(GL_DEPTH_TEST);<br><br>GLuint g_attachments[] = &#123;GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2&#125;; <br><span class="hljs-built_in">glDrawBuffers</span>(<span class="hljs-number">3</span>, g_attachments);<br></code></pre></td></tr></table></figure><p>上面的部分用于构建RSM的缓冲，这些内容和之前的Shadowmap的流程类似，也可以考虑将其和Shadowmap的缓冲合并，不过为了方便自己理解目前是新建了一个。</p><p>另外RSM也新建了一个独立的shader</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++">map&lt;EShaderType, string&gt; shader_path_map = &#123;<br>    &#123;EShaderType::vs, CSceneLoader::<span class="hljs-built_in">ToResourcePath</span>(<span class="hljs-string">&quot;shader/shadow/reflective_shadowmap.vert&quot;</span>)&#125;,<br>    &#123;EShaderType::fs, CSceneLoader::<span class="hljs-built_in">ToResourcePath</span>(<span class="hljs-string">&quot;shader/shadow/reflective_shadowmap.frag&quot;</span>)&#125;<br>&#125;;<br>rsm_shader = <span class="hljs-built_in">make_shared</span>&lt;Shader&gt;(shader_path_map);<br></code></pre></td></tr></table></figure><p>shader的内容十分简单，<em>顶点着色器</em>简单的将顶点的世界坐标和法线传给片段着色器。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-comment">// Input vertex data, different for all executions of this shader.</span><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_pos;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_normal;<br><br><span class="hljs-comment">// Values that stay constant for the whole mesh.</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> light_space_mat;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> model;<br><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> frag_pos;<br><span class="hljs-keyword">out</span> <span class="hljs-type">vec3</span> frag_normal;<br><br><span class="hljs-type">void</span> main()&#123;<br><span class="hljs-built_in">gl_Position</span> =  light_space_mat * model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1</span>);<br>    frag_pos = model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1</span>);<br>frag_normal = <span class="hljs-built_in">normalize</span>(<span class="hljs-type">mat3</span>(<span class="hljs-built_in">transpose</span>(<span class="hljs-built_in">inverse</span>(model))) * in_normal);<br>&#125;<br></code></pre></td></tr></table></figure><p>由于这个shader是从光源视角渲染的，所以<strong>gl_Position</strong>是由光源的<strong>light_space_mat</strong>对世界坐标做变换。</p><p><em>片段着色器</em>将RSM所需的内容存储起来。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> world_pos;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> world_normal;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">2</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> world_flux;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> frag_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> frag_normal;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">vec4</span> albedo;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> light_intensity;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>world_pos = frag_pos;<br>    world_normal = <span class="hljs-type">vec4</span>(frag_normal, <span class="hljs-number">1</span>);<br>    world_flux = albedo;<span class="hljs-comment">// * light_intensity;</span><br>&#125;<br></code></pre></td></tr></table></figure><p>我们这里分别将<strong>世界坐标、世界法线和颜色</strong>存储了到了贴图中。<br>方便起见，KongEngine暂时只支持平行光源的RSM效果，点光源的目前不支持。</p><p>现在我们的平行光源已经有了RSM相关的信息了，在计算光照的时候将这些贴图信息传到光照计算的shader中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + DIRLIGHT_RSM_WORLD_POS);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_pos);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + DIRLIGHT_RSM_WORLD_NORMAL);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_normal);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + DIRLIGHT_RSM_WORLD_FLUX);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_flux);<br></code></pre></td></tr></table></figure><h2 id="间接光源的判定"><a href="#间接光源的判定" class="headerlink" title="间接光源的判定"></a>间接光源的判定</h2><p>RSM的实际原理如下面两张图所示：<br><img src="/2024/11/24/reflective-shadow-map/rsm_principle_1.png" alt="rsm原理图1"></p><p>假如当前我们片段着色器计算的是<strong>X</strong>点的光照，在这个场景中，x点被桌子的阴影挡住了，并没有被光源直接照亮，如左图所示。所以x点的直接光照为0。</p><p>接下来是间接光照的部分。如上面所说，我们将被光源直接照亮的部分当做光源，这里先以被光源直接照射的两个点Xp和Xq来做判断。Xp点被光源照亮，他的法线是Np，光在Xp点散射后是有可能到达X点的，在数学上的判断就是Np和Xp到X连线的点乘大于0。而Xq的法线Nq和Xq到X点连线的点乘小于0，可以从图上看到光在Xq点散射后是无法到达X点的。</p><p>当然我们还知道，在计算PBR的时候，不同的材质的光线散射形状是不一致的，在图中的表现就是，光线散射后沿着XpX方向的分量，比沿着XpY方向的分量是要小的。因此间接光源的法线和两点之间的连线的点乘大小有这判定间接光源亮度的作用。</p><p>下面这张图和原理图1是一样的，强化一下理解。<br><img src="/2024/11/24/reflective-shadow-map/rsm_principle_2.png" alt="rsm原理图2"></p><h2 id="采样间接光源"><a href="#采样间接光源" class="headerlink" title="采样间接光源"></a>采样间接光源</h2><p>之前说到，需要用被光源照亮的点作为间接光源。如果渲染屏幕上像素点的时候对所有照亮的点都去做判断的话，理论上是可以得到最好的效果，但是性能上会有极大的消耗；相反如果采样点过少的话，计算速度虽然是上去了但是效果会大打折扣。</p><p>因此一个优化方法是通过重要性采样。我们判断离当前渲染点越近的间接光照光源对当前点的最终效果影响就越大，因此离当前点近的间接光源采样点就会越多。并且，为了弥补远处的采样点过少可能带来的问题，引入权重的概念，随着采样点离当前点越近，权重越小。</p><p><img src="/2024/11/24/reflective-shadow-map/rsm_sample.png" alt="rsm采样点选择"></p><p>下面是采样点初始化的示例代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// rsm采样点初始化</span><br>std::default_random_engine e;<br><span class="hljs-function">std::uniform_real_distribution&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">u</span><span class="hljs-params">(<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>)</span></span>;<br><span class="hljs-type">float</span> pi_num = <span class="hljs-built_in">pi</span>&lt;<span class="hljs-type">float</span>&gt;();<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; rsm_sample_count; i++)<br>&#123;<br>    <span class="hljs-type">float</span> xi1 = <span class="hljs-built_in">u</span>(e);<br>    <span class="hljs-type">float</span> xi2 = <span class="hljs-built_in">u</span>(e);<br>    <br>    rsm_samples_and_weights.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">vec4</span>(xi1*<span class="hljs-built_in">sin</span>(<span class="hljs-number">2</span>*pi_num*xi2), xi1*<span class="hljs-built_in">cos</span>(<span class="hljs-number">2</span>*pi_num*xi2), xi1*xi1, <span class="hljs-number">0.0</span>));<br>&#125;<br></code></pre></td></tr></table></figure><p>结合上面的两个思想，下面是部分最终代码的呈现，位于defer_pbr.frag中。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> max_sample_radius = <span class="hljs-number">128.</span>;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; rsm_sample_count; ++i) <br>&#123;<br>    <span class="hljs-type">vec3</span> rsm_sample_and_weight = rsm_samples_and_weights[i].xyz;<br>    <span class="hljs-type">vec2</span> uv = proj_coord.xy + max_sample_radius * rsm_sample_and_weight.xy * texel_size;<br>    <span class="hljs-type">vec3</span> flux = <span class="hljs-built_in">texture</span>(rsm_world_flux, uv).rgb;<br>    <span class="hljs-type">vec3</span> x_p = <span class="hljs-built_in">texture</span>(rsm_world_pos, uv).xyz;<br>    <span class="hljs-type">vec3</span> n_p = <span class="hljs-built_in">texture</span>(rsm_world_normal, uv).xyz;<br><br>    <span class="hljs-type">vec3</span> r = <span class="hljs-built_in">normalize</span>(frag_world_pos.xyz - x_p);<br><br>    <span class="hljs-type">float</span> d2 = <span class="hljs-built_in">dot</span>(r, r);<br>    <span class="hljs-type">vec3</span> e_p = flux * (<span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">dot</span>(n_p, r)) * <span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">dot</span>(in_normal, -r))) * rsm_sample_and_weight.z;<br>    <span class="hljs-comment">//e_p *= pow(rsm_sample_offsets[i].x / d2, 2);</span><br>    env_color += e_p;<br>&#125;<br>env_color /= rsm_sample_count;<br></code></pre></td></tr></table></figure><h1 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h1><p>结合了反射阴影贴图后，场景会有一些间接光照效果了，下面是同一个场景的表现效果。<br><img src="/2024/11/24/reflective-shadow-map/rsm_off_sphere.png" alt="rsm关闭1"><br><img src="/2024/11/24/reflective-shadow-map/rsm_on_sphere.png" alt="rsm开启1"></p><p>这里是另外一组。<br><img src="/2024/11/24/reflective-shadow-map/rsm_off_suit.png" alt="rsm关闭2"><br><img src="/2024/11/24/reflective-shadow-map/rsm_on_suit.png" alt="rsm开启2"></p><p>可以看到开启rsm后，靠近红色和绿色墙壁，且没有被光源直接照亮（处于阴影）的部分，被墙壁的散射光源间接点亮了。灰色的球体和人物模型“沾染”上了墙壁的颜色。这种间接光照的影响使得场景变得更加的真实。</p><p>但是，当前的rsm也并不是完美的，比如说目前rsm缺乏判定间接光源是否可达，在第二个例子中，人物模型的右肩上的间接光源呈现的是黄色，也就是红色和绿色的间接光照结合起来的颜色。但是右肩理论上不应该出现红色的分量，因为红色的部分会被身体部位阻挡。渲染点的法线应该也会影响间接光的表现。</p><p>另外就是被当成间接光源的只有被光源照亮且存储起来的部分区域，也就是说间接光源的采样范围相对来说还是比较局限的，不可能采样非常大的区域。在KongEngine中由于采用了CSM来处理阴影，RSM的范围和CSM的最小级的阴影范围采样是一致的，这种处理显然无法照顾大的场景。</p><p>场景的间接光照还需要进一步的去优化，RSM只是其中一个小部分。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>程序化地形生成-2-性能优化</title>
    <link href="/2024/11/19/ProceduralTerrainGeneration2-optimize/"/>
    <url>/2024/11/19/ProceduralTerrainGeneration2-optimize/</url>
    
    <content type="html"><![CDATA[<h1 id="性能优化的需求"><a href="#性能优化的需求" class="headerlink" title="性能优化的需求"></a>性能优化的需求</h1><p>自从实现了程序化地形生成的那个<a href="https://www.shadertoy.com/view/4XByRV">ShaderToy上的Demo</a>之后，我对它的性能表现一直不太满意，随随便便跑一下我的GPU就直接拉到100%了，电脑风扇呼呼的。做了很多次大大小小的优化，最后发现瓶颈还是在对地形的光线步进计算上，不把这个问题解决掉的话这个场景的性能怎么样都无法达到令我满意的程度。</p><p>于是我一直在寻找类似的场景，寻找有什么光线步进的方法能够满足我的要求：首先它必须是要针对实时随机生成的地形，也就是说不能是针对高度图或者其他预处理过的地形数据；其次它需要快，至少能够在我这台笔记本上（3070ti显卡）能够保持50%以下的占用率；最后就是这个光线步进算法需要有一定的精度，但是要求不会很高。</p><p>最后我在ShaderToy上找到了一个非常棒的<a href="https://www.shadertoy.com/view/4slGD4">例子</a>，来自Dave_Hoskins。</p><p>Dave的Demo也是做了地形的渲染，他的场景比我复杂很多，但是这个更为复杂的场景在我的电脑上运行的时候，它的GPU占用率（分辨率768X432）只有35%左右，远低于我的demo让我大为震撼。</p><p>于是我开始研究它的光线步进的逻辑，如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// source:https://www.shadertoy.com/view/4slGD4</span><br><span class="hljs-type">float</span> BinarySubdivision(<span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> rO, <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> rD, <span class="hljs-type">vec2</span> t)<br>&#123;<br><span class="hljs-comment">// Home in on the surface by dividing by two and split...</span><br>    <span class="hljs-type">float</span> halfwayT;<br>  <br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5</span>; i++)<br>    &#123;<br><br>        halfwayT = <span class="hljs-built_in">dot</span>(t, <span class="hljs-type">vec2</span>(<span class="hljs-number">.5</span>));<br>        <span class="hljs-type">vec3</span> p = rO + halfwayT*rD;<br>        <span class="hljs-type">float</span> d = p.y - getTerrainHeight(p.xz, perlinOctaves); <br>        <span class="hljs-comment">// float d = Map(rO + halfwayT*rD); </span><br>         t = <span class="hljs-built_in">mix</span>(<span class="hljs-type">vec2</span>(t.x, halfwayT), <span class="hljs-type">vec2</span>(halfwayT, t.y), <span class="hljs-built_in">step</span>(<span class="hljs-number">0.5</span>, d));<br><br>    &#125;<br><span class="hljs-keyword">return</span> halfwayT;<br>&#125;<br><br><span class="hljs-type">bool</span> rayMarchingTerrain(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd, <span class="hljs-type">float</span> max_dist, <span class="hljs-keyword">out</span> <span class="hljs-type">float</span> res_t)<br>&#123;<br>    <span class="hljs-type">float</span> t = <span class="hljs-number">1.</span> + Hash12(g_frag_coord)*<span class="hljs-number">1.</span>;<br><span class="hljs-type">float</span> oldT = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">float</span> delta = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">bool</span> fin = <span class="hljs-literal">false</span>;<br><span class="hljs-type">bool</span> res = <span class="hljs-literal">false</span>;<br><span class="hljs-type">vec2</span> distances;<br><span class="hljs-keyword">for</span>( <span class="hljs-type">int</span> j=<span class="hljs-number">0</span>; j&lt; <span class="hljs-number">150</span>; j++ )<br>&#123;<br><span class="hljs-keyword">if</span> (fin || t &gt; <span class="hljs-number">240.0</span>) <span class="hljs-keyword">break</span>;<br><span class="hljs-type">vec3</span> p = ro + t*rd;<br><span class="hljs-comment">//if (t &gt; 240.0 || p.y &gt; 195.0) break;</span><br><span class="hljs-type">float</span> h = p.y - getTerrainHeight(p.xz, perlinOctaves); <span class="hljs-comment">// ...Get this positions height mapping.</span><br><span class="hljs-comment">// Are we inside, and close enough to fudge a hit?...</span><br><span class="hljs-keyword">if</span>( h &lt; <span class="hljs-number">0.5</span>)<br>&#123;<br>fin = <span class="hljs-literal">true</span>;<br>distances = <span class="hljs-type">vec2</span>(oldT, t);<br><span class="hljs-keyword">break</span>;<br>&#125;<br><span class="hljs-comment">// Delta ray advance - a fudge between the height returned</span><br><span class="hljs-comment">// and the distance already travelled.</span><br><span class="hljs-comment">// It&#x27;s a really fiddly compromise between speed and accuracy</span><br><span class="hljs-comment">// Too large a step and the tops of ridges get missed.</span><br>delta = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.3</span>*h) + (t*<span class="hljs-number">0.0065</span>);<br>oldT = t;<br>t += delta;<br>&#125;<br><span class="hljs-keyword">if</span> (fin) res_t = BinarySubdivision(ro, rd, distances);<br><br><span class="hljs-keyword">return</span> fin;<br>&#125;<br></code></pre></td></tr></table></figure><p>其实代码逻辑很简单，就是光线步进到的位置和当前XZ坐标的地形高度做比对，当光线步进的位置的高度和地形足够近的时候，记为击中。记录当前和上一步的t的位置，在得到最终结果的时候做一个取中间值的操作。</p><p>这个方法的精华部分是这个：**delta &#x3D; max(0.01, 0.3*h) + (t*0.0065);**，它被用于计算光线步进下一步的距离。如果光线步进每一步距离太近，会严重影响性能；而如果一步太远，则会导致地形的精度不足，出现地表抖动甚至断裂的情况。</p><p>Dave的方法，结合了当前位置和地形的高度差h和光线步进已经经过的长度t。高度差越小，说明可能越接近地表，需要较小的步长（反之亦然）；t的影响则表示远处的地形的精度需求可以逐步降低。</p><p>下面是我原来的计算方式。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">bool</span> rayMarchingTerrain(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd, <span class="hljs-type">float</span> max_dist, <span class="hljs-keyword">out</span> <span class="hljs-type">float</span> res_t)<br>&#123;<br>    <span class="hljs-comment">// float terrain_height = sin(iTime) + 1.;    </span><br>    <span class="hljs-type">float</span> dt_min = <span class="hljs-number">0.1</span>f;<br>    <span class="hljs-type">float</span> dt_max = <span class="hljs-number">3.0</span>f;<br><br>    <span class="hljs-type">float</span> dt = <span class="hljs-number">1.0</span>;<br>    res_t = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-comment">// first pass, step 1</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = mint; t &lt; max_dist; t+=dt)<br>    &#123;<br>        <span class="hljs-type">vec3</span> p = ro+t*rd;<br>        <span class="hljs-type">float</span> terrain_height = getTerrainHeight(p.xz, perlinOctaves);<br>        <span class="hljs-keyword">if</span>(p.y &lt; terrain_height )<br>        &#123;        <br>            <span class="hljs-comment">// res_t = t - dt + dt*(last_h - last_p.y) / (p.y - last_p.y-terrain_height+last_h); </span><br>            res_t = t;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;        <br>        <span class="hljs-comment">// // closer terrain use higher accuracy        </span><br>        <span class="hljs-comment">// last_h = terrain_height;        </span><br>        <span class="hljs-comment">// last_p = p;</span><br>        dt = <span class="hljs-built_in">mix</span>(dt_min, dt_max, <span class="hljs-built_in">pow</span>(t / max_dist, <span class="hljs-number">2.0</span>));<br>    &#125;<br><br>    <span class="hljs-comment">// hit terrain</span><br>    <span class="hljs-keyword">if</span>(res_t &gt; <span class="hljs-number">0.</span>)<br>    &#123;<br>        <span class="hljs-type">float</span> last_h = <span class="hljs-number">0.0</span>;<br>        <span class="hljs-type">vec3</span> last_p = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-type">float</span> mini_dt =  <span class="hljs-built_in">max</span>(<span class="hljs-number">0.01</span>, dt * <span class="hljs-number">0.02</span>);<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = res_t - dt; t &lt; res_t + <span class="hljs-number">.01</span>; t+=mini_dt)<br>        &#123;<br>            <span class="hljs-type">vec3</span> p = ro+t*rd;<br>            <span class="hljs-type">float</span> terrain_height = getTerrainHeight(p.xz, perlinOctaves);<br>            <span class="hljs-keyword">if</span>(p.y &lt; terrain_height)<br>            &#123;        <br>                res_t = t - mini_dt + mini_dt*(last_h - last_p.y) / (p.y - last_p.y-terrain_height+last_h); <br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;        <br>            <span class="hljs-comment">// closer terrain use higher accuracy        </span><br>            last_h = terrain_height;        <br>            last_p = p;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <br>&#125;<br></code></pre></td></tr></table></figure><p>我原来的方法的思想是做两遍测试，先以一个较大步长做一次初步筛选，找到大概的光线穿过地形的区间；然后再在那个区间用较小的步长做另外因此光线步进。</p><p>这个方法的问题在于如果初筛的时候步长太大，可能会穿过一个厚度较小的地形（比如说山峰），所以初筛的步长也不能太小；第二次筛选似乎取值也偏小了，导致还是做了很多次的光线步进检测。</p><h1 id="优化结果"><a href="#优化结果" class="headerlink" title="优化结果"></a>优化结果</h1><p>现在我将新的光线步进方法更新到了我原来的ShaderToy Demo上，在768X432的分辨率60fps的情况下，我的demo在我的电脑上的GPU占用率由80%左右降低到了35%左右，可谓是巨大的提升。</p><p>在demo的代码中，我在第一行添加了代码</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#define OLD_METHOD 0</span><br></code></pre></td></tr></table></figure><p>将<strong>OLD_METHOD</strong>改为1的话可以改为使用老方法，各位有兴趣的话可以实际修改一下代码来对比一下这两种方法的性能差异。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>程序化生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>程序化地形生成-2</title>
    <link href="/2024/11/04/ProceduralTerrainGeneration2/"/>
    <url>/2024/11/04/ProceduralTerrainGeneration2/</url>
    
    <content type="html"><![CDATA[<p>距离上一篇将程序化地形生成的<a href="https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/">教程</a>也已经过去了一段时间了。前段时间一直有其他事情需要忙，现在终于有时间继续之前未完成的工作了。</p><h1 id="丰富地形"><a href="#丰富地形" class="headerlink" title="丰富地形"></a>丰富地形</h1><p>上一篇教程我们已经创建出了绵延的山脉，如下图所示：<br><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_no_grass.png" alt="上次渲染的结果"><br>看起来似乎是有那么点意思了，但是这样的山脉效果还是太单调了。</p><p>接下来我们就计划丰富一下这个场景。</p><h2 id="增加绿植"><a href="#增加绿植" class="headerlink" title="增加绿植"></a>增加绿植</h2><p>我们场景中的山光秃秃的，很像是沙漠，也很像火星上的地貌。</p><p>我想给场景增加一些层次，一些生机，因此我打算将山的一部分渲染为绿植部分。</p><p>那么如何确定哪些部分是绿植，哪些部分是裸露的山体呢？根据地形表面的法线可以做一个简单的判定：法线的y分量越大，也就是面向上的分量越大，表明这个面更平，因此有绿植是更合适的；反正则表明这个面更加陡峭，更适合作为山体表现。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> dirt_color = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.8549</span>, <span class="hljs-number">0.5255</span>, <span class="hljs-number">0.3098</span>);<br><span class="hljs-type">vec3</span> grass_color = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.3137</span>, <span class="hljs-number">0.5412</span>, <span class="hljs-number">0.0157</span>);<br><span class="hljs-comment">// ..</span><br><br><span class="hljs-keyword">if</span>(rd.y &lt; <span class="hljs-number">0.05</span> &amp;&amp; rayMarchingTerrain(ro, rd, maxt, res_t))<br>&#123;<br>    <span class="hljs-type">vec3</span> height_pos = ro+res_t*rd;<br><br>    <span class="hljs-comment">// calculate normla</span><br>    <span class="hljs-type">vec3</span> normal = getNormal(height_pos);<br>    <span class="hljs-type">float</span> grass_ratio = <span class="hljs-built_in">smoothstep</span>(<span class="hljs-number">0.7</span>, <span class="hljs-number">0.98</span>, normal.y);<br>    <span class="hljs-type">vec3</span> ground_color = <span class="hljs-built_in">mix</span>(dirt_color, grass_color, grass_ratio);<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上面是一段实例代码，我们预先设定山体和绿植的颜色，在光线步进山体的时候，获取normal，根据法线的y方向的大小（也可以用dot来判定）做smoothstep取一个合适的值作为当前平面草地的比例，最后混合山体和草地的比例。得到的结果如下：</p><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_grass.png" alt="增加绿植"><br>这样一来场景的丰富程度一下子就提升了。</p><h1 id="天空"><a href="#天空" class="headerlink" title="天空"></a>天空</h1><p>现在最终结果还是挺奇怪的，很大一部分的原因是场景的背景还是黑咕隆咚的。我们的大场景急需增加天空的部分。</p><h2 id="天空的颜色"><a href="#天空的颜色" class="headerlink" title="天空的颜色"></a>天空的颜色</h2><p>天空的颜色我之前有写过一个<a href="https://ruochenhua.github.io/2024/10/15/single-scatter-atmosphere/">教程</a>，是利用单次散射的方法来计算天空大气的颜色。当然这个方法在这依然是可用的。</p><p>不过如果你说，我不想用那么复杂的方法，只想快速出效果呢？那也是很简单，给地形光线步近没有结果的像素设定为蓝色就行了，哈哈。</p><p>如果想再复杂一点，可以做一个小细节的优化。也就是在晴朗的情况下，一般靠近地平线的天的蓝色是更加浅的，所以在给天空像素上色的时候，可以根据当前像素的方向的y值作为判定，在深蓝色和浅蓝色做线性插值。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> low_sky_blue = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.5137</span>, <span class="hljs-number">0.7804</span>, <span class="hljs-number">0.9608</span>);<br><span class="hljs-type">vec3</span> high_sky_blue = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.3216</span>, <span class="hljs-number">0.4706</span>, <span class="hljs-number">0.9725</span>);<br><br><span class="hljs-type">vec3</span> sky_color = <span class="hljs-built_in">mix</span>(low_sky_blue, high_sky_blue, <span class="hljs-built_in">clamp</span>(rd.y, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>));<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky.png" alt="增加天空"></p><h2 id="雾气增强层次感"><a href="#雾气增强层次感" class="headerlink" title="雾气增强层次感"></a>雾气增强层次感</h2><p>在增加了天空之后，我们的渲染结果有了很显著的提升，终于像室外的场景了。</p><p>不过仔细看后，还是觉得怪怪的，远处的山和天空根本不在一个图层上；山的远近层次感也不足，远处的山太清晰了。</p><p>这是因为缺少雾气的结果，雾气能够很好的增加大场景体量感，能够很好的处理场景和天空衔接的感觉。</p><p>增加雾气也十分简单，仅需根据地形光线步近的结果的大小（也就是地形离相机的距离）来计算一个比例，根据这个比例来做场景颜色和雾气颜色的插值即可。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// cal fog density, different between r,g,b so the fog has a blue hue</span><br><span class="hljs-type">vec3</span> calcFog(<span class="hljs-type">float</span> dist)<br>&#123;    <br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">exp</span>(<span class="hljs-number">-5e-3</span>*dist*<span class="hljs-type">vec3</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>));<br>&#125;<br><br><span class="hljs-comment">// ...</span><br><span class="hljs-type">vec3</span> fog_amount = calcFog(res_t);<br>color = <span class="hljs-built_in">mix</span>(<span class="hljs-type">vec3</span>(<span class="hljs-number">0.7</span>),color, fog_amount);<br></code></pre></td></tr></table></figure><p>上面这段便是雾气的计算过程。雾气的比例通过*<em>exp(-5e-3</em>dist*vec3(1,2,4))**计算，得到的雾的比例用于最终颜色的线性插值。</p><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog.png" alt="增加雾气"><br>有了雾气的加持，我们场景的大体量感就有了，层次感也明显了很多。<br>关于雾气的更多内容，可以参考Inigo大神的<a href="https://iquilezles.org/articles/fog/">这篇文章</a>。</p><h2 id="漫反射光照细节"><a href="#漫反射光照细节" class="headerlink" title="漫反射光照细节"></a>漫反射光照细节</h2><p>接下来我想优化一下场景整体的漫反射细节。</p><p>当前的渲染结果其实是有加一个默认的环境光**vec3(0.1)**的，主要是之前的场景太黑了。这是个临时的处理，把这个环境光去掉。<br><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_less_ambient.png" alt="去掉写死的环境光补偿"></p><p>好了，我们再来看一下我们的场景。有没有感觉山体的阴影部分有点太黑了？是的，在现实世界中，处于阴影的场景，在大白天也会被场景的漫反射光给提亮的，这种一片漆黑的感觉是有些难看。所以接下来我们来增加一些场景中应该有的漫反射光。</p><p>首先山体之间是会有漫反射光的影响的，也就是阴影部分的山体会被不在阴影的其他山的漫反射光照亮。当然这种影响我们是无法实时计算的，要计算的东西实在是太多了。但是可以通过一个很简单的方式来提单：我们计算当前点的发现和指向光源方向的点乘，当这个结果大于0的时候，用这个乘积乘以一个小的光照并加到原本的颜色上。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl">color += (<span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">dot</span>(-light_dir, normal))*ground_color/<span class="hljs-number">10.0</span>);<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_mountain.png" alt="增加地形的漫反射光"></p><p>加完地形的漫反射光后，天空其实也有各个方向的漫反射的光会影响地形的亮度。天空的漫反射光可以通过地形法线的y分量和天空颜色的一部分来计算，示例代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl">color += (normal.y + <span class="hljs-number">1.0</span>)/<span class="hljs-number">2.0</span>*low_sky_blue/<span class="hljs-number">10.0</span>;<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_sky.png" alt="增加天空的漫反射光"></p><p>增加了这些漫反射细节，场景的真实度进一步得到了提升。</p><h1 id="云朵"><a href="#云朵" class="headerlink" title="云朵"></a>云朵</h1><p>有了天空，再给天空上增加云的话会进一步增加场景的丰富度，下面就来介绍我给这个场景添加的两部分云的计算。</p><h2 id="高层云"><a href="#高层云" class="headerlink" title="高层云"></a>高层云</h2><p>我给这个场景添加了两种云，高层云是我想模拟在高度很高的地方，云层看起来不厚并且相对静态的感觉。</p><p>高层云的纹理也是利用perlin noise来计算，由于高层的云没有厚实感其实用2D的perlin noise也足够了。</p><p>另外需要注意的是，云的纹理需要根据远近来做处理。远处的云的纹理如果太清晰的话在最终效果上会显得太过于密集。下面是高层云的示例代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 高层云的高度</span><br><span class="hljs-type">float</span> top_sky_plane = <span class="hljs-number">3000.</span>;<br><br><span class="hljs-type">vec3</span> getSkyColor(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd)<br>&#123;    <br>    <span class="hljs-type">vec3</span> hit_sky;<br>    hit_sky.y = top_sky_plane;<br>        <br>    hit_sky.xz = ro.xz + rd.xz * (top_sky_plane - ro.y)/rd.y;    <br>    <br>    <span class="hljs-comment">//降低远处云的密度，看起来效果更好</span><br>    <span class="hljs-type">float</span> hit_dist = <span class="hljs-built_in">distance</span>(hit_sky, ro);<br>    <span class="hljs-type">float</span> cloud_density_percentage = <span class="hljs-number">1.0</span>;<br>    <span class="hljs-keyword">if</span>(hit_dist &gt; cloud_view_distance)<br>    &#123;<br>        cloud_density_percentage *= <span class="hljs-built_in">exp</span>(-(hit_dist - cloud_view_distance)/ cloud_view_distance);<br>    &#125;    <br><br>    <span class="hljs-comment">// 根据云层采样点的远近处理云层的密度</span><br>    <span class="hljs-type">float</span> cloud_density = <span class="hljs-built_in">smoothstep</span>(getCloudDensity(hit_sky.xz/<span class="hljs-number">150.0</span>, <span class="hljs-number">3</span>), <span class="hljs-number">-0.99</span>, <span class="hljs-number">1.9</span>)*cloud_density_percentage * <span class="hljs-number">0.5</span>;<br>    <span class="hljs-type">float</span> res_t;<br><br>    <span class="hljs-comment">// sky color    </span><br>    <span class="hljs-type">vec3</span> sky_color = <span class="hljs-built_in">mix</span>(low_sky_blue, high_sky_blue, <span class="hljs-built_in">clamp</span>(rd.y, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>));<br>    <span class="hljs-type">vec3</span> cloud_color = <span class="hljs-type">vec3</span>(<span class="hljs-number">1.</span>);<br>    <span class="hljs-comment">// 根据云层密度得到最终的高层云和天空颜色</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">mix</span>(sky_color, cloud_color, cloud_density);<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_high_cloud.png" alt="增加天空高层云"></p><p>增加了高层云之后，天空就显得不那么单调了。</p><h2 id="体积云"><a href="#体积云" class="headerlink" title="体积云"></a>体积云</h2><p>最后就是体积云了，体积云的部分我不会在这里详细讨论，这是一个可以讨论的比较深的话题。我这个场景的体积云效果也并不是很理想，这里仅作为一个最后的点缀，在山峰上增加一点点动态效果。</p><p>体积云的效果其实也是在一定区域内进行多个点的采样而来，这个区域内利用FBM来实现云的动态的随机效果。在这个场景内我使用了SDF来圈定体积云的范围，并且给SDF增加了随机现状来获取更好的随机效果。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> scene(<span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> pos)<br>&#123;    <br>    <span class="hljs-type">vec3</span> cloud_pos = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">15.0</span>);<br>    <br>    <span class="hljs-type">vec3</span> filter_pos = <span class="hljs-type">vec3</span>(pos.x, pos.y+iTime, pos.z+iTime);<br>    pos -= cloud_pos;<br>    <span class="hljs-type">float</span> rst = -(rm_box(pos)) + fbm_cloud(pos * <span class="hljs-number">0.1</span>+iTime*<span class="hljs-number">0.3</span>, <span class="hljs-number">5</span>);<br>    rst = rst / <span class="hljs-number">25.0</span> * <span class="hljs-built_in">max</span>(fbm_cloud(filter_pos*<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>) - <span class="hljs-number">1.2</span>, <span class="hljs-number">0.0</span>); <br>    <span class="hljs-keyword">return</span> rst;<br>&#125;<br><br><span class="hljs-type">float</span> max_cloud_dist = <span class="hljs-number">80.</span>;<br><span class="hljs-type">vec4</span> renderMidClouds(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd)<br>&#123;    <br>    <span class="hljs-type">vec4</span> res = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">float</span> depth = <span class="hljs-number">0.0</span>;    <br>    <br>    <span class="hljs-type">int</span> sample_count = <span class="hljs-number">64</span>;<br>    <span class="hljs-type">float</span> dt = max_cloud_dist / <span class="hljs-type">float</span>(sample_count);<br>    <br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_count; ++i)<br>    &#123;<br>        <span class="hljs-type">vec3</span> p = ro + depth*rd;<br>        <span class="hljs-type">float</span> density = scene(p);<br>        <span class="hljs-keyword">if</span>(density &gt; <span class="hljs-number">0.0</span>)<br>        &#123;<br>            <span class="hljs-type">float</span> diffuse = <span class="hljs-built_in">clamp</span>((scene(p) - scene(p + <span class="hljs-number">0.3</span>*light_dir))/<span class="hljs-number">0.3</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>);<br>            <span class="hljs-type">vec3</span> lin = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>) * <span class="hljs-number">1.1</span> + <span class="hljs-number">0.8</span> * <span class="hljs-type">vec3</span>(<span class="hljs-number">0.9333</span>, <span class="hljs-number">0.702</span>, <span class="hljs-number">0.5255</span>)*diffuse;<br>            <span class="hljs-type">vec4</span> color = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">mix</span>(<span class="hljs-type">vec3</span>(<span class="hljs-number">1.0</span>), <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>), density), density);<br>            color.rgb *= color.a;<br><br>            res += color * (<span class="hljs-number">1.0</span> - res.a);<br>        &#125;<br><br>        depth+=dt;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> res;<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_all_cloud.png" alt="增加体积云"></p><h1 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h1><iframe width="640" height="360" frameborder="0" src="https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false" allowfullscreen></iframe><p>以上便是我如何实现这个场景的简单介绍了。这是我初次尝试在ShaderToy上渲染大场景，也是第一次将整个步骤拆解讲解，可能还是会有不少地方讲的不过仔细和通透，也有些遗漏。</p><p>后面我还是会继续尝试创作和讲解，希望能给人带来帮助，也有助于巩固我所学的知识。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>程序化生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>景深的简单实现</title>
    <link href="/2024/10/28/depth-of-field/"/>
    <url>/2024/10/28/depth-of-field/</url>
    
    <content type="html"><![CDATA[<h1 id="关于景深"><a href="#关于景深" class="headerlink" title="关于景深"></a>关于景深</h1><p>景深是一个常在摄像领域出现的词，它一般指的是沿着摄像机或其他成像器的拍摄方向上，能够取得清晰图像的成像所测定的被摄物体前后距离范围。用大白话就是说，拥有浅景深的成像器拍摄出来的效果，是只有焦点附近的图像是清晰的，其他地方的图像都是模糊的；而拥有大景深则可以在离焦点很远的地方也能有清晰的图像。</p><p><img src="/2024/10/28/depth-of-field/dof_butterfly.JPG" alt="一张浅景深的照片"></p><p>有了景深效果的图像可以有重点的突出核心想要表达的内容，不仅仅在摄影摄像的领域有非常多的应用，在游戏领域内也是应用广泛，可以表现出很独特的风格化美术效果（如八方旅人的浅景深效果）。</p><p><img src="/2024/10/28/depth-of-field/game1.jpg" alt="八方旅人"></p><p>下面我来介绍一种基础的景深效果实现，这个方法也在最近接入了<a href="https://github.com/ruochenhua/KongEngine">KongEngine</a></p><h1 id="渲染散景"><a href="#渲染散景" class="headerlink" title="渲染散景"></a>渲染散景</h1><p>浅景深的主要应用是通过调整不同焦距上物体的成像清晰程度来突出渲染画面的重点。清晰的部分我们已经掌握了，就是正常的将场景渲染出来，那不清晰的部分（或者叫做散景）也有不少的实现方式，一般是通过模糊算法来实现。</p><p>模糊的算法有很多种，比如box blur，gaussian blur等等，效果最好的是扩张模糊(dilate blur)，这也是我们会采取的方法。</p><h2 id="扩张模糊（dilate-blur"><a href="#扩张模糊（dilate-blur" class="headerlink" title="扩张模糊（dilate blur)"></a>扩张模糊（dilate blur)</h2><p>扩张模糊它的主要方式，是在给定一个模糊的窗口下，取得这个窗口下的最亮的颜色记录下来，然后将这个最亮的颜色扩张到整个窗口。这样一来经过扩张模糊的画面会有一种亮晶晶，并且很柔和的效果，很适合作为散景的表现效果。</p><p>dilate blur的计算也比较简单，首先我们定义此次blur的窗口大小已经采样的间隔大小。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 窗口的大小，数值越大扩散越大，消耗越高 </span><br><span class="hljs-type">int</span> size = <span class="hljs-number">5</span>;<br><span class="hljs-comment">// 采样间隔的大小，数值越大扩散越大，效果降低</span><br><span class="hljs-type">float</span> separation = <span class="hljs-number">1.0</span>;<br></code></pre></td></tr></table></figure><p>在定义了窗口的尺寸之后，我们在窗口的范围内记录最亮的像素颜色，并保存下来。<strong>窗口的形状不限</strong>，可以是矩形，或者圆形。我们这里实现采取圆形的窗口。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 渲染场景的尺寸</span><br><span class="hljs-type">vec2</span> tex_size = <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(scene_texture, <span class="hljs-number">0</span>).xy);<br><span class="hljs-comment">// 获取场景的原本颜色</span><br>FragColor = <span class="hljs-built_in">texture</span>(scene_texture, TexCoords);<br><br><span class="hljs-keyword">if</span>(size &lt;= <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span>;<br><span class="hljs-type">float</span> mx = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">vec4</span> cmx = FragColor;<br><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = -size; i &lt;= size; ++i)<br>&#123;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = -size; j &lt;= size; ++j)<br>&#123;<br><span class="hljs-comment">// dilate的形状可以多样，如圆形，矩形等等，根据采样点的形状来决定</span><br><span class="hljs-comment">// 这里使用圆形的dilate</span><br><span class="hljs-keyword">if</span>(<span class="hljs-built_in">distance</span>(<span class="hljs-type">vec2</span>(i,j), <span class="hljs-type">vec2</span>(<span class="hljs-number">0</span>)) &gt; size) <span class="hljs-keyword">continue</span>;<br><br><span class="hljs-comment">// 采样区域内点的颜色，不要越界出去了</span><br><span class="hljs-type">vec2</span> sample_coord = TexCoords + <span class="hljs-type">vec2</span>(i, j)*separation/tex_size;<br><span class="hljs-keyword">if</span>(sample_coord.x &gt; <span class="hljs-number">1.0</span> || sample_coord.x &lt; <span class="hljs-number">0.0</span> || sample_coord.y &gt; <span class="hljs-number">1.0</span> || sample_coord.y &lt; <span class="hljs-number">0.0</span>)<br><span class="hljs-keyword">continue</span>;<br><br><span class="hljs-comment">// 拿到采样点</span><br><span class="hljs-type">vec4</span> c = <span class="hljs-built_in">texture</span>(scene_texture, sample_coord);<br><br><span class="hljs-comment">// 和目标颜色做点乘，得到一个灰度值</span><br><span class="hljs-type">float</span> mxt = <span class="hljs-built_in">dot</span>(c.rgb, <span class="hljs-type">vec3</span>(<span class="hljs-number">0.3</span>, <span class="hljs-number">0.59</span>, <span class="hljs-number">0.11</span>));<br><br><span class="hljs-comment">// 保存区域内灰度值最大的颜色</span><br><span class="hljs-keyword">if</span>(mxt &gt; mx)<br>&#123;<br>mx = mxt;<br>cmx = c;<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我们计算最亮区域的方式是通过和一个目标颜色**(0.3, 0.59, 0.11)**来做点乘，当然也可以通过和其他的目标颜色，或者其他的方式来实现。</p><p>最后，我们得到窗口区域内最亮的颜色，我们的最终颜色是原本颜色和最亮颜色的差值。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 模糊采样的颜色和原始颜色的mix上下限</span><br><span class="hljs-type">float</span> min_threshold = <span class="hljs-number">0.1</span>;<br><span class="hljs-type">float</span> max_threshold = <span class="hljs-number">0.3</span>;<br><br><span class="hljs-comment">// 最终颜色是原来颜色和区域内灰度值最大的采样颜色的混合，有上下限做限制</span><br>FragColor.rgb = <span class="hljs-built_in">mix</span>(FragColor.rgb, cmx.rgb, <span class="hljs-built_in">smoothstep</span>(min_threshold, max_threshold, mx));<br></code></pre></td></tr></table></figure><p>这里我们还是采用了一个上下限，尽量控制增亮的程度。</p><h2 id="散景的效果"><a href="#散景的效果" class="headerlink" title="散景的效果"></a>散景的效果</h2><p>这里给出经过扩张模糊得到的散景效果。下面这张图是扩张模糊之前的效果。<br><img src="/2024/10/28/depth-of-field/dilate_before.png" alt="扩张模糊前"><br>下面这张图是扩张模糊之后的效果。<br><img src="/2024/10/28/depth-of-field/dilate_after.png" alt="扩张模糊后"></p><p>当然在实际的场景中，我们可能不会开这么大的扩散效果，此处只是作为对比。</p><h1 id="结合场景"><a href="#结合场景" class="headerlink" title="结合场景"></a>结合场景</h1><p>好了，现在我们有原本场景的渲染效果和扩散后的效果，实现最终的景深效果需要将这两者结合起来。我们需要一种方法来决定画面上哪些部分是需要采用清晰的图像，哪些是采用模糊的图像。</p><p>为了实现这个效果我们需要获得画面上每个点的深度，或者每个点的实际世界坐标。幸运的是，我们在实现<a href="https://ruochenhua.github.io/2024/10/19/defer-render/">延迟渲染</a>的时候已经将这些存放到缓冲中去了，接下来就是实现景深效果了。</p><p>最终的代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> TexCoords;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> scene_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> dilate_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> position_texture;<br><br><span class="hljs-comment">// 焦点距离</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> focus_distance = <span class="hljs-number">3.0</span>;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">vec2</span> focus_threshold;<br><span class="hljs-comment">// 景深的上下限</span><br><span class="hljs-type">float</span> min_dist = focus_threshold.x;<br><span class="hljs-type">float</span> max_dist = focus_threshold.y;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec4</span> focus_color = <span class="hljs-built_in">texture</span>(scene_texture, TexCoords);<br>    <span class="hljs-type">vec4</span> out_of_focus_color = <span class="hljs-built_in">texture</span>(dilate_texture, TexCoords);<br>    <span class="hljs-type">vec3</span> scene_position = <span class="hljs-built_in">texture</span>(position_texture, TexCoords).xyz; <br>    <br><span class="hljs-comment">// 这里采用了画面每个点的世界坐标和相机的距离作为判定模糊的标准</span><br><span class="hljs-comment">// 当然用深度信息也是可以的，性能上也更好，这里为了代码展示更好理解</span><br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br><br>    <span class="hljs-type">float</span> blur_amout = <span class="hljs-built_in">smoothstep</span>(min_dist, max_dist, <span class="hljs-built_in">abs</span>(focus_distance - <span class="hljs-built_in">distance</span>(scene_position, cam_pos)));<br>    <br><span class="hljs-comment">// 最后的颜色是焦距内和散景的混合</span><br>    FragColor = <span class="hljs-built_in">mix</span>(focus_color, out_of_focus_color, blur_amout);<br>&#125;<br></code></pre></td></tr></table></figure><p>这段代码理解起来应该没有什么太大的难度。</p><h1 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h1><p>这里展示一下最终的效果。</p><p><img src="/2024/10/28/depth-of-field/dof_near.png" alt="近焦点"><br><img src="/2024/10/28/depth-of-field/dof_far.png" alt="远焦点"></p><p>上面两张图分别展示了不同焦点的景深的表现结果。可以明显看到不同景深效果的加入可以很容易的将画面上想要着重表达出来的部分勾勒出来。优秀的散景效果也能给画面增加不少美感（虽然我这个测试场景也没有什么美感可言…）。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>延迟渲染实现</title>
    <link href="/2024/10/19/defer-render/"/>
    <url>/2024/10/19/defer-render/</url>
    
    <content type="html"><![CDATA[<p>想要在Kong引擎里面实现的场景慢慢复杂了起来，光源和模型的数量从原先的十以内的数量增长到几十甚至几百的数量级，是时候接入延迟渲染的方法了。</p><h1 id="延迟渲染"><a href="#延迟渲染" class="headerlink" title="延迟渲染"></a>延迟渲染</h1><p><strong>延迟渲染</strong>（Defer Rendering），或者<strong>延迟着色法</strong>（Defer Shading），是区别于<strong>正向渲染</strong>（Forward Shading）的一种计算场景光照的方式。</p><p>正向渲染方法就是遍历场景中的每一个模型，计算一个模型的光照表现后再继续下一个模型的计算，根据深度测试的结果更新屏幕上最终像素显示的颜色。这种方法是很容易让人理解并实现的。但是当场景中的光照和模型数量变多的时候，模型重叠的区域会进行不必要的光照计算（被挡住的模型像素区域最终会被前面的模型遮挡，但是这篇被挡住的区域还是被计算了光照），而光照计算一般来说是渲染消耗的大头，这部分时间就被浪费了。</p><p>而延迟渲染的想法则是将光照计算分成两部分。第一个部分叫做<strong>几何处理阶段</strong>（Geometry Pass），它先将光照计算所需要的模型信息（顶点位置、法线、颜色、材质属性等等）先渲染到多张贴图上（消耗低），经由深度检测保留最终在屏幕上显示的模型部分的这些信息。</p><!-- wp:image {"sizeSlug":"large","align":"center"} --><figure class="wp-block-image aligncenter size-large"><img src="https://learnopengl-cn.github.io/img/05/08/deferred_g_buffer.png" alt=""/></figure><!-- /wp:image --><p>第二部分叫做<strong>光照处理阶段</strong>（Lighting Pass），根据几何处理阶段保存的信息再去进行光照计算，这样就不会将算力浪费在计算被遮挡的模型部分的光照了，从而优化渲染的性能，也有赋予了能够更加方便的实现某些效果的能力（如SSAO）。</p><!-- wp:image {"sizeSlug":"large","align":"center"} --><figure class="wp-block-image aligncenter size-large"><img src="https://learnopengl-cn.github.io/img/05/08/deferred_overview.png" alt=""/></figure><!-- /wp:image --><h1 id="G缓冲"><a href="#G缓冲" class="headerlink" title="G缓冲"></a>G缓冲</h1><p>G缓冲(G-buffer)是对所有用来储存光照相关的数据，并在最后的光照处理阶段中使用的所有纹理的总称。它是我们计算最终渲染输出中的缓存和中转站，为了实现延迟渲染，G-buffer中会包含如下几张纹理的数据：模型顶点位置数据；模型法线数据；模型漫反射颜色数据；材质数据（ao，roughness，metallic）等等。有了这些数据则能够实现Kong引擎的PBR光照计算，初始化G-buffer的代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">DeferBuffer::GenerateDeferRenderTextures</span><span class="hljs-params">(<span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, g_buffer_);<br><br><span class="hljs-comment">// 将当前视野的数据用贴图缓存</span><br><span class="hljs-comment">// 位置数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_position_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_position_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, g_position_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 法线数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_normal_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_normal_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, g_normal_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 顶点颜色数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_albedo_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_albedo_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, g_albedo_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// orm数据（ao，roughness，metallic）</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_orm_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_orm_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT3, GL_TEXTURE_2D, g_orm_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 生成renderbuffer</span><br><span class="hljs-built_in">glGenRenderbuffers</span>(<span class="hljs-number">1</span>, &amp;g_rbo_);<br><span class="hljs-built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, g_rbo_);<br><span class="hljs-built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, width, height);<br><span class="hljs-built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, g_rbo_);<br><span class="hljs-built_in">glEnable</span>(GL_DEPTH_TEST);<br><br><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> attachments[<span class="hljs-number">4</span>] = &#123;GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3&#125;;<br><span class="hljs-built_in">glDrawBuffers</span>(<span class="hljs-number">4</span>, attachments);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>可以从上面的代码看到，我们利用了多渲染目标（multiple render targets）可以一次处理并输出到多个缓冲（GL_COLOR_ATTACHMENT0到3）。简化的几何处理着色器示例代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// defer_geometry_pass.frag</span><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gPosition;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gNormal;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">2</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gAlbedo;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">3</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gORM;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> frag_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> frag_normal;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> frag_uv;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">vec4</span> albedo;    <span class="hljs-comment">// color</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> metallic;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> roughness;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> ao;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-comment">// 深度信息存储到position贴图的w值中</span><br>    gPosition = frag_pos;<br>    gNormal = <span class="hljs-type">vec4</span>(frag_normal, <span class="hljs-number">1.0</span>);<br>    gAlbedo = albedo;<br>    gORM = <span class="hljs-type">vec4</span>(ao, roughness, metallic, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>上方的代码将我们所需要的世界坐标下的顶点坐标信息、法线信息、漫反射颜色和材质信息输出到了四张贴图。带着这四张贴图的信息，我们进入下一个阶段，光照处理阶段。下面是个简化的光照处理着色器代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec3</span> frag_pos = <span class="hljs-built_in">texture</span>(position_texture, TexCoords).xyz;<br>    <span class="hljs-type">vec3</span> frag_normal = <span class="hljs-built_in">texture</span>(normal_texture, TexCoords).rgb;<br>    <span class="hljs-type">vec4</span> env_albedo = <span class="hljs-built_in">texture</span>(albedo_texture, TexCoords);<br><br>    <span class="hljs-type">vec3</span> orm = <span class="hljs-built_in">texture</span>(orm_texture, TexCoords).rgb;<br>    <span class="hljs-type">float</span> ao = orm.x;<br>    <span class="hljs-type">float</span> env_roughness = orm.y;<br>    <span class="hljs-type">float</span> env_metallic = orm.z;<br><br>    <span class="hljs-type">vec3</span> view = <span class="hljs-built_in">normalize</span>(cam_pos - frag_pos);  <span class="hljs-comment">//to_view</span><br><br>    <span class="hljs-type">vec3</span> light_color = CalcLight(light_info, frag_normal, view,  frag_pos, material);<br><br>    <span class="hljs-type">vec3</span> color = ambient + light_color;<br>    FragColor = <span class="hljs-type">vec4</span>(color, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="结合延迟和正向渲染"><a href="#结合延迟和正向渲染" class="headerlink" title="结合延迟和正向渲染"></a>结合延迟和正向渲染</h1><p>延迟渲染实现起来其实还是比较简单明了的，但是需要注意的是，有些材质并不能通过延迟渲染实现，比如说半透明这种需要进行alpha混合的材质，因此就会出现需要结合延迟渲染和正向渲染的情况。</p><p>结合延迟渲染和正向渲染的时候，一般来说是先处理延迟渲染的部分。在处理完延迟渲染后，将延迟渲染的G-buffer的深度缓冲复制到最后输出屏幕的深度缓冲上（我这里最后会继续后处理，所以是会输出到后处理的FrameBuffer上）。如此一来，正向渲染的物体才可以和延迟渲染的场景有正确的深度遮挡结合，否则会出现正向渲染的物体永远在上的情况。实例代码如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 需要将延迟渲染的深度缓冲复制到后面的后处理buffer上</span><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_READ_FRAMEBUFFER, defer_buffer_.g_buffer_);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_DRAW_FRAMEBUFFER, post_process.<span class="hljs-built_in">GetScreenFrameBuffer</span>());<br><span class="hljs-built_in">glBlitFramebuffer</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, window_size.x, window_size.y, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, window_size.x, window_size.y, GL_DEPTH_BUFFER_BIT, <br>GL_NEAREST);<br></code></pre></td></tr></table></figure><h1 id="延迟渲染的效能提升"><a href="#延迟渲染的效能提升" class="headerlink" title="延迟渲染的效能提升"></a>延迟渲染的效能提升</h1><p>之前提过，延迟渲染最大的好处之一便是能够提升渲染的效率，这里大概做一个粗略的测试。下方是一个包含着1000个人物模型和200个点光源的场景，如果按照正常的正向渲染，这个场景在我的笔记本上的帧率大概在35左右：</p><p><img src="/2024/10/19/defer-render/no_defer_render.png" alt="非延迟渲染"></p><p>当使用延迟渲染的情况下，该场景的帧率可以提升到170左右：</p><p><img src="/2024/10/19/defer-render/defer_render.png" alt="延迟渲染"></p><p>当然上方这是个比较极端的场景，实际场景上可能不会有这么复杂的光源，以及模型可能不会像测试场景这样重叠，所以差距可能不会像测试场景那般明显。但是一般来说延迟渲染对渲染场景的性能提升会是比较客观的。</p><h2 id="基于延迟渲染的延伸"><a href="#基于延迟渲染的延伸" class="headerlink" title="基于延迟渲染的延伸"></a>基于延迟渲染的延伸</h2><p>延迟渲染的好处之一不仅仅体现在性能上，由于延迟渲染将很多有用的信息存储下来，基于延迟渲染我们可以实现非常多其他的效果。比如说屏幕空间环境光遮蔽SSAO（如下图）以及屏幕空间反射SSR等等，我计划在后面的文章详细介绍一下。</p><p><img src="/2024/10/19/defer-render/ssao.png" alt="SSAO效果"></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于单次散射的天空大气渲染方法</title>
    <link href="/2024/10/15/single-scatter-atmosphere/"/>
    <url>/2024/10/15/single-scatter-atmosphere/</url>
    
    <content type="html"><![CDATA[<p>最近KongEngine实现了IBL(Image Based Lighting)，可以将HDR环境贴图映射作为3D场景的环境。</p><p><img src="/2024/10/15/single-scatter-atmosphere/kong-screen-shot.png" alt="KongEngine的IBL效果"></p><p>在实现了IBL之后我又产生了一个想法，能否实现类似UE中的大气环境的渲染效果呢？我尝试去寻找答案，发现如果要完全复刻UE中的效果确实需要一定的功夫的，但是最基础的天空大气渲染并没有想象中那么复杂，于是我便花了点时间在KongEngine中实现了这个功能。</p><p><img src="/2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.png" alt="KongEngine天空大气效果"></p><p>我打算将这个方法的基础思想和实现在此简单记录一下。</p><h1 id="单次散射模型"><a href="#单次散射模型" class="headerlink" title="单次散射模型"></a>单次散射模型</h1><p>星球的大气层是一种参与性介质，和在真空环境不同，光在大气层中传播的时候会因为大气中的微小颗粒（水、灰尘等等）发生散射（折射、反射）和吸收等情况。因此我们看向空中的一个点的时候，这个点的颜色是光经过多次散射得到的结果。</p><p>光到达我们眼睛之前经过多少次反射和折射是不一定的，在实时渲染的需求下计算太多次光的变化显然也是不显示的。最简单的方法，是使用单次散射模型：我们假定光在进入我们眼睛之前，有且只发生了一次散射。光一般在第一次散射的时候，还会有最多的能量剩余，后面的多次散射能力相对少，对最后效果的呈现也影响不大，因此这种模型可以在保证性能的情况下，还有不错的效果。</p><p><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_02.png"></p><p>除了散射，光在传播的时候会被大气吸收。一般来说，如果在一个均匀的介质中传播的话，光的被吸收的部分和介质的密度，以及传播的路径长度正相关。放到单散射模型的例子中，就是需要计算光在散射前和散射后的路径上，被吸收了多少能量。<br><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_07.png"></p><p>按照上面的图，假设相机在A点，观察方向为AB，其中有一束光在P点发生散射后沿着PA进入相机。如果我们知道了光线损耗和距离相关的公式，那么似乎是只要计算出CP和PA的长度，在带入公式后就可以得到光该路径上传播后的最终能量了。</p><p><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_10a.png"></p><p>但是对于大气层来说，它的密度并不是均匀的，而是和大气层距离地面的高度相关。所以在计算CP段光线损耗的时候，我们需要将这段距离分为多个小段，每个小段的损耗公式带入对应平均高度，在最后将所有结果相加才。小段划分的越密集，则结果越准确。</p><p>如果我们还要考虑大气中的其他因素，比如说大气中的云层，在这些区域中光的损耗就不仅仅是和高度相关了。</p><p>另外一点就是，当我们考虑AB方向的光线时，它的最终效果，是在大气层内的所有AB连线上面的点的散射结果的总和（P0、P1、P2…Pn），因此我们也同样的需要对AB线段进行分段采样并将结果叠加。AB线段上的每一个采样结果按照上面所描述的计算单一P点的方式。</p><p><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_08a.png"></p><p>以上便是大气单次散射模型的基本思路。</p><h1 id="散射的计算"><a href="#散射的计算" class="headerlink" title="散射的计算"></a>散射的计算</h1><p>之前我们提到了计算光的散射，这里我们介绍一下散射的相关计算。会提及一些公式，但是不会做过多的数学推导工作，对推导过程感兴趣的可以看一下文章中的参考资料。</p><p>一般来说，天空大气的散射主要包括两种，分别是<strong>瑞利散射</strong>和<strong>米氏散射</strong>。</p><ul><li>瑞利散射是当光线通过介质中的微小颗粒或分子时发生的散射现象。由于颗粒或分子的尺寸远小于光的波长，不同波长的光线会以不同的角度散射，一个最经典的案例就是因为蓝色的波长是较短的，所以蓝色很容易发生瑞利散射，导致天空呈现蓝色。</li><li>米氏散射则一般由空气中含有的较大颗粒的介质，如气溶胶、灰尘、水滴等引起。和瑞利散射不同的是，米氏散射和光的波长关系并不大。<br> <img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_13.png"></li></ul><p>那么根据前面的模型思路，光在P点上发生了散射，其中一部分能量沿着PA方向进入相机的实现。获取这一部分能量的计算函数被称之为<strong>相位函数（Phase Function）</strong>。相位函数是用来描述，当光线发生散射的情况时，某个方向（一般是和原光线方向的夹角）占原光线的能量的比例。瑞利散射和米氏散射的相位函数是不同的，同一种散射的相位函数也会有不同的方法进行拟合，这里我不想去做过多的公式推导的工作，有兴趣的可以去查看<a href="https://patapom.com/topics/Revision2013/Revision%202013%20-%20Real-time%20Volumetric%20Rendering%20Course%20Notes.pdf">参考资料</a>的推导过程。</p><p>下方是瑞利散射的相位函数，theta是原光线方向和目标方向的夹角：</p><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mtable displaystyle="true" columnalign="right left right" columnspacing="0em 2em" rowspacing="3pt">    <mtr>      <mtd>        <mi>P</mi>        <mo stretchy="false">(</mo>        <mi>&#x3B8;</mi>        <mo stretchy="false">)</mo>      </mtd>              <mtd>        <mi></mi>        <mo>=</mo>        <mfrac>          <mn>3</mn>          <mrow>            <mn>16</mn>            <mi>&#x3C0;</mi>          </mrow>        </mfrac>        <mo stretchy="false">(</mo>        <mn>1</mn>        <mo>+</mo>        <mi>c</mi>        <mi>o</mi>        <msup>          <mi>s</mi>          <mn>2</mn>        </msup>        <mi>&#x3B8;</mi>        <mo stretchy="false">)</mo>      </mtd>    </mtr>  </mtable></math><!-- /wp:html --><!-- wp:paragraph --><p>下方是米氏散射的相位函数，这里使用的是<a href="https://omlc.org/classroom/ece532/class3/hg.html">Henyey-Greenstein函数</a>来近似。</p><!-- /wp:paragraph --><!-- wp:html --><p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mi>P</mi>  <mo stretchy="false">(</mo>  <mi>&#x3B8;</mi>  <mo stretchy="false">)</mo>  <mo>&#x3D;</mo>  <mfrac>    <mrow>      <mn>1</mn>      <mo>&#x2212;</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>    <mrow>      <mn>4</mn>      <mi>&#x3C0;</mi>      <mo stretchy="false">(</mo>      <mn>1</mn>      <mo>+</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>      <mo>&#x2212;</mo>      <mn>2</mn>      <mi>g</mi>      <mi>c</mi>      <mi>o</mi>      <mi>s</mi>      <mo stretchy="false">(</mo>      <mi>&#x3B8;</mi>      <mo stretchy="false">)</mo>      <msup>        <mo stretchy="false">)</mo>        <mrow>          <mn>3</mn>          <mrow>            <mo>&#x2F;</mo>          </mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>  </mfrac></math></p><!-- /wp:html --><!-- wp:paragraph --><p>好了，现在我们知道了如何计算光线在P点的散射行为。剩下的工作就是需要计算光线在传播过程的损耗了。这一部分的计算方法称之为<strong>衰减系数</strong>，或者<strong>消光系数</strong>。消光系数中的一部分，需要对光线在传播的路线的长度和空气密度进行积分。在程序中的表示就是将光的传播路径分为小段，将每一小段的长度和平均密度（或者小段中点的介质密度）相乘而得到，这个结果我们称之为<strong>光学距离（Optical Depth）</strong>。</p><!-- /wp:paragraph --><!-- wp:paragraph --><p>衰减系数的计算公式如下，红色部分代表的是在海拔为h的散射系数。他可以分解为在海平面上的散射系数乘以在海拔h的介质密度。</p><!-- /wp:paragraph --><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mstyle mathcolor="#00AAFF">    <mi>T</mi>    <mo stretchy="false">(</mo>    <mi>P</mi>    <mi>A</mi>    <mo stretchy="false">)</mo>  </mstyle>  <mo>=</mo><mstyle mathcolor="#00AA00">  <mi>exp</mi></mstyle>  <mrow data-mjx-texclass="ORD">    <mo>&#x2212;</mo>    <msubsup>      <mo data-mjx-texclass="OP">&#x222B;</mo>      <mi>P</mi>      <mi>A</mi>    </msubsup>    <mrow data-mjx-texclass="ORD">      <mstyle mathcolor="Red">        <mi>&#x3B2;</mi>        <mo stretchy="false">(</mo>        <mi>&#x3BB;</mi>        <mo>,</mo>        <mi>h</mi>        <mo stretchy="false">)</mo>      </mstyle>    </mrow>    <mi>d</mi>    <mi>s</mi>  </mrow></math><!-- /wp:html --><!-- wp:paragraph --><p>分解出来后得到的结果如下，其中红色的部分代表的意思是在海平面的散射系数，是一个常量，黄色部分代表了在海拔为h的介质的密度。这个公式的积分便是针对AP路线上的介质密度，其结果也就是光学距离。</p><!-- /wp:paragraph --><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mstyle mathcolor="#00AAFF">    <mi>T</mi>    <mo stretchy="false">(</mo>    <mi>P</mi>    <mi>A</mi>    <mo stretchy="false">)</mo>  </mstyle>  <mo>=</mo>    <mstyle mathcolor="#00AA00">      <mi>exp</mi>    </mstyle>  <mrow data-mjx-texclass="ORD">    <mo>&#x2212;</mo>    <mstyle mathcolor="Red">      <mi>&#x3B2;</mi>      <mo stretchy="false">(</mo>      <mi>&#x3BB;</mi>      <mo stretchy="false">)</mo>    </mstyle>    <msubsup>      <mo data-mjx-texclass="OP">&#x222B;</mo>      <mi>P</mi>      <mi>A</mi>    </msubsup>    <mrow data-mjx-texclass="ORD">      <mstyle mathcolor="Gold">        <mi>&#x3C1;</mi>        <mo stretchy="false">(</mo>        <mi>h</mi>        <mo stretchy="false">)</mo>      </mstyle>    </mrow>    <mi>d</mi>    <mi>s</mi>  </mrow></math><!-- /wp:html --><!-- wp:paragraph --><p>介质密度的计算公式如下，其中H代表的是一个基准海拔，是一个常量。不同散射的基准海拔有所不同，瑞利散射的基准海拔是*8500*，而米氏散射的基准海拔是*1200*。</p><!-- /wp:paragraph --><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mstyle mathcolor="Gold">    <mi>&#x3C1;</mi>    <mo stretchy="false">(</mo>    <mi>h</mi>    <mo stretchy="false">)</mo>  </mstyle>  <mo>=</mo>  <mi>exp</mi>  <mo stretchy="false">(</mo>  <mo>&#x2212;</mo>  <mfrac>    <mi>h</mi>    <mi>H</mi>  </mfrac>  <mo stretchy="false">)</mo></math><!-- /wp:html --><p>自此，我们关于单次散射的天空大气渲染方法的基本预备知识已经了解的差不多了，接下来介绍shader的相关代码。</p><h1 id="Shader代码"><a href="#Shader代码" class="headerlink" title="Shader代码"></a>Shader代码</h1><p>首先，为了计算AB、PC等视线和光线在大气层内的传播距离，我们需要一个函数来计算射线和球体的相交情况。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec2</span> ray_sphere_intersection(<span class="hljs-type">vec3</span> ray_origin, <span class="hljs-type">vec3</span> ray_direction, <span class="hljs-type">vec3</span> sphere_center, <span class="hljs-type">float</span> sphere_radius)<br>&#123;<br>    <span class="hljs-comment">// ray-sphere intersection that assumes</span><br>    <span class="hljs-type">float</span> a = <span class="hljs-built_in">dot</span>(ray_direction, ray_direction);<br>    <span class="hljs-type">vec3</span> oc = ray_origin - sphere_center;<br>    <span class="hljs-type">float</span> b = <span class="hljs-number">2.0</span> * <span class="hljs-built_in">dot</span>(ray_direction, oc);<br>    <span class="hljs-type">float</span> c = <span class="hljs-built_in">dot</span>(oc, oc) - (sphere_radius * sphere_radius);<br>    <span class="hljs-type">float</span> d = (b*b) - <span class="hljs-number">4.0</span>*a*c;<br><br>    <span class="hljs-comment">// 返回击中结果，y小于x代表无结果</span><br>    <span class="hljs-keyword">if</span> (d &lt; <span class="hljs-number">0.0</span>) <span class="hljs-keyword">return</span> <span class="hljs-type">vec2</span>(<span class="hljs-number">1e10</span>,<span class="hljs-number">-1e10</span>);<br>    <span class="hljs-comment">// 击中的话有两个相同或者不同的结果</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-type">vec2</span>(<br>        (-b - <span class="hljs-built_in">sqrt</span>(d))/(<span class="hljs-number">2.0</span>*a),<br>        (-b + <span class="hljs-built_in">sqrt</span>(d))/(<span class="hljs-number">2.0</span>*a)<br>    );<br>&#125;<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>好了，那有了这个辅助公式，我们正式开始计算大气的颜色。首先，按照之前的理论，我们要计算视线向量在大气层内的长度，所以我们对射线方向和大气层，以及射线方向和星球表面做射线检测。得到视线在大气层内的长度后，根据我们预设的想要采样的步数（iSteps），计算出每次采样的长度ds。</p><!-- /wp:paragraph --><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs glsl">ray_dir = <span class="hljs-built_in">normalize</span>(ray_dir);<br><br><span class="hljs-comment">// 视线和大气层大小的尺寸的射线检测</span><br><span class="hljs-comment">// x为大气入射点的距离、y为大气出射点的距离（x==y代表光线和大气球体相切，x&gt;y代表光线不经过大气）</span><br><span class="hljs-type">vec2</span> atmos_hit = ray_sphere_intersection(ray_origin, ray_dir, rAtmos);<br><span class="hljs-comment">// 未击中，返回0</span><br><span class="hljs-keyword">if</span> (atmos_hit.x &gt; atmos_hit.y) <span class="hljs-keyword">return</span> <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br><br>    <span class="hljs-comment">// 视线和星球做射线检测，取得近处的检测结果（远处的那个光被星球本体遮挡）</span><br><span class="hljs-type">vec2</span> planet_hit = ray_sphere_intersection(ray_origin, ray_dir, planet_radius);<br><span class="hljs-type">float</span> light_distance = atmos_hit.y;<br><br><span class="hljs-comment">// hit the planet</span><br><span class="hljs-keyword">if</span>(planet_hit.x &lt; planet_hit.y &amp;&amp; planet_hit.x &gt; <span class="hljs-number">0.1</span>)<br>&#123;<br>    light_distance = planet_hit.x;<br>&#125;<br><br><span class="hljs-comment">// light sample length</span><br><span class="hljs-type">float</span> ds = light_distance / <span class="hljs-type">float</span>(iSteps);<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>那么接下来，便是进入采样的循环。循环有两层，外面的循环是计算<strong>视线方向上的每个采样点的光能量</strong>，而计算这个点的光能量也需要一个循环，这个循环是用于采样该点和光源之间的连线在大气层内的线段（也就是之前图片的PC段）的光学距离。根据前面提到的公式，光学距离乘以海平面的散射系数便可以得到光的衰减系数，因此jSteps循环可以得到光线在进入大气层后，传播到达视线上的采样点（P0、P1...Pn点）的衰减所剩下的能量。</p><!-- /wp:paragraph --><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// Initialize the primary ray time.</span><br><span class="hljs-type">float</span> iTime = <span class="hljs-number">0.0</span>;<br><br><span class="hljs-comment">// Initialize accumulators for Rayleigh and Mie scattering.</span><br><span class="hljs-type">vec3</span> total_scatter_rlh = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br><span class="hljs-type">vec3</span> total_scatter_mie = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// Initialize optical depth accumulators for the primary ray.</span><br><span class="hljs-type">float</span> total_od_rlh = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">float</span> total_od_mie = <span class="hljs-number">0.0</span>;<br><br><span class="hljs-comment">// 对每个视线上的采样点循环</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; iSteps; i++) &#123;<br>    <span class="hljs-comment">// 获取到采样点的位置</span><br>    <span class="hljs-type">vec3</span> iPos = ray_origin + ray_dir * (iTime + ds * <span class="hljs-number">0.5</span>);<br><br>    <span class="hljs-comment">// 在当前点向太阳的位置做射线检测，以大气的半径为球体。.y是代表大气的出射点，j_steps代表采样数</span><br>    <span class="hljs-type">float</span> jStepSize = ray_sphere_intersection(iPos, pSun, rAtmos).y / <span class="hljs-type">float</span>(jSteps);<br><br>    <span class="hljs-type">float</span> jTime = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> jOdRlh = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> jOdMie = <span class="hljs-number">0.0</span>;<br><br>    <span class="hljs-comment">// 在当前采样到大气入射点的距离上，采样计算</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; jSteps; j++) &#123;<br>        <span class="hljs-comment">// 计算采样点到光源的衰减</span><br>        <span class="hljs-type">vec3</span> jPos = iPos + pSun * (jTime + jStepSize * <span class="hljs-number">0.5</span>);<br><br>        <span class="hljs-type">float</span> jHeight = <span class="hljs-built_in">length</span>(jPos-planet_center) - planet_radius;<br><br>        <span class="hljs-comment">// Accumulate the optical depth.</span><br>        jOdRlh += get_atmos_density(jHeight, scale_height_rlh) * jStepSize;<br>        jOdMie += get_atmos_density(jHeight, scale_height_mie) * jStepSize;<br><br>        <span class="hljs-comment">// Increment the secondary ray time.</span><br>        jTime += jStepSize;<br>    &#125;<br><br>    <span class="hljs-comment">// 观察点和星球表面距离</span><br>    <span class="hljs-type">float</span> surface_height = <span class="hljs-built_in">length</span>(iPos-planet_center) - planet_radius;<br><br>    <span class="hljs-comment">// 计算这一步的散射的光学深度结果</span><br>    <span class="hljs-type">float</span> od_step_rlh = get_atmos_density(surface_height, scale_height_rlh) * ds;<br>    <span class="hljs-type">float</span> od_step_mie = get_atmos_density(surface_height, scale_height_mie) * ds;<br>    <br>    total_od_rlh += od_step_rlh;<br>    total_od_mie += od_step_mie;<br><br>    <span class="hljs-comment">// 计算衰减系数，光在经过一定距离后衰减剩下来的比例。</span><br>    <span class="hljs-type">vec3</span> attn = <span class="hljs-built_in">exp</span>(-(kMie * (total_od_mie + jOdMie) + kRlh * (total_od_rlh + jOdRlh)));<br><br>    <span class="hljs-comment">// Accumulate scattering.</span><br>    total_scatter_rlh += od_step_rlh * attn;<br>    total_scatter_mie += od_step_mie * attn;<br><br>    <span class="hljs-comment">// Increment the primary ray time.</span><br>    iTime += ds;<br>&#125;<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>计算瑞利散射和米氏散射的大气密度的代码如下所示，其中scale_height在计算瑞利散射的时候带入的是8500，米氏散射则带入1200。</p><!-- /wp:paragraph --><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 获取大气密度</span><br><span class="hljs-comment">// 传入位置离海平面的高度，以及散射的相关基准高度</span><br><span class="hljs-comment">// 大气中任意一点的散射系数的计算，简化拆解为散射在海平面的散射系数，乘以基于海平面高度的该散射的大气密度计算公式</span><br><span class="hljs-type">float</span> get_atmos_density(<span class="hljs-type">float</span> height_to_sea_level, <span class="hljs-type">float</span> scale_height)<br>&#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">exp</span>(-height_to_sea_level / scale_height);<br>&#125;<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>将iSteps循环的结果累加起来，我们便得到了视线上（AB）的每个采样点的光能量传播到达相机（A点）经过衰减的能量的和。那么还剩一个部分，就是光在P点进行散射的时候，光也损失掉了一部分能量，这个过程可以通过乘以米氏散射和瑞利散射的相位函数来计算。因为每个采样点P的结果都需要乘以相位函数，所以我们可以将它提取到最外面，乘以光的能量的总和即可。</p><!-- /wp:paragraph --><!-- wp:paragraph --><p>不过需要注意的是，前面的公式提到了，相位函数是和光线入射方向和目标方向的夹角相关的，所以如果我们<strong>默认太阳光源是平行光</strong>的话，这个夹角对每个采样点来说是一样的，所以可以将相位函数提取到最外层。如果认为这个夹角对每个采样点不一样的话，那也许还是应该老老实实在计算每个采样点的光的时候单独去处理。</p><!-- /wp:paragraph --><p>最终的结果除了乘以相位函数，还需要乘以海平面的散射系数，结果如下。</p></p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 计算并返回最终颜色</span><br><span class="hljs-comment">// iSun是光源（太阳）的颜色</span><br><span class="hljs-keyword">return</span> iSun * (pRlh * kRlh * total_scatter_rlh + pMie * kMie * total_scatter_mie);<br></code></pre></td></tr></table></figure><p>下面是得到的结果：</p><iframe src="single-scatter-atmosphere.mp4" scrolling="no" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/">https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/</a></li><li><a href="https://www.xianlongok.site/post/8e5d3b12/">https://www.xianlongok.site/post/8e5d3b12/</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>级联阴影贴图实现</title>
    <link href="/2024/10/13/cascade-shadow-map/"/>
    <url>/2024/10/13/cascade-shadow-map/</url>
    
    <content type="html"><![CDATA[<h1 id="阴影贴图的局限"><a href="#阴影贴图的局限" class="headerlink" title="阴影贴图的局限"></a>阴影贴图的局限</h1><p>阴影贴图（shadow map）是3D场景中实现阴影效果的基础手段，它通过预先将光线方向的场景深度存储到贴图中，在渲染的时候取每个场景中的点到光源的距离和深度贴图作比较，来判定该点是否在阴影当中。</p><p>但是在较大的场景中，使用阴影贴图会有几个明显的不足：</p><ol><li>阴影贴图只能覆盖部分场景，在渲染较大的场景的时候（如大世界），远处的场景基本上无法被阴影贴图所覆盖。</li><li>贴图的分辨率是有限的，太大的分辨率会对性能造成非常大的影响。但是在覆盖较大场景的时候，贴图分辨率不足会导致阴影模糊，效果不佳。</li><li>阴影贴图的实现一开始其实并没有考虑玩家相机的视椎体，也就是说在玩家没有看的地方也会渲染阴影贴图，这对渲染资源来说显然是个浪费。</li></ol><p>KongEngine计划在后面接入大地形的渲染，借此机会接入了级联阴影贴图的能力。<br>实现方法参考了<a href="https://learnopengl.com/Guest-Articles/2021/CSM">LearnOpenGL的教程</a>。</p><h1 id="级联阴影贴图的实现"><a href="#级联阴影贴图的实现" class="headerlink" title="级联阴影贴图的实现"></a>级联阴影贴图的实现</h1><p>级联阴影贴图的基本概念包括如下几点：</p><ol><li>将玩家的视椎体划分为几段，每一段视椎体构建一张阴影贴图覆盖，这个阴影贴图完美贴合从光源方向投射到这段视椎体中心点的正交投影。</li><li>和模型LOD的理念类似，离相机近的阴影贴图需要采用较高精度，而离相机远的阴影贴图可以使用低精度。</li><li>将多级阴影贴图传入最后的光照计算着色器，根据每个点所处视椎体的分段不同采用对应不同的阴影贴图计算光照。</li></ol><p>听起来挺简单的对吧，那我们一步一步来。</p><h2 id="视椎体分段"><a href="#视椎体分段" class="headerlink" title="视椎体分段"></a>视椎体分段</h2><p>上面说到我们需要将视椎体分为几段，在每一段视椎体覆盖一张阴影贴图，并计算出这张贴图的从光源方向看向视椎体中心点的正交投影的矩阵，也就是Light projection matrix和Light view matrix。这个矩阵需要紧密贴合这段视椎体，为此我们需要得到视椎体的顶点的世界坐标，得到顶点的min、max和视椎体的中心点。</p><p>我们从相机的视椎体出发，当处于视椎体范围上的顶点的世界坐标经过projection矩阵和view矩阵转换后，xyz都会被映射到[-1,1]范围的屏幕空间坐标。矩阵转换是可逆的，也就是说取屏幕空间坐标为[-1, 1]边界的八个顶点，经过视椎体的projection矩阵和view矩阵的逆矩阵转换后，就能得到边界顶点的世界空间坐标。在代码里面的实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">std::vector&lt;glm::vec4&gt; <span class="hljs-title">CDirectionalLightComponent::GetFrustumCornersWorldSpace</span><span class="hljs-params">(<span class="hljs-type">const</span> glm::mat4&amp; proj_view)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> inv = glm::<span class="hljs-built_in">inverse</span>(proj_view);<br><br>    <span class="hljs-comment">// 顶点的世界坐标在projection和view matrix的转换下的坐标范围是[-1,1]</span><br>    <span class="hljs-comment">// 那么将在[-1,1]这个边界的八个顶点坐标乘以projection和view matrix的逆矩阵则可以得到视锥体边界的顶点的世界坐标</span><br>    vector&lt;vec4&gt; frustum_corners;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; i++)<br>    &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">2</span>; j++)<br>        &#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; <span class="hljs-number">2</span>; k++)<br>            &#123;<br>                <span class="hljs-type">const</span> vec4 pt = inv * <span class="hljs-built_in">vec4</span>(<span class="hljs-number">2.0f</span>*i<span class="hljs-number">-1.0f</span>,<span class="hljs-number">2.0f</span>*j<span class="hljs-number">-1.0f</span>,<span class="hljs-number">2.0f</span>*k<span class="hljs-number">-1.0f</span>, <span class="hljs-number">1.0f</span>);<br>                frustum_corners.<span class="hljs-built_in">push_back</span>(pt / pt.w);<br>            &#125;<br>        &#125;   <br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> frustum_corners;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们得到了视椎体角落的顶点世界坐标，我们希望阴影贴图能够如下图一般贴合每一段视椎体。那么我们需要计算视椎体的中心顶点坐标，中心顶点在计算view矩阵的时候需要用到；我们需要计算在xyz轴上顶点坐标的最大和最小值，这些数值在计算projection矩阵的时候会被用到。</p><p><img src="https://learnopengl.com/img/guest/2021/CSM/frustum_fitting.png" alt="级联阴影贴图由远及近"></p><p>计算中心点的代码十分简单，将视椎体角落的坐标相加后再除以数量即可，代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++">vec3 center = <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0.0f</span>);<br><span class="hljs-keyword">for</span>(<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; v : corners)<br>&#123;<br>    center += <span class="hljs-built_in">vec3</span>(v);<br>&#125;<br>center /= corners.<span class="hljs-built_in">size</span>();   <span class="hljs-comment">// 获取视锥体的中心点</span><br><br><span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> light_view = <span class="hljs-built_in">lookAt</span>(center-light_dir, center, <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0.0f</span>, <span class="hljs-number">1.0f</span>, <span class="hljs-number">0.0f</span>));<br></code></pre></td></tr></table></figure><p>计算贴合视椎体的范围则是比较并记录各个顶点在xyz轴的最大值和最小值，方法如下。这里提一下在z轴方向和一个参数z_mult进行了处理，其意义是阴影的投射源是有可能在视椎体范围之外的，如果不考虑这一部分的影响的话可能在阴影过度的时候会非常生硬，并且丢掉一些本来该显示的阴影导致渲染错误。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span> min_x = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">max</span>();<br><span class="hljs-type">float</span> min_y = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">max</span>();<br><span class="hljs-type">float</span> min_z = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">max</span>();<br><span class="hljs-type">float</span> max_x = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">lowest</span>();<br><span class="hljs-type">float</span> max_y = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">lowest</span>();<br><span class="hljs-type">float</span> max_z = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">lowest</span>();<br><span class="hljs-keyword">for</span> (<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; v : corners)<br>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> trf = light_view * v;<br>    min_x = std::<span class="hljs-built_in">min</span>(min_x, trf.x);<br>    max_x = std::<span class="hljs-built_in">max</span>(max_x, trf.x);<br>    min_y = std::<span class="hljs-built_in">min</span>(min_y, trf.y);<br>    max_y = std::<span class="hljs-built_in">max</span>(max_y, trf.y);<br>    min_z = std::<span class="hljs-built_in">min</span>(min_z, trf.z);<br>    max_z = std::<span class="hljs-built_in">max</span>(max_z, trf.z);<br>&#125;<br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">float</span> z_mult = <span class="hljs-number">10.0f</span>;<br><span class="hljs-keyword">if</span> (min_z &lt; <span class="hljs-number">0</span>)<br>&#123;<br>    min_z *= z_mult;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br>    min_z /= z_mult;<br>&#125;<br><span class="hljs-keyword">if</span> (max_z &lt; <span class="hljs-number">0</span>)<br>&#123;<br>    max_z /= z_mult;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br>    max_z *= z_mult;<br>&#125;<br><br><span class="hljs-type">const</span> mat4 light_projection = <span class="hljs-built_in">ortho</span>(min_x, max_x, min_y, max_y, min_z, max_z);<br></code></pre></td></tr></table></figure><h2 id="计算级联阴影贴图"><a href="#计算级联阴影贴图" class="headerlink" title="计算级联阴影贴图"></a>计算级联阴影贴图</h2><p>一般的阴影贴图我们采用的是GL_TEXTURE_2D，而级联阴影贴图我们需要传入多张贴图，因此对应的贴图类型会变为GL_TEXTURE_2D_ARRAY。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;csm_texture);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D_ARRAY, csm_texture);<br><span class="hljs-built_in">glTexImage3D</span>(GL_TEXTURE_2D_ARRAY, <span class="hljs-number">0</span>, GL_DEPTH_COMPONENT32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, (<span class="hljs-type">int</span>)csm_distances.<span class="hljs-built_in">size</span>()<span class="hljs-number">+1</span>, <span class="hljs-number">0</span>, GL_DEPTH_COMPONENT, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER);<br><span class="hljs-built_in">glTexParameterfv</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_BORDER_COLOR, border_color);<br><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, shadowmap_fbo);<br><span class="hljs-built_in">glFramebufferTexture</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, csm_texture, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">glDrawBuffer</span>(GL_NONE);<br><span class="hljs-built_in">glReadBuffer</span>(GL_NONE);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>除此之外，我们需要一次性渲染多张贴图，我们参考点光源阴影贴图使用geometry shader的做法，将顶点映射到不同的视椎体分段的光源的投影。代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">triangles</span>, <span class="hljs-keyword">invocations</span> = <span class="hljs-number">6</span>) <span class="hljs-keyword">in</span>;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">triangle_strip</span>, <span class="hljs-keyword">max_vertices</span> = <span class="hljs-number">3</span>) <span class="hljs-keyword">out</span>;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> light_space_matrix[<span class="hljs-number">16</span>];<br><br><br><span class="hljs-type">void</span> main()<br>&#123;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">3</span>; ++i)<br>&#123;<br><span class="hljs-built_in">gl_Position</span> = light_space_matrix[<span class="hljs-built_in">gl_InvocationID</span>] * <span class="hljs-built_in">gl_in</span>[i].<span class="hljs-built_in">gl_Position</span>;<br><span class="hljs-built_in">gl_Layer</span> = <span class="hljs-built_in">gl_InvocationID</span>;<br><span class="hljs-built_in">EmitVertex</span>();<br>&#125;<br><span class="hljs-built_in">EndPrimitive</span>();<br>&#125; <br></code></pre></td></tr></table></figure><p>这里新增的<strong>invocations &#x3D; 6</strong>代表了这个Shader可以被实例化，每个实例同时平行进行运算，实例的个数为6。内置的<strong>gl_InvocationID</strong>代表了当前处理的是哪一个实例，我们将其赋值到<strong>gl_Layer</strong>。其余的阴影贴图渲染步骤和普通的阴影贴图类似。</p><p>下面几张图所示展示的，就是从近到远的几个级联阴影贴图的表现：<br><img src="/2024/10/13/cascade-shadow-map/csm_near.png"><br><img src="/2024/10/13/cascade-shadow-map/csm_mid.png"><br><img src="/2024/10/13/cascade-shadow-map/csm_far.png"></p><h2 id="使用级联阴影贴图"><a href="#使用级联阴影贴图" class="headerlink" title="使用级联阴影贴图"></a>使用级联阴影贴图</h2><p>级联阴影贴图的使用和阴影贴图是类似的，由于传入给光照Shader的是GL_TEXTURE_2D_ARRAY，需要使用vec3来索引贴图数据的，vec3的z值代表的是Layer索引。</p><p>Layer代表的是使用哪一个视椎体分段的阴影贴图，取决于当前像素和相机的距离。取得对应的Layer参数后带入texcoord的z值读取对应的阴影贴图的值。示例代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 计算阴影</span><br><span class="hljs-type">float</span> ShadowCalculation_DirLight(<span class="hljs-type">vec4</span> frag_world_pos, <span class="hljs-type">vec3</span> to_light_dir, <span class="hljs-type">vec3</span> in_normal)<br>&#123;<br>    <span class="hljs-comment">// 获取像素和相机的距离，也就是view转换后的z值</span><br>    <span class="hljs-type">vec4</span> frag_pos_view_space = matrix_ubo.view * frag_world_pos;<br>    <span class="hljs-type">float</span> depthValue = <span class="hljs-built_in">abs</span>(frag_pos_view_space.z);<br><br>    <span class="hljs-comment">// 根据距离和每段视椎体分段的距离区间，获取Layer值</span><br>    <span class="hljs-type">int</span> layer = <span class="hljs-number">-1</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; csm_level_count; ++i)<br>    &#123;<br>        <span class="hljs-keyword">if</span> (depthValue &lt; csm_distances[i])<br>        &#123;<br>            layer = i;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (layer == <span class="hljs-number">-1</span>)<br>    &#123;<br>        layer = csm_level_count;<br>    &#125;<br>    <span class="hljs-comment">// 下面的和应用普通阴影贴图的一致</span><br>    <span class="hljs-comment">// 转换到-1,1的范围，再转到0,1的范围</span><br>    <span class="hljs-type">vec4</span> frag_pos_light_space = light_space_matrices[layer] * frag_world_pos;<br>    <span class="hljs-comment">// perform perspective divide</span><br>    <span class="hljs-type">vec3</span> proj_coord = frag_pos_light_space.xyz / frag_pos_light_space.w;<br>    <span class="hljs-comment">// transform to [0,1] range</span><br>    proj_coord = proj_coord * <span class="hljs-number">0.5</span> + <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-comment">// get depth of current fragment from light&#x27;s perspective</span><br>    <span class="hljs-type">float</span> current_depth = proj_coord.z;<br><br>    <span class="hljs-comment">// keep the shadow at 0.0 when outside the far_plane region of the light&#x27;s frustum.</span><br>    <span class="hljs-keyword">if</span> (current_depth &gt; <span class="hljs-number">1.0</span>)<br>    &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span>;<br>    &#125;<br><br>    <span class="hljs-comment">// PCF</span><br>    <span class="hljs-type">float</span> shadow = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">vec2</span> texel_size = <span class="hljs-number">1.0</span> / <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(shadow_map, <span class="hljs-number">0</span>));<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> x = <span class="hljs-number">-1</span>; x &lt;= <span class="hljs-number">1</span>; ++x)<br>    &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> y = <span class="hljs-number">-1</span>; y &lt;= <span class="hljs-number">1</span>; ++y)<br>        &#123;<br>            <span class="hljs-type">float</span> pcf_depth = <span class="hljs-built_in">texture</span>(shadow_map, <span class="hljs-type">vec3</span>(proj_coord.xy + <span class="hljs-type">vec2</span>(x, y) * texel_size, layer)).r;<br>            shadow += current_depth &gt; pcf_depth ? <span class="hljs-number">1.0</span> : <span class="hljs-number">0.0</span>;<br>        &#125;<br>    &#125;<br>    shadow /= <span class="hljs-number">9.0</span>;<br>        <br>    <span class="hljs-keyword">return</span> shadow;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="效果对比"><a href="#效果对比" class="headerlink" title="效果对比"></a>效果对比</h1><h2 id="原先的阴影贴图"><a href="#原先的阴影贴图" class="headerlink" title="原先的阴影贴图"></a>原先的阴影贴图</h2><p>原先的阴影贴图只能覆盖有限的场景：<br><img src="/2024/10/13/cascade-shadow-map/sm_near.png"></p><p>提升覆盖范围后，阴影的质量则会出现下降：<br><img src="/2024/10/13/cascade-shadow-map/sm_far.png"></p><h2 id="级联阴影贴图"><a href="#级联阴影贴图" class="headerlink" title="级联阴影贴图"></a>级联阴影贴图</h2><p>采用级联阴影贴图可以覆盖很大的场景，并且在可控的性能消耗下仍然有不错的显示智联。<br><img src="/2024/10/13/cascade-shadow-map/csm_result.png"></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>程序化地形生成-1</title>
    <link href="/2024/10/11/ProceduralTerrainGeneration/"/>
    <url>/2024/10/11/ProceduralTerrainGeneration/</url>
    
    <content type="html"><![CDATA[<p><a href="https://www.shadertoy.com/">ShaderToy</a>是一个很有趣的网站，它上面有着非常多的渲染案例分享，最近一段时间我也是沉迷了。在看了不少大佬的作品之后，不禁手痒。前一段时间看了Inigo大佬的一个<a href="https://www.shadertoy.com/view/4ttSWf">教程案例</a>，想着把这个效果自己来实现一次，因此就有了今天的这篇文章。</p><p>我最终的成品也放到了shadertoy上面，有兴趣的同学可以一起讨论参考一下。看起来还不错对吧，虽然还有不少地方需要完善，但这个demo已经实现了我心中的大部分效果，包括无限的基于噪音的地形生成、地形阴影、雾气、云等等。</p><iframe width="640" height="360" frameborder="0" src="https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false" allowfullscreen></iframe><p>那么下面，就让我来一步步说明这个demo的实现过程吧。</p><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="在ST上渲染地形"><a href="#在ST上渲染地形" class="headerlink" title="在ST上渲染地形"></a>在ST上渲染地形</h2><p>对ShaderToy上运行的Shader代码，对应着可编程渲染管线的片段着色器(或者叫像素着色器)。片段着色器主要是是图形光栅化后的像素信息，所以渲染3D场景需要进行一些额外的步骤。</p><p>ShaderToy的程序一般是这样的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">mainImage</span><span class="hljs-params">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>...<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>fragColor</strong>是输出，代表这这个像素的最终颜色；<strong>fragCoord</strong>是输入，代表这个像素点的xy坐标。ShaderToy提供了固定变量<strong>iResolution</strong>用来表示整个屏幕的xy的分辨率。</p><p>为了渲染3D物体，我们需要采用ray cast&#x2F;marching的方法，构建一个相机的位置作为光线射出的起点<strong>ro</strong>，再根据当前像素点的坐标和ro的差获得光线射出的方向<strong>rd</strong>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">mainImage</span><span class="hljs-params">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>    vec2 uv = fragCoord / iResolution.xy;<br><span class="hljs-comment">// 以屏幕中心为（0,0）</span><br>    uv = uv * <span class="hljs-number">2.0</span> - <span class="hljs-number">1.0</span>;<br><span class="hljs-comment">// 缩放x，在画面拉伸的时候保证比例正确</span><br>    uv.x *= iResolution.x/iResolution.y;<br><span class="hljs-comment">// 原点位置</span><br>    vec3 ro = vec3(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-1</span>);<br>    <span class="hljs-comment">// 射线方向</span><br>    vec3 rd = normalize(vec3(uv, <span class="hljs-number">2</span>));<br><br>fragColor = rayMarching(ro, rd);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="和地形相交"><a href="#和地形相交" class="headerlink" title="和地形相交"></a>和地形相交</h2><p>在shadertoy中渲染3D物体，一般是使用raymarching方法配合SDFs来渲染3D的物体。SDF（Signed Distance Field）是一种物体的隐式表达，用于存储和计算点到图形表面的最近距离。经由一个起点和一个方向，可以用SDF来达到低消耗的射线检测效果。</p><p>这里可以参考Inigo对SDF的介绍的介绍：<a href="https://iquilezles.org/articles/distfunctions/">https://iquilezles.org/articles/distfunctions/</a></p><p>地形的渲染也是类似的，我们通过ray marching方法来找到距离地形最近的点，以此来获取地形的形状。但是和SDF不同的是，我们无法很轻易的判断射线当前距离地形的最近距离，尤其是当我们的地形完全是通过噪音来随机生成的时候，这变成了一个不可能完成的任务。所以在判断地形相交的时候，只能回归到笨办法，一步一步慢慢的往前“挪”，<em>若当前的顶点在地形之下，而之前的一个迭代在地形之上的话</em>，那我们就找到了击中地表的区间段。<br><img src="https://iquilezles.org/articles/terrainmarching/gfx02.png" alt="射线和地表相交"></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">bool</span> <span class="hljs-title function_">rayMarch</span><span class="hljs-params">(vec3 ro, vec3 rd, out <span class="hljs-type">float</span> <span class="hljs-type">hit_t</span>)</span><br>&#123;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> dt = <span class="hljs-number">0.01f</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> <span class="hljs-type">min_t</span> = <span class="hljs-number">1e-3</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> <span class="hljs-type">max_t</span> = <span class="hljs-number">1e3</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = <span class="hljs-type">min_t</span>; t &lt; <span class="hljs-type">max_t</span>; t+=dt)<br>&#123;<br><span class="hljs-type">const</span> vec3 p = ro+rd*t;<br><span class="hljs-keyword">if</span>(p.y &lt; f(p.x, p.z));<br>&#123;<br><span class="hljs-comment">// 取中间点减小误差</span><br><span class="hljs-type">hit_t</span> = t - <span class="hljs-number">0.5f</span>*dt;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>这个方法简单易懂，但显而易见在性能上并不是最优的，尤其是涉及到范围很大的地形的时候，dt的值如果取得太小，那么渲染完成一个场景的时间将会非常的长，消耗巨大；而若是dt的值取得太大，则很有可能会出现取值错误的情况。</p><p>当场景距离我们足够远的时候，由于透视的原因，近大远小，远处的场景精度对于观察者来说是越来越不重要了，因此dt的值可以随着光线步近而逐渐组建增大，动态变化。在合适的dt取值和变化曲线下，能够满足精度和性能的要求。Inigo给出的方法是类似这样的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//其他和上方代码一致</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = <span class="hljs-type">min_t</span>; t&lt;<span class="hljs-type">max_t</span>; t+=dt)<br>&#123;<br>    <span class="hljs-type">const</span> vec3 p = ro+rd*t;<br>    <span class="hljs-type">const</span> <span class="hljs-type">float</span> h = f(p.xz);<br>    <span class="hljs-keyword">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class="hljs-type">hit_t</span> = t - <span class="hljs-number">0.5f</span>*dt;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>    dt=<span class="hljs-number">0.01f</span>*t;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br></code></pre></td></tr></table></figure><p>t的起始值和dt的增长倍数可以自己尝试选择一个合适的值。</p><p>另外，如果我们能对最终渲染的效果有所了解的话，可以通过过滤掉很多不需要做射线检测的情况来极大的提升性能。如果我们最终的效果是一个在空中的相机，天空和地面占据画面各一半的话，那么上半部分的画面（通过rd.y&gt;0判断）是可以完全跳过射线检测的。或者通过增加min_t的值来减少前期昂贵且不必要的性能消耗。</p><p>在相交点的取值上，也可以进一步优化。原来仅仅是取两次光线步近的平均值，我们可以额外获取两次步近时位置的地形高度，用高度变化的连线和光线步近的线段做相交的判定取交点。这样得到的值将会更加精确。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//其他和上方代码一致</span><br><span class="hljs-type">float</span> lh = <span class="hljs-number">0.0f</span>;<br><span class="hljs-type">float</span> ly = <span class="hljs-number">0.0f</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = <span class="hljs-type">min_t</span>; t&lt;<span class="hljs-type">max_t</span>; t+=dt)<br>&#123;<br>    <span class="hljs-type">const</span> vec3 p = ro+rd*t;<br>    <span class="hljs-type">const</span> <span class="hljs-type">float</span> h = f(p.xz);<br>    <span class="hljs-keyword">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class="hljs-comment">// 计算两个线段的相交点</span><br>        <span class="hljs-type">hit_t</span> = t - dt + dt*(lh-ly)/(p.y-ly-h+lh);<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>    dt=<span class="hljs-number">0.01f</span>*t;<br>    lh = h;<br>    ly = p.y;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br></code></pre></td></tr></table></figure><p>至此，我们就可以在ShaderToy渲染出地形了。</p><h1 id="地形生成"><a href="#地形生成" class="headerlink" title="地形生成"></a>地形生成</h1><h2 id="生成的基础：噪音"><a href="#生成的基础：噪音" class="headerlink" title="生成的基础：噪音"></a>生成的基础：噪音</h2><p>当我们提到噪音，往往会很生活化的把噪音和声音连接起来，从声学的角度来说是正确的。噪音其实可以用来表示所有通过振幅（amplitude）和频率（frequency）描述的波动，它可以是声音，它可以是辐射，也可以是其他的任意一种波动。</p><p>在数学课上，我们学过正弦、余弦等三角函数，sin和cos其实就是一种噪音的表现方式。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> amplitude = <span class="hljs-number">1.0</span>;<br><span class="hljs-type">float</span> frequencey = <span class="hljs-number">1.0</span>;<br><span class="hljs-type">float</span> y = amplitude * <span class="hljs-built_in">sin</span>(frequency * x);<br></code></pre></td></tr></table></figure><p>就像上面的代码所示，通过改变amplitude和frequency，我们可以改变sin波形的状态。</p><p>噪音在很多程序化生成算法中都有着举足轻重的地位。</p><h2 id="分形布朗运动"><a href="#分形布朗运动" class="headerlink" title="分形布朗运动"></a>分形布朗运动</h2><p>噪音是一种波，它是可以相互叠加的。两个相同的sin波形叠加会形成振幅更加强大的sin波形，而频率相差π&#x2F;2的两个sin波形叠加后会相互抵消。</p><p>在地形随机生成中，为了最终的结果噪音有着更好的随机性和更好的细节，将会循环多次计算噪音，循环的次数为我们称之为octave。每次循环的同一个噪音以一定倍数（lacunarity）升高频率，同时以一定比例（gain）降低振幅，最终将每个噪音计算的结果叠加得到一个最终的噪音，这个噪音的生成技术叫做“分形布朗运动”（fractal brownian motion，fbm）。</p><p>下面是分形布朗运动的一个简单的代码演示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> <span class="hljs-title function_">fbm</span><span class="hljs-params">(vec2 uv, <span class="hljs-type">float</span> frequency, <span class="hljs-type">float</span> amplitude, <span class="hljs-type">int</span> octave)</span><br>&#123;<br><span class="hljs-type">float</span> lacunarity = <span class="hljs-number">2.0</span>;<br><span class="hljs-type">float</span> gain = <span class="hljs-number">0.5</span>;<br><span class="hljs-type">float</span> noise_val = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">float</span> amp = amplitude;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> index = <span class="hljs-number">0</span>; index &lt; octave; ++index)<br>&#123;<br>nose_val += noiseInterpolate(uv * frequency) * amp;<br>amp *= gain;<br>frequency *= lacunarity;<br>&#125;<br><br><span class="hljs-keyword">return</span> noise_val;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中noiseInterpolate可以是perlin noise或者是simplex noise等任意一种噪音算法。<br>demo中的地形生成和云层的生成，也使用了该技术。关于FBM除了上面简单的使用还有很多其他的变种，这里我们就不扩展了，后面有机会的话可以专门介绍一下。</p><h2 id="地形的基础表现"><a href="#地形的基础表现" class="headerlink" title="地形的基础表现"></a>地形的基础表现</h2><p>这里我将地形部分拆解出来。demo的地形计算使用了perlin noise，octave数量达到了11。更多的octave数量会给地形带来更多的细节，但是一般来说后面的效果收益会越来越少。下方是octave数量分布为5和11下的地形的形状对比。<br><img src="/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc5_noshadow.png"><br><img src="/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_noshadow.png"></p><p>除了每次叠加噪音会进行频率和振幅的变化，为了获得更好的随机性，以及进一步减少噪音可能出现的重复pattern，可以将噪音进行旋转（也就是将传入的uv或者是坐标乘以一个默认的旋转矩阵）后再叠加到原来的噪音上。</p><p>我们也需要地形的法线来和光源结合，渲染出地形的明暗部分。获得法线的方法有很多种，可以采样当前计算的地形上点的x轴和z轴（这里假定y轴为up）方向不远的一两个点，和目标点相减得到切线和副切线方向，通过叉乘得到目标点的法线。亦或是采样其他点后通过中心差分法求得目标点的法线。</p><h2 id="阴影"><a href="#阴影" class="headerlink" title="阴影"></a>阴影</h2><p>仅仅通过法线来渲染地形的明部和暗部是不够的，我们还需要计算地形投射在地表上的阴影。地形的阴影计算原理非常简单，就是将地形上渲染的目标点，沿着光源方向进行射线检测，如果和地形相交的话，那该点就是处于阴影之下。理想情况下，射线检测的距离当然是实际上光源和地形上的点的距离，但是往往由于性能的原因，我们需要缩短这个距离。<em>实际的检测距离可以结合当前点的高度以及地形可能的最高位置进行计算</em>。</p><p>在判断当前点处于阴影的时候，计算最终颜色的时候需要再乘以一个阴影的系数。<br><img src="/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_hardshadow.png" alt="硬阴影"></p><p>为了提升效果，我们通常不希望阴影的边缘非常生硬，而是希望有一种柔软的过度，这种更加符合现实的表现。实现这种软阴影的方法可能有很多种，这里采用的是Inigo教程的一种方法。</p><p>上面提到判定阴影是通过从地形上面的点向光源方向做射线检测得到的，如果和地形相交则该点处于阴影当中，若不相交，则需要再取一个值，这值是地形向着光源方向移动距离t长度的位置，它和地形高度的差值d和距离t的比值的最小值，乘以某个常数X（10~32等等，可以自己尝试合适的范围）后经过smoothstep限制在（0,1）范围内。这个值作为阴影系数放入光照计算后就可以得到不错的软阴影效果。<br><img src="/2024/10/11/ProceduralTerrainGeneration/calc_soft_shadow.png" alt="软阴影"></p><p>通过下面的对比图我们可以看到，在加入了软阴影计算后，地形阴影的边缘有了一种较为平滑的过度，显得没那么生硬了。想要更改软阴影的表现的话可以通过修改常数X。<br><img src="/2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain.png"></p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>好了，我们已经得到了一个基础的程序化生成地形的效果了，但是它看起来还是有些单调。地形的深度表现、天空、云彩等等应该如何表现呢？</p><p>无需着急，我们将会在后面的文章中对它进行进一步的优化。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://thebookofshaders.com/13/?lan=ch">https://thebookofshaders.com/13/?lan=ch</a><br><a href="https://iquilezles.org/articles/morenoise">https://iquilezles.org/articles/morenoise</a><br><a href="https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g">https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>程序化生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>个人博客启动</title>
    <link href="/2024/10/09/StartMyBlog/"/>
    <url>/2024/10/09/StartMyBlog/</url>
    
    <content type="html"><![CDATA[<p>晚上好。</p><p>还是打算在个人的github.io继续更新自己的技术博客了。<a href="qrc-eye.com">原网站</a>本来是打算用于和朋友一起写点东西上去的，结果现在倒是变成了只有我自己的碎碎念，着实不太好。</p><p>最近一段时间会尽快的将我的部分文章搬运过来，一些琐碎的文章暂时就不管了。</p>]]></content>
    
    
    <categories>
      
      <category>生活杂谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>生活</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
