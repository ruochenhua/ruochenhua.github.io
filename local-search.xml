<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>虚幻引擎的Shader课堂之Material Expression</title>
    <link href="/2025/05/18/ue-shader-materialexpression/"/>
    <url>/2025/05/18/ue-shader-materialexpression/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在<a href="https://ruochenhua.github.io/2025/05/11/ue-shader-globalshader/">上一章</a>的内容我们大致介绍了一下虚幻引擎Global Shader的相关内容，按照计划来说，接下来就是Material Shader了。不过由于最近工作比较忙，没有时间来好好整理Material Shader的内容，并且Material Shader在本系列也是比较重要的一个知识点，所以为了能把它讲清楚，我决定还是将这篇文章推迟。</p><p>因此今天我会先来介绍一个和Material Shader比较相关的概念，就是<strong>Material Expression</strong>。</p><p>Material Expression是一个非常重要的部分，它可以让我们在材质编辑器中创建一个自定义的材质节点，来实现各种各样的计算，影响最终的渲染效果。Material Shader很多时候也是通过Material Expression来应用在渲染流程中的。所以，理解Material Expression的基本概念和用法，对于掌握Material Shader的实现也非常重要。</p><p><strong>另外这里要提一嘴的就是，本次教程所基于的引擎版本为5.5，若是有些示例代码或者方法不生效可能是版本不一致导致的，但是概念应该基本相通，可以作为参考。</strong></p><h2 id="Material-Expression的基本概念">Material Expression的基本概念</h2><p>Material Expression是一个非常重要的概念，它是构建材质（Material）的核心组件，用于定义材质的外观、行为和交互逻辑。材质通过可视化节点网络（材质图）连接各种表达式，实现对光照、纹理、颜色、物理属性等的复杂控制。</p><p>上面的说起来可能比较抽象，简单的来说，就是在材质蓝图（Material Blueprint）中，除了辅助性的节点（如注释、分组、参数节点等等），绝大部分的功能性的节点都是Material Expression。例如：</p><ul><li>数据采样：UMaterialExpressionMaterialSample、UMaterialExpressionVertexColor、UMaterialExpressionSceneColor等等</li><li>数学计算: UMaterialExpressionAdd、UMaterialExpressionMaterialXMinus等等</li><li>属性控制：UMaterialExpressionScalarParameter、UMaterialExpressionVectorParameter等等</li></ul><p>还有很多其他类型就不一一列举了。</p><p>这些Material expression，在材质蓝图文件中都是以节点的形式存在的，我们可以通过拖拽的方式将它们连接起来，来实现我们想要的效果。</p><p><img src="material_blueprint.png" alt="一个简单的材质蓝图文件示例"></p><p>那么接下来，我们就以一个简单的例子，来介绍一下如何实现自定义的Material Expression。</p><h2 id="实现一个简单的Material-Expression">实现一个简单的Material Expression</h2><p>接下来我们来实现一个很简单的材质节点：将传入的颜色的r和b通道互换，并乘以另外一个传入的参数Intensity，将最后的结果输出。</p><h3 id="创建一个新的Material-Expression类">创建一个新的Material Expression类</h3><p>首先，我们新建一个继承自UMaterialExpression的类，如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> once</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;Materials/MaterialExpression.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;ColorShaderNode.generated.h&quot;</span></span><br><br><span class="hljs-built_in">UCLASS</span>()<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">UColorShaderNode</span> : <span class="hljs-keyword">public</span> UMaterialExpression<br>&#123;<br><span class="hljs-built_in">GENERATED_BODY</span>()<br><br><span class="hljs-keyword">public</span>:<br><span class="hljs-comment">// 输入引脚：基础颜色和强度</span><br><span class="hljs-built_in">UPROPERTY</span>(meta = (RequiredInput = <span class="hljs-string">&quot;false&quot;</span>))<br>FExpressionInput BaseColor;<br><br><span class="hljs-built_in">UPROPERTY</span>(meta = (RequiredInput = <span class="hljs-string">&quot;false&quot;</span>))<br>FExpressionInput Intensity;<br><br><span class="hljs-comment">// 编译函数</span><br><span class="hljs-function"><span class="hljs-keyword">virtual</span> int32 <span class="hljs-title">Compile</span><span class="hljs-params">(<span class="hljs-keyword">class</span> FMaterialCompiler* Compiler, int32 OutputIndex)</span>  <span class="hljs-keyword">override</span></span>;<br><br>    <span class="hljs-comment">// 获取节点的标题</span><br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">GetCaption</span><span class="hljs-params">(TArray&lt;FString&gt;&amp; OutCaptions)</span> <span class="hljs-type">const</span> <span class="hljs-keyword">override</span></span>;<br>&#125;;<br></code></pre></td></tr></table></figure><p>在这个类的内容其实很通俗易懂，由以下三个部分组成：</p><ol><li>输入引脚：顾名思义，用于定义材质节点的输入参数。每个输入引脚都是类型为<strong>FExpressionInput</strong>的UPROPERTY。这个例子我们定义了两个引脚，分别是输入颜色和强度。</li><li><strong>编译函数Compile</strong>：它定义了如何将这个节点编译成Shader代码，以及如何传入对应的参数。这个方法是材质节点至关重要的逻辑部分。</li><li>获取节点的标题：这个函数用于获取节点的标题，在材质蓝图中显示。</li></ol><p>当然其实还有很多可以重写的方法，比如PostLoad、PostEditChangeProperty等等，这些方法都是在材质节点的生命周期中被调用的，我们可以根据需要来重写它们。</p><p>实现GetCaption函数非常简单，就不单独讲了，示例代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">UColorShaderNode::GetCaption</span><span class="hljs-params">(TArray&lt;FString&gt;&amp; OutCaptions)</span> <span class="hljs-type">const</span></span><br><span class="hljs-function"></span>&#123;<br>OutCaptions.<span class="hljs-built_in">Add</span>(<span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;MyColorShaderNode&quot;</span>));<br>&#125;   <br></code></pre></td></tr></table></figure><h3 id="实现Compile函数">实现Compile函数</h3><p>接下来我们来实现Compile函数，这个函数是材质节点的核心逻辑，它定义了如何将这个节点编译成Shader代码，以及如何传入对应的参数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;ColorShaderNode.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;MaterialCompiler.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;Materials/MaterialExpressionCustom.h&quot;</span></span><br><br><span class="hljs-function">int32 <span class="hljs-title">UColorShaderNode::Compile</span><span class="hljs-params">(<span class="hljs-keyword">class</span> FMaterialCompiler* Compiler, int32 OutputIndex)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// 1. 获取输入参数（默认值处理）</span><br>int32 BaseColorInput = BaseColor.<span class="hljs-built_in">GetTracedInput</span>().Expression ? BaseColor.<span class="hljs-built_in">Compile</span>(Compiler) : Compiler-&gt;<span class="hljs-built_in">Constant3</span>(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>); <span class="hljs-comment">// 默认白色;</span><br>int32 intensityInput = Intensity.<span class="hljs-built_in">GetTracedInput</span>().Expression ? Intensity.<span class="hljs-built_in">Compile</span>(Compiler) : Compiler-&gt;<span class="hljs-built_in">Constant</span>(<span class="hljs-number">1</span>);<br><br><span class="hljs-comment">// 2. 实现节点逻辑</span><br>UMaterialExpressionCustom* MaterialExpressionCustom = <span class="hljs-built_in">NewObject</span>&lt;UMaterialExpressionCustom&gt;();<br><br>MaterialExpressionCustom-&gt;Inputs[<span class="hljs-number">0</span>].InputName = <span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;BaseColor&quot;</span>);<br>MaterialExpressionCustom-&gt;Inputs.<span class="hljs-built_in">Add</span>(&#123; <span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;Intensity&quot;</span>) &#125;);<br>MaterialExpressionCustom-&gt;<span class="hljs-built_in">GetInputType</span>(<span class="hljs-number">0</span>);<br>MaterialExpressionCustom-&gt;OutputType = ECustomMaterialOutputType::CMOT_Float3;<br>MaterialExpressionCustom-&gt;Code =<br><span class="hljs-built_in">TEXT</span>(<span class="hljs-string">R&quot;(float3 result = BaseColor * Intensity;</span><br><span class="hljs-string">float r_tmp = result.r;</span><br><span class="hljs-string">result.r = clamp(result.b, 0.0, 1.0);</span><br><span class="hljs-string">result.b = clamp(r_tmp, 0.0, 1.0);</span><br><span class="hljs-string">return result;)&quot;</span>);<br><br>TArray&lt;int32&gt; BaseColorInputs &#123;BaseColorInput, intensityInput&#125;;<br><br><span class="hljs-keyword">return</span> Compiler-&gt;<span class="hljs-built_in">CustomExpression</span>(MaterialExpressionCustom, <span class="hljs-number">0</span>, BaseColorInputs);<br>&#125;<br></code></pre></td></tr></table></figure><p>上方是完整的代码，接下来我来逐步解释一下：</p><h3 id="输入参数">输入参数</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp">int32 BaseColorInput = BaseColor.<span class="hljs-built_in">GetTracedInput</span>().Expression ? BaseColor.<span class="hljs-built_in">Compile</span>(Compiler) : Compiler-&gt;<span class="hljs-built_in">Constant3</span>(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>); <span class="hljs-comment">// 默认白色;</span><br>int32 intensityInput = Intensity.<span class="hljs-built_in">GetTracedInput</span>().Expression ? Intensity.<span class="hljs-built_in">Compile</span>(Compiler) : Compiler-&gt;<span class="hljs-built_in">Constant</span>(<span class="hljs-number">1</span>);<br></code></pre></td></tr></table></figure><p>代码的第一部分是处理输入参数。我们定义了BaseColor和Intensity两个输入引脚，首先利用：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-built_in">GetTracedInput</span>().Expression<br></code></pre></td></tr></table></figure><p>来判断该引脚是否有输入。如果有输入，通过Compile方法获取对应的输入参数。如果没有输入，就使用默认值。</p><p>在获取到连接值或者是默认值之后，我们得到一个int32类型的变量索引，这个索引是引擎的Shader编译器用于高效管理作用域的变量的。</p><h3 id="生成自定义Shader代码">生成自定义Shader代码</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp">UMaterialExpressionCustom* MaterialExpressionCustom = <span class="hljs-built_in">NewObject</span>&lt;UMaterialExpressionCustom&gt;();<br>MaterialExpressionCustom-&gt;Inputs[<span class="hljs-number">0</span>].InputName = <span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;BaseColor&quot;</span>);<br>MaterialExpressionCustom-&gt;Inputs.<span class="hljs-built_in">Add</span>(&#123; <span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;Intensity&quot;</span>) &#125;);<br>MaterialExpressionCustom-&gt;OutputType = ECustomMaterialOutputType::CMOT_Float3;<br>MaterialExpressionCustom-&gt;Code =<br><span class="hljs-built_in">TEXT</span>(<span class="hljs-string">R&quot;(float3 result = BaseColor * Intensity;</span><br><span class="hljs-string">float r_tmp = result.r;</span><br><span class="hljs-string">result.r = clamp(result.b, 0.0, 1.0);</span><br><span class="hljs-string">result.b = clamp(r_tmp, 0.0, 1.0);</span><br><span class="hljs-string">return result;)&quot;</span>);<br>    <br>    TArray&lt;int32&gt; BaseColorInputs &#123;BaseColorInput, intensityInput&#125;;<br><br><span class="hljs-keyword">return</span> Compiler-&gt;<span class="hljs-built_in">CustomExpression</span>(MaterialExpressionCustom, <span class="hljs-number">0</span>, BaseColorInputs);<br><br></code></pre></td></tr></table></figure><p>接下来，为了让我们的material expression可以灵活的实现我们想要的功能，我决定在我们的material expression中，使用UMaterialExpressionCustom来实现自定义Shader。</p><p><strong>UE预设了非常多样的material expression，如加减、采样、以及上面的Custom等等。我们在实现自己的material expression的时候，可以将UE的预设节点组合起来。</strong></p><p><img src="MaterialExpressionCustom.png" alt="UMaterialExpressionCustom就是对应着它"></p><p>所以第二部分的代码逻辑，就是初始化Custom节点，设置对应的输入参数。Custom节点自带一个输入，所以我们可以直接将**inputs[0]**设置为我们的BaseColor。而后面的参数如Intensity就需要加到Inputs队列中。</p><p><img src="custom_node_input.png" alt="Custom节点默认包含一个输入"></p><p>然后设置OutputType为CMOT_Float3，这是因为我们的输出类型是一个float3类型，即RGB颜色。</p><p>最后设置Code，这是我们的Shader代码，我们可以在这里实现我们想要的功能。这里我简单的实现了一个将BaseColor的r和b通道互换，并乘以Intensity的功能。这一部分也对应Custom节点的代码部分。</p><p>最后的部分：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp">TArray&lt;int32&gt; BaseColorInputs &#123;BaseColorInput, intensityInput&#125;;<br><br><span class="hljs-keyword">return</span> Compiler-&gt;<span class="hljs-built_in">CustomExpression</span>(MaterialExpressionCustom, <span class="hljs-number">0</span>, BaseColorInputs);<br></code></pre></td></tr></table></figure><p>这一段内容，是将我们的输入参数传入到Custom节点中，以便在Shader中使用。其中BaseColorInput、intensityInput这两个索引需要对应到我们之前设置的Custom节点的Inputs。</p><p>最后，我们调用Compiler的CustomExpression方法，将我们的Custom节点编译成Shader代码，并返回结果对应的索引。</p><p>好了，下面就是我们节点的输出结果了。</p><p><img src="CustomNode.gif" alt="输出结果"></p><h3 id="组合多个material-expression方法">组合多个material expression方法</h3><p>正如我前面所说，我们可以将UE的预设节点组合起来实现更加复杂的功能。我将上面节点的代码稍作修改：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 前面的都一样</span><br>TArray&lt;int32&gt; BaseColorInputs &#123;BaseColorInput, intensityInput&#125;;<br><br><span class="hljs-keyword">auto</span> result = Compiler-&gt;<span class="hljs-built_in">CustomExpression</span>(MaterialExpressionCustom, <span class="hljs-number">0</span>, BaseColorInputs);<br><br>int32 Timer = Compiler-&gt;<span class="hljs-built_in">RealTime</span>(<span class="hljs-literal">false</span>, <span class="hljs-number">0.0</span>);;<br>int32 SinTimer = Compiler-&gt;<span class="hljs-built_in">Sine</span>(Timer);<br><span class="hljs-keyword">return</span> Compiler-&gt;<span class="hljs-built_in">Add</span>(result, SinTimer);<br></code></pre></td></tr></table></figure><p>我将Custom Node的结果暂存，然后将现实的时间作为参数，取sine值后和Custom Node的结果相加，就可以得到一个随着时间变化的颜色。</p><p><img src="CustomNodePro.gif" alt="更加复杂的输出结果"></p><p>通过这个方法，我们有这非常大的自由度去实现各种各样的节点效果。</p><h2 id="结语">结语</h2><p>好了，到这里，我们就完成了一个简单的Material Expression的实现。当然，这只是一个简单的示例，我们可以根据自己的需求去实现更加复杂的节点。</p><p>当然可能也有同学有疑问的就是，为什么不直接通过蓝图来实现类似的效果，蓝图完全也是可以做到的，也没有这么麻烦。</p><p>对我来说，用C++的代码来实现Material Expression，有以下几个好处：</p><ol><li>性能：C++实现的Material Expression在材质编译时直接生成优化的HLSL代码，避免蓝图节点组合可能产生的冗余计算。</li><li>和引擎底层关联：Material Expression可以直接访问引擎的底层API，例如访问纹理、光照等信息，也可以根据平台的信息来使用不同的方法。</li><li>可维护性：如果逻辑比较复杂的话，C++代码更易于维护和调试，我想谁也不想去debug一个复杂的像意面图一样的蓝图吧。</li></ol><p>还有其他的好处，当然蓝图也不是一无是处，灵活掌握两种方法，在不同的情况下使用合适的方法，才能更好的实现我们的需求。</p><h2 id="参考资料">参考资料</h2><p>本次教程的内容可以参考引擎的代码：UnrealEngine\Engine\Plugins\Interchange\Runtime\Source\Import\Private\MaterialX\MaterialExpressions\MaterialExpressionFractal3D.cpp</p>]]></content>
    
    
    <categories>
      
      <category>UE技术渲染</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>虚幻引擎</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>虚幻引擎的Shader课堂之Global Shader</title>
    <link href="/2025/05/11/ue-shader-globalshader/"/>
    <url>/2025/05/11/ue-shader-globalshader/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在上一篇关于<a href="https://ruochenhua.github.io/2025/05/01/UE-SceneViewExtension/">虚幻引擎SceneViewExtension的介绍</a>里面简单的提到了一些关于UE中的Shader的一些介绍。由于那篇文章的重点是关于SceneViewExtensionTemplate的，所以并没有将Shader这部分内容展开和整理起来。</p><p>现在回想起来，觉得如果需要对UE的渲染流程做自定义的话，弄清楚UE的不同的shader的类型，以及各自的用法还是非常有必要的，因此打算开一个系列的文章，讲讲虚幻引擎的Shader。</p><p>相比较Unity对自定义shader的开发，UE从设计上其实更鼓励使用者通过可视化节点工具来实现自定义的渲染效果，可能和UE设计上的目标人群很多是设计师和影视行业从业者等非技术人员有关。因此，在UE中实现自定义Shader开发确实存在一定门槛，不过只要稍微了解核心逻辑并辅以实践，依然是可行的。也希望这个系列内容能为读者提供具体的思路与帮助，让复杂的技术变得更易上手。</p><p>第一篇，我会先介绍一下<strong>Global Shader</strong>。</p><h2 id="Global-Shader是什么">Global Shader是什么</h2><p>Global Shader是UE中一类<strong>不依赖具体材质或游戏对象的着色器</strong>，它可以用来处理全局场景相关的渲染逻辑。与依赖材质属性的<strong>Material Shader</strong>不同，Global Shader的逻辑始终围绕<strong>整个场景</strong>展开。</p><p>由于它的这个特点，所以Global Shader的应用范围非常广泛，包括：</p><ul><li>全场景的效果，如场景雾效</li><li>后处理效果，如模糊、颜色filter等等（当然后处理也可以通过后处理材质shader来实现）</li><li>Compute Shader（这个后面会单独讲一期）</li><li>等等</li></ul><p>所以总而言之，只要需要达到的效果不依赖于具体的材质属性，那么大概率都可以通过global shader来实现。</p><h2 id="一个简单的Global-Shader例子">一个简单的Global Shader例子</h2><p>好了，接下来我们来创建一个简单的Global Shader，并让它在UE中跑起来。通过跑通这个简单的例子，相信大家也能对Global Shader有一个大概的了解。</p><h3 id="准备工作">准备工作</h3><p>为了表现出我们将要创建的Global Shader的效果，参照前面<a href="https://ruochenhua.github.io/2025/05/01/UE-SceneViewExtension/">SceneViewExtension的文章</a>，采用SceneViewExtension的方法来插入我们的渲染修改，简单做一些准备工作：</p><ol><li>新建一个插件</li><li>在插件内新建一个UEngineSubsystem的子类，和一个FSceneViewExtensionBase的子类。</li><li>在Subsystem中处理SceneViewExtension的初始化和销毁</li><li>在插件Module类中的StartupModule将添加虚拟Shader路径。</li><li>创建Shaders目录</li></ol><p>准备工作都做完后，我们的目录看起来大概是这个样子的：<br><img src="prepare.png" alt="简单的前期准备工作"></p><h3 id="创建GlobalShader类">创建GlobalShader类</h3><p>接下来我们创建Global Shader类。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> once</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;SceneTexturesConfig.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;ShaderParameterStruct.h&quot;</span></span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GLOBALSHADEREXAMPLE_API</span> FSampleGlobalShader : <span class="hljs-keyword">public</span> FGlobalShader<br>&#123;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-comment">//生成着色器类型并且序列化</span><br><span class="hljs-built_in">DECLARE_GLOBAL_SHADER</span>(FSampleGlobalShader)<br><span class="hljs-built_in">SHADER_USE_PARAMETER_STRUCT</span>(FSampleGlobalShader, FGlobalShader);<br><span class="hljs-built_in">BEGIN_SHADER_PARAMETER_STRUCT</span>(FParameters,)<br><span class="hljs-comment">//定义输入的色、贴图参数</span><br><span class="hljs-built_in">SHADER_PARAMETER</span>(FVector3f, TargetColor)<br><span class="hljs-built_in">SHADER_PARAMETER_RDG_TEXTURE</span>(Texture2D, SceneColorTexture)<br>        <span class="hljs-comment">// 包含另外一个预定义的Shader结构体参数FSceneTextureShaderParameters</span><br><span class="hljs-built_in">SHADER_PARAMETER_STRUCT_INCLUDE</span>(FSceneTextureShaderParameters, SceneTextures)<br><br><span class="hljs-comment">//绑定输出的渲染目标</span><br><span class="hljs-built_in">RENDER_TARGET_BINDING_SLOTS</span>()<br><span class="hljs-built_in">END_SHADER_PARAMETER_STRUCT</span>()<br>&#125;;<br></code></pre></td></tr></table></figure><p>在上面这段代码中，<strong>FSamplerGlobalShader</strong>是我们自定义的Global Shader类，这个类中包含几个最基本的部分：</p><ul><li><p>DECLARE_GLOBAL_SHADER：在类中声明一个全局着色器类型，生成必要的元数据，包括类型标识符、序列化信息得到，让引擎能够识别、编译和管理这个shader。</p><ul><li>它等价于<strong>DECLARE_SHADER_TYPE(FSampleGlobalShader, Global)</strong>。</li><li>如果需要shader跨模块可见，需要对应的使用<em>DECLARE_EXPORTED_GLOBAL_SHADER</em>或者<em>DECLARE_EXPORTED_SHADER_TYPE</em></li></ul></li><li><p>SHADER_USE_PARAMETER_STRUCT:将GlobalShader和参数结构体绑定起来，确保引擎可以正确处理参数传递。</p></li><li><p>BEGIN/END_SHADER_PARAMETER_STRUCT:这段代码是用于定义shader所需参数的结构。</p><ul><li>SHADER_PARAMETER：申明一个float3类型的输入，名称为TargetColor。参照这种写法我们可以传入各种不同的参数，如float、int等等</li><li>SHADER_PARAMETER_RDG_TEXTURE：声明一个与RDG兼容的2D纹理参数SceneColorTexture，使用这个MARCO可以确保纹理资源在RDG中被正确的跟踪依赖关系。我们可以参照这个例子将更多的纹理传入shader</li><li>SHADER_PARAMETER_STRUCT_INCLUDE：如注释所说，这里我们包含了另外一个<strong>预定义的参数结构体</strong>，UE包含很多的预定义结构体，可以适当应用避免重复定义。当前这个结构体包括：<ul><li>SceneDepthTexture：场景深度纹理（用于获取像素的世界位置）；</li><li>SceneNormalsTexture：场景法线纹理（用于区分表面朝向）；</li><li>SceneVelocityTexture：场景运动向量纹理（用于动态物体检测）。</li></ul></li><li>RENDER_TARGET_BINDING_SLOTS：申明这个shader动态绑定的渲染输出目标。</li></ul></li></ul><p>好了，这就是一个非常简单的Global Shader的样子了。我们再来回顾一下，这个基本的GlobalShader类的几个部分：</p><ol><li>声明Global Shader，自动生成必要的元数据；</li><li>将Global Shader和参数结构体绑定起来；</li><li>申明Global Shader的参数结构体</li></ol><p>接下来，我们需要注册我们的shader，将C++类和HLSL文件以及文件中的入口函数绑定。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">IMPLEMENT_GLOBAL_SHADER</span>(FSampleGlobalShader, <span class="hljs-string">&quot;/Plugins/GlobalShaderExample/SamplePS.usf&quot;</span>, <span class="hljs-string">&quot;MainPS&quot;</span>, SF_Pixel);<br></code></pre></td></tr></table></figure><p>如上面的代码所示，我们将HLSL文件以及入口函数绑定到了我们声明的Global Shader类，并且申明该Shader的阶段是Pixel Shader。</p><h3 id="通过SceneViewExtension使Global-Shader生效">通过SceneViewExtension使Global Shader生效</h3><p>接下来我们要将shader通过SceneViewExtension对UE的渲染做出改变。</p><p>这里我们选择重写SceneViewExtension的PrePostProcessPass_RenderThread方法，这个方法会在UE进行后处理之前被调用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs c++"><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">ShaderExampleSceneViewExtension::PrePostProcessPass_RenderThread</span><span class="hljs-params">(FRDGBuilder&amp; GraphBuilder,</span></span><br><span class="hljs-params"><span class="hljs-function"><span class="hljs-type">const</span> FViewInfo&amp; InView, <span class="hljs-type">const</span> FPostProcessingInputs&amp; Inputs)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">/// 1.从预定义参数结构体中获取场景纹理与视口信息</span><br><span class="hljs-type">const</span> FIntRect Viewport = InView.ViewRect;<br><span class="hljs-type">const</span> FSceneTextureShaderParameters SceneTextures = <span class="hljs-built_in">CreateSceneTextureShaderParameters</span>(GraphBuilder, InView, ESceneTextureSetupMode::SceneColor | ESceneTextureSetupMode::GBuffers);<br><br><span class="hljs-comment">// 包装场景颜色纹理及其视口，确保后续渲染仅影响该区域</span><br><span class="hljs-function"><span class="hljs-type">const</span> FScreenPassTexture <span class="hljs-title">SceneColorTexture</span><span class="hljs-params">((*Inputs.SceneTextures)-&gt;SceneColorTexture, Viewport)</span></span>;<br><br><span class="hljs-comment">/// 2.为全局着色器配置输入与输出</span><br>FSampleGlobalShader::FParameters* Parameters = GraphBuilder.<span class="hljs-built_in">AllocParameters</span>&lt;FSampleGlobalShader::FParameters&gt;();<br>    <span class="hljs-comment">//将对应的输入参数赋值给Shader声明的输入参数</span><br>Parameters-&gt;SceneColorTexture = SceneColorTexture.Texture;<br>Parameters-&gt;SceneTextures = SceneTextures;<br>Parameters-&gt;TargetColour = <span class="hljs-built_in">FVector3f</span>(<span class="hljs-number">1.0f</span>, <span class="hljs-number">0.9f</span>, <span class="hljs-number">0.7f</span>);<br><br><span class="hljs-comment">//绑定输出渲染目标（此处直接复用输入的场景颜色纹理）</span><br>Parameters-&gt;RenderTargets[<span class="hljs-number">0</span>] = <span class="hljs-built_in">FRenderTargetBinding</span>((*Inputs.SceneTextures)-&gt;SceneColorTexture, ERenderTargetLoadAction::ELoad);<br><br>    <span class="hljs-comment">/// 3.执行全屏幕渲染通道</span><br>    <span class="hljs-comment">//从全局shader映射中获取我们定义的Global Shader实例</span><br><span class="hljs-type">const</span> FGlobalShaderMap* GlobalShaderMap = <span class="hljs-built_in">GetGlobalShaderMap</span>(GMaxRHIFeatureLevel);<br><span class="hljs-function">TShaderMapRef&lt;FSampleGlobalShader&gt; <span class="hljs-title">PixelShader</span><span class="hljs-params">(GlobalShaderMap)</span></span>;<br><br>    <span class="hljs-comment">// 在全屏幕渲染通道将我们的执行命令加到RDG中</span><br>FPixelShaderUtils::<span class="hljs-built_in">AddFullscreenPass</span>(GraphBuilder, GlobalShaderMap, <span class="hljs-built_in">FRDGEventName</span>(<span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;Color Calibration Pass&quot;</span>)), PixelShader, Parameters, Viewport);<br>&#125;<br></code></pre></td></tr></table></figure><p>这段执行的代码也是相对来说比较简单易懂的，大体分为3个部分：</p><ol><li>准备需要传入给shader结构体的参数；</li><li>将输入输出参数绑定到shader的结构体上；</li><li>将执行shader的指令添加到RDG上，通过RDG确保依赖关系正确，最终调用渲染指令。</li></ol><h3 id="一个简单的示例Shader">一个简单的示例Shader</h3><p>最后，这里贴一个对应上面我们定义的Global Shader类的shader代码。UE的Shader执行内容都放在**usf（unreal shading file）<strong>类型的文件中，很多公共定义、函数声明、结构体等复用的代码放在</strong>ush（unreal shading header）**类型的文件里面。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs HLSL">// 一个简单的色彩滤镜shader<br>#include &quot;/Engine/Private/Common.ush&quot;<br>#include &quot;/Engine/Public/Platform.ush&quot;<br><br>float3 TargetColour;<br>Texture2D&lt;float4&gt; SceneColorTexture;<br><br>float4 MainPS(float4 SvPosition : SV_POSITION) : SV_Target0<br>&#123;<br>// 步骤1：采样场景颜色<br>float2 UV = SvPosition.xy / SvPosition.w;  // 转换为归一化UV坐标<br>float4 SceneColour = SceneColorTexture.Load(int3(UV, 0));<br><br>// 步骤2：基于目标颜色的色偏校正（RGB通道乘法）<br>float3 CorrectedColor = SceneColour.rgb * TargetColour;<br><br>// 步骤3：限制颜色范围（避免过曝，保持在[0,1]）<br>CorrectedColor = saturate(CorrectedColor);<br><br>return float4(CorrectedColor, 1.0); <br>&#125;<br></code></pre></td></tr></table></figure><p>这是一个非常简单的色彩滤镜的shader代码，我们添加一个控制指令来开启和关闭SceneViewExtension的效果，看看最终的结果吧。</p><p><img src="global_shader_effect.gif" alt="最终效果"></p><h2 id="结语">结语</h2><p>好了，UE的global shader就先简单介绍到这里了。Global Shader 的应用非常广泛，目前这个例子只能是作为一个简单的入门，带大家了解一下这个过程。万事开头难，希望这个例子能对各位有所帮助。</p><h2 id="参考资料">参考资料</h2><p><a href="https://dev.epicgames.com/documentation/zh-cn/unreal-engine/adding-global-shaders-to-unreal-engine">https://dev.epicgames.com/documentation/zh-cn/unreal-engine/adding-global-shaders-to-unreal-engine</a></p>]]></content>
    
    
    <categories>
      
      <category>UE技术渲染</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>虚幻引擎</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>虚幻引擎之浅谈SceneViewExtension</title>
    <link href="/2025/05/01/UE-SceneViewExtension/"/>
    <url>/2025/05/01/UE-SceneViewExtension/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>我们都知道虚幻引擎是一个非常强大且使用广泛的商业引擎，在虚幻引擎的强大的渲染能力加持下，只要有质量足够好的模型，一个新手都可以得到非常逼真的渲染场景。</p><p>但是如果你是一个图形开发工程师，在虚幻引擎中定制自己的渲染过程是非常麻烦的，很有可能涉及到修改虚幻引擎的源代码，那这样一个很简单的修改调试起来都会非常的麻烦。（想起来之前做UE项目的时候，只要有引擎相关的代码更新，我们本地编译基本上就是2、3个小时起了，基本上干不了活。）</p><p>在这方面Unity的URP的灵活性就要好很多，也许是引擎的设计理念不同，Unity的可能更多的是面向技术人员，需要有更多的图形学技术能力以及自定义能力；而虚幻引擎可能更多的面向美术和设计人员，更多的是使用蓝图来实现多样的效果，提供统一且强大的渲染管线。</p><p>在虚幻引擎4.12版本中，Epic引入了<strong>SceneViewExtension</strong>，它为开发者提供了一种在场景渲染过程中插入自定义渲染逻辑的方式，通过它可以实现很多自定义渲染效果，比如后处理效果、自定义的调试信息显示等。这种机制允许开发者在不直接修改引擎核心渲染代码的前提下，扩展和定制渲染流程。</p><p>在网上SceneViewExtension的内容其实并不多，或者说是讲的都是比较粗浅的内容，如何通过SceneViewExtension一步一步实现自定义渲染效果好像还没有官方的教程。幸运的是，我找到了一个开源的Github项目<a href="https://github.com/A57R4L/SceneViewExtensionTemplate">SceneViewExtensionTemplate</a>，上面提供了一个利用SceneViewExtension修改后处理的模板，今天这篇文章就以这个模板来讲讲SceneViewExtension的相关内容。</p><p>当然UE的渲染过程其实还是比较复杂的，想要去修改它还需要很多学习。</p><h2 id="创建SceneViewExtension插件">创建SceneViewExtension插件</h2><p>这里我们使选择通过一个插件来实现SceneViewExtension的能力。</p><h3 id="在引擎中创建插件">在引擎中创建插件</h3><p>创建插件非常简单，</p><ul><li>从<strong>编辑-&gt;插件</strong>打开UE的插件窗口</li><li>点击左上角的<strong>添加</strong>按钮</li><li>选择<strong>空白</strong>模板，填写插件的名称和一些基础信息后点击<strong>创建插件</strong></li></ul><p><img src="create_ue_plugin.png" alt="创建插件"></p><p>等待一小段时间让UE处理相关的文件创建，我们就可以在项目工程中看到我们的插件了。</p><p>这里提一点，我们的SceneViewExtension插件会调用一个Shader来实现后处理，为了让Shader能够正常的编译，插件的<strong>uplugin</strong>文件中，LoadingPhase需要设置为PostConfigInit，如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;Modules&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;Name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;SimpleSVE&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;Type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Runtime&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;LoadingPhase&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;PostConfigInit&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure><h3 id="插件结构">插件结构</h3><p>一个空白的插件目录结构大概如下所示：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs 1c">工程目录<br>    <span class="hljs-string">|----Plugins        </span><br>            <span class="hljs-string">|----MyPlugin                </span><br>                    <span class="hljs-string">|----Config</span><br>                    <span class="hljs-string">|----Resources</span><br>                    <span class="hljs-string">|----Source</span><br>                            <span class="hljs-string">|----MyPlugin</span><br>                                    <span class="hljs-string">|----Private</span><br>                                            <span class="hljs-string">|----MyPlugin.cpp</span><br>                                    <span class="hljs-string">|----Public</span><br>                                            <span class="hljs-string">|----MyPlugin.h</span><br>                                    <span class="hljs-string">|----MyPlugin.Build.cs</span><br>                            <span class="hljs-string">|----MyPlugin.uplugin</span><br><br></code></pre></td></tr></table></figure><p>在MyPlugin.h/cpp中定义了插件的Module，在对应的Engine LoadingPhase的时候会调用</p><blockquote><p>FMyPluginModule::StartupModule</p></blockquote><p>来执行一些初始化的工作。<strong>LoadingPhase</strong>有多个阶段，包括PostEngineInit、PostConfigInit、Default、PreDefault、PostDefault等等，后面有机会会专门整理一篇文章讲讲UE的初始化（TODO）。当前我们设定为PostConfigInit。</p><h3 id="创建SceneViewExtension扩展">创建SceneViewExtension扩展</h3><p>接下来我们来创建SceneViewExtension的类，来实现我们自定义的渲染内容。示例代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> once</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;SceneViewExtension.h&quot;</span></span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleSceneViewExtension</span> : <span class="hljs-keyword">public</span> FSceneViewExtensionBase<br>&#123;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-built_in">SimpleSceneViewExtension</span>(<span class="hljs-type">const</span> FAutoRegister&amp; Register)<br>: <span class="hljs-built_in">FSceneViewExtensionBase</span>(Register)<br>&#123;&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">SetupViewFamily</span><span class="hljs-params">(FSceneViewFamily&amp; InViewFamily)</span> <span class="hljs-keyword">override</span></span>;<br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">SetupView</span><span class="hljs-params">(FSceneViewFamily&amp; InViewFamily, FSceneView&amp; InView)</span> <span class="hljs-keyword">override</span> </span>&#123;&#125;;<br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">BeginRenderViewFamily</span><span class="hljs-params">(FSceneViewFamily&amp; InViewFamily)</span> <span class="hljs-keyword">override</span> </span>&#123;&#125;;<br>&#125;;<br><br></code></pre></td></tr></table></figure><p>下面来介绍一下这个扩展：</p><p>首先，我们的子类需要继承<strong>FSceneViewExtensionBase</strong>这个基类，这个基类继承于<strong>ISceneViewExtension</strong>这个Interface。其中SetupViewFamily、SetupView和BeginRenderViewFamily这三个纯虚函数需要在子类中实现。</p><h4 id="View和ViewFamily">View和ViewFamily</h4><p>这里有个概念需要特别的说明一些，就是View和ViewFamily，因为在处理UE的渲染的时候可能会经常遇到这两个词，包括在SceneViewExtension中，所以还是需要分清楚的。</p><p>简单来说，View和ViewFamily的关系如下：</p><ul><li><p>View：代表一个具体的视角，对应一个摄像机的视图参数（如位置、朝向、投影矩阵、视口尺寸等），例如玩家摄像机的视图、过场动画中的特写镜头、分屏游戏中的某个玩家视图，或立体渲染中的左眼 / 右眼视图。</p><ul><li>每个 View 包含独立的视图信息（FMinimalViewInfo）、投影矩阵、裁剪参数等。</li><li>是渲染流程的基本单元，直接对应最终输出的一个图像（如屏幕上的一个视口）。</li></ul></li><li><p>ViewFamily：是一组相关 View 的集合，这些 View 共享相同的渲染配置和上下文（如渲染目标、渲染管线设置、立体渲染模式等）。</p><ul><li>用于管理具有相同渲染需求的多个 View，例如：<ul><li>立体渲染（Stereo Rendering）中的左眼和右眼 View 属于同一个 Family。</li><li>分屏游戏中，每个玩家的 View 可能属于不同的 Family（若渲染目标不同），或同一 Family（若共享相同的渲染配置）。</li></ul></li><li>是更高层次的组织单元，负责协调旗下 View 的渲染顺序、资源共享和同步。</li></ul></li></ul><p>一个ViewFamily可以对应不止一个View，但每个View必须从属与一个View Family。</p><p>那么对于上面的几个函数：<strong>SetupView会在每个View初始化的时候调用，SetupViewFamily会在创建ViewFamily的时候调用</strong>。</p><h4 id="ISceneViewExtension的方法">ISceneViewExtension的方法</h4><p>除了上面介绍的SetupView和SetupViewFamily两个方法，还有其他的方法可以重写，这里简单介绍几个。</p><ul><li>BeginRenderViewFamily：<em>在游戏线程即将渲染视图家族时调用</em>。可以在视图家族渲染开始前进行一些准备工作，例如记录一些统计信息。</li><li>PreRenderViewFamily_RenderThread: <em>在渲染线程开始渲染视图家族时调用</em>。使用 FRDGBuilder 可以在渲染线程上为视图家族的渲染进行一些前期准备，例如创建一些渲染资源。</li><li>PreRenderView_RenderThread: <em>在渲染线程开始渲染每个视图时调用，在 PreRenderViewFamily_RenderThread 之后</em>。可以为每个视图的渲染进行一些特定的准备工作。</li><li>PostRenderViewFamily_RenderThread: <em>在渲染线程完成视图家族的 3D 内容渲染之后调用</em>。可以在视图家族渲染完成后进行一些额外的渲染操作，例如绘制调试信息。</li><li>PostRenderView_RenderThread: <em>在渲染线程完成每个视图的 3D 内容渲染之后调用</em>。可以在每个视图渲染完成后进行一些额外的渲染操作，例如绘制调试信息。</li><li>SubscribeToPostProcessingPass: <em>在后处理开始时调用，确保每个视图扩展都有机会订阅某个后处理通道的回调</em>。可以订阅特定的后处理通道，在该通道处理完成后执行自定义的回调函数。</li></ul><h3 id="注册SceneViewExtension方法">注册SceneViewExtension方法</h3><p>注册SceneViewExtension的方法非常简单，我们需要在一个合适的地方调用以下方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> MyExtension = FSceneViewExtensions::<span class="hljs-built_in">NewExtension</span>&lt;SimpleSceneViewExtension&gt;();<br></code></pre></td></tr></table></figure><p>在合适的地方管理MyExtension的生命周期，可以在插件的Module类中（不是特别建议），或者在某个Subsystem中。</p><p>好了，这就是SceneViewExtension的基本内容了。</p><h2 id="使用SceneViewExtension进行后处理">使用SceneViewExtension进行后处理</h2><p>一般的教程里面关于SceneViewExtension的内容就是这些了，如果只讲到这些内容的话，其实对于刚接触UE渲染的同学们来说还是一头雾水：好的，我继承了FSceneViewExtensionBase类，并且创建了NewExtension，通过断点或者Log打印能看到我们的Extension中的函数被调用了，然后呢？</p><p>是的，然后呢，后面其实很多教程不会讲到是因为后面的内容严格来说并不是SceneViewExtension的内容，而是和UE的渲染调用、自定义shader的使用这些相关。这些内容还有很多东西可以讲，但是我不在这里拓展了，后面会专门找机会对这些内容写几篇文章介绍。</p><p>下面的内容只是我根据SceneViewExtensionTemplate给出的例子，做一个简单介绍。遵循这个例子的流程，我们就能实现一个简单的流程，在自己的SceneViewExtension中实现一些后处理的效果。</p><h3 id="Extension的初始化和反初始化">Extension的初始化和反初始化</h3><p>前面我提到过，可以在一个Subsystem中初始化SceneViewExtension，这是比较推荐的做法。这里我们创建一个EngineSubsystem的子类，在这个Subsystem中管理Extension的生命周期（一直存在）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">UCLASS</span>()<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">USimpleSveSubsystem</span> : <span class="hljs-keyword">public</span> UEngineSubsystem<br>&#123;<br><span class="hljs-built_in">GENERATED_BODY</span>()<br><span class="hljs-keyword">public</span>:<br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Initialize</span><span class="hljs-params">(FSubsystemCollectionBase&amp; Collection)</span> <span class="hljs-keyword">override</span></span>;<br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Deinitialize</span><span class="hljs-params">()</span> <span class="hljs-keyword">override</span></span>;<br><br><span class="hljs-keyword">private</span>:<br>TSharedPtr&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleSceneViewExtension</span>, ESPMode::ThreadSafe&gt; CustomSceneViewExtension;<br>&#125;;<br><br></code></pre></td></tr></table></figure><p>初始化就是简单的调用FSceneViewExtensions::NewExtension并保存结果。反初始化的代码如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">USimpleSveSubsystem::Deinitialize</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>&#123;<br>        <span class="hljs-comment">// 清理掉所有还关联的IsActiveThisFrameFunctions</span><br>CustomSceneViewExtension-&gt;IsActiveThisFrameFunctions.<span class="hljs-built_in">Empty</span>();<br><br>FSceneViewExtensionIsActiveFunctor IsActiveFunctor;<br><br>IsActiveFunctor.IsActiveFunction = [](<span class="hljs-type">const</span> ISceneViewExtension* SceneViewExtension, <span class="hljs-type">const</span> FSceneViewExtensionContext&amp; Context)<br>&#123;<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">TOptional</span>&lt;<span class="hljs-type">bool</span>&gt;(<span class="hljs-literal">false</span>);<br>&#125;;<br><br>        <span class="hljs-comment">// 添加一个返回是false的Functor</span><br>CustomSceneViewExtension-&gt;IsActiveThisFrameFunctions.<span class="hljs-built_in">Add</span>(IsActiveFunctor);<br>&#125;<br><br>    <span class="hljs-comment">// 释放Extension</span><br>CustomSceneViewExtension.<span class="hljs-built_in">Reset</span>();<br>CustomSceneViewExtension = <span class="hljs-literal">nullptr</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中<strong>IsActiveThisFrameFunctions</strong>是一个函数方法队列，每个方法都是用来判断这个Extension在当前Context和当前帧是否是激活状态。在释放前我们讲这个队列清除，只保留一个返回是否的方法。</p><h3 id="定义我们的shader">定义我们的shader</h3><p>在SceneViewExtensionTemplate示例中，通过添加一个自定义的Shader加到后处理的流程中，来达到实现改变渲染效果。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-built_in">BEGIN_SHADER_PARAMETER_STRUCT</span>(FCommonShaderParameters, )<br><span class="hljs-built_in">SHADER_PARAMETER_STRUCT_REF</span>(FViewUniformShaderParameters, ViewUniformBuffer)<br><span class="hljs-built_in">END_SHADER_PARAMETER_STRUCT</span>()<br></code></pre></td></tr></table></figure><p>首先这里定义了一个通用的着色器参数结构体，用于集中管理多个着色器的共享参数。</p><ul><li>BEGIN_SHADER_PARAMETER_STRUCT宏声明这个结构体的名称，END_SHADER_PARAMETER_STRUCT结束这个结构体的申明</li><li>SHADER_PARAMETER_STRUCT_REF引用另外一个名为<em>FViewUniformShaderParameters</em>的结构体，将其重命名为ViewUniformBuffer</li></ul><p>ViewUniformBuffer，也就是FViewUniformShaderParameters，会被UE的渲染管线自动填充，包括当前帧的视图相关数据。如果熟悉OpenGL或者Vulkan的同学，可能会对UBO这个概念比较了解，其实ViewUniformBuffer就类似与UE原有的和View相关的一个UBO，会自动更新数据，让多个shader都可以共享里面的数据。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Custom Post Process Shader</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SIMPLESVE_API</span> FSVECustomShader : <span class="hljs-keyword">public</span> FGlobalShader<br>&#123;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-built_in">DECLARE_GLOBAL_SHADER</span>(FSVECustomShader)<br><span class="hljs-built_in">SHADER_USE_PARAMETER_STRUCT</span>(FSVECustomShader, FGlobalShader)<br><br><span class="hljs-built_in">BEGIN_SHADER_PARAMETER_STRUCT</span>(FParameters, )<br><span class="hljs-built_in">SHADER_PARAMETER_STRUCT_INCLUDE</span>(FCommonShaderParameters, CommonParameters)<br><span class="hljs-built_in">SHADER_PARAMETER</span>(FIntRect, ViewportRect)<br><br><span class="hljs-built_in">SHADER_PARAMETER</span>(FVector2f, ViewportInvSize)<br><span class="hljs-built_in">SHADER_PARAMETER</span>(FVector2f, SceneColorUVScale)<br><br><span class="hljs-built_in">SHADER_PARAMETER_RDG_TEXTURE</span>(Texture2D, OriginalSceneColor)<br><span class="hljs-built_in">SHADER_PARAMETER_RDG_TEXTURE_UAV</span>(RWTexture2D&lt;float4&gt;, Output)<br><br><span class="hljs-built_in">END_SHADER_PARAMETER_STRUCT</span>()<br><br><span class="hljs-comment">// Basic shader stuff</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">bool</span> <span class="hljs-title">ShouldCompilePermutation</span><span class="hljs-params">(<span class="hljs-type">const</span> FGlobalShaderPermutationParameters&amp; Parameters)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">IsFeatureLevelSupported</span>(Parameters.Platform, ERHIFeatureLevel::SM5);<br>&#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>然后这里定义了一个<strong>FSVECustomShader类</strong>，这是一个继承于<strong>FGlobalShader</strong>的自定义全局着色器。</p><ul><li>DECLARE_GLOBAL_SHADER宏声明全局着色器。他会自动生成一些必要的代码，像着色器的构造函数、静态方法等。</li><li>SHADER_USE_PARAMETER_STRUCT(FSVECustomShader, FGlobalShader)：此宏用于指定该着色器使用的参数结构体，这里表明 FSVECustomShader 使用的参数结构体基于 FGlobalShader。</li><li>在BEGIN_SHADER_PARAMETER_STRUCT和END_SHADER_PARAMETER_STRUCT之间定义了 FSVECustomShader 所使用的参数结构体 FParameters。<ul><li>SHADER_PARAMETER_STRUCT_INCLUDE：这个宏用于包含之前定义的通用参数结构体 FCommonShaderParameters，并将其命名为 CommonParameters。</li><li>SHADER_PARAMETER：用于声明一个普通的着色器参数。这里声明了 ViewportRect（视口矩形）、ViewportInvSize（视口大小的倒数）和 SceneColorUVScale（场景颜色纹理的 UV 缩放因子）。</li><li>SHADER_PARAMETER_RDG_TEXTURE：用于声明一个渲染依赖图（RDG）纹理参数。这里声明了 OriginalSceneColor，它是一个 Texture2D 类型的纹理，代表原始的场景颜色纹理。</li><li>SHADER_PARAMETER_RDG_TEXTURE_UAV：用于声明一个可读写的渲染依赖图纹理参数。这里声明了 Output，它是一个 RWTexture2D&lt;float4&gt; 类型的可读写纹理，作为着色器的输出。</li></ul></li></ul><p>最后的<strong>ShouldCompilePermutation函数</strong>用于判断是否应该编译该着色器的某个变体。IsFeatureLevelSupported是一个函数，用于检查当前平台是否支持指定的特性级别。这里检查当前平台是否支持 ERHIFeatureLevel::SM5（Shader Model 5），如果支持则返回 true，表示应该编译该着色器变体；否则返回 false。</p><p>当我们定义好shader之后，我们还需要将shader注册到UE的着色器系统中，并且关联源代码。这里SceneViewExtensionTemplate做了以下几件事：</p><ol><li>在Module的StartupModule函数中，将Shader文件的路径映射到一个虚拟路径，这样做的好处是，即使项目的文件结构发生变化，只要正确配置了路径映射，就无需修改大量的着色器引用代码。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">FSimpleSVEModule::StartupModule</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// 找到我们Plugin下的Shaders目录路径</span><br>FString PluginShaderDir = FPaths::<span class="hljs-built_in">Combine</span>(IPluginManager::<span class="hljs-built_in">Get</span>().<span class="hljs-built_in">FindPlugin</span>(<span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;SimpleSVE&quot;</span>))-&gt;<span class="hljs-built_in">GetBaseDir</span>(), <span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;Shaders&quot;</span>));<br>    <span class="hljs-comment">// 将Shader路径映射到Shader管理器中的一个虚拟地址&quot;/Plugins/SimpleSVE&quot;</span><br><span class="hljs-built_in">AddShaderSourceDirectoryMapping</span>(<span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;/Plugins/SimpleSVE&quot;</span>), PluginShaderDir);<br>&#125;<br></code></pre></td></tr></table></figure><ol start="2"><li>在Extension中实现我们定义的着色器。下面的方法，会把我们定义的FSVECustomShader注册到UE的着色器系统中，然后将FSVECustomShader和usf文件关联起来（<strong>注意这里的usf文件的路径是上面映射的虚拟路径</strong>）。之后指定入口函数<strong>MainCS</strong>以及设定shader的类型为ComputeShader（SF_Compute）</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">IMPLEMENT_GLOBAL_SHADER</span>(FSVECustomShader, <span class="hljs-string">&quot;/Plugins/SimpleSVE/PostProcessCS.usf&quot;</span>, <span class="hljs-string">&quot;MainCS&quot;</span>, SF_Compute);<br></code></pre></td></tr></table></figure><h3 id="使用自定义shader">使用自定义shader</h3><p>好了，接下来如何使用我们的自定义shader呢？在SceneViewExtension中，有一个方法<strong>SubscribeToPostProcessingPass</strong>，在前面有简单的提到过，这个函数可以将一个回调函数注册到一个后处理通道上，当这个后处理通道执行完成后会回调我们注册的函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">SimpleSceneViewExtension::SubscribeToPostProcessingPass</span><span class="hljs-params">(EPostProcessingPass Pass, <span class="hljs-type">const</span> FSceneView&amp; InView,</span></span><br><span class="hljs-params"><span class="hljs-function">                                                         FAfterPassCallbackDelegateArray&amp; InOutPassCallbacks, <span class="hljs-type">bool</span> bIsPassEnabled)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">if</span> (Pass == EPostProcessingPass::MotionBlur)<br>&#123;<br>InOutPassCallbacks.<span class="hljs-built_in">Add</span>(FAfterPassCallbackDelegate::<span class="hljs-built_in">CreateRaw</span>(<span class="hljs-keyword">this</span>, &amp;SimpleSceneViewExtension::CustomPostProcessing));<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我们将一个自定义的函数CustomPostProcessing注册到了后处理通道MotionBlur上，后处理通道有很多类型，这里就先不展开了。</p><p>接下来的关键就是CustomPostProcessing的实现了，整个流程还是比较直观的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">FScreenPassTexture <span class="hljs-title">SimpleSceneViewExtension::CustomPostProcessing</span><span class="hljs-params">(FRDGBuilder&amp; GraphBuilder, <span class="hljs-type">const</span> FSceneView&amp; SceneView, <span class="hljs-type">const</span> FPostProcessMaterialInputs&amp; Inputs)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// 获取view family</span><br><span class="hljs-type">const</span> FSceneViewFamily&amp; ViewFamily = *SceneView.Family;<br><span class="hljs-comment">// 获取输入的场景颜色纹理</span><br><span class="hljs-type">const</span> FScreenPassTexture&amp; SceneColor = FScreenPassTexture::<span class="hljs-built_in">CopyFromSlice</span>(GraphBuilder, Inputs.<span class="hljs-built_in">GetInput</span>(EPostProcessMaterialInput::SceneColor));<br><br><span class="hljs-comment">// 检查是否启用了自定义后处理效果</span><br><span class="hljs-keyword">if</span> (!SceneColor.<span class="hljs-built_in">IsValid</span>() || CVarShaderOn.<span class="hljs-built_in">GetValueOnRenderThread</span>() == <span class="hljs-number">0</span>)<br>&#123;<br><span class="hljs-keyword">return</span> SceneColor;<br>&#125;<br><br><span class="hljs-comment">// 创建一个渲染图事件RDG，用于跟踪自定义后处理效果的执行</span><br><span class="hljs-built_in">RDG_EVENT_SCOPE</span>(GraphBuilder, <span class="hljs-string">&quot;Custom Postprocess Effect&quot;</span>);<br>&#123;<br><span class="hljs-comment">// 获取全局着色器映射</span><br>FGlobalShaderMap* GlobalShaderMap = <span class="hljs-built_in">GetGlobalShaderMap</span>(ViewFamily.<span class="hljs-built_in">GetFeatureLevel</span>());<br><br><span class="hljs-comment">// 定义输出纹理描述</span><br>FRDGTextureDesc OutputDesc;<br>&#123;<br><span class="hljs-comment">// 获取当前场景输出纹理描述</span><br>OutputDesc = SceneColor.Texture-&gt;Desc;<br>OutputDesc.<span class="hljs-built_in">Reset</span>();<span class="hljs-comment">// 重置纹理描述</span><br>OutputDesc.Flags |= TexCreate_UAV;<span class="hljs-comment">// 设置纹理描述的标志，TexCreate_UAV 表示该纹理可以作为无序访问视图使用</span><br><span class="hljs-comment">//移除TexCreate_RenderTargetable和TexCreate_FastVRAM这两个标志，意味着该纹理不会被用作渲染目标，也不会使用快速显存。</span><br>OutputDesc.Flags &amp;= ~(TexCreate_RenderTargetable | TexCreate_FastVRAM);<br><span class="hljs-comment">// 设置纹理的清除值，这里使用黑色作为清除值</span><br><span class="hljs-function">FLinearColor <span class="hljs-title">ClearColor</span><span class="hljs-params">(<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>)</span></span>;<br>OutputDesc.ClearValue = <span class="hljs-built_in">FClearValueBinding</span>(ClearColor);<br>&#125;<br><br><span class="hljs-comment">// 创建输出纹理</span><br>FRDGTextureRef OutputTexture = GraphBuilder.<span class="hljs-built_in">CreateTexture</span>(OutputDesc, <span class="hljs-built_in">TEXT</span>(<span class="hljs-string">&quot;Custom Effect Output Texture&quot;</span>));<br><span class="hljs-comment">// 设定shader参数</span><br>FSVECustomShader::FParameters* PassParameters = GraphBuilder.<span class="hljs-built_in">AllocParameters</span>&lt;FSVECustomShader::FParameters&gt;();<br><span class="hljs-comment">// 输入是场景颜色纹理</span><br>PassParameters-&gt;OriginalSceneColor = SceneColor.Texture;<br><span class="hljs-comment">// 获取当前场景的视口可见区域和源纹理的大小</span><br>FIntRect PassViewSize = SceneColor.ViewRect;<br>FIntPoint SrcTextureSize = SceneColor.Texture-&gt;Desc.Extent;<br>PassParameters-&gt;ViewportRect = PassViewSize;<br>PassParameters-&gt;ViewportInvSize = <span class="hljs-built_in">FVector2f</span>(<span class="hljs-number">1.0f</span> / PassViewSize.<span class="hljs-built_in">Width</span>(), <span class="hljs-number">1.0f</span> / PassViewSize.<span class="hljs-built_in">Height</span>());<br><br><span class="hljs-comment">// 从完整的纹理尺寸转换到实际使用的尺寸, 参考Screenpass.h了解UE如何处理不同视口尺寸的缩放</span><br>PassParameters-&gt;SceneColorUVScale = <span class="hljs-built_in">FVector2f</span>(<span class="hljs-built_in">float</span>(PassViewSize.<span class="hljs-built_in">Width</span>()) / <span class="hljs-built_in">float</span>(SrcTextureSize.X), <span class="hljs-built_in">float</span>(PassViewSize.<span class="hljs-built_in">Height</span>()) / <span class="hljs-built_in">float</span>(SrcTextureSize.Y));<br><span class="hljs-comment">// 设定通用参数，我们使用这个来传递 ViewUniformBuffer 数据</span><br>FCommonShaderParameters CommonParameters;<br>CommonParameters.ViewUniformBuffer = SceneView.ViewUniformBuffer;<br>PassParameters-&gt;CommonParameters = CommonParameters;<br><br><span class="hljs-comment">// 创建UAV作为输出纹理</span><br>PassParameters-&gt;Output = GraphBuilder.<span class="hljs-built_in">CreateUAV</span>(<span class="hljs-built_in">FRDGTextureUAVDesc</span>(OutputTexture));<br><br><span class="hljs-comment">// 设定计算着色器的线程组大小和线程组数量</span><br><span class="hljs-type">const</span> int32 kDefaultGroupSize = <span class="hljs-number">8</span>;<br><span class="hljs-function">FIntPoint <span class="hljs-title">GroupSize</span><span class="hljs-params">(kDefaultGroupSize, kDefaultGroupSize)</span></span>;<br>FIntVector GroupCount = FComputeShaderUtils::<span class="hljs-built_in">GetGroupCount</span>(PassViewSize.<span class="hljs-built_in">Size</span>(), GroupSize);<br><br><span class="hljs-comment">// 加载计算着色器</span><br><span class="hljs-function">TShaderMapRef&lt;FSVECustomShader&gt; <span class="hljs-title">ComputeShader</span><span class="hljs-params">(GlobalShaderMap)</span></span>;<br><br><span class="hljs-comment">// 添加计算着色器的渲染图传递RDG</span><br>FComputeShaderUtils::<span class="hljs-built_in">AddPass</span>(<br>GraphBuilder,<br><span class="hljs-built_in">RDG_EVENT_NAME</span>(<span class="hljs-string">&quot;Custom SceneViewExtension Post Processing CS Shader %dx%d&quot;</span>, PassViewSize.<span class="hljs-built_in">Width</span>(), PassViewSize.<span class="hljs-built_in">Height</span>()),<br>ComputeShader,<br>PassParameters,<br>GroupCount);<br><br><span class="hljs-comment">// 将输出纹理复制回 SceneColor</span><br><span class="hljs-built_in">AddCopyTexturePass</span>(GraphBuilder, OutputTexture, SceneColor.Texture);<br>&#125;<br><br><span class="hljs-comment">// 返回输入的场景颜色纹理</span><br><span class="hljs-keyword">return</span> SceneColor;<br>&#125;<br></code></pre></td></tr></table></figure><p>上面的代码有几个点：</p><ol><li>我们这里创建了一个命令来控制这个效果的开关CVarShaderOn</li><li>修改UE的渲染效果需要通过RDG（Render Dependency Graph渲染依赖图）来实现，它是一种用于管理和优化渲染流程的技术，并且UE中它兼容了不同平台和不同的API。这也是个可以深入挖掘很长时间，并且渲染开发人员需要掌握的能力。</li><li>shader的代码可以参考一下SceneViewExtensionTemplate仓库中的<em>PostProcessCS.usf</em>，只要掌握了前面的shader定义里面的逻辑还是比较易懂的。需要注意的是shader中的变量<em>View</em>来自于通用着色器参数结构体ViewUniformBuffer，他可以隐式传递无需手动声明。</li></ol><h2 id="结语">结语</h2><p><img src="sceneviewextension-effect.gif" alt="最终效果"></p><p>最后这里就是这个SceneViewExtension的效果了。实现的效果非常的简单，但是只要掌握了这部分的能力，就已经能够对UE的渲染框架和流程有着一定程度的理解了。</p><p>UE的渲染架构庞大且复杂，还有很多可以研究的地方，后续也会继续探讨这方面的内容。</p><h2 id="参考资料">参考资料</h2><p><a href="https://github.com/A57R4L/SceneViewExtensionTemplate">https://github.com/A57R4L/SceneViewExtensionTemplate</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈 - 渲染</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>虚幻引擎</tag>
      
      <tag>android</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vulkan阴影贴图实践总结</title>
    <link href="/2025/04/26/vulkan-shadowmap/"/>
    <url>/2025/04/26/vulkan-shadowmap/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>好了，继续我们的Vulkan之旅。</p><p>在上一次Vulkan相关的文章中，我们利用subpass实现了延迟渲染的流程。</p><p><img src="https://ruochenhua.github.io/2025/03/22/vulkan-defer-render/scene-defer.png" alt="上一章内容的平平无奇的渲染图"></p><p>延迟渲染实现之后，下一步当然是实现阴影了，缺少了阴影的场景看起来还是差点意思。于是乎我自然而然的计划将阴影贴图的实现提上日程。</p><p>阴影贴图的原理我这里就不再多介绍了，和OpenGL的实现原理是一致的。我们之前的文章也有介绍过阴影贴图的各种延展应用，比如说<strong>CSM（级联阴影贴图）<strong>和</strong>rsm（反射阴影贴图）</strong>。</p><p>本来想着的是我都实现过几次阴影贴图了，那这次Vulkan的接入也应该很快才对，结果由于各种各样的生活和工作的事件影响，再加上Vulkan上面有许多的细节需要调整，导致这个效果拖了大半个月才算弄好。</p><p>这篇文章简单记录一下我实现过程中踩的各种坑。</p><h2 id="Vulkan实现阴影贴图过程中踩的坑">Vulkan实现阴影贴图过程中踩的坑</h2><h3 id="准备深度纹理">准备深度纹理</h3><p>在准备深度纹理上就有不少细节需要关注。</p><h4 id="VkImageCreateInfo-Usage">VkImageCreateInfo.Usage</h4><p>首先在创建深度纹理的时候，VkImageCreateInfo中的Usage需要添加采样的Flag位。这一位在延迟渲染和天空盒等没有直接对深度纹理采样的过程中是不需要添加的，只有ColorAttachment的颜色纹理需要添加。但是现在我们需要在光照计算中对阴影贴图（深度纹理）进行采样，所以得加上这一段。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">depthImageInfo.usage = VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT | VK_IMAGE_USAGE_SAMPLED_BIT;   <span class="hljs-comment">// 为了渲染深度图，需要增加采样图像用法</span><br></code></pre></td></tr></table></figure><h4 id="深度纹理的sampler">深度纹理的sampler</h4><p>因为深度纹理需要在shader中进行采样，所以深度纹理需要创建它对应的sampler（之前因为不需要采样所以是不需要的）。</p><p>深度纹理的sampler设置和颜色纹理差不多，但是有以下几点需要修改：</p><ul><li>borderColor = VK_BORDER_COLOR_FLOAT_OPAQUE_WHITE: 边缘的颜色设为白色，也就是最大的深度值（1.0）。和颜色不同，颜色纹理一般是设置为BLACK。</li><li>compareEnable = VK_TRUE：需要开启比较，在光照渲染的时候会用到。</li><li>compareOp = VK_COMPARE_OP_LESS： 比较的方法，这里用LESS的方法，和pipeline中的那个类似</li></ul><p>详细的代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++">VkSamplerCreateInfo samplerInfo&#123;&#125;;<br>samplerInfo.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO;<br>samplerInfo.magFilter = VK_FILTER_LINEAR;<br>samplerInfo.minFilter = VK_FILTER_LINEAR;<br>samplerInfo.mipmapMode = VK_SAMPLER_MIPMAP_MODE_LINEAR;<br>samplerInfo.addressModeU = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE;<br>samplerInfo.addressModeV = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE;<br>samplerInfo.addressModeW = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE;<br>samplerInfo.anisotropyEnable = VK_FALSE;<br>samplerInfo.borderColor = VK_BORDER_COLOR_FLOAT_OPAQUE_WHITE;<br>samplerInfo.compareEnable = VK_TRUE;<br>samplerInfo.compareOp = VK_COMPARE_OP_LESS;<br><br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">vkCreateSampler</span>(VulkanGraphicsDevice::<span class="hljs-built_in">GetGraphicsDevice</span>()-&gt;<span class="hljs-built_in">GetDevice</span>(), &amp;samplerInfo, <span class="hljs-literal">nullptr</span>, &amp;m_sampler) != VK_SUCCESS) &#123;<br>    <span class="hljs-keyword">throw</span> std::<span class="hljs-built_in">runtime_error</span>(<span class="hljs-string">&quot;failed to create texture sampler!&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="深度纹理的输入格式">深度纹理的输入格式</h4><p>在渲染阴影贴图纹理的renderpass中，我们要设定阴影贴图的<strong>attachment.finalLayout</strong>，这个finalLayout可能是<strong>VK_IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL</strong>，或者是<strong>VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL</strong>，这两个layout是没有办法作为输入传到shader中的。</p><p>为了让光照计算阶段的shader能够读取阴影贴图纹理，我们需要在光源渲染完阴影贴图后（vkCmdEndRenderPass）以及光照计算之前（vkCmdBeginRenderPass）将纹理的layout装换，这就需要使用到<strong>pipelineBarrier</strong>。</p><p>转换的代码如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 创建图像内存屏障</span><br>VkImageMemoryBarrier imageMemoryBarrier = &#123;&#125;;<br>imageMemoryBarrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;<br>imageMemoryBarrier.oldLayout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL;<br>imageMemoryBarrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;<br>imageMemoryBarrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;<br>imageMemoryBarrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;<br>imageMemoryBarrier.image = m_depthTexture-&gt;m_image;<br>imageMemoryBarrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_DEPTH_BIT;<br>imageMemoryBarrier.subresourceRange.baseMipLevel = <span class="hljs-number">0</span>;<br>imageMemoryBarrier.subresourceRange.levelCount = <span class="hljs-number">1</span>;<br>imageMemoryBarrier.subresourceRange.baseArrayLayer = <span class="hljs-number">0</span>;<br>imageMemoryBarrier.subresourceRange.layerCount = <span class="hljs-number">1</span>;<br>imageMemoryBarrier.srcAccessMask = VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT;<br>imageMemoryBarrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;<br><br><span class="hljs-comment">// 调用 vkCmdPipelineBarrier</span><br><span class="hljs-built_in">vkCmdPipelineBarrier</span>(<br>    frameInfo.commandBuffer,<br>    VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT,<br>    VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT,<br>    <span class="hljs-number">0</span>,<br>    <span class="hljs-number">0</span>, <span class="hljs-literal">nullptr</span>,<br>    <span class="hljs-number">0</span>, <span class="hljs-literal">nullptr</span>,<br>    <span class="hljs-number">1</span>, &amp;imageMemoryBarrier<br>);<br></code></pre></td></tr></table></figure><p>这里比较关键的就是：</p><ul><li>oldLayout/newLayout: VK_IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL -&gt; VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL</li><li>srcAccessMask/dstAccessMask: VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT -&gt; VK_ACCESS_SHADER_READ_BIT</li></ul><h3 id="渲染深度纹理">渲染深度纹理</h3><p>好了，关于纹理准备部分大概的几个关键点就是这些了（可能还有些细碎的记不太清楚了。。。），接下来就是生成和使用深度纹理的部分了。</p><h3 id="viewport和scissor">viewport和scissor</h3><p>在我们每个渲染system进行渲染之前，都会BeginRenderPass，在这个操作之后会设定<strong>viewport</strong>和<strong>scissor</strong>的大小。</p><p>之前都是默认使用swapchain的extent大小，但是在渲染阴影贴图的时候需要将viewport和scissor改为阴影贴图的尺寸，否则渲染出来的阴影贴图就要么不全，要么超出了窗口尺寸报错了。</p><p>代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 阴影贴图渲染系统设定renderArea的尺寸</span><br>renderAreaExtent = &#123;SHADOW_RESOLUTION, SHADOW_RESOLUTION&#125;;<br><br><span class="hljs-comment">// ......</span><br><span class="hljs-comment">// BeginRenderPass中修改viewport和scissor大小（也不是所有系统都需要）</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">VulkanRenderSystem::BeginRenderPass</span><span class="hljs-params">(VkCommandBuffer commandBuffer, VkFramebuffer framebuffer)</span></span><br><span class="hljs-function"></span>&#123;<br>    VkRenderPassBeginInfo renderPassInfo = &#123;&#125;;<br>    renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO;<br>    renderPassInfo.renderPass = m_renderPass;<br>    <span class="hljs-comment">// 没有传入framebuffer的话就用默认的系统统一framebuffer</span><br>    renderPassInfo.framebuffer = framebuffer == VK_NULL_HANDLE ? m_framebuffer : framebuffer;<br><br>    renderPassInfo.renderArea.offset = &#123; <span class="hljs-number">0</span>, <span class="hljs-number">0</span> &#125;;<br>    renderPassInfo.renderArea.extent = renderAreaExtent;<br>    <br>    renderPassInfo.clearValueCount = <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(m_clearValues.<span class="hljs-built_in">size</span>());<br>    renderPassInfo.pClearValues = m_clearValues.<span class="hljs-built_in">data</span>();<br>        <br>    <span class="hljs-built_in">vkCmdBeginRenderPass</span>(commandBuffer, &amp;renderPassInfo, VK_SUBPASS_CONTENTS_INLINE);<br><br>    VkViewport viewport&#123;&#125;;<br>    viewport.x = <span class="hljs-number">0.0f</span>;<br>    viewport.y = <span class="hljs-number">0.0f</span>;<br>    viewport.width = <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">float</span>&gt;(renderAreaExtent.width); <span class="hljs-comment">//static_cast&lt;float&gt;(m_swapChain-&gt;GetSwapChainExtent().width);</span><br>    viewport.height = <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">float</span>&gt;(renderAreaExtent.height); <span class="hljs-comment">//static_cast&lt;float&gt;(m_swapChain-&gt;GetSwapChainExtent().height);</span><br>    viewport.minDepth = <span class="hljs-number">0.0f</span>;<br>    viewport.maxDepth = <span class="hljs-number">1.0f</span>;<br>    VkRect2D scissor&#123;&#123;<span class="hljs-number">0</span>,<span class="hljs-number">0</span>&#125;, renderAreaExtent&#125;;<br>    <span class="hljs-built_in">vkCmdSetViewport</span>(commandBuffer, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, &amp;viewport);<br>    <span class="hljs-built_in">vkCmdSetScissor</span>(commandBuffer, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, &amp;scissor);<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上面示例代码还处理了clearValue，就相当于OpenGL中的glClear和glClearColor，这里要对应我们的attachment的数量给出对应的clearValue数量，以及合适的clearColor值。</p><h3 id="使用深度纹理">使用深度纹理</h3><p>最后是使用深度纹理这部分了，这里主要有两点：</p><h4 id="使用sampler2DShadow代替sampler2D">使用sampler2DShadow代替sampler2D</h4><p>在渲染的光照阶段shader中传入阴影贴图：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// ...</span><br><span class="hljs-keyword">layout</span>(set = <span class="hljs-number">1</span>, <span class="hljs-keyword">binding</span> = <span class="hljs-number">4</span>) <span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2DShadow</span> shadowmap_tex;<br><span class="hljs-comment">// ...</span><br></code></pre></td></tr></table></figure><p>这里使用的是sampler2DShadow这种形式，sampler2DShadow是专门用于阴影贴图（深度纹理）的采样，存储的是单通道深度值（而非颜色）。其实这并不是一个Vulkan的新特性，在OpenGL中就已经有这样的用法。</p><p>在处理阴影贴图的时候，sampler2DShadow的应用方法如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl">shadow += <span class="hljs-built_in">texture</span>(shadowmap_tex, <span class="hljs-type">vec3</span>(proj_coord.xy, proj_coord.z<span class="hljs-number">-0.01</span>));          <br></code></pre></td></tr></table></figure><p>texture传入sampler2DShadow纹理的时候，除了传入采样坐标xy之外，还需要额外传入一个深度值。函数会将采样阴影贴图得到的深度和传入的深度值进行对比，返回一个表示阴影的浮点数（0 表示完全阴影，1 表示完全光照）。</p><p>这样实现的有着高效的优点：</p><ul><li><p>硬件加速：sampler2DShadow 是专门为阴影贴图采样设计的，现代图形硬件针对这种类型的采样进行了优化。当使用 sampler2DShadow 时，<strong>硬件可以直接在纹理查找阶段进行深度比较，这使得阴影计算更加高效</strong>。相比之下，如果使用 sampler2D 手动实现相同的阴影计算，需要额外的步骤来读取深度值并进行比较，这会增加计算量和内存访问。</p></li><li><p>减少带宽需求：由于硬件在采样过程中直接进行深度比较，减少了将深度值从纹理中读取到着色器中进行处理的需求，从而<strong>降低了内存带宽的使用</strong>。这对于资源受限的设备（如移动设备）尤为重要，可以在不牺牲太多性能的情况下实现阴影效果。</p></li><li><p>更好的阴影效果：硬件优化的采样算法可以有效地减少阴影走样（如锯齿和闪烁）。通过使用 sampler2DShadow，开发者可以利用硬件的抗锯齿功能，获得更加平滑和自然的阴影效果。</p></li></ul><h4 id="注意深度（z）的范围！">注意深度（z）的范围！</h4><p>最后这一点可能是我被坑的最惨的一点，也是让我写这篇文章的源动力之一。下面是我在OpenGL中实现的光照计算阴影的部分代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 转换到-1,1的范围，再转到0,1的范围</span><br><span class="hljs-type">vec4</span> frag_pos_light_space = light_space_matrix * frag_world_pos;<br><span class="hljs-comment">// perform perspective divide</span><br><span class="hljs-type">vec3</span> proj_coord = frag_pos_light_space.xyz / frag_pos_light_space.w;<br><span class="hljs-comment">// transform to [0,1] range</span><br>proj_coord = proj_coord * <span class="hljs-number">0.5</span> + <span class="hljs-number">0.5</span>;<br><br><span class="hljs-comment">// get depth of current fragment from light&#x27;s perspective</span><br><span class="hljs-type">float</span> current_depth = proj_coord.z;<br><br><span class="hljs-comment">// keep the shadow at 0.0 when outside the far_plane region of the light&#x27;s frustum.</span><br><span class="hljs-keyword">if</span> (proj_coord.z &gt; <span class="hljs-number">1.0</span> || proj_coord.z &lt; <span class="hljs-number">0.0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span>;<br><br><span class="hljs-comment">// ... shadow采样比较，略</span><br></code></pre></td></tr></table></figure><p>下面是Vulkan中的</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 转换到-1,1的范围，再转到0,1的范围</span><br><span class="hljs-type">vec4</span> frag_pos_light_space = light_space_mat * frag_world_pos;<br><span class="hljs-comment">// perform perspective divide</span><br><span class="hljs-type">vec3</span> proj_coord = frag_pos_light_space.xyz / frag_pos_light_space.w;<br><span class="hljs-comment">// transform to [0,1] range</span><br><span class="hljs-comment">// !!!注意注意，这里只对xy做[0,1]映射，不能修改z，否则深度比较会出错</span><br>proj_coord.xy = proj_coord.xy * <span class="hljs-number">0.5</span> + <span class="hljs-number">0.5</span>;<br><br><span class="hljs-comment">// keep the shadow at 0.0 when outside the far_plane region of the light&#x27;s frustum.</span><br><span class="hljs-keyword">if</span> (proj_coord.z &gt; <span class="hljs-number">1.0</span> || proj_coord.z &lt; <span class="hljs-number">0.0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span>;<br><br><span class="hljs-type">float</span> shadow = <span class="hljs-number">0.0</span>f;<br><br><span class="hljs-comment">// ... shadow采样比较，略</span><br><br></code></pre></td></tr></table></figure><p>细心的你一定看出最重要的区别了，那就是vulkan中的这一段：</p><blockquote><p>proj_coord.xy = proj_coord.xy * 0.5 + 0.5;</p></blockquote><p>为什么OpenGL中没有指定xy呢？</p><p>我们这一步的目的是为了将坐标从NDC的坐标系[-1,1]下转到[0,1]，重点在于：</p><p><strong>OpenGL在NDC坐标系下，深度值（z）的范围是[-1,1]，而Vulkan中是[0,1]。</strong></p><p>这句话我在之前也听说过，但是并没有在这里关联起来，因此在一开始Vulkan的实现中我也将proj_coord.z的值进行了*0.5+0.5的映射。但是Vulkan中一开始proj_coord.z的值就是在[0,1]区间的，这么一映射导致了阴影结果完全不对。</p><p>在好几天的百思不得其解，仔细筛查后，终于发现了这个问题，改正之后阴影完美的绘制出来了。被这么一个小地方卡主这么久真的是让我哭笑不得，打算写一篇文章记录一下。</p><h2 id="结语">结语</h2><p><img src="Vulkan-shadowmap.png" alt="vulkan阴影贴图效果"></p><p>好了，以上就是我在实现阴影贴图的一些小记录了。效果虽然和之前OpenGL实现的没什么太大区别，但是真的也是让我对Vulkan的理解也更加深入了。哈哈，坑踩多了慢慢也会变成专家，后面会继续将Vulkan的内容做下去。</p><p>既然实现了阴影贴图，那csm和rsm这些延伸内容也会顺便实现了，如果没什么特别需要记录的话就到时简短的写一篇文章记录一下就行了。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>虚幻引擎之Android环境配置</title>
    <link href="/2025/04/06/ue-android-setup/"/>
    <url>/2025/04/06/ue-android-setup/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>最近工作又出现了变动，去年我这个快十年游戏客户端和引擎开发经验的被调去做AI后端，迷茫了一年后今年又要被调去做安卓Native C++开发了，真的是这两年转的方向比我原来工作七八年的时间都要多。</p><p>不过至少安卓Native C++开发比后端开发更加贴合我的工作了，说不定也是件好事。周末闲来无事，想着我好像从来没有自己构建过UE的安卓工程，打算来走走这个流程。</p><h2 id="构建安卓环境">构建安卓环境</h2><h3 id="Android-Studio">Android Studio</h3><p>要构建安卓包，首先需要下载<a href="https://developer.android.google.cn/studio?hl=zh-cn"><strong>Android Studio</strong></a>，在官网下载后安装即可。</p><p>安装完运行Android studio，第一次打开会做Studio的初始化，需要安装一些默认的组件，选择需要的（一般是提示的都选了）的后等待下载安装完成即可。</p><p><img src="android_studio_setup.png" alt="AndroidStudio第一次打开配置"></p><p>然后我们会进到Android Studio的欢迎界面，由于我们一般不用Android Studio来开发UE的工程，这里我们不打开我们的C++代码目录，而是直接打开<strong>More Actions-&gt;SDK Manager</strong>，在弹出来的设置界面中，选择<strong>SDK Tools</strong>，勾选<strong>NDK(Side by side)和Android SDK Command-line Tools(latest)</strong>，然后点击Apply或者OK，Android Studio会自动安装对应的NDK和SDK命令行工具。</p><p><img src="sdk_manager.png" alt="安装NDK和命令行工具"></p><h3 id="运行虚幻引擎设定脚本">运行虚幻引擎设定脚本</h3><p>好了，Android Studio的部分就到这了，接下来我们要打开引擎的安装路径，找到<strong>Engine/Extra/Android</strong>目录。这个目录下面有三个名为SetupAndroid的脚本，后缀为.bat是Windows平台下的脚本，.sh是Linux下，.command是MacOS的脚本。</p><p><img src="setup_android_script.png" alt="SetupAndroid脚本"></p><p>运行对应系统的脚本，这个脚本会自动配置虚幻引擎构建安卓平台所需要的内容，并且会自动下载缺少的部分。</p><p><img src="run_setup_android.png" alt="运行SetupAndroid脚本"></p><p>（<em>注：上面这张图是我已经设定好一次后再运行一次脚本的结果，可能和第一次运行的表现不一样，但是结果返回都是成功。</em>）</p><p>当脚本跑完之后，我们需要重启电脑，保证配置生效。</p><h3 id="虚幻引擎构建安卓包">虚幻引擎构建安卓包</h3><p>然后打开对应的虚幻引擎项目，在<strong>平台-&gt;Android中选择打包项目</strong>：<br><img src="build_android_project.png" alt="打包安卓项目"><br>和构建Windows包类似，你需要选择一个目录，然后编辑器会自动烘焙、构建对应的APK包。</p><p>这里我们可以看到有几个选项：<strong>ASTC、DXT和ETC2</strong>，这是指定打包的纹理压缩格式。</p><ul><li>ASTC：适用于对图像质量要求较高、纹理复杂度较大的项目，如 AAA 级游戏、虚拟现实（VR）和增强现实（AR）应用等。由于其高压缩率和高质量的特点，ASTC 可以在不牺牲太多画质的情况下减少纹理数据的存储空间。</li><li>DXT：在 PC 游戏开发中仍然被广泛使用，特别是对于那些需要兼容旧显卡的项目。由于其在 PC 平台上的广泛支持，DXT 格式可以确保游戏在各种硬件环境下都能正常显示。</li><li>ETC2：主要用于移动游戏和应用开发，特别是在 Android 平台上。由于大多数 Android 设备支持 ETC2，使用该格式可以确保游戏在移动设备上具有良好的性能和兼容性。</li></ul><p>根据项目自身选择合适的纹理格式，然后就是等待了，如果需要烘焙的资源比较多的话，时间可能会比较久。比如在我的ROG枪神12笔记本上，第一人称射击模板项目打包就用了33分钟，</p><p><img src="Android_build_success.png" alt="安卓构建成功"></p><p>打包的输出结果如下，你可以使用APK包安装到安卓环境上进行测试。<br><img src="Android_package_file.png" alt="安卓包文件"></p><p>安装到安卓环境可以使用adb命令，用</p><blockquote><p>adb devices</p></blockquote><p>命令可以查看当前环境下的安卓设备，然后使用</p><blockquote><p>adb install</p></blockquote><p>命令将apk安装到设备上。</p><p><img src="install_android_package.png" alt="安装安卓包"></p><h4 id="No-Google-Play-Store-Key-No-OBB-found-and-no-store-key">No Google Play Store Key (No OBB found and no store key)</h4><p>装完包，app打开可能会出现上面这个报错，在网上查了下可以通过将<strong>项目设定 &gt; 平台/Android &gt; Package game data inside .apk</strong>打开解决（参考资料2），不过这个可能并不是最终的原因，需要进一步的调查。</p><h4 id="直接快速启动">直接快速启动</h4><p>虚幻引擎还提供了直接快速启动的方式，也就是在检测到本地的安卓设备后（我使用的是Android Studio的模拟环境），可以从平台选择对应的设备快速打开：</p><p><img src="android_quick_start.png" alt="快速启动"></p><p>这样极大的便利了安卓开发流程，并且Log可以在电脑上直接看到，推荐这种做法。</p><p><img src="Android_sim.gif" alt="安卓模拟器的效果（似乎有点小bug）"></p><h2 id="结语">结语</h2><p>好了，这就是基础的虚幻引擎安卓打包流程了，其实这么看来虚幻项目在安卓上的流程还是比较简单的，当然难的是在实实在在的项目开发上，这就是我后面需要慢慢学习的东西了。</p><h2 id="参考资料">参考资料</h2><p><a href="https://dev.epicgames.com/documentation/en-us/unreal-engine/setting-up-android-sdk-and-ndk-for-unreal?application_version=4.27">https://dev.epicgames.com/documentation/en-us/unreal-engine/setting-up-android-sdk-and-ndk-for-unreal?application_version=4.27</a></p><p><a href="https://forums.unrealengine.com/t/solution-no-google-play-store-key-no-obb-found-and-no-store-key/464902/14">https://forums.unrealengine.com/t/solution-no-google-play-store-key-no-obb-found-and-no-store-key/464902/14</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>虚幻引擎</tag>
      
      <tag>android</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Vulkan中利用subpass实现延迟渲染</title>
    <link href="/2025/03/22/vulkan-defer-render/"/>
    <url>/2025/03/22/vulkan-defer-render/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p><img src="scene-defer.png" alt="另外一张平平无奇的渲染图"></p><p>这又是一张平平无奇的渲染图，和上一篇文章的那张图片好像也没什么区别。从表面上看是的，在渲染效果上这张图片没有什么进步，但是这张图片是用了另外的技术实现的，也就是<strong>延迟渲染</strong>。</p><p>延迟渲染这个概念在网上有很多的资料，我也在我<a href="https://ruochenhua.github.io/2024/10/19/defer-render/#">之前的一篇文章</a>介绍过，所以这篇文章我不会再对延迟渲染的概念做介绍。今天这篇文章的主要内容，是如何在Vulkan中实现这个效果。</p><h2 id="在Vulkan中实现延迟渲染">在Vulkan中实现延迟渲染</h2><p>当然，延迟渲染的原理是一样的，无论是用Vulkan还是OpenGL，大概分为两个步骤：</p><ul><li>几何阶段和光照阶段。在几何阶段搜集画面中用于光照计算的信息。</li><li>传输到光照阶段计算出最终的结果。</li></ul><p>既然Vulkan和OpenGL实现是差不多的，为什么这里还有专门写一篇文章呢？因为在Vulkan中，可以利用RenderPass中的subpass，来将两个步骤放到同一个render pass中，这样可以减少延迟渲染两个阶段之间的额外数据处理和传输，从而提升性能。</p><h3 id="Vulkan中的Render-Pass和Subpass">Vulkan中的Render Pass和Subpass</h3><p>在Vulkan里，Render Pass（渲染过程）是一个十分关键的概念，它对渲染操作的整体结构和流程进行了定义。简单来说，Render Pass规定了渲染操作要用到的附件（像颜色附件、深度模板附件等）、这些附件的格式以及它们在渲染过程中的使用方式。</p><p>Subpass（子通道）是 Render Pass 中的一个子集，代表了渲染过程中的一个特定阶段。每个Render Pass中至少都会有一个subpass，每个Subpass可以有自己的输入附件、颜色附件、深度模板附件等，并且可以定义这些附件的使用方式。<br>Subpass 的主要作用是将渲染过程拆分成多个步骤，每个步骤专注于完成特定的任务，例如几何阶段、光照阶段各自是一个单独的Subpass。通过使用 Subpass，可以在同一个渲染过程中高效地重用附件，避免不必要的内存读写操作。</p><h3 id="延迟渲染的render-pass创建">延迟渲染的render pass创建</h3><p>好的，在简单的介绍了一下render pass和subpass的关系之后，我们用实际的例子来介绍一下延迟渲染中具体怎么实现多个subpass的初始化。</p><p>首先，我们几何阶段需要输出四个颜色附件（位置、法线、反照率和材质参数）作为光照阶段的输入，在光照阶段需要输出一个颜色附件和深度附件作为后续渲染阶段（天空盒、后处理）的输入。因此一共有5个颜色附件和1个深度附件共6个附件。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs c++">std::vector&lt;VkAttachmentDescription&gt; geoStageOutputAttachments = &#123;&#125;;<br>&#123;<br>    <span class="hljs-comment">// 位置</span><br>    VkAttachmentDescription positionAttachment = &#123;&#125;;<br>    positionAttachment.format = VK_FORMAT_R32G32B32A32_SFLOAT;<br>    positionAttachment.samples = VK_SAMPLE_COUNT_1_BIT;<br>    positionAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;<br>    positionAttachment.storeOp = VK_ATTACHMENT_STORE_OP_STORE; <span class="hljs-comment">// </span><br>    positionAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;<br>    positionAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;<br>    positionAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;<br>    positionAttachment.finalLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;  <span class="hljs-comment">// </span><br>    geoStageOutputAttachments.<span class="hljs-built_in">push_back</span>(positionAttachment);<br>    <br>    <span class="hljs-comment">// 1法线</span><br>    VkAttachmentDescription normalAttachment = &#123;&#125;;<br>    <span class="hljs-comment">// ...和位置类似</span><br>    geoStageOutputAttachments.<span class="hljs-built_in">push_back</span>(normalAttachment);<br>    <br>    <span class="hljs-comment">// 2反照率</span><br>    VkAttachmentDescription albedoAttachment = &#123;&#125;;<br>    <span class="hljs-comment">// ...和位置类似</span><br>    geoStageOutputAttachments.<span class="hljs-built_in">push_back</span>(albedoAttachment);<br>    <br>    <span class="hljs-comment">// 3材质数据</span><br>    VkAttachmentDescription ormAttachment = &#123;&#125;;<br>    <span class="hljs-comment">// ...和位置类似</span><br>    geoStageOutputAttachments.<span class="hljs-built_in">push_back</span>(ormAttachment);<br><br>    <span class="hljs-comment">// 4输出颜色</span><br>    VkAttachmentDescription outputColorAttachment = &#123;&#125;;<br>    outputColorAttachment.format = VK_FORMAT_R8G8B8A8_SRGB;<br>    outputColorAttachment.samples = VK_SAMPLE_COUNT_1_BIT;<br>    outputColorAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;<br>    outputColorAttachment.storeOp = VK_ATTACHMENT_STORE_OP_STORE;<br>    outputColorAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;<br>    outputColorAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;<br>    outputColorAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;<br>    outputColorAttachment.finalLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;<br>    geoStageOutputAttachments.<span class="hljs-built_in">push_back</span>(outputColorAttachment);<br>&#125;<br><br><span class="hljs-comment">// 5深度</span><br>VkAttachmentDescription depthAttachment = &#123;&#125;;<br>depthAttachment.format = m_swapChain-&gt;<span class="hljs-built_in">FindDepthFormat</span>();<br>depthAttachment.samples = VK_SAMPLE_COUNT_1_BIT;        <br>depthAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;   <br><span class="hljs-comment">// depthAttachment.storeOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;</span><br>depthAttachment.storeOp = VK_ATTACHMENT_STORE_OP_STORE;     <br><br>depthAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;<br>depthAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;<br>depthAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;      <br>depthAttachment.finalLayout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;<br>geoStageOutputAttachments.<span class="hljs-built_in">push_back</span>(depthAttachment);<br></code></pre></td></tr></table></figure><p>上面是创建了所有attachment，然后需要创建对应的attachment reference，其中前五个attachment是颜色附件的，最后一个是深度附件。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 颜色附件reference</span><br>std::vector&lt;VkAttachmentReference&gt; geoStageAttachmentRefs = &#123;&#125;;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; geoStageOutputAttachments.<span class="hljs-built_in">size</span>()<span class="hljs-number">-1</span>; i++)    <br>&#123;<br>    VkAttachmentReference colorAttachmentRef = &#123;&#125;;<br>    colorAttachmentRef.attachment = <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(i);  <br>    colorAttachmentRef.layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;  <br>    geoStageAttachmentRefs.<span class="hljs-built_in">push_back</span>(colorAttachmentRef);<br>&#125;<br><br><span class="hljs-comment">// 深度附件reference</span><br>VkAttachmentReference depthAttachmentRef = &#123;&#125;;<br>depthAttachmentRef.attachment = <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(geoStageOutputAttachments.<span class="hljs-built_in">size</span>()<span class="hljs-number">-1</span>); <span class="hljs-comment">//depth位置在最后</span><br>depthAttachmentRef.layout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL;<br><br></code></pre></td></tr></table></figure><p>接下来便是subpass的创建了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/*</span><br><span class="hljs-comment">* 子通道依赖用于描述子通道之间的执行顺序和数据依赖关系。</span><br><span class="hljs-comment">* 它确保一个子通道在另一个子通道完成特定操作后才开始执行，从而保证渲染结果的正确性。</span><br><span class="hljs-comment">*/</span><br><span class="hljs-comment">// 子通道依赖:定义子通道之间的依赖关系，确保渲染操作按正确顺序执行。</span><br><span class="hljs-function">std::vector&lt;VkSubpassDescription&gt; <span class="hljs-title">subpasses</span><span class="hljs-params">(<span class="hljs-number">2</span>)</span></span>;<br><span class="hljs-comment">// 两个subpass</span><br>subpasses[<span class="hljs-number">0</span>].pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS;<span class="hljs-comment">// 指定绑定的管线类型(这里表示绑定图形管线)</span><br>subpasses[<span class="hljs-number">0</span>].colorAttachmentCount = <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(geoStageAttachmentRefs.<span class="hljs-built_in">size</span>()<span class="hljs-number">-1</span>); <span class="hljs-comment">// 颜色附件数量</span><br>subpasses[<span class="hljs-number">0</span>].pColorAttachments = geoStageAttachmentRefs.<span class="hljs-built_in">data</span>(); <span class="hljs-comment">// 颜色附件引用的指针</span><br>subpasses[<span class="hljs-number">0</span>].pDepthStencilAttachment = &amp;depthAttachmentRef;<span class="hljs-comment">// 深度模板附件引用的指针</span><br><br><span class="hljs-comment">// 几何阶段作为光照阶段输入的attachment refs</span><br>std::vector&lt;VkAttachmentReference&gt; inputAttachmentRefs;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; geoStageOutputAttachments.<span class="hljs-built_in">size</span>()<span class="hljs-number">-2</span>; i++)<br>&#123;<br>    VkAttachmentReference inputAttachmentRef = &#123;&#125;;<br>    inputAttachmentRef.attachment = <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(i);<br>    inputAttachmentRef.layout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;<br>    inputAttachmentRefs.<span class="hljs-built_in">push_back</span>(inputAttachmentRef);<br>&#125;<br><br>VkAttachmentReference outputAttachmentRef = &#123;&#125;;<br>outputAttachmentRef.attachment = geoStageOutputAttachments.<span class="hljs-built_in">size</span>() - <span class="hljs-number">2</span>;  <br>outputAttachmentRef.layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;<br>subpasses[<span class="hljs-number">1</span>].pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS;<br>subpasses[<span class="hljs-number">1</span>].inputAttachmentCount = <span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">uint32_t</span>&gt;(inputAttachmentRefs.<span class="hljs-built_in">size</span>());<br>subpasses[<span class="hljs-number">1</span>].pInputAttachments = inputAttachmentRefs.<span class="hljs-built_in">data</span>();<br>subpasses[<span class="hljs-number">1</span>].colorAttachmentCount = <span class="hljs-number">1</span>;<br>subpasses[<span class="hljs-number">1</span>].pColorAttachments = &amp;outputAttachmentRef;<br><span class="hljs-comment">// !光照阶段不要修改depth，不需要深度附件否则后面的步骤会出</span><br>subpasses[<span class="hljs-number">1</span>].pDepthStencilAttachment = &amp;depthAttachmentRef;<br></code></pre></td></tr></table></figure><p>这里可以看到我们创建了两个subpass：</p><ul><li>subpasses[0]是几何阶段的subpass，它的结果输出到四张颜色附件上，因此它的ColorAttachmentCount是总的颜色附件数量（5）减一等于4。</li><li>subpasses[1]是光照阶段的subpass，它需要几何阶段的输出作为输入。我们可以将几何阶段的输出保存写到纹理里面，再利用纹理数据传输到光照阶段，这种处理和OpenGL类似，但是效率不高。Vulkan中可以利用InputAttachment将前面subpass的结果作为后续subpass的输入。</li></ul><blockquote><p>Input Attachment 是 Subpass 可以使用的一种特殊类型的附件。它允许在一个 Subpass 中写入数据到附件，然后在后续的 Subpass 中直接读取这些数据，而无需将数据从显存中复制到内存再进行传递。这种机制使得数据可以在不同的渲染阶段之间快速共享，提高了渲染效率。</p></blockquote><p>最后，我们需要定义subpass之间的依赖（dependency）信息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">/*</span><br><span class="hljs-comment">* 子通道依赖用于描述子通道之间的执行顺序和数据依赖关系。</span><br><span class="hljs-comment">* 它确保一个子通道在另一个子通道完成特定操作后才开始执行，从而保证渲染结果的正确性。</span><br><span class="hljs-comment">*/</span><br><span class="hljs-comment">// 子通道依赖:定义子通道之间的依赖关系，确保渲染操作按正确顺序执行。</span><br>VkSubpassDependency dependency = &#123;&#125;;<br>dependency.srcSubpass = <span class="hljs-number">0</span>;   <span class="hljs-comment">// 指定源子通道</span><br>dependency.srcAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;   <span class="hljs-comment">// 指定源子通道的访问掩码(这里表示对颜色附件写入数据）</span><br>dependency.srcStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT<br>| VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;   <span class="hljs-comment">// 指定管线阶段(这里表示包括颜色附件输出阶段和早期片段测试阶段)</span><br><br>dependency.dstSubpass = <span class="hljs-number">1</span>;  <span class="hljs-comment">// 指定目标子通道</span><br>dependency.dstStageMask= VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT<br>| VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT;   <span class="hljs-comment">// 指定目标子通道的管线阶段,和源子通道相同</span><br>dependency.dstAccessMask = VK_ACCESS_INPUT_ATTACHMENT_READ_BIT<br>| VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT; <span class="hljs-comment">// 指定目标子通道访问掩码,包括颜色附件写入和深度模板附件写入操作</span><br>dependency.dependencyFlags = VK_DEPENDENCY_BY_REGION_BIT; <span class="hljs-comment">// VK_DEPENDENCY_BY_REGION_BIT表示存在subpass前后的依赖关系</span><br><br></code></pre></td></tr></table></figure><p>如上的依赖关系设定子通道0（几何阶段）执行结束并对颜色附件进行写入操作之后，子通道1（光照阶段）才会进行执行。至此，多subpass的初始化便完成了。</p><h3 id="InputAttachment在shader中的输入">InputAttachment在shader中的输入</h3><p>上一小节我们介绍了子通道0的输出作为子通道1的输入，这个流程不需要经过纹理的写入和读取，而是可以经过<strong>InputAttachment</strong>的传递。在shader中，我们想要读取InputAttachment的数据的话，需要经过如下的设定。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-keyword">layout</span>(input_attachment_index = <span class="hljs-number">0</span>, set = <span class="hljs-number">1</span>, <span class="hljs-keyword">binding</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">uniform</span> subpassInput inPosition;<br><span class="hljs-keyword">layout</span>(input_attachment_index = <span class="hljs-number">1</span>, set = <span class="hljs-number">1</span>, <span class="hljs-keyword">binding</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">uniform</span> subpassInput inNormal;<br><span class="hljs-keyword">layout</span>(input_attachment_index = <span class="hljs-number">2</span>, set = <span class="hljs-number">1</span>, <span class="hljs-keyword">binding</span> = <span class="hljs-number">2</span>) <span class="hljs-keyword">uniform</span> subpassInput inAlbedo;<br><span class="hljs-keyword">layout</span>(input_attachment_index = <span class="hljs-number">3</span>, set = <span class="hljs-number">1</span>, <span class="hljs-keyword">binding</span> = <span class="hljs-number">3</span>) <span class="hljs-keyword">uniform</span> subpassInput inOrm;<br></code></pre></td></tr></table></figure><ul><li><p>layout(input_attachment_index = 0)：input_attachment_index 是一个布局限定符，用于指定要读取的输入附件的索引。在 Render Pass 中，每个附件都有一个唯一的索引，这里的 0 表示从索引为 0 的颜色附件中读取数据。</p></li><li><p>set = 1：set 用于指定描述符集的编号。在 Vulkan 中，描述符集是一组描述符的集合，用于向着色器传递数据。这里的 1 表示该输入附件属于编号为 1 的描述符集。</p></li><li><p>binding = 0：binding 用于指定描述符在描述符集中的绑定点。同一个描述符集中的不同描述符通过绑定点来区分。这里的 0 表示该输入附件在编号为 1 的描述符集中的绑定点为 0。</p></li><li><p>uniform subpassInput：uniform 表示这是一个统一变量，意味着在整个着色器调用过程中其值保持不变。subpassInput 是 Vulkan 着色器语言中特有的类型，用于表示从 Subpass 输入附件中读取的数据。</p></li><li><p>inPosition：这是变量的名称，用于在着色器代码中引用从索引为 0 的颜色附件中读取的数据。</p></li></ul><p>需要注意的是，InputAttachment的也需要设定对应的DescriptorSetLayout信息，以便在DescriptorSet中被正确的引用，这里我简单用KongEngine封装过的函数来示意一下。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> textureLayout = VulkanDescriptorSetLayout::<span class="hljs-built_in">Builder</span>()<br>    <span class="hljs-comment">// VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT</span><br>    .<span class="hljs-built_in">AddBinding</span>(<span class="hljs-number">0</span>, VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT, VK_SHADER_STAGE_FRAGMENT_BIT, <span class="hljs-number">1</span>) <span class="hljs-comment">// position texture</span><br>    .<span class="hljs-built_in">AddBinding</span>(<span class="hljs-number">1</span>, VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT, VK_SHADER_STAGE_FRAGMENT_BIT, <span class="hljs-number">1</span>) <span class="hljs-comment">// normal texture</span><br>    .<span class="hljs-built_in">AddBinding</span>(<span class="hljs-number">2</span>, VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT, VK_SHADER_STAGE_FRAGMENT_BIT, <span class="hljs-number">1</span>) <span class="hljs-comment">// albedo texture</span><br>    .<span class="hljs-built_in">AddBinding</span>(<span class="hljs-number">3</span>, VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT, VK_SHADER_STAGE_FRAGMENT_BIT, <span class="hljs-number">1</span>) <span class="hljs-comment">// orm texture</span><br>    .<span class="hljs-built_in">AddBinding</span>(<span class="hljs-number">4</span>, VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER, VK_SHADER_STAGE_FRAGMENT_BIT, <span class="hljs-number">1</span>) <span class="hljs-comment">// direct shadow map   </span><br>    .<span class="hljs-built_in">Build</span>();<br></code></pre></td></tr></table></figure><p>另外还需要注意的是，InputAttachment它并不是纹理，所以并不能按照以往用纹理传递几何阶段的信息那样对InputAttachment的数据做<strong>texture()</strong>，而是需要使用<strong>subpassLoad</strong>函数。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> fragPos = subpassLoad(inPosition).xyz;<br><span class="hljs-type">vec3</span> objNormal = subpassLoad(inNormal).xyz;<br><span class="hljs-type">vec4</span> orm = subpassLoad(inOrm);<br></code></pre></td></tr></table></figure><p>subpassLoad函数不需要提供额外的索引输入。在 Render Pass 的不同 Subpass 中，每个像素的处理是一一对应的。也就是说，在第一个 Subpass 里某个像素位置写入的数据，在后续使用 Input Attachment 的 Subpass 中，相同像素位置就能读取到对应的数据。</p><p>subpassLoad 函数默认读取的是当前正在处理的像素位置的数据，它会自动关联到当前片段着色器所处理的像素。所以，不需要额外提供像 UV 坐标这类信息来指定读取位置，因为当前片段的位置就决定了要读取的数据位置。</p><h3 id="其他注意事项">其他注意事项</h3><p>至此，延迟渲染的关键步骤就是这些了。另外还需要注意的一点是，延迟渲染的光照subpass不能再对深度附件做写入了，否则后续的渲染阶段（尤其是天空盒这种需要获取场景深度信息的）的输出结果会受到影响。这里也花了我一些时间来debug。想要屏蔽掉光照阶段的深度写入，不把深度附件传入到光照阶段即可；另外一个比较推荐的方式则是在光照阶段的pipeline config里面，将depthWriteEnable关闭。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">pipelineConfig.subpass = <span class="hljs-number">1</span>;<br><span class="hljs-comment">// !光照阶段修改深度附件，否则后面的步骤会出错</span><br>pipelineConfig.depthStencilInfo.depthWriteEnable = VK_FALSE;<br></code></pre></td></tr></table></figure><h2 id="结语">结语</h2><p>好了，今天这篇文章的内容就到这了。可能Vulkan相关的内容似乎不可避免的需要贴很多代码，因为Vulkan相比较OpenGL还是太底层了，很多步骤都需要依靠调用者自己处理。但是对底层的灵活可定制化确实也体现出了它的强大，subpass的设计我认为就是很好的一个例子。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>Vulkan</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Vulkan接入小总结</title>
    <link href="/2025/03/15/kong-vulkan-intro/"/>
    <url>/2025/03/15/kong-vulkan-intro/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p><img src="vulkan-scene.png" alt="一张平平无奇的渲染图"></p><p>这是一张平平无奇的渲染图，没有阴影，没有IBL，也没有反射等各种酷炫高大上的效果。</p><p>但这张平平无奇的渲染图是我断断续续花了一个月的时间才完成的结果：<strong>这是KongEngine接入Vulkan后得到的最新效果</strong>。在前面的几篇文章我也提到过，我最近一直在处理这个事，为此我将KongEngine的渲染代码重构，并将Vulkan整合进来。当然原有的OpenGL能力我还是保留着，目前的目标是先利用Vulkan还原原有的OpenGL效果。</p><p>这篇文章也不是什么Vulkan入门教程，不会系统的讲Vulkan的初始化流程是怎么样的，Render Pass和Pipeline是什么，DescriptorSet要怎么设定等等。这些内容太复杂了，很难在一篇文章内讲清楚，况且我现在也不能说是很精通。这篇文章只是会大概介绍一下KongEngine目前的Vulkan结构。</p><h2 id="KongEngine的Vulkan结构">KongEngine的Vulkan结构</h2><p>如下图所示:</p><p><img src="kong-render-structure.png" alt="KongEngine的渲染结构"></p><p>KongEngine目前将图形API的部分整合了起来，封装成了OpenGL部分和Vulkan的部分。目前这两个部分的流程还是有一定的区别，本来按照原有计划是将OpenGL的渲染流程按照Vulkan的流程来实现的，但是发现这样做难度不小，改动很大。放到后面再慢慢整合吧。</p><p>为了资源管理的统一，我将Buffer、Texture等通用的概念封装成了基础类，OpenGL和Vulkan会分别实现对应的子类来实现具体的流程。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">enum</span> <span class="hljs-title class_">BufferType</span> : <span class="hljs-type">short</span><br>&#123;<br>    VERTEX_BUFFER = <span class="hljs-number">0</span>,<br>    INDEX_BUFFER,<br>    UNIFORM_BUFFER,<br>    NONE_BUFFER,<br>    <br>&#125;;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">KongBuffer</span><br>&#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">KongBuffer</span>() = <span class="hljs-keyword">default</span>;<br>    <span class="hljs-keyword">virtual</span> ~<span class="hljs-built_in">KongBuffer</span>() = <span class="hljs-keyword">default</span>;<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Initialize</span><span class="hljs-params">(BufferType type, <span class="hljs-type">uint64_t</span> size, <span class="hljs-type">uint32_t</span> instanceCount, <span class="hljs-type">void</span>* data = <span class="hljs-literal">nullptr</span>)</span></span><br><span class="hljs-function">    </span>&#123;<br>        m_type = type;<br>        m_isValid = <span class="hljs-literal">true</span>;<br>    &#125;<br>    <br>    <span class="hljs-built_in">KongBuffer</span>(<span class="hljs-type">const</span> KongBuffer&amp; other) = <span class="hljs-keyword">delete</span>;<br>    KongBuffer&amp; <span class="hljs-keyword">operator</span>=(<span class="hljs-type">const</span> KongBuffer&amp; other) = <span class="hljs-keyword">delete</span>;<br><br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Bind</span><span class="hljs-params">(<span class="hljs-type">void</span>* commandBuffer = <span class="hljs-literal">nullptr</span>)</span> </span>&#123;&#125;    <br><br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">IsValid</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>&#123;<span class="hljs-keyword">return</span> m_isValid;&#125;<br><span class="hljs-keyword">protected</span>:<br>    BufferType m_type &#123;NONE_BUFFER&#125;;<br>    <span class="hljs-type">bool</span> m_isValid &#123;<span class="hljs-literal">false</span>&#125;;<br>&#125;;<br></code></pre></td></tr></table></figure><p>比如说像上面的代码是OpenGL和Vulkan的buffer类的基类，两个图形API会分别继承这个基类实现各自的buffer类：<strong>OpenGLBuffer</strong>和<strong>VulkanBuffer</strong>。这样可以在大体流程不变的情况下针对OpenGL和Vulkan分别做一些特化实现。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">CQuadShape::InitRenderInfo</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">// 屏幕mesh</span><br>    std::vector&lt;Vertex&gt; quadVertexArray = &#123;<br>        &#123;&#123;<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;, &#123;<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;&#125;,<br>        &#123;&#123;<span class="hljs-number">-1</span>,<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>&#125;, &#123;<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;&#125;,<br>        &#123;&#123;<span class="hljs-number">1</span>,<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;, &#123;<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>&#125;, &#123;<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;&#125;,<br>        &#123;&#123;<span class="hljs-number">1</span>,<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;, &#123;<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>&#125;, &#123;<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;&#125;,<br>        &#123;&#123;<span class="hljs-number">1</span>,<span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;, &#123;<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>&#125;, &#123;<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;&#125;,<br>        &#123;&#123;<span class="hljs-number">-1</span>,<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>&#125;, &#123;<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>&#125;, &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>&#125;&#125;,<br>    &#125;;<br>    <br>    mesh_resource = <span class="hljs-built_in">make_shared</span>&lt;MeshResource&gt;();<br>    <span class="hljs-keyword">auto</span> quadMesh = <span class="hljs-built_in">make_shared</span>&lt;CMesh&gt;();<br>    <br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> RENDER_IN_VULKAN</span><br>    <span class="hljs-keyword">auto</span> vertex_buffer = <span class="hljs-built_in">make_unique</span>&lt;OpenGLBuffer&gt;();<br>    vertex_buffer-&gt;<span class="hljs-built_in">Initialize</span>(VERTEX_BUFFER, <span class="hljs-built_in">sizeof</span>(Vertex), quadVertexArray.<span class="hljs-built_in">size</span>(), &amp;quadVertexArray[<span class="hljs-number">0</span>]);<br>    std::vector&lt;OpenGLVertexAttribute&gt; vertexAttributes = &#123;<br>        &#123;<span class="hljs-number">3</span>, GL_FLOAT, GL_FALSE, <span class="hljs-built_in">sizeof</span>(Vertex), (<span class="hljs-type">void</span>*)<span class="hljs-built_in">offsetof</span>(Vertex, position)&#125;,<br>        &#123;<span class="hljs-number">3</span>, GL_FLOAT, GL_FALSE, <span class="hljs-built_in">sizeof</span>(Vertex), (<span class="hljs-type">void</span>*)<span class="hljs-built_in">offsetof</span>(Vertex, normal)&#125;,<br>        &#123;<span class="hljs-number">2</span>, GL_FLOAT, GL_FALSE, <span class="hljs-built_in">sizeof</span>(Vertex), (<span class="hljs-type">void</span>*)<span class="hljs-built_in">offsetof</span>(Vertex, uv)&#125;,<br>        &#123;<span class="hljs-number">3</span>, GL_FLOAT, GL_FALSE, <span class="hljs-built_in">sizeof</span>(Vertex), (<span class="hljs-type">void</span>*)<span class="hljs-built_in">offsetof</span>(Vertex, tangent)&#125;,<br>        &#123;<span class="hljs-number">3</span>, GL_FLOAT, GL_FALSE, <span class="hljs-built_in">sizeof</span>(Vertex), (<span class="hljs-type">void</span>*)<span class="hljs-built_in">offsetof</span>(Vertex, bitangent)&#125;,<br>    &#125;;<br>    vertex_buffer-&gt;<span class="hljs-built_in">AddAttribute</span>(vertexAttributes);<br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br>    <span class="hljs-keyword">auto</span> vertex_buffer = <span class="hljs-built_in">make_unique</span>&lt;VulkanBuffer&gt;();<br>    vertex_buffer-&gt;<span class="hljs-built_in">Initialize</span>(VERTEX_BUFFER, <span class="hljs-built_in">sizeof</span>(Vertex), quadVertexArray.<span class="hljs-built_in">size</span>(), &amp;quadVertexArray[<span class="hljs-number">0</span>]);<br>    <br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>    <br>    quadMesh-&gt;m_RenderInfo-&gt;vertex_buffer = std::<span class="hljs-built_in">move</span>(vertex_buffer);<br>    quadMesh-&gt;m_RenderInfo-&gt;vertices = quadVertexArray;<br>    mesh_resource-&gt;mesh_list.<span class="hljs-built_in">push_back</span>(quadMesh);<br>&#125;<br></code></pre></td></tr></table></figure><p>上方就是对一个quad形状初始化的代码，OpenGL和Vulkan会使用同样的原始数据，不过由于OpenGLBuffer使用了VAO，所以这里会初始化Attribute布局，而Vulkan这部分逻辑是放在pipeline的，所以这里会有个小差异。</p><p>同样这么处理的还有<strong>Texture</strong>、<strong>RenderInfo</strong>等类型。Texture和RenderInfo这两个类型有很多可以细讲的内容，这篇文章就不深入了，会计划单独拿一篇文章来详细介绍（埋个坑）。</p><h2 id="Vulkan的渲染系统">Vulkan的渲染系统</h2><p>Vulkan目前有三个渲染系统，分别是：<strong>SimpleVulkanRenderSystem、VulkanPostProcessSystem和VulkanSkyBoxRenderSystem</strong>。这三个渲染系统分别对应着PBR、后处理和天空盒。每个Vulkan的渲染系统有着独立的pipeline、renderpass和descriptor set，在创建系统的时候，会按照不同渲染系统的需求来初始化。下面的例子是SimpleVulkanRenderSystem的创建流程。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++">SimpleVulkanRenderSystem::<span class="hljs-built_in">SimpleVulkanRenderSystem</span>(VulkanSwapChain* swapChain, KongRenderModule* renderModule)<br>    :<span class="hljs-built_in">VulkanRenderSystem</span>(swapChain, renderModule)<br>&#123;<br>    <span class="hljs-built_in">CreateRenderPass</span>();<br>    <span class="hljs-built_in">CreateFrameBuffers</span>();<br>    <span class="hljs-built_in">CreateDescriptorSetLayout</span>();<br>    <span class="hljs-built_in">CreatePipelineLayout</span>();<br>    <span class="hljs-built_in">CreatePipeline</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>渲染的时候，每个渲染系统会各自绑定自己的renderpass和pipeline，以及对应的descriptor set输入。目前SimpleVulkanRenderSystem还会使用push constant将modelMatrix传到GPU中（后续这里可能会有修改）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs c++"><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">SimpleVulkanRenderSystem::Draw</span><span class="hljs-params">(<span class="hljs-type">const</span> FrameInfo&amp; frameInfo)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-built_in">BeginRenderPass</span>(frameInfo.commandBuffer);<br>    <br>    m_pipeline-&gt;<span class="hljs-built_in">Bind</span>(frameInfo.commandBuffer);<br>    <br>    <span class="hljs-keyword">auto</span> actors = KongSceneManager::<span class="hljs-built_in">GetActors</span>();<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> actor : actors)<br>    &#123;<br>        <span class="hljs-keyword">auto</span> mesh_component = actor-&gt;<span class="hljs-built_in">GetComponent</span>&lt;CMeshComponent&gt;();<br>        <span class="hljs-keyword">if</span> (!mesh_component)<br>        &#123;<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">auto</span> mesh_shader = mesh_component-&gt;shader_data;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">dynamic_pointer_cast</span>&lt;DeferInfoShader&gt;(mesh_shader) || <span class="hljs-built_in">dynamic_pointer_cast</span>&lt;DeferredTerrainInfoShader&gt;(mesh_shader))<br>        &#123;<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        <br>        SimplePushConstantData push&#123;&#125;;<br>        push.modelMatrix = actor-&gt;<span class="hljs-built_in">GetModelMatrix</span>();<br><br>        <span class="hljs-built_in">vkCmdPushConstants</span>(frameInfo.commandBuffer, m_pipelineLayout,<br>            VK_SHADER_STAGE_VERTEX_BIT | VK_SHADER_STAGE_FRAGMENT_BIT,<br>            <span class="hljs-number">0</span>, <span class="hljs-built_in">sizeof</span>(SimplePushConstantData), &amp;push);<br>        <br>        mesh_component-&gt;<span class="hljs-built_in">Draw</span>(frameInfo, m_pipelineLayout);<br>    &#125;<br><br>    <span class="hljs-built_in">EndRenderPass</span>(frameInfo.commandBuffer);<br>&#125;<br></code></pre></td></tr></table></figure><p>那么整体的更新流程就如下面所示。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">KongRenderModule::Update</span><span class="hljs-params">(<span class="hljs-type">double</span> delta)</span></span><br><span class="hljs-function"></span>&#123;<br>mainCamera-&gt;<span class="hljs-built_in">Update</span>(delta);<br><span class="hljs-built_in">UpdateSceneRenderInfo</span>();<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> RENDER_IN_VULKAN</span><br><span class="hljs-keyword">if</span> (<span class="hljs-keyword">auto</span> commandBuffer = <span class="hljs-built_in">GetCurrentCommandBuffer</span>())<br>&#123;<br><span class="hljs-type">int</span> frameIndex = <span class="hljs-built_in">GetFrameIndex</span>();<br>FrameInfo frameInfo&#123;<br>frameIndex,<br><span class="hljs-built_in">static_cast</span>&lt;<span class="hljs-type">float</span>&gt;(delta),<br>commandBuffer<br>&#125;;<br><br>m_vkSimpleRenderSystem-&gt;<span class="hljs-built_in">UpdateMeshUBO</span>(frameInfo);<br><br>m_vkSimpleRenderSystem-&gt;<span class="hljs-built_in">Draw</span>(frameInfo);<br>m_vkSkyboxSystem-&gt;<span class="hljs-built_in">Draw</span>(frameInfo);<br>m_vkPostProcessSystem-&gt;<span class="hljs-built_in">Draw</span>(frameInfo);<br>&#125;<br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br>    <span class="hljs-comment">// ...... OpenGL的流程</span><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>当然，这里面有很多东西可以讲的，比如说怎么创建对应的Pipeline和renderpass，怎么创建DescriptorSet等等，这些很细节的内容这里就不做介绍了，我会找时间整理一下，看看有没有机会系统的写一篇文章（再埋个坑）。</p><h2 id="接入ImGui">接入ImGui</h2><p>为了方便，我在处理完几个渲染系统后还将ImGui接入了进来。</p><p>接入ImGui其实比我想象中要简单不少，ImGui的官网其实提供了<a href="https://github.com/ocornut/imgui/blob/master/examples/example_glfw_vulkan/main.cpp">Vulkan接入ImGui的例子</a>，但是一开始看得我云里雾里的。</p><p>后面在AI的帮助下，发现和OpenGL的流程其实大差不差。比OpenGL更加复杂的部分就是需要在初始化ImGui的时候传入Vulkan的实例信息。这里我还为ImGui单独创建了一个CommandPool，不太确定是不是必须的，还是可以和模型那边共用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">KongUIManager::Init</span><span class="hljs-params">(GLFWwindow* windowHandle)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// 初始化imgui</span><br><span class="hljs-built_in">IMGUI_CHECKVERSION</span>();<br>ImGui::<span class="hljs-built_in">CreateContext</span>();<br>ImGuiIO&amp; io = ImGui::<span class="hljs-built_in">GetIO</span>(); (<span class="hljs-type">void</span>)io;<br><br>io.ConfigFlags |= ImGuiConfigFlags_NavEnableKeyboard;     <span class="hljs-comment">// Enable Keyboard Controls</span><br>io.ConfigFlags |= ImGuiConfigFlags_NavEnableGamepad;      <span class="hljs-comment">// Enable Gamepad Controls</span><br>    io.<span class="hljs-built_in">AddMouseButtonEvent</span>(GLFW_MOUSE_BUTTON_LEFT, GLFW_PRESS);<br><br>ImGui::<span class="hljs-built_in">StyleColorsDark</span>();<br><br><span class="hljs-comment">// 初始化imgui后端</span><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> RENDER_IN_VULKAN</span><br><br><span class="hljs-keyword">auto</span> windowModule = KongWindow::<span class="hljs-built_in">GetWindowModule</span>();<br><span class="hljs-keyword">auto</span> vulkanDevice = VulkanGraphicsDevice::<span class="hljs-built_in">GetGraphicsDevice</span>();<br><br>VkDescriptorPoolSize pool_sizes[] =<br>&#123;<br>&#123; VK_DESCRIPTOR_TYPE_SAMPLER, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_STORAGE_IMAGE, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_STORAGE_BUFFER, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC, <span class="hljs-number">1000</span> &#125;,<br>&#123; VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT, <span class="hljs-number">1000</span> &#125;<br>&#125;;<br><br>VkDescriptorPoolCreateInfo pool_info = &#123;&#125;;<br>pool_info.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO;<br>pool_info.flags = VK_DESCRIPTOR_POOL_CREATE_FREE_DESCRIPTOR_SET_BIT;<br>pool_info.maxSets = <span class="hljs-number">1000</span>;<br>pool_info.poolSizeCount = std::<span class="hljs-built_in">size</span>(pool_sizes);<br>pool_info.pPoolSizes = pool_sizes;<br><br><span class="hljs-keyword">if</span>(<span class="hljs-built_in">vkCreateDescriptorPool</span>(vulkanDevice-&gt;<span class="hljs-built_in">GetDevice</span>(), &amp;pool_info, <span class="hljs-literal">nullptr</span>, &amp;imguiPool) != VK_SUCCESS)<br>&#123;<br><span class="hljs-keyword">throw</span> std::<span class="hljs-built_in">runtime_error</span>(<span class="hljs-string">&quot;failed to create imgui descriptor pool&quot;</span>);<br>&#125;<br><br><span class="hljs-built_in">ImGui_ImplGlfw_InitForVulkan</span>(windowHandle, <span class="hljs-literal">true</span>);   <span class="hljs-comment">// opengl类似</span><br>ImGui_ImplVulkan_InitInfo init_info&#123;&#125;;<br>init_info.Instance = vulkanDevice-&gt;m_instance;<br>init_info.Device = vulkanDevice-&gt;m_device;<br>init_info.PhysicalDevice = vulkanDevice-&gt;m_physicalDevice;<br>init_info.QueueFamily = vulkanDevice-&gt;<span class="hljs-built_in">FindQueueFamilies</span>(vulkanDevice-&gt;m_physicalDevice).graphicsFamily;<br>init_info.Queue = vulkanDevice-&gt;m_graphicsQueue;<br>init_info.PipelineCache = VK_NULL_HANDLE;<br>init_info.MinImageCount = <span class="hljs-number">2</span>;<br>init_info.ImageCount = <span class="hljs-number">2</span>;<br>init_info.MSAASamples = VK_SAMPLE_COUNT_1_BIT;<br>init_info.RenderPass = KongRenderModule::<span class="hljs-built_in">GetRenderModule</span>().<span class="hljs-built_in">GetSwapChainRenderPass</span>();<br>init_info.Subpass = <span class="hljs-number">0</span>;<br>init_info.DescriptorPool = imguiPool;<br><br><span class="hljs-built_in">ImGui_ImplVulkan_Init</span>(&amp;init_info);                  <span class="hljs-comment">// opengl类似</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br><span class="hljs-built_in">ImGui_ImplGlfw_InitForOpenGL</span>(windowHandle, <span class="hljs-literal">true</span>);          <span class="hljs-comment">// Second param </span><br><span class="hljs-built_in">ImGui_ImplOpenGL3_Init</span>();<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>    <span class="hljs-comment">// .......</span><br><br>&#125;<br></code></pre></td></tr></table></figure><p>代码如上面所示。目前最终的渲染代码放在VulkanPostprocessSystem的Draw函数中，EndRenderPass前了，因为后处理使用的是swapchain的render pass。这是临时的处理，后面会放到另外合适的地方。</p><h2 id="shader预处理">shader预处理</h2><p>VUlkan的shader使用的是SPIR-V(SPV)二进制格式，而不是像OpenGL的glsl，所以在Vulkan中引用shader之前，所有的shader都需要进行编译转换为SPV格式。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs shell">@echo off<br>setlocal enabledelayedexpansion<br><br>set SHADER_DIR=resource\shader<br><br>rem 编译顶点着色器<br>for /R &quot;%SHADER_DIR%&quot; %%f in (*.vulkan.vert) do (<br>    %VULKAN_SDK%\Bin\glslc.exe &quot;%%f&quot; -o &quot;%%~dpnf.vert.spv&quot; 2&gt;nul<br>    if !errorlevel! neq 0 (<br>        echo [ERROR] Failed to compile %%f<br>        %VULKAN_SDK%\Bin\glslc.exe &quot;%%f&quot; -o &quot;%%~dpnf.vert.spv&quot;<br>        echo Press any key to continue...<br>        pause &gt;nul<br>    ) <br>)<br><br>rem 编译片段着色器<br>for /R &quot;%SHADER_DIR%&quot; %%f in (*.vulkan.frag) do (<br>    %VULKAN_SDK%\Bin\glslc.exe &quot;%%f&quot; -o &quot;%%~dpnf.frag.spv&quot; 2&gt;nul<br>    if !errorlevel! neq 0 (<br>        echo [ERROR] Failed to compile %%f<br>        %VULKAN_SDK%\Bin\glslc.exe &quot;%%f&quot; -o &quot;%%~dpnf.frag.spv&quot;<br>        echo Press any key to continue...<br>        pause &gt;nul<br>    )<br>)<br><br>echo All shaders compiled successfully<br>pause<br></code></pre></td></tr></table></figure><p>这里使用的是VULKAN_SDK\BIn路径下的glslc.exe帮助程序来实现编译shader的功能。如果VulkanSDK被正确安装的话，VULKAN_SDK路径会写到system path里面，所以可以直接使用这个脚本。Path里面没有的话，那这个路径一般就是<strong>C:/VulkanSDK/实际的版本号</strong>。可以按需替换。</p><p>用glslc很方便的一点就是可以处理shader之间的引用。在OpenGL中除了要在450版本之后，并且在shader中加入<strong>GL_ARB_Shading_language_include</strong>的申明之外。还需要在代码编译shader的时候做一些处理：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">OpenGLShader::IncludeShader</span><span class="hljs-params">(<span class="hljs-type">const</span> string&amp; include_path)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// already include</span><br><span class="hljs-keyword">if</span>(shader_include_set.<span class="hljs-built_in">find</span>(include_path) != shader_include_set.<span class="hljs-built_in">end</span>())<br>&#123;<br><span class="hljs-keyword">return</span>;<br>&#125;<br><br><span class="hljs-comment">// include 文件名需要以“/”开头，要不然会报错，为什么？？</span><br>string full_path = CSceneLoader::<span class="hljs-built_in">ToResourcePath</span>(<span class="hljs-string">&quot;/shader&quot;</span>+include_path);<br>string include_content_str = Utils::<span class="hljs-built_in">ReadFile</span>(full_path);<br><br><span class="hljs-built_in">glNamedStringARB</span>(GL_SHADER_INCLUDE_ARB,<br>include_path.<span class="hljs-built_in">size</span>(),<br>include_path.<span class="hljs-built_in">c_str</span>(),<br>include_content_str.<span class="hljs-built_in">size</span>(),<br>include_content_str.<span class="hljs-built_in">c_str</span>());<br>&#125;<br><br><span class="hljs-function">std::vector&lt;std::string&gt; <span class="hljs-title">OpenGLShader::FindIncludeFiles</span><span class="hljs-params">(<span class="hljs-type">const</span> string&amp; code_content)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-function">std::regex <span class="hljs-title">includeRegex</span><span class="hljs-params">(<span class="hljs-string">&quot;#include \&quot;(.+)\&quot;&quot;</span>)</span></span>;  <span class="hljs-comment">// Regex for #include statements</span><br>std::vector&lt;std::string&gt; includes;  <span class="hljs-comment">// Vector to store extracted includes</span><br><br><span class="hljs-comment">// Iterate through lines in the code</span><br><span class="hljs-function">std::istringstream <span class="hljs-title">iss</span><span class="hljs-params">(code_content)</span></span>;<br>std::string line;<br><span class="hljs-keyword">while</span> (std::<span class="hljs-built_in">getline</span>(iss, line)) &#123;<br>std::smatch match;<br><span class="hljs-comment">// For each line, try to match the #include regex</span><br><span class="hljs-keyword">if</span> (std::<span class="hljs-built_in">regex_search</span>(line, match, includeRegex)) &#123;<br>includes.<span class="hljs-built_in">push_back</span>(match[<span class="hljs-number">1</span>]);  <span class="hljs-comment">// Add matched content to includes</span><br>&#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> includes;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>而通过glslc处理的话，就不需要上面的C++逻辑，只需要在shader中开启一些extension，glslc会自动帮我们处理引用，还是非常方便的。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450</span><br><span class="hljs-meta">#extension GL_ARB_separate_shader_objects : enable</span><br><span class="hljs-meta">#extension GL_EXT_scalar_block_layout : enable</span><br><br><span class="hljs-meta">#include &quot;common.glsl&quot;</span><br><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span>=<span class="hljs-number">0</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> fragPos;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span>=<span class="hljs-number">1</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> fragNormal;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span>=<span class="hljs-number">2</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> fragUV;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span>=<span class="hljs-number">3</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">mat3</span> TBN;<br></code></pre></td></tr></table></figure><h2 id="结语">结语</h2><p>好了，不知不觉中已经贴了这么多代码了。今天的这篇文章可能略显无聊，并且都是大段的介绍性文字和代码，读起来可能并不怎么有趣。</p><p>确实，这篇文章只是我对学习Vulkan，并将它的能力接入到KongEngine的第一阶段的成果，并不有趣也并没有什么了不起的，但也是一个里程碑，可以记录一下。</p><p>现在我慢慢将OpenGL的一些能力接入到Vulkan里面，目前正在做的是延迟渲染的流程。在处理延迟渲染这个流程的时候，我会使用单个Render Pass多Subpass的方法，这是Vulkan相较于OpenGL的一个很重要的区别。</p><p>在同一个render pass的多段subpass可以共享附件，不需要等待前一个渲染命令将结果存到内存中，也缓解了GPU的带宽压力；同时subpass的出现可以减少状态切换的开销，也支持并行处理。还有其他很多好处，这里就不一一列举了。</p><h2 id="参考资料">参考资料</h2><p>除了官方的资料外，我这次接入Vulkan很大程度上是依照了这个视频系列<a href="https://youtu.be/Y9U9IE0gVHA?si=-JnDZWIx8WiipZi0">Vulkan(C++) Game Engine Tutorials</a>。作者深入浅出的将如何实现一个Vulkan渲染引擎的步骤讲解的非常明白，并且将很多图形学上的原理也讲解的十分生动，这里强烈推荐。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>Vulkan</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于图像的光照-镜面反射</title>
    <link href="/2025/03/07/ibl-specular/"/>
    <url>/2025/03/07/ibl-specular/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p><a href="https://ruochenhua.github.io/2025/02/28/ibl-diffuse-irradiance/">上一篇文章</a>介绍了IBL的漫反射部分，接下来这篇文章关注的是镜面反射的部分，也就是拆分方程的后面部分。</p><h2 id="分割求和近似法">分割求和近似法</h2><p>我们回到反射方程的镜面反射部分：</p><p>$$L_o(p, \omega_o) =  \int_{\Omega} \left(\frac{k_s DFG}{4(\omega_o \cdot \mathbf{n})(\omega_i \cdot \mathbf{n})}\right) L_i(p, \omega_i) \mathbf{n} \cdot \omega_i , d\omega_i$$</p><p>我们发现这个积分的结果在积分上不是常数，他受入射光和观察视角两个因素影响。如果对所有入射光方向和所有可能的视角方向做积分，这个计算消耗十分昂贵，是没有办法这么做的。</p><p>为了解决这个问题，<strong>Epic Games</strong>提出了一个解决方案，叫做<strong>分割求和近似法</strong>。它将方程的镜面部分分割成了两个独立的部分，分别对这两个部分求卷积，并在PBR着色器重求和，用于IBL的镜面反射部分。</p><p>分割求和近似法包含两部分：</p><ul><li>预过滤环境贴图：对不同粗糙度的环境光进行卷积，存储为mipmap层级的立方体贴图。</li><li>BRDF积分贴图：预计算BRDF的响应系数，存储为2D查找表。</li></ul><p>我们也可以从公式的层面上进行理解，我们将镜面反射部分的公式变换成以下的形式：</p><p>$$L_o(p, \omega_o) =  \int_{\Omega} \left(\frac{k_s DFG}{4(\omega_o \cdot \mathbf{n})(\omega_i \cdot \mathbf{n})}\right) \mathbf{n} \cdot \omega_i , d\omega_i * \int_{\Omega} L_i(p, \omega_i)  d\omega_i$$</p><h3 id="BRDF积分贴图">BRDF积分贴图</h3><p>卷积的第一部分是镜面反射的卷积部分，也就是<strong>BRDF积分贴图</strong>的部分。BRDF 积分贴图的原理是通过预计算将复杂的 BRDF 镜面反射积分转换为可快速查询的二维查找表。</p><p>我们假设从每个方向的入射辐射度都为白色（1.0），在给定的粗糙度、光线和法线的夹角（$\mathbf{n} \cdot \omega_i$）下可以预计算BRDF的响应结果，并将这部分预处理好存储在一张查找纹理上。</p><p><img src="brdf-lut.png" alt="BRDF积分贴图"></p><p>这张贴图分别以<strong>粗糙度</strong>和<strong>光线和法线的夹角</strong>作为坐标轴。存储的是菲涅尔响应的系数和偏差值。</p><h3 id="预过滤环境贴图">预过滤环境贴图</h3><p>卷积的第二部分是<strong>预过滤环境贴图</strong>，他也是预计算环境的卷积贴图，类似于上一篇文章的漫反射辐照度贴图。但是这里会跟进一步考虑到粗糙度的，粗糙度的不同会导致环境贴图的采样更加分散，反射更加模糊。我们将不同粗糙度级别的预处理结果存放在预过滤环境贴图的不同mipmap等级中，粗糙度越高mipmap等级越高。</p><p><img src="pre-filtered-environment-map.png" alt="预处理环境贴图"></p><p>但是积分的这个部分需要考虑视角方向，而在预处理环境贴图的时候是不知道这部分数据的。Epic Games给出了一个妥协的方法，就是假设镜面反射的方向和输出的采样方向$\omega_o$是一致的。这样预处理环境卷积就可以不需要关心视角方向了，虽然在某些情况下会有些许失真，但是在大部分情况下都有不错的表现。</p><p>结合上面两部分的贴图，我们就能得到近似的镜面反射结果。</p><h2 id="计算预过滤环境贴图">计算预过滤环境贴图</h2><p>下面是代码实现的部分，首先是预过滤环境贴图。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 和环境光辐照度积分不同，镜面反射依赖于材质表面的粗糙度。镜面反射光的形状，称为镜面波瓣(Specular lobe)依赖于入射方向和粗糙度</span><br><span class="hljs-comment">// 采用蒙特卡洛积分和重要性采样（大数定律）</span><br><span class="hljs-comment">// 从总体（理论上大小是无限）中挑选样本N生成采样值并求平均</span><br><span class="hljs-comment">// 用低差异序列随机采样的蒙特卡洛方法（拟蒙特卡洛积分）+ 重要性采样（可以做到实时求解）</span><br>prefilter_calculation_shader-&gt;<span class="hljs-built_in">Use</span>();<br>prefilter_calculation_shader-&gt;<span class="hljs-built_in">SetInt</span>(<span class="hljs-string">&quot;cube_map&quot;</span>, <span class="hljs-number">0</span>);<br>prefilter_calculation_shader-&gt;<span class="hljs-built_in">SetMat4</span>(<span class="hljs-string">&quot;projection&quot;</span>, projection);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_CUBE_MAP, cube_map_id);<br><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, preprocess_fbo);<br><span class="hljs-comment">// 启用立方体贴图之间的正确过渡，去除面之间的接缝</span><br><span class="hljs-built_in">glEnable</span>(GL_TEXTURE_CUBE_MAP_SEAMLESS);<br><span class="hljs-type">int</span> map_mip_levels = <span class="hljs-number">5</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> mip = <span class="hljs-number">0</span>; mip &lt; map_mip_levels; ++mip)<br>&#123;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> mip_width = <span class="hljs-number">128</span> * <span class="hljs-built_in">pow</span>(<span class="hljs-number">0.5</span>, mip);<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> mip_height = <span class="hljs-number">128</span> * <span class="hljs-built_in">pow</span>(<span class="hljs-number">0.5</span>, mip);<br>    <br>    <span class="hljs-built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, preprocess_rbo);<br>    <span class="hljs-built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT24, mip_width, mip_height);<br>    <span class="hljs-built_in">glViewport</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, mip_width, mip_height);<br><br>    <span class="hljs-comment">// 不同的粗糙度对应不同的mip等级</span><br>    <span class="hljs-type">float</span> roughness = (<span class="hljs-type">float</span>)mip/((<span class="hljs-type">float</span>)map_mip_levels - <span class="hljs-number">1.0f</span>);<br>    prefilter_calculation_shader-&gt;<span class="hljs-built_in">SetFloat</span>(<span class="hljs-string">&quot;roughness&quot;</span>, roughness);<br>    <br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">6</span>; ++i)<br>    &#123;<br>        prefilter_calculation_shader-&gt;<span class="hljs-built_in">SetMat4</span>(<span class="hljs-string">&quot;view&quot;</span>, skybox_views[i]);<br>        <span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, <br>                                GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, prefilter_map_id, mip);<br>        <span class="hljs-built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);<br><br>        box_mesh-&gt;<span class="hljs-built_in">Draw</span>();<br>    &#125;<br>&#125;<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, GL_NONE);<br></code></pre></td></tr></table></figure><p>首先我们创建预过滤环境贴图的资源。这里我们创建了5个mipmap层级，每个层级对应不同的粗糙度预处理。在渲染循环中，我们通过<strong>glFramebufferTexture2D</strong>函数来指定需要渲染目标的mip级别。</p><p>接下来是<strong>shader</strong>的实现：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> WorldPos;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">samplerCube</span> cube_map;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> roughness;<br><br><span class="hljs-keyword">const</span> <span class="hljs-type">float</span> PI = <span class="hljs-number">3.14159265359</span>;<br><br><span class="hljs-comment">//.......省略采样部分代码</span><br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec3</span> N = <span class="hljs-built_in">normalize</span>(WorldPos);<br>    <span class="hljs-type">vec3</span> R = N;<br>    <span class="hljs-type">vec3</span> V = R;<br><br>    <span class="hljs-keyword">const</span> <span class="hljs-type">uint</span> SAMPLE_COUNT = <span class="hljs-number">1024</span>u;<br>    <span class="hljs-type">float</span> totalWeight = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">vec3</span> prefilteredColor = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">uint</span> i = <span class="hljs-number">0</span>u; i &lt; SAMPLE_COUNT; ++i)<br>    &#123;<br>        <span class="hljs-type">vec2</span> Xi = Hammersley(i, SAMPLE_COUNT);<br>        <span class="hljs-type">vec3</span> H  = ImportanceSampleGGX(Xi, N, roughness);<br>        <span class="hljs-type">vec3</span> L  = <span class="hljs-built_in">normalize</span>(<span class="hljs-number">2.0</span> * <span class="hljs-built_in">dot</span>(V, H) * H - V);<br><br>        <span class="hljs-type">float</span> NdotL = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(N, L), <span class="hljs-number">0.0</span>);<br>        <span class="hljs-keyword">if</span>(NdotL &gt; <span class="hljs-number">0.0</span>)<br>        &#123;<br>            <span class="hljs-comment">// sample from the environment&#x27;s mip level based on roughness/pdf</span><br>            <span class="hljs-type">float</span> D   = DistributionGGX(N, H, roughness);<br>            <span class="hljs-type">float</span> NdotH = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(N, H), <span class="hljs-number">0.0</span>);<br>            <span class="hljs-type">float</span> HdotV = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(H, V), <span class="hljs-number">0.0</span>);<br>            <span class="hljs-type">float</span> pdf = D * NdotH / (<span class="hljs-number">4.0</span> * HdotV) + <span class="hljs-number">0.0001</span>;<br><br>            <span class="hljs-type">float</span> resolution = <span class="hljs-number">512.0</span>; <span class="hljs-comment">// resolution of source cubemap (per face)</span><br>            <span class="hljs-type">float</span> saTexel  = <span class="hljs-number">4.0</span> * PI / (<span class="hljs-number">6.0</span> * resolution * resolution);<br>            <span class="hljs-type">float</span> saSample = <span class="hljs-number">1.0</span> / (<span class="hljs-type">float</span>(SAMPLE_COUNT) * pdf + <span class="hljs-number">0.0001</span>);<br><br>            <span class="hljs-type">float</span> mipLevel = roughness == <span class="hljs-number">0.0</span> ? <span class="hljs-number">0.0</span> : <span class="hljs-number">0.5</span> * <span class="hljs-built_in">log2</span>(saSample / saTexel);<br><br>            prefilteredColor += <span class="hljs-built_in">textureLod</span>(cube_map, L, mipLevel).rgb * NdotL;<br>            totalWeight      += NdotL;<br>        &#125;<br>    &#125;<br>    prefilteredColor = prefilteredColor / totalWeight;<br><br>    FragColor = <span class="hljs-type">vec4</span>(prefilteredColor, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>输入的粗糙度对应预过滤的立方体贴图的不同mipmap等级，我们根据粗糙度预过滤环境贴图，并把结果存在<strong>prefilteredColor</strong>里。最后prefilteredColor再除以采样权重总和得到最终的结果。</p><p>由于镜面反射的高频细节多，在某些环境的较为粗糙的mip贴图上，直接采样环境贴图可能会导致强光明亮的环境附近出现噪点。最直接的方法是增加采样数量，但是这往往不是最好的方法。所以示例代码里面采用的方法是不直接采样环境贴图，而是基于积分的PDF(Probability Density Function，即基于概率密度函数的方法)和粗糙度来采样环境贴图的mipmap。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> D   = DistributionGGX(N, H, roughness);<br><span class="hljs-type">float</span> NdotH = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(N, H), <span class="hljs-number">0.0</span>);<br><span class="hljs-type">float</span> HdotV = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(H, V), <span class="hljs-number">0.0</span>);<br><span class="hljs-type">float</span> pdf = D * NdotH / (<span class="hljs-number">4.0</span> * HdotV) + <span class="hljs-number">0.0001</span>;<br><br><span class="hljs-type">float</span> resolution = <span class="hljs-number">512.0</span>; <br><span class="hljs-type">float</span> saTexel  = <span class="hljs-number">4.0</span> * PI / (<span class="hljs-number">6.0</span> * resolution * resolution);<br><span class="hljs-type">float</span> saSample = <span class="hljs-number">1.0</span> / (<span class="hljs-type">float</span>(SAMPLE_COUNT) * pdf + <span class="hljs-number">0.0001</span>);<br><br><span class="hljs-type">float</span> mipLevel = roughness == <span class="hljs-number">0.0</span> ? <span class="hljs-number">0.0</span> : <span class="hljs-number">0.5</span> * <span class="hljs-built_in">log2</span>(saSample / saTexel);<br><span class="hljs-comment">// 这里不是直接 texture(cube_map, L).rgb * NdotL，而是采样cubemap的mipmap</span><br>prefilteredColor += <span class="hljs-built_in">textureLod</span>(cube_map, L, mipLevel).rgb * NdotL;<br></code></pre></td></tr></table></figure><p>上面这种方法可以有效的减少噪点的情况。</p><p>另外就是，示例代码中省略的采样部分其实就是<strong>重要性采样</strong>。和我们上一篇文章不同，上一篇文章是将采样半球平均划分成多个小块，对每个小块的结果进行平均得到最后的结果。而由于镜面反射是强方向性的，镜面反射的GGX分布有明显的<strong>各向异性</strong>，使用平均采样的话会导致大量的采样样本贡献低。而如果镜面反射的采样样本不够的话，会有展现很明显的噪点，对场景的渲染效果是影响非常大，因此我们对镜面反射一般会采用重要性采样的方法。</p><p>采样可以延伸很多内容出来，这里我不做过多的介绍，有兴趣可以去参考资料里面的文章详细阅读。</p><p><img src="prefiltered-cubemap.png" alt="预过滤环境贴图作为天空盒在场景中展示"></p><h2 id="计算BRDF积分贴图">计算BRDF积分贴图</h2><p>接下来是BRDF积分贴图。</p><p>在游戏里实时计算金属的反光效果的时候，我们每帧都要对每个像素做一次包含菲涅尔效应（边缘反光变强）、粗糙度模糊（表面颗粒感）、微平面分布（微观凹凸结构）的复杂积分计算。这在针对固定几个光源的场景是可以接受的，而在IBL中，光源可以是整个半球的方向，若对整个半球的光源做积分的话是无法满足实时渲染的要求的。</p><p>因此我们需要预处理这部分数据存为贴图，BRDF积分贴图是提前把不同粗糙度和视角下的计算结果预先计算，并存储为纹理作为辅助光照计算的输入。</p><p>打个比方就是，实时计算BRDF的这部分相当于手工炒菜，可能非常美味（准确度高）但是人力消耗大（性能低）；而BRDF积分贴图的方法类似吃预制菜，味道一般但可接受（准确度稍低一些），做起来快（性能高）。</p><p>brdf积分贴图是一张2D贴图，只需要RG两位的信息。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">////////// brdf预计算贴图</span><br>TextureCreateInfo brdf_lut_map_create_info &#123;&#125;;<br>brdf_lut_map_create_info.width = brdf_lut_map_create_info.height = CUBE_MAP_RES;<br>brdf_lut_map_create_info.wrapS = brdf_lut_map_create_info.wrapR = brdf_lut_map_create_info.wrapT = GL_CLAMP_TO_EDGE;<br>brdf_lut_map_create_info.minFilter = brdf_lut_map_create_info.magFilter = GL_LINEAR;<br>brdf_lut_map_create_info.format = GL_RG;<br>brdf_lut_map_create_info.data_type = GL_FLOAT;<br>brdf_lut_map_create_info.internalFormat = GL_RG16F;<br><br>TextureBuilder::<span class="hljs-built_in">CreateTexture</span>(brdf_lut_map_id, brdf_lut_map_create_info);<br></code></pre></td></tr></table></figure><p>下面是shader的实现：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec2</span> FragColor;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> TexCoords;<br><br><span class="hljs-keyword">const</span> <span class="hljs-type">float</span> PI = <span class="hljs-number">3.14159265359</span>;<br><span class="hljs-comment">// ......重要性采样部分省略</span><br><br><span class="hljs-type">vec2</span> IntegrateBRDF(<span class="hljs-type">float</span> NdotV, <span class="hljs-type">float</span> roughness)<br>&#123;<br>    <span class="hljs-type">vec3</span> V;<br>    V.x = <span class="hljs-built_in">sqrt</span>(<span class="hljs-number">1.0</span> - NdotV*NdotV);<br>    V.y = <span class="hljs-number">0.0</span>;<br>    V.z = NdotV;<br><br>    <span class="hljs-type">float</span> A = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> B = <span class="hljs-number">0.0</span>;<br><br>    <span class="hljs-type">vec3</span> N = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>);<br><br>    <span class="hljs-keyword">const</span> <span class="hljs-type">uint</span> SAMPLE_COUNT = <span class="hljs-number">1024</span>u;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">uint</span> i = <span class="hljs-number">0</span>u; i &lt; SAMPLE_COUNT; ++i)<br>    &#123;<br>        <span class="hljs-comment">// 创建一个基于某个指定方向，并按照重要性采样分布的采样方向        </span><br>        <span class="hljs-type">vec2</span> Xi = Hammersley(i, SAMPLE_COUNT);<br>        <span class="hljs-type">vec3</span> H = ImportanceSampleGGX(Xi, N, roughness);<br>        <span class="hljs-type">vec3</span> L = <span class="hljs-built_in">normalize</span>(<span class="hljs-number">2.0</span> * <span class="hljs-built_in">dot</span>(V, H) * H - V);<br><br>        <span class="hljs-type">float</span> NdotL = <span class="hljs-built_in">max</span>(L.z, <span class="hljs-number">0.0</span>);<br>        <span class="hljs-type">float</span> NdotH = <span class="hljs-built_in">max</span>(H.z, <span class="hljs-number">0.0</span>);<br>        <span class="hljs-type">float</span> VdotH = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(V, H), <span class="hljs-number">0.0</span>);<br><br>        <span class="hljs-keyword">if</span>(NdotL &gt; <span class="hljs-number">0.0</span>)<br>        &#123;<br>            <span class="hljs-type">float</span> G = GeometrySmith(N, V, L, roughness);<br>            <span class="hljs-type">float</span> G_Vis = (G * VdotH) / (NdotH * NdotV);<br>            <span class="hljs-type">float</span> Fc = <span class="hljs-built_in">pow</span>(<span class="hljs-number">1.0</span> - VdotH, <span class="hljs-number">5.0</span>);<br><br>            A += (<span class="hljs-number">1.0</span> - Fc) * G_Vis;<br>            B += Fc * G_Vis;<br>        &#125;<br>    &#125;<br>    A /= <span class="hljs-type">float</span>(SAMPLE_COUNT);<br>    B /= <span class="hljs-type">float</span>(SAMPLE_COUNT);<br>    <span class="hljs-keyword">return</span> <span class="hljs-type">vec2</span>(A, B);<br>&#125;<br><span class="hljs-comment">// ----------------------------------------------------------------------------</span><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec2</span> integratedBRDF = IntegrateBRDF(TexCoords.x, TexCoords.y);<br>    FragColor = integratedBRDF;<br>&#125;<br></code></pre></td></tr></table></figure><p>BRDF预计算中，我们将角度和粗糙度作为输入（对应两个坐标轴）。按照重要性采样，计算每个样本上的菲涅尔系数$F_0$和偏差。</p><p>另外在PBR中，BRDF的几何项在固定光源下是：<br>$$<br>K_{direction} = (\alpha+1)^2/8<br>$$<br>而在IBL中：<br>$$<br>K_{IBL} = \alpha ^ 2 / 2<br>$$<br>这里在计算的时候需要按照下面的公式来计算，即：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> GeometrySchlickGGX(<span class="hljs-type">float</span> NdotV, <span class="hljs-type">float</span> roughness)<br>&#123;<br>    <span class="hljs-type">float</span> a = roughness;<br>    <span class="hljs-type">float</span> k = (a * a) / <span class="hljs-number">2.0</span>;    <span class="hljs-comment">// 用IBL的k参数</span><br><br>    <span class="hljs-type">float</span> nom   = NdotV;<br>    <span class="hljs-type">float</span> denom = NdotV * (<span class="hljs-number">1.0</span> - k) + k;<br><br>    <span class="hljs-keyword">return</span> nom / denom;<br>&#125;<br><br><span class="hljs-type">float</span> GeometrySmith(<span class="hljs-type">vec3</span> N, <span class="hljs-type">vec3</span> V, <span class="hljs-type">vec3</span> L, <span class="hljs-type">float</span> roughness)<br>&#123;<br>    <span class="hljs-type">float</span> NdotV = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(N, V), <span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">float</span> NdotL = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(N, L), <span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">float</span> ggx2 = GeometrySchlickGGX(NdotV, roughness);<br>    <span class="hljs-type">float</span> ggx1 = GeometrySchlickGGX(NdotL, roughness);<br><br>    <span class="hljs-keyword">return</span> ggx1 * ggx2;<br>&#125;<br></code></pre></td></tr></table></figure><p>最后得到的结果如前面展示过的这张图片类似：</p><p><img src="brdf-lut.png" alt="BRDF积分贴图"></p><h2 id="PBR中应用">PBR中应用</h2><p>最后我们要在PBR中应用反射的结果。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-keyword">uniform</span> <span class="hljs-type">samplerCube</span> skybox_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">samplerCube</span> skybox_diffuse_irradiance_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">samplerCube</span> skybox_prefilter_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> skybox_brdf_lut_texture;<br><br>......<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    ......<br><br>    F0 = <span class="hljs-built_in">mix</span>(F0, env_albedo.xyz, env_metallic);<br>    <span class="hljs-type">vec3</span> kS = FresnelSchlickRoughness(<span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(frag_normal, view), <span class="hljs-number">0.0</span>), F0, env_roughness);<br>    <span class="hljs-type">vec3</span> kD = <span class="hljs-number">1.0</span> - kS;<br>    kD *= <span class="hljs-number">1.0</span> - env_metallic;<br>    <span class="hljs-comment">// IBL漫反射分量</span><br>    <span class="hljs-type">vec3</span> env_diffuse = env_albedo.xyz * skybox_irradiance;<br>    <span class="hljs-comment">// IBL镜面反射分量</span><br>    <span class="hljs-type">vec3</span> reflect_vec = <span class="hljs-built_in">reflect</span>(-view, frag_normal);<br>    <span class="hljs-keyword">const</span> <span class="hljs-type">float</span> MAX_REFLECTION_LOD = <span class="hljs-number">4.0</span>;<br>    <span class="hljs-type">vec3</span> prefiltered_color = <span class="hljs-built_in">textureLod</span>(skybox_prefilter_texture, reflect_vec, env_roughness*MAX_REFLECTION_LOD).xyz;<br><br>    <span class="hljs-type">vec2</span> env_BRDF = <span class="hljs-built_in">texture</span>(skybox_brdf_lut_texture, <span class="hljs-type">vec2</span>(<span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(frag_normal, view), <span class="hljs-number">0.0</span>), env_roughness)).rg;<br>    <span class="hljs-type">vec3</span> env_specular = prefiltered_color * (kS * env_BRDF.x + env_BRDF.y);<br>    ambient = (kD*env_diffuse + env_specular);<br>&#125;<br></code></pre></td></tr></table></figure><p>得到最终的结果如下：</p><p><img src="ibl-result.gif" alt="最终的结果"></p><h2 id="结语">结语</h2><p>以上就是IBL的简单实现流程。</p><p>从环境贴图的卷积模糊到 BRDF 积分的查表优化，IBL 技术用预计算的智慧解决了实时渲染的核心难题。通过将复杂的物理光照模型转化为可快速查询的纹理数据，它让计算机生成的场景拥有了与真实世界媲美的光影互动能力。</p><p>这项技术的突破在于空间换时间的极致应用：用离线计算的成本换取实时渲染的流畅，以有限的纹理存储替代无限的方向采样。当我们在游戏中看到金属表面反射出细腻的环境细节，或是在 VR 设备中感受材质与光照的自然交融时，背后正是 IBL 在默默支撑着每秒 60 帧的视觉魔法。</p><p>IBL 甚至可以与动态 GI、神经渲染等技术深度融合，逐步突破静态环境的限制。随着硬件光线追踪的普及，预计算与实时计算的界限会进一步模糊，虚拟世界的光照将变得更加动态、智能。但无论技术如何演进，IBL 所奠定的 “将物理规律转化为高效算法” 的思想，仍将是图形学领域的重要方法论。</p><h1>参考资料</h1><p><a href="https://learnopengl.com/PBR/IBL/Specular-IBL">https://learnopengl.com/PBR/IBL/Specular-IBL</a><br><a href="https://learnopengl-cn.github.io/07%20PBR/03%20IBL/02%20Specular%20IBL/#brdf">https://learnopengl-cn.github.io/07 PBR/03 IBL/02 Specular IBL/#brdf</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于图像的光照-漫反射辐照度</title>
    <link href="/2025/02/28/ibl-diffuse-irradiance/"/>
    <url>/2025/02/28/ibl-diffuse-irradiance/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p><a href="https://github.com/ruochenhua/KongEngine">KongEngine</a>的Vulkan接入还在进行中。好消息是已经能够实现一个基本的Vulkan渲染流程，将简单的带有贴图模型渲染到场景中了；坏消息是，这就是他目前利用Vulkan能做到的所有事了。</p><p>其实按照目前的进展，是可以准备一篇文章来讲讲接入Vulkan这段时间的一些内容了。不过思来想去，还是计划延后，等更加完善了再来详细说说。为了尽量实现我一周一篇文章的计划，也想填填以前的坑，今天这篇文章打算讲讲基于图像的光照技术：<strong>IBL</strong>。</p><h2 id="什么是IBL">什么是IBL</h2><p>IBL 即<strong>Image-Based Lighting</strong>，是基于物理的渲染（PBR）中一种重要的光照技术。传统的光照计算通常是基于光源的，例如点光源、方向光等，这些光源模型比较简单，难以模拟出复杂的真实世界光照环境。而 IBL 则是利用环境图像（通常是高动态范围图像，HDR）来捕捉场景周围的光照信息，将其作为场景中物体的光照来源，从而为物体提供更真实、更自然的光照效果。</p><p>IBL 的核心思想是<strong>将环境光照视为无数个微小的光源，这些光源分布在物体周围的各个方向上。通过对环境图像进行采样和处理，可以计算出物体表面从各个方向接收到的光线能量，进而模拟出物体在复杂光照环境下的外观</strong>。</p><h2 id="IBL的理论基础">IBL的理论基础</h2><p>在之前的光照计算中我们主要是计算点光源和方向光源的辐照度，这个十分简单，因为我们能够事先知道对辐照度有贡献的光的方向。而IBL中的光源是来自四面八方的，环境的每个方向都有可能对最终的辐照度有一定的影响，和我们之前所面对的问题是不一样的，因此我们需要换一个思路。</p><p>那么为了实现IBL的效果，我们需要解决两个必要的条件：</p><ul><li>我们需要想办法获取场景中任意方向的辐照度贡献。</li><li>要快，性能要在能接受的范围之内。</li></ul><h3 id="漫反射辐照度">漫反射辐照度</h3><p>我们来回顾一下PBR的反射方程。</p><p>$$<br>L_o(p, \omega_o) = \int_{\Omega} \left(\frac{k_d c}{\pi} +  \frac{k_s DFG}{4(\omega_o \cdot \mathbf{n})(\omega_i \cdot \mathbf{n})}\right) L_i(p, \omega_i) \mathbf{n} \cdot \omega_i , d\omega_i<br>$$</p><p>可以看出PBR的漫反射部分和镜面反射部分是独立的，所以可以将积分拆分成如下两个部分：<br>$$L_o(p, \omega_o) = \int_{\Omega} \left(\frac{k_d c}{\pi}\right) L_i(p, \omega_i) \mathbf{n} \cdot \omega_i , d\omega_i + \int_{\Omega} \left(\frac{k_s DFG}{4(\omega_o \cdot \mathbf{n})(\omega_i \cdot \mathbf{n})}\right) L_i(p, \omega_i) \mathbf{n} \cdot \omega_i , d\omega_i$$</p><p>这篇文章我们主要关注的是漫反射部分，也就是公式的前一个部分.将常数项移除出积分后，我们得到下面的公式：</p><p>$$L_o(p, \omega_o) = \frac{k_d c}{\pi} \int_{\Omega}  L_i(p, \omega_i) \mathbf{n} \cdot \omega_i , d\omega_i$$</p><p>上述公式表示的是一个是依赖于 $\omega_i$的积分。</p><h3 id="预计算辐照度贴图">预计算辐照度贴图</h3><p>根据环境贴图，获取$\omega_i$方向上的辐照度的方法非常简单，如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> radiance = <span class="hljs-built_in">texture</span>(cubemap, w_i).rgb;<br></code></pre></td></tr></table></figure><p>而有上面的公式可知,漫反射辐照度是一个依赖于$\omega_i$的积分，那么我们可以想到通过对环境贴图进行预处理，让它在每个采样方向中存储漫反射积分的结果，这样就能实时的在场景中获取IBL的漫反射辐照度了。</p><p>预计算的核心在于对环境贴图进行<strong>卷积处理</strong>，生成一张新的纹理，也就是辐照度贴图（Irradiance Map）。这个过程我们会在渲染前完成的，性能更佳的方式是离线完成，不需要在每帧渲染时重复计算。在实际渲染时，只需从辐照度贴图中采样就能快速获取物体表面的漫反射辐照度，从而大大提高渲染效率。</p><p><img src="Convolution.png" alt="对所有方向进行卷积"></p><h2 id="IBL的实现">IBL的实现</h2><p>好了，其实理论非常简单，接下来是实际的实现部分。以下的代码都已经整合到KongEngine的OpenGL渲染的流程中。</p><p>我们使用<a href="https://github.com/nothings/stb/blob/master/stb_image.h">stb_image</a>库来加载图像，它能够支持HDR格式的图片。一般来说，HDR环境贴图是存储在一张等距柱状投影图(Equirectangular Map)中，我们可以直接使用等距柱状投影图来获取环境信息，但是这相对来说还是比较昂贵的，所以一般会先将等距柱状投影图转换为立方体贴图。</p><p><img src="Equirectangular-Map.png" alt="等距柱状投影图"></p><h3 id="等距柱状投影图转换为立方体贴图">等距柱状投影图转换为立方体贴图</h3><p>好了，下面就是实际的代码展示。<br>首先我们需要创建对应的fbo，和立方体贴图作为预处理的输出：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 创建fbo</span><br><span class="hljs-built_in">glGenFramebuffers</span>(<span class="hljs-number">1</span>, &amp;preprocess_fbo);<br><span class="hljs-built_in">glGenRenderbuffers</span>(<span class="hljs-number">1</span>, &amp;preprocess_rbo);<br><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, preprocess_fbo);<br><span class="hljs-built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, preprocess_rbo);<br><span class="hljs-built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT24, CUBE_MAP_RES, CUBE_MAP_RES);<br><span class="hljs-built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, preprocess_rbo);<br><br><span class="hljs-comment">// 创建立方体贴图</span><br>GLuint cube_map_id;<br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;cube_map_id);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_CUBE_MAP, cube_map_id);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">6</span>; ++i)<br>&#123;<br>    <span class="hljs-comment">// note that we store each face with 16 bit floating point values</span><br>    <span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, <span class="hljs-number">0</span>, GL_RGB16F, <br>                 CUBE_MAP_RES, CUBE_MAP_RES, <span class="hljs-number">0</span>, GL_RGB, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br>&#125;<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAG_FILTER, GL_LINEAR);<br></code></pre></td></tr></table></figure><p>然后我们需要将面向立方体六个面对应的六个方向的视图矩阵准备好，每个投影矩阵的fov设置为90度，这样能够将所有方向都包含进来：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// projection和view矩阵</span><br>vec3 scene_center = <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>);<br>vector&lt;mat4&gt; skybox_views;<br>skybox_views.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">lookAt</span>(scene_center, scene_center+<span class="hljs-built_in">vec3</span>(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>), <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">-1</span>,<span class="hljs-number">0</span>)));<br>skybox_views.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">lookAt</span>(scene_center, scene_center+<span class="hljs-built_in">vec3</span>(<span class="hljs-number">-1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>), <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">-1</span>,<span class="hljs-number">0</span>)));<br>skybox_views.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">lookAt</span>(scene_center, scene_center+<span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>), <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)));<br>skybox_views.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">lookAt</span>(scene_center, scene_center+<span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">-1</span>,<span class="hljs-number">0</span>), <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">-1</span>)));<br>skybox_views.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">lookAt</span>(scene_center, scene_center+<span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>), <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">-1</span>,<span class="hljs-number">0</span>)));<br>skybox_views.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">lookAt</span>(scene_center, scene_center+<span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">-1</span>), <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">-1</span>,<span class="hljs-number">0</span>)));<br><br>mat4 projection = glm::<span class="hljs-built_in">perspective</span>(glm::<span class="hljs-built_in">radians</span>(<span class="hljs-number">90.0f</span>), <span class="hljs-number">1.0f</span>, <span class="hljs-number">0.1f</span>, <span class="hljs-number">10.0f</span>);<br></code></pre></td></tr></table></figure><p>然后对每个面，我们将对应的投影矩阵传入并做一次draw，输出的结果。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 将等距柱状投影图转换为立方体贴图</span><br>equirectangular_to_cubemap_shader-&gt;<span class="hljs-built_in">Use</span>();<br>equirectangular_to_cubemap_shader-&gt;<span class="hljs-built_in">SetInt</span>(<span class="hljs-string">&quot;sphere_map&quot;</span>, <span class="hljs-number">0</span>);<br>equirectangular_to_cubemap_shader-&gt;<span class="hljs-built_in">SetMat4</span>(<span class="hljs-string">&quot;projection&quot;</span>, projection);<br><br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, sphere_map_texture);<br><br><span class="hljs-built_in">glViewport</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, CUBE_MAP_RES, CUBE_MAP_RES); <span class="hljs-comment">// don&#x27;t forget to configure the viewport to the capture dimensions.</span><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, preprocess_fbo);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">6</span>; ++i)<br>&#123;<br>equirectangular_to_cubemap_shader-&gt;<span class="hljs-built_in">SetMat4</span>(<span class="hljs-string">&quot;view&quot;</span>, skybox_views[i]);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, <br>GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, cube_map_id, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);<br><br>box_mesh-&gt;<span class="hljs-built_in">Draw</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>对应的shader如下：</p><p>vert:</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><span class="hljs-keyword">layout</span> (<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> aPos;<br><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec3</span> WorldPos;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> projection;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> view;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    WorldPos = aPos;<br>    <span class="hljs-built_in">gl_Position</span> =  projection * view * <span class="hljs-type">vec4</span>(WorldPos, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>fragment</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> WorldPos;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> sphere_map;<br><br><span class="hljs-keyword">const</span> <span class="hljs-type">vec2</span> invAtan = <span class="hljs-type">vec2</span>(<span class="hljs-number">0.1591</span>, <span class="hljs-number">0.3183</span>);<br><span class="hljs-type">vec2</span> SampleSphericalMap(<span class="hljs-type">vec3</span> v)<br>&#123;<br>    <span class="hljs-type">vec2</span> uv = <span class="hljs-type">vec2</span>(<span class="hljs-built_in">atan</span>(v.z, v.x), <span class="hljs-built_in">asin</span>(v.y));<br>    uv *= invAtan;<br>    uv += <span class="hljs-number">0.5</span>;<br>    <span class="hljs-keyword">return</span> uv;<br>&#125;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec2</span> uv = SampleSphericalMap(<span class="hljs-built_in">normalize</span>(WorldPos));<br>    <span class="hljs-type">vec3</span> color = <span class="hljs-built_in">texture</span>(sphere_map, uv).rgb;<br><br>    FragColor = <span class="hljs-type">vec4</span>(color, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>在片段着色器中，我们将一个球面环境纹理（通常是一个全景图）映射到一个三维场景中的物体表面。具体来说，它根据物体表面上每个片段的世界空间位置，计算出对应的球面纹理坐标，这个算法我不在这里深入，有兴趣可以深入了解一下<strong>球面坐标与三维空间向量的关系</strong>以及<strong>从三维向量到二维纹理坐标的转换</strong>。</p><p>好了，经过了上面这些步骤，我们将一张等距柱状投影图转换成了立方体贴图。这个贴图可以按照原有的天空盒渲染流程渲染为天空背景。</p><p>当然，这仅仅只是实现IBL漫反射辐照度的第一步。</p><h3 id="立方体贴图的卷积">立方体贴图的卷积</h3><p>好了，现在我们有了从等距柱状投影图得来的立方体贴图，接下来的部分是重中之重：我们要计算所有方向的间接漫反射的积分。</p><p>回到我们之前提到的方法，我们可以通过<strong>预处理环境贴图</strong>，对其进行<strong>卷积处理</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 预计算辐照度贴图</span><br>irradiance_calculation_shader-&gt;<span class="hljs-built_in">Use</span>();<br>irradiance_calculation_shader-&gt;<span class="hljs-built_in">SetInt</span>(<span class="hljs-string">&quot;cube_map&quot;</span>, <span class="hljs-number">0</span>);<br>irradiance_calculation_shader-&gt;<span class="hljs-built_in">SetMat4</span>(<span class="hljs-string">&quot;projection&quot;</span>, projection);<br><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, preprocess_fbo);<br><span class="hljs-built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, preprocess_rbo);<br><span class="hljs-built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT24, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_CUBE_MAP, cube_map_id);<br><br><span class="hljs-built_in">glViewport</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>); <span class="hljs-comment">// don&#x27;t forget to configure the viewport to the capture dimensions.</span><br><br><span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">6</span>; ++i)<br>&#123;<br>irradiance_calculation_shader-&gt;<span class="hljs-built_in">SetMat4</span>(<span class="hljs-string">&quot;view&quot;</span>, skybox_views[i]);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, <br>GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, irradiance_tex_id, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);<br><br>box_mesh-&gt;<span class="hljs-built_in">Draw</span>();<br>&#125;<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>如上面的代码所示，我们将转换后的立方体贴图传入到辐照度预计算的shader里面。<strong>irradiance_tex_id</strong>是创建的预处理的漫反射辐照度贴图，由于预处理的结果是对原辐照度贴图卷积而来，它丢失了原有贴图的大部分高频细节，因此可以用较低的分辨率来存储，这里使用的是32X32。</p><p>接下来是对立方体贴图做卷积处理，卷积的处理方法有很多种，这里采用的是一个方法是将球体表面根据立体角平均划分为多个小区域，对每片区域采样固定数量的结果并取平均值。<br><img src="sphere-coords.png" alt="球体的坐标"></p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 330 core</span><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> WorldPos;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">samplerCube</span> cube_map;<br><br><span class="hljs-keyword">const</span> <span class="hljs-type">float</span> PI = <span class="hljs-number">3.14159265359</span>;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-comment">// 天空盒的模型空间顶点方向，计算该方向为中心的半球的辐照度的积分</span><br>    <span class="hljs-type">vec3</span> N = <span class="hljs-built_in">normalize</span>(WorldPos);<br><br>    <span class="hljs-type">vec3</span> irradiance = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>);<br><br>    <span class="hljs-comment">// 以切线空间为准</span><br>    <span class="hljs-type">vec3</span> up    = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">vec3</span> right = <span class="hljs-built_in">normalize</span>(<span class="hljs-built_in">cross</span>(up, N));<br>    up         = <span class="hljs-built_in">normalize</span>(<span class="hljs-built_in">cross</span>(N, right));<br><br>    <span class="hljs-type">float</span> sampleDelta = <span class="hljs-number">0.025</span>;<br>    <span class="hljs-type">float</span> nrSamples = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> phi = <span class="hljs-number">0.0</span>; phi &lt; <span class="hljs-number">2.0</span> * PI; phi += sampleDelta)<br>    &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> theta = <span class="hljs-number">0.0</span>; theta &lt; <span class="hljs-number">0.5</span> * PI; theta += sampleDelta)<br>        &#123;<br>            <span class="hljs-comment">// 球面坐标系到笛卡尔坐标</span><br>            <span class="hljs-type">vec3</span> tangentSample = <span class="hljs-type">vec3</span>(<span class="hljs-built_in">sin</span>(theta) * <span class="hljs-built_in">cos</span>(phi),  <span class="hljs-built_in">sin</span>(theta) * <span class="hljs-built_in">sin</span>(phi), <span class="hljs-built_in">cos</span>(theta));<br>            <span class="hljs-comment">// 切线空间转换到世界坐标</span><br>            <span class="hljs-type">vec3</span> sampleVec = tangentSample.x * right + tangentSample.y * up + tangentSample.z * N;<br><br>            irradiance += <span class="hljs-built_in">texture</span>(cube_map, sampleVec).rgb * <span class="hljs-built_in">cos</span>(theta) * <span class="hljs-built_in">sin</span>(theta);<br>            nrSamples++;<br>        &#125;<br>    &#125;<br>    irradiance = PI * irradiance * (<span class="hljs-number">1.0</span> / <span class="hljs-type">float</span>(nrSamples));<br><br>    FragColor = <span class="hljs-type">vec4</span>(irradiance, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>上面的shader代码，我们以WorldPos指向的方向为$\omega_o$，采样一个半球范围的辐照度数据。phi=$\phi$对应上图球体坐标的“经度”，范围是0到360度；theta=$\theta$对应着上图球体坐标的“纬度”，范围是0到90度。</p><p>在循环中，我们将球面的坐标转换为3D世界坐标，以3D世界坐标作为索引去采样辐照度立方体贴图的数据，并对所有采样结果取平均值。</p><p>完成了这个流程后，我们就得到了一个预计算好的辐照度贴图。</p><p><img src="original-scene.png" alt="原场景图"></p><p><img src="irradiance-scene.png" alt="预计算漫反射辐照图"></p><h2 id="应用在PBR算法中">应用在PBR算法中</h2><p>有了预计算好的辐照贴图，我们需要将它应用于PBR的算法中。漫反射辐照度贴图用于表示周边环境中的间接光积累的结果，可以将它应用于环境光的部分：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> skybox_irradiance = <span class="hljs-built_in">texture</span>(skybox_diffuse_irradiance_texture, frag_normal).xyz;<br></code></pre></td></tr></table></figure><p>我们在之前的公式变换中，将光照拆分为漫反射和镜面反射两个部分。由于漫反射和镜面反射在间接光照中所起的作用不同，我们需要借助菲涅尔方程来确定物体表面的间接反射率，以此来对漫反射部分进行恰当的加权处理，以实现更精准的光照模拟。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 和BRDF LUT相关的取值，</span><br><span class="hljs-comment">// Fresnel-Schlick近似法接收一个参数F0，被称为0°入射角的反射率，或者说是直接(垂直)观察表面时有多少光线会被反射。</span><br><span class="hljs-comment">// 这个参数F0会因为材料不同而不同，而且对于金属材质会带有颜色。</span><br><span class="hljs-type">vec3</span> FresnelSchlickRoughness(<span class="hljs-type">float</span> cosTheta, <span class="hljs-type">vec3</span> F0, <span class="hljs-type">float</span> roughness)<br>&#123;<br>    <span class="hljs-keyword">return</span> F0 + (<span class="hljs-built_in">max</span>(<span class="hljs-type">vec3</span>(<span class="hljs-number">1.0</span> - roughness), F0) - F0) * <span class="hljs-built_in">pow</span>(<span class="hljs-built_in">clamp</span>(<span class="hljs-number">1.0</span> - cosTheta, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>), <span class="hljs-number">5.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>上面这个方法也被用在PBR光照计算中。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs glsl">F0 = <span class="hljs-built_in">mix</span>(F0, env_albedo.xyz, env_metallic);<br><span class="hljs-type">vec3</span> kS = FresnelSchlickRoughness(<span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(frag_normal, view), <span class="hljs-number">0.0</span>), F0, env_roughness);<br><span class="hljs-type">vec3</span> kD = <span class="hljs-number">1.0</span> - kS;<br>kD *= <span class="hljs-number">1.0</span> - env_metallic;<br><span class="hljs-comment">// IBL漫反射分量</span><br><span class="hljs-type">vec3</span> env_diffuse = env_albedo.xyz * skybox_irradiance;<br></code></pre></td></tr></table></figure><p>加上漫反射环境贴图后，效果如下面的gif所示。<br><img src="PixPin_2025-03-02_23-35-25.gif" alt="漫反射环境贴图的表现"></p><h2 id="结语">结语</h2><p>好了，这部分主要是介绍IBL中漫反射的处理部分，下一篇文章我们会聚焦于IBL镜面反射的部分，实现完整的IBL效果。</p><p><img src="ibl-final.png" alt="完整的IBL效果"></p><h2 id="参考资料">参考资料</h2><p>整个IBL的实现是参照<a href="https://learnopengl.com/PBR/IBL/Diffuse-irradiance">Learn OpenGL上的Diffuse irradiance部分</a>上的步骤来实现的，讲解的非常详细。<a href="https://learnopengl-cn.github.io/07%20PBR/03%20IBL/01%20Diffuse%20irradiance/#_1">中文版</a>对应的是这一篇文章。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OpenGL优化技巧之DSA</title>
    <link href="/2025/02/22/opengl-dsa/"/>
    <url>/2025/02/22/opengl-dsa/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>最近工作依旧是处于比较繁忙的阶段，由于我突然被委以一项不大不小但是进度十分紧急的任务，导致我每天所能挤出来更新的时间是越来越少了。<a href="https://github.com/ruochenhua/KongEngine">KongEngine</a>的重构有所进展，现在已经将最基础的模型渲染抽象了出来，并且实现了Vulkan渲染的一个简单流程，但是离最终目标还有一定距离。</p><p>以前的一些坑（IBL、SSAO）也没有什么精力来填了，这篇文章打算“水”一期，讲讲一个关于OpenGL优化的非常小的一个方面，Direct State Acess（DSA）。</p><p>为了聊明白Direct State Acess（以下简称DSA）是什么，以及为什么它可以作为一种优化OpenGL的方法，我们首先需要理解一个概念，即：OpenGL本质上是一个状态机。</p><h2 id="OpenGL本质上是一个状态机">OpenGL本质上是一个状态机</h2><p>该如何理解这句话呢？我们来思考一下，状态机最核心的组成部分是各个不同的状态，以及状态之间的逻辑转换，对于到OpenGL可以做以下的理解：</p><ul><li><p>状态：<strong>OpenGL有大量可配置的状态</strong>。例如，绘图模式（点、线、三角形等）、光照模型（是否启用光照、光源位置和属性等）、纹理参数（纹理过滤方式、纹理坐标模式等）、当前绑定的帧缓存以及各种测试和混合函数的设置等。这些状态决定了 OpenGL 如何处理和渲染图形数据。<strong>一旦状态被设置，它们就会影响后续OpenGL命令的执行结果</strong>。比如设置了当前绑定的帧缓存，后面的操作就会在指定的缓存上生效，直到解绑或者绑定另外的缓存。</p></li><li><p>状态之间的装换：<strong>OpenGL 就像一个具有不同状态的机器，用户通过调用 OpenGL 的函数来切换状态和执行操作</strong>。例如，通过调用函数可以从一种绘图模式切换到另一种绘图模式，或者启用不同的着色器。每个状态下可以执行相应的操作，并且操作的结果取决于当前所处的状态。<strong>OpenGL 命令不是孤立执行的，而是基于当前的状态来执行</strong>。例如，当执行绘制三角形的命令时，它会根据当前的绘图模式、颜色状态、纹理状态等，来确定如何绘制这个三角形。</p></li></ul><p>这些概念可能看着有点抽象，可以通过下面的示例代码来理解：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><br><span class="hljs-keyword">auto</span> mesh_shader = water_comp-&gt;shader_data;<br><br>mesh_shader-&gt;<span class="hljs-built_in">Use</span>();<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, water_render_helper_.water_reflection_texture);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE1);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, water_render_helper_.water_refraction_texture);<br><br>mesh_shader-&gt;<span class="hljs-built_in">SetMat4</span>(<span class="hljs-string">&quot;model&quot;</span>, water_actor-&gt;<span class="hljs-built_in">GetModelMatrix</span>());<br>mesh_shader-&gt;<span class="hljs-built_in">SetFloat</span>(<span class="hljs-string">&quot;move_factor&quot;</span>, <span class="hljs-built_in">fmodf</span>(water_render_helper_.total_move*water_render_helper_.move_speed, <span class="hljs-number">1.0</span>));<br><br>water_comp-&gt;<span class="hljs-built_in">Draw</span>(scene_render_info);<br><br></code></pre></td></tr></table></figure><p>这段代码非常简单，首先获取一个将要使用的shader：<strong>mesh_shader</strong>。将其设定为使用后，激活他的两个纹理通道，将两张纹理分别绑定到对应的位置上。然后设置一些shader将要使用的参数的值，最后渲染。</p><p>这里面<strong>mesh_shader-&gt;Use()<strong>就是一次状态的转换，将OpenGL从其他状态转换到了mesh_shader对应的状态上。后面的代码是基于OpenGL处于mesh_shader下的状态而来的，这两张纹理以及后面的参数是要作为mesh_shader的输入，而不是其他的shader。以及最后的</strong>Draw</strong>函数更是基于当前处于mesh_shader下的状态。</p><p>另外值得注意的是，<strong>glActiveTexture</strong>以及<strong>glBindTexture</strong>这两个函数的调用也可以视为一个状态的转换。从状态机的角度来看，OpenGL 维护着一个当前激活纹理单元的状态。<strong>调用 glActiveTexture 函数会改变这个状态，将当前激活的纹理单元从一个切换到另一个</strong>，而<strong>当调用 glBindTexture 函数时，会改变当前激活纹理单元所绑定的纹理对象</strong>。</p><p>OpenGL的原本设计中，状态切换是很频繁的，在图形技术和方法发展的越来越快的时候，这带来了不少的问题。</p><h2 id="状态切换的缺点">状态切换的缺点</h2><p>在现在发展的越来越复杂、步骤越来越长的图形算法的影响下，一次渲染可能需要非常多次的OpenGL中的状态切换。</p><p>比如KongEngine也实现了的延迟渲染，它需要先将部分信息渲染到帧缓存上，分别放置于不同的几张纹理之中，然后利用这些纹理再做一次渲染得到结果。而这个结果可能要再次经过几个不同的后处理才能最终在屏幕上呈现。这个渲染流程很长很复杂，其中涉及到的状态切换非常多。</p><p>而状态切换这个操作是有一定的性能损耗的：</p><ul><li><p>硬件寄存器的修改损耗：每次状态变化都需要GPU修改其内部的硬件寄存器。这些寄存器存储了当前渲染所需的参数，如深度测试、混合模式等。<strong>频繁的状态切换导致GPU不断重新配置这些寄存器，增加了硬件的处理负担</strong>。</p></li><li><p>驱动程序的处理消耗：状态变化需要通过驱动程序进行处理。<strong>驱动程序将这些变化转换为GPU可以执行的命令传输到GPU。这一过程消耗了CPU资源和总线带宽</strong>，尤其是在频繁切换的情况下，性能损失更为明显。</p></li><li><p>CPU和GPU的同步损耗：状态切换通常需要CPU和GPU之间的同步操作。<strong>频繁的状态变化导致更多的同步开销，增加了CPU的负载，同时也可能造成GPU的等待时间</strong>，进而降低了整体渲染效率。</p></li><li><p>GPU渲染管线的重构损耗：OpenGL的渲染管线包括多个阶段，如顶点处理、光栅化和着色器执行。<strong>状态变化可能导致管线的某些部分需要重新初始化</strong>，例如切换着色器时需要重新编译和加载新的程序。这会引入额外的延迟，尤其是在需要频繁切换渲染状态时。</p></li></ul><p>所以在图形算法流程复杂度不变的情况下，减少OpenGL状态切换能够帮助性能提升，这正是DSA的主要作用。</p><h2 id="直接状态访问">直接状态访问</h2><p>DSA，直接状态访问，是用来解决OpenGL状态切换引起的性能损耗的方法之一。它是OpenGL 4.5引入的一个重要特性，它允许开发者直接访问和修改 OpenGL 对象的状态，而不需要将这些对象绑定到全局状态机上。</p><p>我们同样是以上面那个代码来举例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> mesh_shader = water_comp-&gt;shader_data;<br><br>mesh_shader-&gt;<span class="hljs-built_in">Use</span>();<br><br><span class="hljs-built_in">glBindTextureUnit</span>(<span class="hljs-number">0</span>, water_render_helper_.water_reflection_texture);<br><span class="hljs-built_in">glBindTextureUnit</span>(<span class="hljs-number">1</span>, water_render_helper_.water_refraction_texture);<br><br>mesh_shader-&gt;<span class="hljs-built_in">SetMat4</span>(<span class="hljs-string">&quot;model&quot;</span>, water_actor-&gt;<span class="hljs-built_in">GetModelMatrix</span>());<br>mesh_shader-&gt;<span class="hljs-built_in">SetFloat</span>(<span class="hljs-string">&quot;move_factor&quot;</span>,<span class="hljs-built_in">fmodf</span>(water_render_helper_.total_move*water_render_helper_.move_speed, <span class="hljs-number">1.0</span>));<br><br>water_comp-&gt;<span class="hljs-built_in">Draw</span>(scene_render_info);<br></code></pre></td></tr></table></figure><p>和之前的代码对比可以看到，glActiveTexture和glBindTexture这两个函数被替换成了<strong>glBindTextureUnit</strong>，这个函数可以不需要OpenGL进行状态的转换，而是直接将纹理资源对应到shader指定的输入上。</p><p>和glBindTextureUnit类似的方法还有很多：</p><h3 id="缓存对象操作">缓存对象操作</h3><p>不使用DSA：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 生成缓冲区对象</span><br>GLuint VBO;<br><span class="hljs-built_in">glGenBuffers</span>(<span class="hljs-number">1</span>, &amp;VBO);<br><br><span class="hljs-comment">// 绑定缓冲区对象</span><br><span class="hljs-built_in">glBindBuffer</span>(GL_ARRAY_BUFFER, VBO);<br><br><span class="hljs-comment">// 设置缓冲区数据</span><br><span class="hljs-built_in">glBufferData</span>(GL_ARRAY_BUFFER, <span class="hljs-built_in">sizeof</span>(vertices), vertices, GL_STATIC_DRAW);<br><br><span class="hljs-comment">// 解绑缓冲区对象</span><br><span class="hljs-built_in">glBindBuffer</span>(GL_ARRAY_BUFFER, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>使用DSA：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 生成缓冲区对象</span><br>GLuint VBO;<br><span class="hljs-built_in">glCreateBuffers</span>(<span class="hljs-number">1</span>, &amp;VBO);<br><br><span class="hljs-comment">// 直接设置缓冲区数据</span><br><span class="hljs-built_in">glNamedBufferData</span>(VBO, <span class="hljs-built_in">sizeof</span>(vertices), vertices, GL_STATIC_DRAW);<br></code></pre></td></tr></table></figure><p>使用DSA后，创建VBO后的绑定和解绑步骤可以省略。</p><h3 id="纹理对象操作">纹理对象操作</h3><p>不使用DSA：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 生成纹理对象</span><br>GLuint textureID;<br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;textureID);<br><br><span class="hljs-comment">// 绑定纹理对象</span><br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, textureID);<br><br><span class="hljs-comment">// 设置纹理参数</span><br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);<br><br><span class="hljs-comment">// 解绑纹理对象</span><br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>使用DSA：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 生成纹理对象</span><br>GLuint textureID;<br><span class="hljs-built_in">glCreateTextures</span>(GL_TEXTURE_2D, <span class="hljs-number">1</span>, &amp;textureID);<br><br><span class="hljs-comment">// 直接设置纹理参数</span><br><span class="hljs-built_in">glTextureParameteri</span>(textureID, GL_TEXTURE_WRAP_S, GL_REPEAT);<br><span class="hljs-built_in">glTextureParameteri</span>(textureID, GL_TEXTURE_WRAP_T, GL_REPEAT);<br><span class="hljs-built_in">glTextureParameteri</span>(textureID, GL_TEXTURE_MIN_FILTER, GL_LINEAR);<br><span class="hljs-built_in">glTextureParameteri</span>(textureID, GL_TEXTURE_MAG_FILTER, GL_LINEAR);<br></code></pre></td></tr></table></figure><p>使用DSA后，纹理生成对象生成后可以直接设置他的参数，不需要绑定和解绑</p><h3 id="帧缓冲对象">帧缓冲对象</h3><p>不使用DSA：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 生成帧缓冲对象</span><br>GLuint FBO;<br><span class="hljs-built_in">glGenFramebuffers</span>(<span class="hljs-number">1</span>, &amp;FBO);<br><br><span class="hljs-comment">// 绑定帧缓冲对象</span><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, FBO);<br><br><span class="hljs-comment">// 附加纹理到帧缓冲</span><br>GLuint texture;<br><span class="hljs-comment">// 假设 texture 已经正确创建和设置</span><br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texture, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 解绑帧缓冲对象</span><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>使用DSA：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 生成帧缓冲对象</span><br>GLuint FBO;<br><span class="hljs-built_in">glCreateFramebuffers</span>(<span class="hljs-number">1</span>, &amp;FBO);<br><br><span class="hljs-comment">// 附加纹理到帧缓冲</span><br>GLuint texture;<br><span class="hljs-comment">// 假设 texture 已经正确创建和设置</span><br><span class="hljs-built_in">glNamedFramebufferTexture</span>(FBO, GL_COLOR_ATTACHMENT0, texture, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>使用DSA后，创建帧缓存后对其进行设置的时候，可以不需要绑定和解绑操作。</p><p>当然以上只是几个DSA的用法，除此之外还有很多，可以参考<a href="https://www.khronos.org/opengl/wiki/Direct_State_Access">官方wiki</a>上的介绍来进一步了解。</p><h2 id="结语">结语</h2><p>综上所述，深入了解 OpenGL 状态机有助于我们把握图形渲染的底层逻辑，而 DSA 则为解决传统状态切换带来的性能问题提供了有效途径。虽然在实际使用中，DSA 的优化效果可能因各种因素而异，但它在减少状态切换开销、提高代码可读性和可维护性等方面的优势不容忽视。<br>对于开发者而言，应根据具体的应用场景和硬件环境，合理运用 DSA 进行优化。通过不断地实践和总结，我们能够更好地发挥 OpenGL 的性能，为用户带来更加优质的图形体验。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编程</tag>
      
      <tag>OpenGL</tag>
      
      <tag>优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Gerstner波形</title>
    <link href="/2025/02/13/gerstner-wave/"/>
    <url>/2025/02/13/gerstner-wave/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>好久不见，最近正处于工作比较忙的阶段，每天为了应付工作上的事情就已经筋疲力尽了。为了得到更好的渲染效率，<a href="https://github.com/ruochenhua/KongEngine">KongEngine</a>目前正处于比较大的重构之中。同时最近我开始为KongEngine增加对<strong>Vulkan</strong>的支持，一起都还处于最初的混沌之中，所以KongEngine的渲染特性目前没有什么增加，没有什么可写的。我计划等一起都尘埃落定在详细的介绍一下。</p><p>今天这篇文章，算是对之前水面渲染的一个小小的延伸，也是填了之前埋得一个小小的坑。</p><h2 id="生成波浪">生成波浪</h2><p>我在<a href="https://ruochenhua.github.io/2025/01/12/water-effect-1/">《水面效果-1》</a>和<a href="https://ruochenhua.github.io/2025/01/19/water-effect-2/">《水面效果-2》</a>这两篇文章中，我简单介绍了一种水面渲染效果的方法。这种方法最后的结果能输出出不错的水面效果，但是有一个比较大的缺陷就是，这种方法渲染出来的水面是平的。<br>尽管在这两篇文章中，我们尝试使用了几种方法来让水面产生波纹扰动，包括dudv map和normal map。但是水面的mesh最终只是一个平面，如果你以相对平行的视角去看的话，水面是没有起伏的。</p><p>如何解决这个问题呢？那有个很简单的思路，我们只要让水面不只是一个平面，让他是一个有波纹扰动的mesh就可以了。在《水面效果-2》的文章的最后提到了Gerstner波形和Navier-Strokes流体方程，这两种方法经常用在3D水体渲染方面。</p><h3 id="波浪的方法">波浪的方法</h3><ul><li><p>Gerstner Wave是一种用于描述水面波动的数学模型，由奥地利数学家和工程师 Franz Ernst Gerstner 在 1802 年提出。它是一种精确的非线性表面波解，能够很好地描述有限深度水域中水波的传播，尤其适用于大振幅波的情况。</p></li><li><p>Navier-Stokes 方程是描述粘性流体运动的基本方程，以法国工程师 Claude-Louis Navier 和英国数学家 George Gabriel Stokes 的名字命名。它建立在牛顿第二定律和质量守恒定律的基础上，是流体动力学的核心方程。</p></li></ul><p>其中<strong>Gerstner波形</strong>由于性能优秀且有着不错的效果，被广泛的应用于游戏的水体模拟之上，比如说虚幻引擎的water plugin就采用的是这种方法。单个的Gerstner波形可以用来描述一种简单规则的水波形态，为了得到更好的水波效果，通常是采用将多个Gerstner波形叠加的方式来实现。</p><p><img src="water-plugin-ue.png" alt="虚幻引擎的water plugin"></p><p>而<strong>Navier-Strokes方程</strong>则是用来进行更为复杂精度要求更高的流体物理模拟，它的效果惊人但是随之而来的性能消耗也是巨大，所以一般只是用在工业设计、大气模拟等对实时性能要求不是那么高的领域。</p><p>今天的重点会是介绍并实现<strong>Gerstner波形</strong>。</p><h2 id="Gerstner波形">Gerstner波形</h2><h3 id="什么是Gerstner波形">什么是Gerstner波形</h3><p>我们从最简单的sin波形开始，一个基础的sin波形如下所示：</p><p><img src="sin-wave.gif" alt="sin波形"></p><p>sin波形非常常见且易懂，它的波形比较圆润。可以把位于sin波形上的每一个点想想成一个水分子，水分子随着x的变化上下摆动，公式如下。</p><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mtable displaystyle="true" columnalign="right left right" columnspacing="0em 2em" rowspacing="3pt">    <mtr>      <mtd>        <mi>y</mi>      </mtd>      <mtd>        <mo>=</mo>      </mtd>      <mtd>        <mi>A</mi>        <mo>&#x22C5;</mo>        <mi>sin</mi>        <mo stretchy="false">(</mo>        <mfrac>          <mrow>            <mn>2</mn>            <mo>&#x22C5;</mo>            <mi>&#x3C0;</mi>          </mrow>          <mi>l</mi>        </mfrac>        <mo stretchy="false">(</mo>        <mi>x</mi>        <mo>&#x2212;</mo>        <mi>vt</mi>        <mo stretchy="false">)</mo>        <mo stretchy="false">)</mo>      </mtd>    </mtr>  </mtable></math><!-- /wp:html --><p>其中</p><ul><li><strong>A</strong>代表振幅</li><li><strong>l</strong>代表波长，<strong>2*pi/l</strong>代表的是频率</li><li><strong>x</strong>代表初始相位</li><li><strong>v</strong>代表波形移动的速度，<strong>t</strong>是时间，所以<strong>vt</strong>代表波形当前的相位移动。</li></ul><p>如果用代码来表现的话，sin波形的2D表现方式大概是这样的:</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> p = vertex.xyz;<br><span class="hljs-type">float</span> k = <span class="hljs-number">2</span> * PI / l;<br><span class="hljs-type">float</span> f = k*(p.x - v*t);<br><br>p.y = A * <span class="hljs-built_in">sin</span>(f);<br><br><span class="hljs-comment">// ......</span><br></code></pre></td></tr></table></figure><p>Sin波中每个点是做上下运动，只涉及到y方向，得到的效果比较圆滑，比较适合用在平静的湖面上。在处理类似收到风力影响的海水的时候，它的波形往往会更加尖锐。</p><p>Gerstner波为了更准确且真实的描述水分子的运动，它将每个水分子的运动不只是视为sin波形中的上下运动，而是在做一种圆周运动，设计到x和y方向。他们两种的对比如下图所示。</p><p><img src="sin-gerstner.png" alt="sin波形和Gerstner波形的对比"></p><p>为了描述这种圆周运动，我们回忆一下圆形的公式。设圆的半径为r，在圆上的点和坐标轴的夹角为e，可得：</p><ul><li>x = r*cos(e)</li><li>y = r*sin(e)</li></ul><p>那么转换为代码的话大概如下所示：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> p = vertex.xyz;<br><span class="hljs-type">float</span> k = <span class="hljs-number">2</span> * PI / l;<br><span class="hljs-type">float</span> f = k*(p.x - v*t);<br><br>p.x += A * <span class="hljs-built_in">cos</span>(f);<span class="hljs-comment">//x点也会在原相位的位置波动</span><br>p.y = A * <span class="hljs-built_in">sin</span>(f);<br><br><span class="hljs-comment">// ......</span><br></code></pre></td></tr></table></figure><p>得到的结果如下图所示:</p><p><img src="gerstner-wave-simple.gif" alt="Gerstner波形"></p><p>我们可以调整Gerstner波形的波长和振幅来达到不同的效果，我们发现在<strong>振幅乘以2PI大于波长</strong>的时候，Gerstner波形会出现一种“打结”的情况，这是由于引入了x方向的位置变动所引起的，所以在实际上使用Gerstner波形的时候需要有一定的条件限制。</p><p><img src="Gerstner-wave-tangle.png" alt="Gerstner波形打结"></p><h3 id="Gerstner波形的实现">Gerstner波形的实现</h3><p>好了，我们已经知道了基本的Gerstner波形了，并且上面的代码已经介绍了2D的波形要如何生成。代入到3D的场景中也是类似的，我们只需要带入另外一个维度的移动（y或者z，取决于up方向是哪个轴，这里以y轴为up方向作为示例），根据波形的实际方向为x轴和z轴赋予不同的权重来计算y轴的值。下面是示例代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><br><span class="hljs-type">vec3</span> GerstnerWave(<span class="hljs-type">vec3</span> p, <span class="hljs-type">vec3</span> wave_direction, <span class="hljs-type">float</span> steepness, <span class="hljs-type">float</span> wave_length, <span class="hljs-type">float</span> speed_factor, <span class="hljs-keyword">inout</span> <span class="hljs-type">vec3</span> binormal, <span class="hljs-keyword">inout</span> <span class="hljs-type">vec3</span> tangent)<br>&#123;<br>    <span class="hljs-type">float</span> k = <span class="hljs-number">2.0</span> * PI / wave_length;<br>    <span class="hljs-comment">//    float wave_speed = 0.5;</span><br>    <span class="hljs-type">float</span> wave_speed = <span class="hljs-built_in">sqrt</span>(<span class="hljs-number">9.8</span> / k) * speed_factor;<br>    <span class="hljs-type">float</span> _amplitude = steepness / k;<br><br><br>    <span class="hljs-type">float</span> f = k * (<span class="hljs-built_in">dot</span>(wave_direction, p.xz) - wave_speed * <span class="hljs-type">float</span>(iTime));<br><br>    tangent += <span class="hljs-type">vec3</span>(-wave_direction.x*wave_direction.x * steepness * <span class="hljs-built_in">sin</span>(f),<br>                        wave_direction.x*steepness*<span class="hljs-built_in">cos</span>(f),<br>                        -wave_direction.z*wave_direction.x*steepness*<span class="hljs-built_in">sin</span>(f));<br><br>    binormal += <span class="hljs-type">vec3</span>(-wave_direction.x*wave_direction.z * steepness * <span class="hljs-built_in">sin</span>(f),<br>                        wave_direction.z*steepness*<span class="hljs-built_in">cos</span>(f),<br>                        -wave_direction.z*wave_direction.z*steepness*<span class="hljs-built_in">sin</span>(f));<br><br>    <span class="hljs-type">vec3</span> p;<br>    p.x = wave_direction.x * _amplitude * <span class="hljs-built_in">cos</span>(f);<br>    p.y = _amplitude*<span class="hljs-built_in">sin</span>(f);<br>    p.z = wave_direction.z * _amplitude * <span class="hljs-built_in">cos</span>(f);<br><br>    <span class="hljs-keyword">return</span> p;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里整体的思路和前面的2D计算方式是一样的，多了两个对<strong>tangent</strong>和<strong>binormal</strong>的计算。这两个参数的计算是为了得到正确的法线参数，用于计算波浪的正确光照表现。tangent和binormal的值是通过分别对方向x和z方向求偏导而得来的。</p><p><img src="Gerstner-wave-3d.gif" alt="3D Gerstner波形"></p><h3 id="波形的叠加">波形的叠加</h3><p>Gerstner波形我们已经实现了，看起来好像还挺不错的，但是仅仅这样的话和实际上的海浪形态差距还是很大。为了让Gerstner波形更好的表现真实的波浪效果，就需要用到我们前面提到的概念：<strong>波形叠加</strong>。</p><p>这个概念其实并不陌生，在我们实现<a href="https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/#%E5%88%86%E5%BD%A2%E5%B8%83%E6%9C%97%E8%BF%90%E5%8A%A8">程序化地形生成</a>的时候就提到了类似的概念：<strong>分形布朗运动（FBM）</strong>。通过将不同频率，不同振幅，不同波长的波形叠加起来，可以得到更加随机，更加复杂的效果。</p><p>在这里也是一样的，我们可以创建多个不同参数的Gerstner波形，将他们的效果叠加。下面是一个将8个波形叠加的效果：</p><p><img src="gerstner-wave-3d-complicate.gif" alt="3D叠加Gerstner波形"></p><p>这个波形的配置如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><br><span class="hljs-type">vec4</span> wave_list[wave_num] = <span class="hljs-type">vec4</span>[wave_num](<br> <span class="hljs-comment">// direction.x, direction.y, steepness, wave_length</span><br>    <span class="hljs-type">vec4</span>(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.05</span>, <span class="hljs-number">201</span>),<br>    <span class="hljs-type">vec4</span>(<span class="hljs-number">6.0</span>, <span class="hljs-number">-2.0</span>, <span class="hljs-number">0.10</span>, <span class="hljs-number">153</span>),<br>    <span class="hljs-type">vec4</span>(<span class="hljs-number">1.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">0.13</span>, <span class="hljs-number">98</span>),<br>    <span class="hljs-type">vec4</span>(<span class="hljs-number">-0.5</span>, <span class="hljs-number">-1.5</span>, <span class="hljs-number">0.22</span>, <span class="hljs-number">73</span>),<br>    <span class="hljs-type">vec4</span>(<span class="hljs-number">3.5</span>, <span class="hljs-number">1.5</span>, <span class="hljs-number">0.23</span>, <span class="hljs-number">52</span>),<br>    <span class="hljs-type">vec4</span>(<span class="hljs-number">-2.5</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">0.32</span>, <span class="hljs-number">37</span>),<br>    <span class="hljs-type">vec4</span>(<span class="hljs-number">4.5</span>, <span class="hljs-number">-2.4</span>, <span class="hljs-number">0.37</span>, <span class="hljs-number">13</span>),<br>    <span class="hljs-type">vec4</span>(<span class="hljs-number">0.75</span>, <span class="hljs-number">1.2</span>, <span class="hljs-number">0.08</span>, <span class="hljs-number">3.3</span>)<br>);<br><span class="hljs-type">float</span> total_steepness = <span class="hljs-number">0.0</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; wave_num; i++)<br>&#123;<br>    total_steepness += wave_list[i].z;<br>&#125;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; wave_num; i++)<br>&#123;<br>   wave_list[i].z /= total_steepness;<br>&#125;<br></code></pre></td></tr></table></figure><p>为了方便配置，这里我将所有波形的振幅都记录下来，然后做归一化处理，这样以来如果想要保持最终波形的样式不变，只是单纯改变他的振幅大小的话，处理起来就非常方便了。</p><h2 id="收尾">收尾</h2><p>最后，我们将波纹作为水面的mesh带入原有的场景。为了保证还是有细小波纹的效果，我保留了对dudv map的使用。水面的顶点采用了地形类似的tessellation处理，最终得到的结果如下所示。</p><p><img src="gerstner-scene.gif" alt="Gerstner波形在场景中的效果"></p><p>当然，水体渲染还有很多可以优化的部分，比如说浪花的泡沫、采用更加准确的Navier-Stroke方程模拟、水的颜色根据水深做调整、水和陆地接触部分的表现优化等等。</p><p>在处理完Vulkan的接入后，会在这部分做进一步的工作。</p><h2 id="参考资料">参考资料</h2><p><a href="https://zhuanlan.zhihu.com/p/404778222">https://zhuanlan.zhihu.com/p/404778222</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>水</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DeepSeek-R1本地部署</title>
    <link href="/2025/02/03/deepseek-local-deploy/"/>
    <url>/2025/02/03/deepseek-local-deploy/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>蛇年新年好。最近因为过年有很多其他事情需要忙，KongEngine的重构工作也暂停了，文章也有一阵子没有更新。今天是大年初六，总算是回到了深圳家，自己也可以稍微的放松了一下。</p><p>今年过年的这段时间，最大的新闻应该就是DeepSeek了。他前几次模型的发布还不显山不漏水的，这次R1推理大模型的发布和开源不仅仅震动了科技圈、AI圈，而是完完全全的出圈了。我在过年的时候也花了很长时间去使用它的应用，它确实展现了很惊艳的效果，但是由于各方面的原因，它的网站确确实实不够稳定，经常会卡住需要重试。于是我就想尝试着本地部署。</p><p><img src="DeepSeek-icon.png" alt="DeepSeek"></p><h2 id="Ollama">Ollama</h2><p>这次部署我使用的是<strong>Ollama</strong>。</p><h3 id="Ollama简介">Ollama简介</h3><p>Ollama 是一个开源的本地大型语言模型运行框架，旨在简化在本地运行大语言模型的过程，降低使用门槛。它支持 Llama 2、Mistral、Gemma 等众多主流开源模型，能将模型权重、配置和数据捆绑为 Modelfile 进行统一管理。</p><p>Ollama 具有自动硬件加速功能，可充分利用系统硬件资源，还支持多操作系统，提供简单的命令行界面和 REST API，拥有丰富的预构建模型库，具备轻量级、可扩展、开源免费等特点，为开发者、研究人员和爱好者在本地进行语言模型的实验、项目开发等提供了便捷且隐私安全的解决方案。</p><h3 id="Ollama安装">Ollama安装</h3><p>Ollama的安装十分简单，从<a href="https://ollama.com/download">官网下载</a>对应操作系统的Ollama版本<br>，我这里使用的Windows版本。</p><p><img src="Ollama-site.png" alt="Ollama官网"></p><p>安装完成后，打开命令行工具，通过使用&quot;ollama run ‘model-name’&quot;来安装/调用模型能力。</p><h3 id="DeepSeek安装">DeepSeek安装</h3><p>为了在Ollama中使用DeepSeek，我们在Ollama的<a href="https://ollama.com/search">模型页面</a>找到<a href="https://ollama.com/library/deepseek-r1">DeepSeek-R1</a>的页面。</p><p>DeepSeek-R1有多个版本，处理完整模型671b，还提供了很多个蒸馏模型，从1.5b到-70b。</p><p>一般来说家用电脑的硬件是没办法支持部署完整版本的，我们这里选择8b的版本。<br><img src="deepseek-requirements.png" alt="DeepSeek-R1各版本配置要求"></p><p>在命令行总输入:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">ollama <span class="hljs-built_in">run</span> deepseek-r1:8b<br></code></pre></td></tr></table></figure><p>ollama会自动下载对应版本的模型并运行。</p><p><img src="Ollama-Download-Models.png" alt="Ollama下载模型和运行"></p><h2 id="使用chatbox">使用chatbox</h2><p>当然我们可以很愉快的在命令行中和DeepSeek交流，但是这样还是太不方便了。如果我们想要开启多个对话，或者更好的去调整模型参数的话，还是可以借助其他工具。这种工具有很多种，这里提供一个例子<strong>chatbox</strong>。</p><p><a href="https://chatboxai.app/zh">Chatbox AI</a>是一款 AI 客户端应用和智能助手，支持众多先进的 AI 模型和 API，可在 Windows、MacOS、Android、iOS、Linux 和网页版上使用。</p><p>从官网上下载对应系统的安装包安装，后打开chatbox程序。新建一个对话，在对话设置里面选择模型提供方为<strong>OLLAMA API</strong>，模型选择对应的DeepSeek模型，这样就能在chatbox中和DeepSeek，或者其他模型对话了。</p><p><img src="chatbox-set-ds.png" alt="chatbox设定DeepSeek"></p><p><img src="chatbox-ds-conversation.png" alt="和DeepSeek对话"></p><h2 id="结语">结语</h2><p>好了，今天这篇文章简单的介绍了如何在自己的机器上搭建一个和DeepSeek对话的能力。除了DeepSeek这个方法还能和其他的很多模型配合使用。</p><p>AI的一个新的阶段似乎已经到来，保持探索，enjoy。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>LLM</tag>
      
      <tag>DeepSeek</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>水面效果-2</title>
    <link href="/2025/01/19/water-effect-2/"/>
    <url>/2025/01/19/water-effect-2/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在之前的文章，我们已经结合了反射纹理和折射纹理，有了一个初步的水面效果了。今天这篇文章我们会继续深入，优化水面的效果。</p><h2 id="菲涅尔现象">菲涅尔现象</h2><p>如果你对基于物理的渲染管线（PBR）比较熟悉的话，那很有可能你已经知道菲涅尔现象（Fresnel Effect）是什么了。简单的来说，当光线照射到两种不同介质（例如从空气照射到玻璃或者从水照射到空气）的分界面时，一部分光会被反射，一部分光会折射进入另一种介质。菲涅尔反射描述了<strong>反射光和折射光的比例与光线入射角之间的关系</strong>。</p><p>根据菲涅尔方程（Fresnel equations），反射率会随着入射角的变化而变化。当光线垂直（入射角为 0°）入射到界面时，反射率是一个固定的值；而当入射角增大时，反射率会逐渐增大。当入射角接近 90°（掠射角）时，反射率趋近于 1，几乎所有的光都会被反射。</p><p>在渲染水面时，<strong>当视线垂直于水面，可以看到水下一定的深度，此时光大部分折射进入水中，反射的较少。但当视线与水面夹角很小时（接近平行于水面看），水面就像一面镜子，反射很强</strong>。这就是菲涅尔现象在起作用。</p><p>下面的两张截图表现了这个效果。</p><p><img src="water-fresnel-parallel.png" alt="视线平行水面，水面像一面镜子反射场景"></p><p><img src="water-fresnel-horizontal.png" alt="视线垂直水面，可以更多的看到水面下的场景"></p><p>那么该如何实现这种效果呢，很简单，在渲染的时候，我们可以根据视线和水面的夹角来调整反射纹理和折射纹理的混合参数。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs glsl">   <span class="hljs-comment">// ....</span><br><br>   <span class="hljs-comment">// 获取视线方向</span><br><span class="hljs-type">vec3</span> view_vector = <span class="hljs-built_in">normalize</span>(cam_pos-frag_pos); <br><br>   <span class="hljs-comment">// 利用点乘计算视线和水面的夹角，限制在0到1之间</span><br><span class="hljs-type">float</span> fresnel_blend = <span class="hljs-built_in">clamp</span>(<span class="hljs-built_in">dot</span>(water_normal, view_vector), <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>);<br>   <br>   <span class="hljs-comment">// 这里的pow操作是调整效果，可以根据需求使用</span><br>fresnel_blend = <span class="hljs-built_in">pow</span>(fresnel_blend, <span class="hljs-number">2.2</span>);<br><br>   <span class="hljs-type">vec4</span> color = <span class="hljs-built_in">mix</span>(reflection_color, refraction_color, fresnel_blend);<br><br>   <span class="hljs-comment">// ....</span><br></code></pre></td></tr></table></figure><h2 id="水面的动态">水面的动态</h2><p>好了，我们的水面现在看起来很棒，但是太过于平静了。现在的水面就像是一面镜子，一块玻璃，现实中的水面会因为风或者其他接触物的影响有波纹或者扰动产生，我们需要想办法增加这种效果。</p><p>水的动态效果模拟其实是一个很深的研究课题，像虚幻引擎的water插件的水面模拟采用了<strong>gerstner wave</strong>，通过不同频率、波长的波的叠加来实现复杂的水面效果（其实这就和地形生成的FBM类似，详情可以参考<a href="https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/">这篇文章</a>）。如果想要做的更加真实一点，可以采用Navior-Stroker方程来模拟，这是一个经典的用于模拟水体的方法，可以带来更加真实的效果，当然消耗也更大。</p><p>我们今天就来介绍一种最为简单的方法，利用贴图来实现这个效果。</p><h3 id="dudv-map">dudv map</h3><p>我们在这里需要使用一种叫做dudv map的资源，常见的dudv map如下：</p><p><img src="waterDUDV.png" alt="dudv map"></p><p>dudv map是用来辅助表现水面的扰动程度的，如果你有基础的渲染知识的话应该知道法线贴图（normal map），其实dudv map和法线贴图的思路是类似的。</p><p>我们可以看到dudv map整体是呈黄色，因为dudv map主要是包含了X轴（红色）和Y轴（绿色）的数据，黄色是由这两种颜色组合而来。使用dudv map的方法可以参考下面的代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><br><span class="hljs-meta">#version 450 compatibility</span><br><span class="hljs-meta">#extension GL_ARB_shading_language_include : require</span><br><span class="hljs-meta">#include &quot;/common/common.glsl&quot;</span><br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> out_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> out_normal;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> out_texcoord;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> clip_space;<br><br><span class="hljs-keyword">layout</span> (<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> reflection_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> refraction_texture;<br><span class="hljs-comment">// 输入dudv map</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> dudv_map;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br><span class="hljs-type">vec2</span> ndc = clip_space.xy / clip_space.w;<br>ndc = ndc / <span class="hljs-number">2.0</span> + <span class="hljs-type">vec2</span>(<span class="hljs-number">0.5</span>);<br><span class="hljs-type">vec2</span> reflection_coord = <span class="hljs-type">vec2</span>(ndc.x, -ndc.y);<br><span class="hljs-type">vec2</span> refraction_coord = ndc;<br><br>    <span class="hljs-comment">// 利用dudv map来制造水面扰动</span><br><span class="hljs-type">vec2</span> distorted_texcoords = <span class="hljs-built_in">texture</span>(dudv_map, <span class="hljs-type">vec2</span>(out_texcoord.x, out_texcoord.y)).rg * <span class="hljs-number">0.1</span>;<br>distorted_texcoords = out_texcoord + <span class="hljs-type">vec2</span>(distorted_texcoords.x, distorted_texcoords.y + move_factor);<br><span class="hljs-type">vec2</span> total_distort = (<span class="hljs-built_in">texture</span>(dudv_map, distorted_texcoords).rg * <span class="hljs-number">2.0</span> - <span class="hljs-number">1.0</span>) * wave_strength;<br><br>reflection_coord += total_distort;<br>reflection_coord.x = <span class="hljs-built_in">clamp</span>(reflection_coord.x, <span class="hljs-number">0.001</span>, <span class="hljs-number">0.999</span>);<br>reflection_coord.y = <span class="hljs-built_in">clamp</span>(reflection_coord.y, <span class="hljs-number">-0.999</span>, <span class="hljs-number">-0.001</span>);<br><br>refraction_coord += total_distort;<br>refraction_coord = <span class="hljs-built_in">clamp</span>(refraction_coord, <span class="hljs-number">0.001</span>, <span class="hljs-number">0.999</span>);<br><br><span class="hljs-type">vec4</span> reflection_color = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">texture</span>(reflection_texture, reflection_coord).xyz, <span class="hljs-number">1.0</span>);<br><span class="hljs-type">vec4</span> refraction_color = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">texture</span>(refraction_texture, refraction_coord).xyz, <span class="hljs-number">1.0</span>);<br><br><span class="hljs-type">vec3</span> view_vector = <span class="hljs-built_in">normalize</span>(matrix_ubo.cam_pos.xyz-out_pos);<br><span class="hljs-type">float</span> fresnel_blend = <span class="hljs-built_in">clamp</span>(<span class="hljs-built_in">dot</span>(out_normal, view_vector), <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>);<br>fresnel_blend = <span class="hljs-built_in">pow</span>(fresnel_blend, <span class="hljs-number">2.2</span>);<br><br><span class="hljs-type">vec4</span> color = <br><span class="hljs-built_in">mix</span>(reflection_color, refraction_color, fresnel_blend);<br><br>FragColor = color;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>dudv map主要用于制造水面的扰动效果，实现的效果如下：<br><img src="water-with-dudv.png" alt="dudv map的效果"></p><p>哇，已经很有感觉了。当然最好在计算distorted_texcoords的时候增加一个随着时间变化的变量，加上动态效果的话会更有真实感。</p><h3 id="法线贴图">法线贴图</h3><p>在上面我们已经提到了法线贴图，在渲染水面的时候其实也可以使用法线贴图来增加实感效果。</p><p><img src="waterNormal.png" alt="法线贴图"></p><p>一个比较好的法线贴图使用的地方是在水面高光的渲染上，现在的水面有了扰动，但是和光源的交互还是相对较弱的。增加了高光后可以进一步加强水面的实感表现。</p><p><img src="water-no-specular.png" alt="没有水面高光"></p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><br>....<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> normal_map;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br><br>    ......<br><br><span class="hljs-type">vec3</span> specular_highlights = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);<br>    <span class="hljs-comment">// 检查光源</span><br><span class="hljs-keyword">if</span>(light_info_ubo.has_dir_light.r != <span class="hljs-number">0</span>)<br>&#123;<br><span class="hljs-type">vec4</span> normal_map_color = <span class="hljs-built_in">texture</span>(normal_map, distorted_texcoords);<br><span class="hljs-type">vec3</span> normal = <span class="hljs-built_in">normalize</span>(<span class="hljs-type">vec3</span>(normal_map_color.r * <span class="hljs-number">2.0</span> - <span class="hljs-number">1.0</span>, normal_map_color.b, normal_map_color.g * <span class="hljs-number">2.0</span> - <span class="hljs-number">1.0</span>));<br><br><span class="hljs-comment">//fresnel_blend = clamp(dot(normal, view_vector), 0.0, 1.0);</span><br><br><span class="hljs-type">vec3</span> light_dir = light_info_ubo.directional_light.light_dir.xyz;<br><span class="hljs-type">vec3</span> light_color = light_info_ubo.directional_light.light_color.xyz;<br><br>        <span class="hljs-comment">// 高光的简单计算</span><br><span class="hljs-type">vec3</span> reflected_light = <span class="hljs-built_in">reflect</span>(light_dir, normal);<br><span class="hljs-type">float</span> specular = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(reflected_light, view_vector), <span class="hljs-number">0.0</span>);<br><span class="hljs-type">float</span> shine_damper = <span class="hljs-number">100.0</span>;<br>specular = <span class="hljs-built_in">pow</span>(specular, shine_damper);<br><br><span class="hljs-type">float</span> reflectivity = <span class="hljs-number">1.5</span>;<br>specular_highlights = light_color * specular * reflectivity;<br>&#125;<br><br>    .....<br><br>    <span class="hljs-type">vec4</span> blue_color = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">1.0</span>); <span class="hljs-comment">// add some blue color</span><br><span class="hljs-type">vec4</span> color = <span class="hljs-built_in">mix</span>(<br><span class="hljs-built_in">mix</span>(reflection_color, refraction_color, fresnel_blend)<br>, blue_color<br>, <span class="hljs-number">0.1</span>) + <span class="hljs-type">vec4</span>(specular_highlights, <span class="hljs-number">0.0</span>);        <span class="hljs-comment">// 将高光加到场景中</span><br><br>FragColor = color;<br>&#125;<br><br></code></pre></td></tr></table></figure><p><img src="water-with-specular.png" alt="增加水面高光"></p><p>水面终于有了波光粼粼的效果了。</p><p>在上面的代码中，我在最后增加了一点点蓝色的tint，增加表现效果。</p><h2 id="结语">结语</h2><p>好了，这就是一个简单的水面效果渲染的流程了。这个流程很简单易懂，但是有这不错的效果，希望能够对大家有所帮助。</p><p>另外上面所有的参数，可以根据实际的需求或者审美来调整。比如说调整reflectivity来改变高光的强度；调整fresnel的power系数来改变菲涅尔现象的表现。</p><h2 id="what’s-more？">what’s more？</h2><p>当然水的渲染，或者说模拟是个很深入的话题，除了我前面提到的gerstner wave和navior-stroke方法，还有很多其他的内容，比如说可以根据水的深度来让深水区的颜色有更深的蓝色晕染，浅水区的颜色更加透明。后续有时间可能会找其中的一两种优化方法再来讨论一下。</p><h2 id="参考资料">参考资料</h2><p><a href="https://www.youtube.com/watch?v=HusvGeEDU_U&amp;list=PLRIWtICgwaX23jiqVByUs0bqhnalNTNZh&amp;ab_channel=ThinMatrix">ThinMatrix’s OpenGL water guide</a></p><p><a href="https://medium.com/@vincehnguyen/simplest-way-to-render-pretty-water-in-opengl-7bce40cbefbe">Simplest way to render pretty water in OpenGL</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>水</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>水面效果-1</title>
    <link href="/2025/01/12/water-effect-1/"/>
    <url>/2025/01/12/water-effect-1/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在经过了逐步的迭代，KongEngine中已经接入了不错的地形和体积云效果（体积云的相关文章我还在整理计划当中，打算后续和IBL连着一起写），所谓好山好水好风光，有了山和云，接下来我的计划便是将水的渲染纳入KongEngine的能力中。</p><p><img src="kong_terrain_cloud.png" alt="KongEngine的地形效果"></p><h2 id="水面的渲染">水面的渲染</h2><p>下面我们来介绍如何实现一个简单的水面渲染效果。</p><h3 id="水面渲染的构成">水面渲染的构成</h3><p>水面的渲染主要由两部分构成：<strong>反射和折射</strong>，分别对应着水面之上和之下的内容。我在之前已经有文章分享过屏幕空间反射（SSR）的实现细节，但是对于水面来说，反射的范围一般来说是会更大的，包含的内容也会更多。如果仅仅是只能反射屏幕空间的内容的话渲染效果其实并不理想，因此对于水面我们这里使用另外一种方式来实现反射效果。</p><h3 id="基础能力">基础能力</h3><p>为了实现水面的渲染，需要下面几个基础能力的帮助。</p><h4 id="帧缓冲对象（Framebuffer-Objects）">帧缓冲对象（Framebuffer Objects）</h4><p>在实现前面的很多渲染效果的过程中，我们多次使用了帧缓冲对象，应该对这个很了解了。我们使用的延迟渲染技术就和帧缓冲对象是分不开的。</p><p>如果不熟悉这个的同学可以去翻看一下前面的文章，简单的来说帧缓冲对象能让我们将场景内容渲染到它上面，经过处理后再输出到屏幕。</p><p>为了实现水面的反射和折射，我们需要两个FBO来分别存储反射和折射的纹理。由于KongEngine使用了延迟渲染的架构（包括地形我已经将它的渲染改为支持延迟渲染了），因此目前<strong>折射</strong>的纹理我直接使用的是延迟渲染的FBO，当然其实这并不是最准确的，至于为什么我将会在下面的部分解释。</p><p>为了表现反射，我们假定原来的场景如下图所示。<br><img src="water-scene.png" alt="一个包含水面的场景"></p><p>右侧的相机向左边看去，它的视线和水面相交的时地方，反射的内容会需要呈现岸上的场景。那么我们应该如何获取到岸上的景色呢，很简单，根据视线的方向和水面的法线，我们可以计算出反射向量，而这个向量相当于将相机按照水平面镜像的结果，如下图所示。</p><p><img src="water-scene-mirror-camera.png" alt="镜像相机"></p><p>用镜像相机得到的渲染得出的纹理作为水面反射的内容表现。</p><h4 id="裁切平面">裁切平面</h4><p><em>水面的反射用来表现水面之上的场景，水面的折射用于表现水面只下的场景</em>。那么理论上来说我按照上面所述的方法渲染反射，很有可能会包含到水下的内容，这样反射的纹理就不对了。</p><p>因此在渲染反射和折射的内容时需要利用裁切平面，分别将水面之下和水面之上的内容裁切掉。</p><p>在OpenGL中，可以使用Clip Distance来实现这个功能，首先需要在C++中启用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glEnable</span>(GL_CLIP_DISTANCE0)<br></code></pre></td></tr></table></figure><p>在vertex shader中里面，通过改变*gl_ClipDistance[0]*的值来告诉opengl哪些顶点是要被裁切掉的。当gl_ClipDistance[0]的值小于0，表明这个顶点需要被裁切掉；相反，大于0则代表该顶点需要保留。</p><p><em>在KongEngine的实现中，由于直接使用了延迟渲染的帧缓冲内容，所以这里并没有做平面裁切，因此折射和反射的表现其实会有一些问题。</em></p><h4 id="投影纹理映射">投影纹理映射</h4><p>当我们有了水面的反射和折射的纹理后，我们接下来将这两张纹理应用于水面上就可以了。。。吗？</p><p><img src="water-normal-texcoord.png" alt="直接使用纹理"></p><p>上面这张图，nanosuit的脚底下本来是水面的，现在这个表现是因为直接将纹理按照水平面四边形（Quad）的纹理坐标贴了上去。为了得到正确的结果，我们需要用<strong>投影纹理映射将水面模型的3D的坐标映射到屏幕的2D坐标上</strong>。</p><p><img src="coord-trans.png" alt="坐标转换"></p><p>上面是一张来自<a href="https://antongerdelan.net/opengl/raycasting.html#:~:text=Overview,is%20usually%20called%20ray%20casting.">Anton Gerdelan的关于坐标系转换的图示</a>。我们需要以水面模型的屏幕空间的坐标来采样纹理，在vertex shader里面，水面的模型顶点已经经过了转换到达了<strong>齐次裁切空间（Homogeneous Clip Space）</strong>。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><br><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_pos;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_normal;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">2</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> in_texcoord;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> model;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> view;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> projection;<br><br><br><span class="hljs-comment">// out vec3 normal_world;</span><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec3</span> out_pos;<br><span class="hljs-keyword">out</span> <span class="hljs-type">vec3</span> out_normal;<br><span class="hljs-keyword">out</span> <span class="hljs-type">vec2</span> out_texcoord;<br><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> clip_space;<br><br><span class="hljs-keyword">const</span> <span class="hljs-type">float</span> tiling = <span class="hljs-number">6.0</span>;<br><br><span class="hljs-type">void</span> main()&#123;<br><span class="hljs-built_in">gl_Position</span> = projection * view * model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1.0</span>);<br>    clip_space = <span class="hljs-built_in">gl_Position</span>;<br>    out_pos = (model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1.0</span>)).xyz;<br><span class="hljs-comment">//</span><br>    out_normal = <span class="hljs-built_in">normalize</span>(<span class="hljs-type">mat3</span>(<span class="hljs-built_in">transpose</span>(<span class="hljs-built_in">inverse</span>(model))) * in_normal);<br>out_texcoord = in_texcoord * tiling;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>其中clip_space是水面顶点的eye space坐标，将会输入到fragment shader中。<br>我们需要通过以下步骤获得屏幕空间的采样坐标：</p><ol><li><p>将坐标从<em>齐次裁切空间</em>转换到<em>标准设备空间（Normalized Device Space）</em></p><ul><li>转换的方法是将x、y的坐标除以w。</li></ul></li><li><p>将坐标从<em>标准设备空间</em>转换到<em>采样空间</em>，也就是屏幕空间</p><ul><li>需要将坐标的范围从[-1,1]映射到[0,1]，方法就是对坐标乘以0.5后再加0.5。</li></ul></li></ol><p>下面是fragment shader的示例代码。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> out_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> out_normal;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> out_texcoord;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> clip_space;<br><br><span class="hljs-keyword">layout</span> (<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> reflection_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> refraction_texture;<br><br><br><span class="hljs-type">void</span> main()<br>&#123;<br><span class="hljs-type">vec2</span> ndc = clip_space.xy / clip_space.w;<br>ndc = ndc / <span class="hljs-number">2.0</span> + <span class="hljs-type">vec2</span>(<span class="hljs-number">0.5</span>);<br><br><span class="hljs-type">vec2</span> reflection_coord = <span class="hljs-type">vec2</span>(ndc.x, -ndc.y);    <span class="hljs-comment">// 反射的垂直方向坐标是反的，所以y是负的。</span><br><span class="hljs-type">vec2</span> refraction_coord = ndc;<br><br><span class="hljs-type">vec4</span> rfr = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">texture</span>(refraction_texture, refraction_coord).xyz, <span class="hljs-number">1.0</span>);<br><span class="hljs-type">vec4</span> rfl = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">texture</span>(reflection_texture, reflection_coord).xyz, <span class="hljs-number">1.0</span>);<br><br>FragColor = <span class="hljs-built_in">mix</span>(rfr, rfl , <span class="hljs-number">0.785</span>);<br><span class="hljs-keyword">return</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>得到的结果如下图所示。</p><p><img src="water-effect-correct.png" alt="正确的水面纹理效果"></p><h2 id="结语">结语</h2><p>至此，其实我们已经初步实现了水面的效果了。从上面的效果图来看其实也颇有模有样，但是距离真正的结束还差的远呢。在后面的文章我会继续补充水面渲染的内容，最终我们的效果会如下图一般。</p><p><img src="kong_water.png" alt="最终的水面效果"></p><p>如何实现这个效果就敬请期待后续的内容了。</p><h2 id="参考资料">参考资料</h2><p><a href="https://www.youtube.com/watch?v=HusvGeEDU_U&amp;list=PLRIWtICgwaX23jiqVByUs0bqhnalNTNZh&amp;ab_channel=ThinMatrix">ThinMatrix’s OpenGL water guide</a></p><p><a href="https://medium.com/@vincehnguyen/simplest-way-to-render-pretty-water-in-opengl-7bce40cbefbe">Simplest way to render pretty water in OpenGL</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>水</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数字人仿真的渲染技术（四）</title>
    <link href="/2025/01/09/digital-human-render-4/"/>
    <url>/2025/01/09/digital-human-render-4/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>这篇文章是我在OGEEK上做过的《浅谈数字人仿真的渲染技术》分享的最后一部分，这一部分的内容主要包含的内容是**非真实感渲染（Non-photorealistic Rendering, NPR）**技术，通常这项技术会被用在渲染卡通风格的内容。</p><h2 id="非真实感渲染">非真实感渲染</h2><p>前面的渲染技术一般都是用于高真实度数字人的渲染，接下来我们来介绍一下NPR。</p><h3 id="什么是NPR">什么是NPR</h3><p><strong>NPR</strong>，我们一般指的是<strong>非真实感渲染（Non-photorealistic Rendering）</strong>，它是相对于**真实渲染（Photorealistic Rendering）**的。</p><p>真实感渲染的目的在于渲染出照片级别的高真实度画面；而非真实感渲染，他的目的多种多样，它可以模拟艺术化的绘制风格，呈现出手绘的效果。</p><p>这是游戏”犬神“的画面，它的渲染模拟出一种独特的水墨风格。<br><img src="okami.png" alt="犬神"></p><p>这是游戏”荒野之息“的画面，它就有点类似于日本动画的风格。<br><img src="zelda.png" alt="塞尔达传说-荒野之息"></p><p>他们显然不是想游戏画面看起来和显示世界一模一样的，所以利用NPR来突出自己独特的美术基调，展现不同的美术风格，从而吸引玩家。</p><h3 id="NPR在数字人的体现">NPR在数字人的体现</h3><p>在数字人的概念在互联网中异常火热的时候，业界也出现了很多热门虚拟数字人或虚拟偶像，如下面这张图里面列举的一些例子。</p><p><img src="npr-digi-human.png" alt="NPR与数字人"></p><p>最左边的的Miquela（美国），以及最右边的AYAYI（燃麦科技）是主打写实，超写实风格的数字人。<br>中间的四个，分别是洛天依，初音，鹿鸣和暖暖，她们的美术风格其实都多多少少有带点二次元风格，如果大家有关注虚拟主播这个行业的话，其实很多虚拟主播都是带着二次元风格的化身（皮套）。</p><p>二次元风格，或者卡通风格的渲染，都属于NPR的渲染风格。NPR在数字人的应用上也是很广泛的。</p><p>当然，非真实感是一个非常宽泛的定义，我们这里不会去展开太多，今天我们只关注于其中的卡通渲染，针对这个领域来介绍一些相关的渲染技术。</p><h2 id="卡通渲染">卡通渲染</h2><p><strong>卡通渲染</strong>是NPR领域应用最广的渲染技术之一，那么他和真实感渲染有很多地方是不一样的，其中最主要的两点，就是<strong>描边处理</strong>，和<strong>艺术化着色</strong>。</p><p>接下来我们就来重点聊一聊这两个方面。</p><h3 id="描边">描边</h3><p>首先来介绍一下描边处理。</p><p>描边几乎是所有非真实渲染都要实现的效果，它比较容易呈现出一种手绘的视觉风格。目前主流使用的描边技术包括几类，分别是<strong>基于几何的生成方法</strong>，<strong>基于视角的勾边</strong>，<strong>基于图像处理的勾边</strong>。这三种方法之间也可以混合使用。我们今天也会主要介绍这三种描边。</p><h4 id="基于几何的生成方法">基于几何的生成方法</h4><p>首先我们来介绍一些基于几何生成的描边方法。</p><p>这个方法的特点是，描边本身是一个单独的几何体，这个几何体通过特殊的方式渲染出来，结合原本渲染的模型，可以达到描边的效果。</p><p>基于几何的描边需要有两个渲染pass。</p><ol><li><p>在第一个Pass中只渲染背面的面片。在第一个Pass进行描边处理时，我们可以利用顶点着色器将物体本身沿法线方向进行一定的扩展，得到一个<em>比原来模型略大一些的模型</em>来实现物体的轮廓可见的效果，这种方法一般被称为<strong>Shell method</strong>或者<strong>Halo method</strong>；用这个扩大的模型来实现描边的效果。<br>也可以使用另外一种叫做<strong>z-bias</strong>的方法，也是绘制模型背面，但不膨胀模型，而是把背面顶点的Z值稍微向前偏移一点点，使得背面的些许部分显示出来形成描边效果。但是这种方法比较不可控，实现的效果较Shell method差很多。</p></li><li><p>然后第二个Pass中对模型进行正常的渲染。</p></li></ol><p>下面的这张图是一个大致的原理介绍。</p><p><img src="outline-geo-based.png" alt="基于几何的描边方法"></p><p>几何生成方法描边的优点是实现简单，可以得到轮廓均匀的描边效果，对大部分模型都有效。<br>同样该方法也有很多的缺点：无法用来描边棱角分明的模型，比如立方体；一般只能用来勾勒物体的外部轮廓(Silhouette)而无法绘制物体内部的轮廓(Contour)；需要处理双倍的Mesh数量，性能不友好。</p><h4 id="基于视角的勾边">基于视角的勾边</h4><p>接下来介绍基于视角的勾边，这部分的计算依赖于我们的一个直觉观察：当我们的视线和某个表面相切时，这个表面上的像素点往往就是模型的边缘，基于这个观察，我们可以用视线的向量和模型法线向量的点乘来估计一个像素的“边缘程度”，当边缘程度超过一定阈值的时候，就判定其为描边区域。</p><p>当然，这个值也可以用来作为纹理坐标去采样一张预定义的“轮廓纹理”。</p><p>基于视角的描边，处理起来相对比较简单，但是最大的缺点是线宽粗细差别较大，不易控制。</p><p><img src="outline-view-based.png" alt="基于视角的描边"></p><h4 id="基于图像处理的勾边">基于图像处理的勾边</h4><p>最后是基于图像处理的描边，这类方法的实现可以说更接近于“边缘”这一概念的本质定义。</p><p>什么是“边缘”呢？边缘就是在深度或者法线上不连续的位置。为了获取边缘，我们只需要在图片上找到不连续的位置即可，因此，我们一般将深度信息和法线信息的形式传入，运用边缘检测算法去寻找这些像素。</p><p>这类方法的优点是描边的线宽一致，适应性广，大部分的边缘检测都可以利用该方法，缺点是需要额外的法线和深度信息。</p><p>由于近年来流行的<strong>延迟渲染框架</strong>，法线和深度本来就是G-Buffer的一部分，因此往往不需要额外绘制法线和深度的信息。</p><p>如果没有G-Buffer，需要单独获取深度图和法线图，会有额外的性能消耗。而且对于深度和法线变化很小的地方，可能无法检测出来，比如桌上的纸张。</p><p>其实除了边缘，基于图像处理还可以根据<strong>漫反射颜色的变化</strong>，<strong>光照区域的变化</strong>，甚至<strong>自定义模板</strong>等等来自定义想要处理的勾边。</p><p><img src="outline-image-process.png" alt="基于图像处理的描边"></p><p>边缘检测的算法这里不深入去拓展了，提一下比较主流的有sobel算子，robert算子，prewitt算子等等。可以去参考图像识别、处理相关的知识。</p><h3 id="艺术化着色">艺术化着色</h3><p>然后我们再来聊一聊另外一个重点部分，就是艺术化着色。</p><p>艺术化着色很考验美术的能力，好的着色效果需要有好的美术风格和造型，当然这里我们就不深入讨论这块了（程序员审美），我们还是简单介绍一下比较常用来实现艺术化着色的技术。</p><p>这里主要介绍两个方式，即卡通着色和基于色调的着色。</p><h4 id="卡通着色">卡通着色</h4><p>卡通渲染的着色方式是<strong>Cel Shading或者Toon Shading</strong>，Cel来自于Celluloid，是传统卡通的制作材料，Toon来自于卡通Cartoon。</p><p>他们的基本思想就是降低色阶，与现实环境丰富的色阶相比，卡通渲染尽量减少使用的色阶，从而实现手工着色的效果。</p><p>下面这张图的场景是采用了PBR，可以看到他的色阶是非常多的，阴影，高光过度很平滑。</p><p><img src="cartoon-pbr.png" alt="PBR场景"></p><p>这张图的场景我们降低了色阶，体现比较明显的是橙色的球的阴影部分，稍微有点卡通的风格了。</p><p><img src="cartoon-lower.png" alt="降低色阶"></p><p>这张图片则是进一步降低了色阶，可以看到有一种很强烈的手工着色的感觉，有种古早卡通的风格。</p><p><img src="cartoon-lowest.png" alt="进一步降低色阶"></p><p>实现这种效果的方法很多，一般计算光照的时候，有一个步骤会根据模型法线和光线法线的点乘，得到一个数值，这个数值会影响最终光照的效果。在PBR中这个数值的影响是连续的，但是在NPR中，我们可以提前定义一个分段函数，这个分段函数定义一个数字区间的颜色值。</p><p>打个比方这个球，可以点乘结果大于0.85用亮橘色，小于0.5用黑色，中间可以继续分段。如果想要平滑过渡的效果，也可以在函数的分段中用平滑计算的方式获取一个插值。</p><p><img src="npr-coloring.png" alt="NPR着色分段"></p><p>目前来说大部分的卡通渲染，会将N和L的点乘结果对应到一张<strong>Ramp Texture</strong>上， 如下图所示，根据ramp texture上的颜色数据上颜色。这样美术就可以比较方便的控制想要的颜色效果。</p><p><img src="ramp-texture.png" alt="ramp texture"></p><p>下面这张图是对应ramp texture对应的效果。</p><p><img src="ramp-texture-effect.png" alt="ramp texture对应的效果"></p><p>另外为了模拟PBR中光线和视角相关的效果(菲涅尔项)，还需要视角相关的信息。通过法线和视线方向的点乘得到另一个纹理坐标在ramp texture上取值，ramp texture的制作也需要考虑相关的因素。</p><p><img src="ramp-texture-fresnel.png" alt="ramp texture菲涅尔项"></p><h4 id="基于色调的着色">基于色调的着色</h4><p>最后我们简单介绍一下tone based shading，他的主要思想是首先由美术指定冷色调和暖色调，比如说冷色调设定为蓝色，暖色调设定为橙色。而最终模型着色将根据法线和光线的夹角，在这两个色调的基础上进行插值。</p><p>下面是基于色调着色的公式。<br><img src="tone-base-shading.png" alt="基于色调的着色公式"></p><p>这里公式里面的l是光线照射方向，和我们前面BRDF等公式里面的光线方向相反。这里可以看到，公式计算中法线和光线向量的点乘越低，暖色调的比例就越高，冷色调的比例就越低，反之亦然。</p><h3 id="what’s-more">what’s more</h3><p>当然，目前我们说介绍的这些，也只是对NPR的一个最基础的介绍了，为了更好的效果，很多细节需要优化。<br>比如说可能会有更加风格化的高光和阴影，如下图所示。</p><p><img src="highlight-shadow.png" alt="风格化的高光和阴影"></p><p>以及还需要将环境光照的影响考虑进来。</p><p>还有就是现在很多产品选择的在NPR中使用PBR，就比如说我们前面在PBR里面介绍的kajiya-kay的头发高光计算方法，比如说很多二次元风格的模型会在皮肤眼睛等部位同样使用次表面散射的模型。</p><p><img src="NPR-kajiya-kay.png" alt="在NPR中结合Kajiya-Kay"></p><h2 id="未来数字人技术的展望">未来数字人技术的展望</h2><p>最后稍微讲一下我们对未来数字人技术的展望吧。</p><p>首先由于其渲染的复杂度和性能消耗，高保真类型的数字人可能会更趋近于在云端渲染，包括我们的端云渲染平台andeverse，大家可以关注一下。云渲染可以利用云端的强大的分布式硬件，以及高速网络， 实现在一般设备上的真实人物表现。</p><p>同时今年大热的AI技术成果爆发，也让我们不禁想去探索AI辅助的数字人生产制作流程。它能对整个生产管线的效率和效果有多大的提升。</p><p>另外其实皮肤的效果是否还有更进一步的解决办法，因为目前实时渲染还是采用一种近似方法。皮肤下面其实离毛细血管是比较近的，在人类在表现激动情绪的时候会有脸红等肤色的变化的细节。这些细节的完善，可以帮助我们进一步提升写实类人物的渲染，从而走出恐怖谷。</p><p><img src="metahuman.png" alt="metahuman"></p><h2 id="结语">结语</h2><p>《浅谈数字人渲染技术》的内容终于总结完了，这个分享我准备了很久，ppt在交付前一再精简，最后还是有55页，也是整整拆分成四篇文章才勉强将里面的内容将完。</p><p>这次分享也给了我很多的启发，让我熟悉了数字人渲染的相关技术，以及整个产业的发展。里面的内容广泛而深入，这几篇浅显的文章既希望能够帮助到有需要的人，也是我对自己的一次小小的总结。</p><p>希望后面有机会能够进一步深入这个领域。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>数字孪生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数字人仿真的渲染技术（三）</title>
    <link href="/2025/01/06/digital-human-render-3/"/>
    <url>/2025/01/06/digital-human-render-3/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>这篇文章是我在OGEEK上做过的《浅谈数字人仿真的渲染技术》分享的第三部分，在这一部分我会着重介绍数字人的毛发渲染的技术。</p><h2 id="毛发">毛发</h2><p>在前面的内容，我们大致了解了一些皮肤相关的技术，接下来我们再简单了解一些毛发的渲染算法。</p><p>和皮肤一样，其实毛发的构造比我们预想的也要复杂许多，它包括表皮的<em>角质层</em>，角质层里面的<em>皮质</em>，以及<em>发髓</em>。</p><p><img src="hair-structure.png" alt="头发的结构"></p><p>角质层有坑坑洼洼的表面，而且头发的坑坑洼洼具有较为统一的指向性，从发根指向发尾，简化后的头发模型如下图所示。</p><p><img src="simple-hair-structure.png" alt="头发的简化结构"></p><h2 id="Kajiya-Kay模型">Kajiya-Kay模型</h2><p>下面我们来了解一下可能是游戏中毛发渲染最常用的毛发渲染模型，<strong>Kajiya-kay模型</strong>。</p><h3 id="简介">简介</h3><p>首先需要说明的是，Kajiya-Kay模型是一个<strong>基于经验</strong>的模型，也就是说这个模型并不是根据头发的物理结构得出的，所以会有一些并不真实的地方。</p><p>作为一个1989年的shading model，它具有算法简单，便于理解，计算量小。且头发的主高光的性价比高，效果明显。</p><p>那么kajiya-kay模型的一个核心就是各向异性高光，不知道有没有对各向异性不熟悉的朋友，这里简单说明一下，各向异性就是物体的某些特征根据方向的不同而有所变化。</p><p>如下图所示，头发在微观层面的一小段我们把它简化为一个圆柱体，圆柱体的一个截面的normal均匀分布。但是这个normal都是从横截面的中心向外扩散的，不会出现沿着这个圆柱体的法线，其实这就是一种各向异性的体现。</p><p><img src="normal-to-fiber.png" alt="头发的法线"></p><p>我们渲染头发的时候，单个像素里面是一根或者多根极其短且细的头发，按照普通的模型一般是获取单个像素的一个唯一法线的值，但是头发可能在一个像素里面存在着n个法线，法线的不唯一性导致不能再简单的用一个固定法线值去模拟了。</p><p>因此根据经验，kajiya-kay算法采用了一种近似的方法。头发的发根到发尾的方向是这跟头发的<strong>切线方向</strong>，这个方向对于头发来说是统一的，同时也方便美术去制作，因为在一个圆柱体截面上，切线的方向都是一致的。</p><p>如下图所示，L是光线方向在头发某点切线T方向上的分量，我们需要的法线N，它满足垂直于切线，且与L，T同平面，且点乘光线L大于0的方向，我们可以用这个作为N法线来近似高光所需要的法线。只要能够获取到发线，就可以按照我们前面提到的方法计算出这个点的高光了。</p><p><img src="kajiya-get-normal.png" alt="法线的计算"></p><p>我们是通过切线，光线和视线的方向来得到法线，kajiya-kay模型的公式其实也变成了和切线相关的.</p><p>这里大概贴一下kajiya-kay模型的公式，这里我们不去推导这个公式。主要是大家可以看到公式的参数是和切线T，以及半程向量H（光线向量和视线向量的中间）相关的。</p><p><img src="kajiya-kay.png" alt="Kajiya-Kay公式"></p><h4 id="对比">对比</h4><p>这里我们放一个高光的对比效果，黑球上的高光是普通的高光计算，绿球则是带有各向异性计算出来的高光，可以看见绿球的高光有种我们叫天使环的效果，这也是人物头发高光经常会出现的效果。</p><p><img src="kajiya-kay-result.png" alt="Kajiya-Kay效果"></p><p>为了更加贴近头发我们添加一个头发的法线贴图看看效果，同时也给个纹理。</p><p><img src="kajiya-kay-normal-result.png" alt="添加了法线贴图的Kajiya-kay效果"></p><h4 id="优化">优化</h4><p>但是其实仅仅出现天使环效果也不够理想，这是因为Kajiya-Kay模型只是基于经验而不是真正的物理。</p><p>经过观察头发的高光，法线一般是有一个主要高光的，这个主要是受光源颜色的影响，大部分时候是白色。另外一个是受头发颜色的影响，会生成次一点的带颜色高光的。这个其实是有物理意义的，也就是光进入头发里面传输然后透射出来造成的效果。</p><p><img src="kajiya-kay-optimize.png" alt="优化Kajiya-Kay"></p><p>所以现在一般kajiya-kay会加上两个高光的优化。这个效果有时会被称为近似Marschner模型。</p><p>这里我们提到了一个Marschner模型，这个是基于物理建模的毛发渲染模型，我们后续再详细介绍。</p><p>如何实现上述的双层高光效果呢？其实也很简单，就是<em>算两个高光，然后偏移其中一个</em>就好了。</p><p>我们前面看过kajiya-kay的公式，公式的参数是切线和半程向量。按照切线从发根指向发梢，我们在切线上加上像素点的法线并归一化，其实就相当于将切线沿着头发上移或者下移了。</p><p><img src="hair-tangent.png" alt="头发切线方向"></p><p>同时我们增加一个扰动的偏移贴图，可以让高光更有沿着发丝等表面的感觉。<br>左下是偏移贴图，右边是增加了高光偏移和偏移贴图的最终效果，可以看出效果有质的提升。</p><p><img src="kajiya-kay-optimize-result.png" alt="优化Kajiya-Kay的效果"></p><p>不过kajika-kay模型虽然久经沙场，但它始终是基于经验的，他的模型过于简单。<br>并且kajika-kay模型假设头发纤维是光滑的圆柱体，而我们之前见到过头发真正的表面是粗糙的鳞片组成的不规则几何体，所以有很多细节是不够准确的。</p><p>接下来我们来简单介绍一下基于物理的marschner模型。</p><h3 id="Marschner模型">Marschner模型</h3><p>Marschner’s Model是基于头发纤维的结构，进行了相对准确的物理分析并得出的计算方法。</p><p>头发纤维从微观角度来看，实际上是一个从外到内有很多层的结构，它的最外层像鳞片一样，光线在穿过层层头发纤维内部的过程中也会发生折射，反射等，因此我们看到的最终头发呈现的颜色实际上是多条光路综合作用的结果。</p><p>该模型将毛发的光照分为三个部分</p><ul><li>反射：主高光，刚刚kajiya-kay算法其实主要处理的就是这部分，但是marschner模型会考虑头发的角质层的结构，所以说高光是更加有方向性的</li><li>传输-传输：光线照射并穿透毛囊，然后从另一边照射出去。这是光线在一定发量中的散射过程。</li><li>传输-反射-传输路线，光线进入毛囊，从内表面边界反射出来，然后再照射出来。这样产生的是次高光。这也是我们在kajiya-kay近似marschner处理中所做的工作</li></ul><p><img src="Marschner-model.png" alt="Marschner模型"></p><p>其他的光线分量对视觉效果影响比重比较小，我们在实时渲染一般就忽略了。</p><p>由于头发的复杂造型，为了便于分析光线的散射，一般把头发上光的散射行为分为两类，即<strong>纵向散射</strong>和<strong>方位角散射</strong>。</p><p><img src="marschner-diffuse.png" alt="Marschner模型的散射"></p><p><strong>纵向散射</strong>是沿着头发发根到发尾的散射，对于光滑的圆柱体，给定入射方向，反射方向确定的，如下图，但是头发纤维的表面是比较粗糙的，因此并不会发生精确的镜面反射，于是我们就需要一个函数来估计在给定的出射方向（观察方向）上，到底有多少比例的光线射出。这个函数和入射L1、出射方向L2有关，我们用M(L1,L2)来表示，可以简单的认为M就是一个高斯分布的概率密度函数。</p><p><strong>方位角散射</strong>是表示垂直于发丝方向的散射角度和能量的变化，这期间可能会发生比较多的折射和透射，我们也可以用一个函数来估计发生方位角散射时给定出射方向上光线的比例，这个函数除了和入射方向、出射方向投影在圆柱法平面的方位角有关，还和头发内部的折射率n有关，我们用N函数来表示。</p><p>那么每一个光路，R，TT，TRT，都包含了纵向散射和方向角散射，所以我们可以得出一个BSDF模型的公式，即Sp = Mp * Np, p = R,TT,TRT，</p><p><img src="bsdf-model.png" alt="BSDF模型"></p><p>M和N的数值，一般是预处理做成两张LUT，在实时渲染点时候方便直接查找。这里和我们在皮肤渲染的方式有一些类似。不过这种方法一般只支持一种头发颜色和粗糙度。</p><p><img src="bsdf-lut.png" alt="BSDF查找表"></p><p>当然，Marschner模型的关键，也就是M和N函数的计算会涉及比较深入的数学推导和物理原理，今天这里我们就不深入了，有兴趣的同学可以看一下steve  marschner的论文。</p><p>绝大部分的现代渲染器，包括虚幻引擎，目前使用的也是marschner模型来做毛发渲染。</p><h2 id="其他领域">其他领域</h2><p>目前，我们只是浅谈了一些写实数字人的部位的渲染技术，但是还有很多部位是需要特殊处理的。</p><p>比如说作为心灵窗口的眼睛，有非常复杂的生态构造，且充满了液体。在渲染上也会遇到光线的反射散射折射。</p><p>牙齿其实也需要用到次表面散射的模型，他的材质会有一种玉石的散射效果。</p><p>这些部分其实都可以展开来讲。今天时间有限，我们暂时不深入去探讨。有兴趣并且对UE有了解的同学可以去看一下UE的metahuman工程。</p><p><img src="ue-metahuman-face.png" alt="人脸的其他部分"></p><h2 id="结语">结语</h2><p>今天这篇文章简短的介绍了一下数字人毛发渲染的技术，后面的分享将会介绍**非真实感渲染（Non-photorealistic Rendering, NPR）**技术，通常这项技术会被用在渲染卡通风格的内容。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>数字孪生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数字人仿真的渲染技术（二）</title>
    <link href="/2025/01/04/digital-human-render-2/"/>
    <url>/2025/01/04/digital-human-render-2/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>新年好。这是接着上次关于数字人渲染技术的第二部分，今天的这部分的分享，我会开始介绍一些关于数字人渲染的实际技术。</p><h2 id="数字人渲染技术介绍">数字人渲染技术介绍</h2><p>接下来我们来聊一下数字人渲染技术方面的课题，我本身其实在这方面也不是什么大牛，在这里只是把一些我所学到的东西分享给大家。本次也不涉及到过深的技术讨论，如果想要对某个算法的细节想做更深的探讨，我们可以做后续的讨论。</p><p>在这里我提前预告一下，接下来的分享会包括哪些方面。</p><p>首先是会介绍一些数字人常用的渲染技术，比如皮肤，头发的渲染技术。在介绍这些渲染技术的时候，我主要会解释一下这个算法的构成，他是基于哪些理论而得出的算法，他的流程大致是怎样的，以及效果的一些展示。</p><p>本次分享不会包括的方面有：</p><ul><li><p>数学公式推导，当今很多渲染的算法都会遵循实际的物理意义，大多包含较为复杂的数学公式的推导，以辅助实现最后的算法。我们今天的分享是浅谈，所以不会讲的那么深，要是专注于数学公式推导的话会花上非常多的时间，门槛也会提升很多，这块并不是今天的目的。</p></li><li><p>另外一个是不会Review相关的Shader代码或者材质蓝图连线，今天主要是希望大家理解好概念就好，代码这些在理解了概念后自己动手去写可以进一步帮助理解。</p></li></ul><h3 id="基于物理的渲染方式（Physically-Based-Rendering-PBR）">基于物理的渲染方式（Physically Based Rendering - PBR）</h3><p>首先我们来看一下基于物理的渲染方式，也就是我们所说的PBR，这种方式一般是用于渲染写实、高保真类型风格的数字人。</p><p>这里我大概介绍一下PBR的概念。PBR的是基于物理的渲染，他的定义是利用真实世界的原理和理论，通过各种数学方法推导或者简化或者模拟出一系列的渲染方程，来输出拟真的画面。</p><p><img src="pbr_sample.png" alt="PBR对比传统渲染方法"></p><p>上面两张图是PBR和传统的shader的比较。在PBR出现之前，若想渲染出一张高质量的图，需要机械化的死记各种参数，然后基于烘焙贴图来实现的，并且通常环境光、物体位置必须保持不变。这些缺点在高质量的实时渲染里面显然是不能接受的。</p><p>而使用PBR这种渲染方式的话，我们需要分析物体自身物理属性然后给材质设定正确的光照参数，无论物体位置、光照如何改变，都有很好的效果。</p><p>但是PBR并不是纯粹的物理渲染，目前PBR还没办法用和现实一模一样的物理规律来实现渲染效果，这其中有硬件条件的限制（GPU，人眼5亿到10亿个像素的信息量），也有知识水平的限制，光照建模没办法达到和现实一模一样，所以在效果和性能上会需要做取舍。</p><h4 id="BRDF">BRDF</h4><p>这里稍微做个补充，这段在原先的PPT中是没有包括的。</p><p>PBR的一个很经典的方法就是BRDF模型。</p><p><strong>BRDF</strong>的是双向反射分布函数（Bidirectional Reflectance Distribution Function）的英文缩写。<em>它从本质上描述了光线如何在物体表面反射，是一个用于量化给定入射方向的光在某个出射方向上的反射比例的函数。</em></p><p>具体来说，它定义为出射方向的反射辐射率<strong>r0</strong>（radiance）与入射方向的辐照度<strong>r1</strong>（irradiance）的比值，基于入射光方向，和观察（出射）方向。</p><p>例如，假设有一束光从某个方向照射到一个物体表面（这是入射方向），我们从另一个方向观察这个物体表面反射出来的光（这是出射方向），BRDF 就可以告诉我们从这个观察方向看到的反射光的强度和特性与入射光的关系。</p><p>有很多具体实现BRDF的方法，如<em>Cook-Torrance模型</em>、<em>Disney模型</em>等等。BRDF很适用于渲染非透明的物体，如墙壁、木头等等，对于人的皮肤，玉石等带有透明的材质则不太合适。这些材质需要用到<strong>次表面散射（BSSRDF）模型</strong>。</p><h4 id="PBR-皮肤">PBR-皮肤</h4><p>好了，简单理解一下PBR的一些概念后，我们现在来介绍一下写实风格的数字人的皮肤渲染。</p><p>皮肤的渲染一直是渲染领域的难点之一：皮肤具有许多微妙的视觉特征，而观察者对皮肤的外观，特别是脸部的外观会非常敏感（恐怖谷）。皮肤的真实感渲染模型须包括皱纹，毛孔，雀斑等细节，而真实还原人体皮肤上的这些细节则是一个较大的挑战。</p><p><img src="layers_of_skin.png" alt="皮肤多层结构"></p><p>皮肤作为一种属性复杂的材质，不同于简单的材质表面比如说水泥墙这些，其物理结构由<strong>多层结构</strong>组成，其表面油脂层主要贡献了皮肤光照的<em>反射</em>部分，而油脂层下面的表皮层和真皮层则贡献了的<em>次表面散射</em>部分，而且还有一部分光会<em>透射</em>过皮肤的边缘或者很薄的地方。</p><p>这三个方面组成了皮肤渲染的主要因素，我们今天也着重介绍这三部分的一些计算方法。</p><h5 id="镜面反射">镜面反射</h5><p>在皮肤渲染中，高光这部分主要是皮肤的油脂层贡献的。高光的算法可以使用基本的**<a href="https://zhuanlan.zhihu.com/p/715918965">cook Torrance brdf模型</a>**的高光计算部分，因为时间比较紧张，我们就不花时间介绍了。这是最经典PBR算法之一了，如果大家网上搜BRDF就很容易能能够找到。大致思路是高光表现会依据平面的粗糙度，观测角度等不同而不同。如下方图所示。</p><p><img src="Cook-Torrance-BRDF.png" alt="Cook-Torrance BRDF"></p><p>但是直接用BRDF计算皮肤高光一般并不能获得最好的效果，因为皮肤是一个复合的表面，他的突出部分和凹陷部分的粗糙度是不一样的。导致有两个粗糙参数，也就有两个高光需要表示。</p><p>所以虚幻引擎等某些渲染器会使用一个叫做<em>双镜叶高光</em>的技术。<strong>镜叶 lobe</strong>，也是如下图所示，其实就是光在某一个粗糙度平面下的一个分布状态。</p><p>![镜叶]](specular-lobe.png)</p><p>下面这张图是UE里面默认的高光混合的参数，通过混合两个粗糙度的高光表现，可以达到更贴近人脸皮肤的效果:</p><p><img src="skin-specular.png" alt="皮肤高光"></p><h5 id="次表面散射-BSSRDF">次表面散射(BSSRDF)</h5><p>计算完高光后，我们之前提到，光线接触到皮肤时，有大约94%被皮肤各层散射，只有大约6%被反射。<br>我们可以看下对比图，前面我们提到的BRDF，其实主要就是假设光线的反射基于图a的现象，入射点和出射点是同一个，光在这个地方发生漫反射:</p><p><img src="diffuse-comparison.png" alt="反射对比"></p><p>但其实光线在进入皮肤后的真实情况是更接近图b的，光线会进入我们的皮肤，通过油脂层到下面的表皮层和真皮层，会进行一阵游走，然后最终有一部分光线会被反射出来。</p><p>实际上几乎所有材质都存在次表面散射现象，区别只在于材质散射密度分布的集中程度，如果绝大部分能量都集中在入射点附近，就表示附近像素对当前像素的光照贡献不明显，可以忽略，则在渲染时我们就用漫反射代替，如果该函数分布比较均匀，附近像素对当前像素的光照贡献明显，则需要单独计算次表面散射。</p><p>为了模拟这种光线表现，提出了<strong>BSSRDF</strong>。</p><p><img src="BSSRDF.png" alt="BSSRDF"></p><p>BSSRDF描述的是，对于当前出射点和出射方向，某个入射点和入射方向的光线能量对其结果的贡献。<br>我们观察点是固定的po，已知需要的出射方向，根据这些条件获取周围点对他的光照贡献（w：omega）。</p><p>如果我们想要按照真实世界，实时的模拟出每一束光在皮肤材质中的路线，从而获取到每一束光的正确出射点和角度的话，是难道很大的。BSSRDF的意义在于快速的近似真实世界的效果，为了平衡性能和效果，我们假设了4个前提：</p><ul><li>物体是一个曲率为0的平面。</li><li>平面的厚度和大小都是无限。</li><li>内部的介质参数是均匀的。</li><li>光线永远是从垂直方向入射表面。</li></ul><p>基于这些前提，我们就可以单纯以像素的距离作为权重，距离当前像素近的入射光照，贡献就大，反之距离远的，贡献小。对应的也就是公式上的R(||pi-po||)这部分。</p><p><img src="BSSRDF-1.png" alt="BSSRDF-1"></p><p>当然真正人体表面的皮肤是不满足与上面四点的，但是考虑到实时渲染的性能，单纯按照两个点的距离的近似可以达到能接受的效果。</p><p>用来描述光在物体内部的散射或者扩散的行为，就是公式中R那个部分，这个分布函数我们叫做<em>散射剖面（diffusion profile）</em>，也有叫<em>扩散剖面</em>的。</p><p>计算散射剖面的算法有很多种，常见的有<strong>偶极子，多极子，高斯和拟合</strong>等等。这里内容比较深，由于时间的关系我们暂时不做详细介绍了。</p><p>同时，由于是单纯的根据距离来获得光照的权重，我们可以预处理散射剖面，做成一张lookup table，在实时渲染的时候直接查找对应的值，以加速渲染。<br>可以看一下这张图，reflectance（反射率）根据距离的变化，而且rgb三原色是分开计算的.</p><p><img src="reflectance-lookup-table.png" alt="反射率参照表"></p><h5 id="基于模糊的算法">基于模糊的算法</h5><p>计算次表面散射的光照的时候，当前像素的光照会受到周边像素的影响，而这个影响的程度我们是以距离来决定的。那其实换个角度想想，这是不是就是我们把原来当前像素的漫反射，抹匀到了周边，因为光的能量经过次表面散射分散到了周边的像素。这其实就是一个模糊操作，从数学角度上，都是做卷积处理。所以就有了基于模糊的皮肤渲染算法。</p><p>那么根据施加模糊的空间，分为了<em>纹理空间模糊</em>和<em>屏幕空间模糊</em>：</p><h6 id="纹理空间模糊">纹理空间模糊</h6><p>纹理空间模糊他的一般步骤大概是：</p><ol><li>首先需要获得一张拉伸校正贴图，一般是会预计算这张帖图，主要是为了表示每个Texel（纹素）需要进行多大范围的模糊。</li><li>然后渲染出模型的光照，漫反射，然后将模型的光照展开到纹理空间。</li><li>将这张图根据拉伸校正贴图所标定的范围，进行模糊处理，保存成一张或者多张纹理贴图。</li><li>最终渲染的时候，我们会获取依据这些贴图，然后按照某些特定的权重将它们混合，得到最后的漫反射结果</li></ol><p><img src="texture-space-blur.png" alt="纹理空间模糊"></p><p>在纹理空间模糊的好处很明显：比较正确，不会穿帮，可以进行低精度的绘制再利用硬件插值来辅助Blur，模糊的方法也很多。</p><p>但缺点也很明显：主要是背面也同样要绘制，而且美术需要处理好纹理不然会有接缝问题。</p><h6 id="屏幕空间模糊">屏幕空间模糊</h6><p>那么屏幕空间模糊就比较好理解了，就是在屏幕空间对皮肤的光照结果进行模糊。<br><img src="screen-space-blur.png" alt="屏幕空间模糊"></p><p>需要注意一下边界问题，不能模糊出界了，处理的时候可以根据深度等作为模板处理。<br>下面的图是皮肤在纹理空间和屏幕空间的模糊的效果的不同。</p><p><img src="blur-camparison.png" alt="模糊比较"></p><h5 id="透射">透射</h5><p>最后我们简单讲一下透射，透射和次表面散射的区别是透射的光一般是从另外一面照射过来的，而次表面散射我们一般是按照光源和我们的观察点在模型的同一侧。像是我们手指边缘，或者耳垂部分，是比较容易出现这种现象的。</p><p>我们一般计算透射的方式的步骤包括三步：</p><ol><li>计算光照在进入半透明介质时的强度</li><li>计算光线在介质中经过的路径</li><li>根据路径长度和BTDF来计算出射光线的强度</li></ol><p>那这里我们又要提出一个BXXXDF了，也就是BTDF，其中的T就代表透射。他和BRDF较为类似，只不过光源是从另外一面穿出来的。</p><p><img src="BTDF.png" alt="BTDF"></p><p>当然由于光在另外一面穿到前面来，光的强度会有损失，光也会在皮肤出现次表面散射，不过BTDF作为一种近似算法在实时渲染中一般只简化为一个和光线路径长度的函数。</p><p>不过一般来说皮肤渲染上透射出现的区域也是比较小的。</p><h4 id="UE里面的皮肤着色模型">UE里面的皮肤着色模型</h4><p>皮肤的渲染算法我们目前就介绍到这里了，当然作为浅谈我们只是稍微触及了一些皮毛，想要做出更好更加真实的皮肤效果还有很多地方可以深入。</p><p><img src="ue-skin.png" alt="UE皮肤着色模型"></p><p>这里我大概介绍一下UE，可能很多同学自己做项目也是用的UE。UE的皮肤材质有很多种着色类型，在材质的着色类型可以选择，一般来说皮肤的材质会默认是<strong>次表面轮廓类型</strong>，这是效果最好的着色模型，像是metahuman的皮肤材质着色也是这种类型。</p><p><strong>次表面</strong>就是我们前面讲的基于次表面散射的着色模型，因为次表面散射也可以用作冰川等材质，所以如果选择次表面着色模型且针对皮肤想要有更好的效果的话，需要自己进行调整。</p><p>最后<strong>预整合皮肤</strong>也是我们之前提到的优化方法之一，他精度比次表面略低但是性能开销也低。</p><h2 id="结语">结语</h2><p>写实风格的皮肤渲染技术就分享到这了，不知不觉文章的长度已经超长了，剩下的部分只能放到后续的文章了。下次的分享的主要内容将会是头发的渲染。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>数字孪生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数字人仿真的渲染技术（一）</title>
    <link href="/2024/12/28/digital-human-render-1/"/>
    <url>/2024/12/28/digital-human-render-1/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在2022年12月，我受邀在OGEEK上做过一次关于数字人渲染技术的分享，名为《浅谈数字人仿真的渲染技术》。为了这次分享我查阅了大量资料做了很多准备，但是很不幸的是在分享的前两天我便感染了新冠，身体开始发烧外加喉咙开始隐隐作痛。为了不影响OGEEK的流程我便在病情还未恶化的时候将分享提前录了下来，以播片的形式参加。</p><p>这段经历确实还挺难忘，近期又翻到了这篇准备的PPT，和演讲的录屏，于是想将这部分内容做个记录，整理成文章分享出来。</p><p>由于PPT内容还是比较多的，哪怕是精简后的版本也还有50多页，于是乎会准备做成一个系列，当初精简掉的部分可能也会想办法补充回来，让内容尽量的充分。</p><h2 id="数字人简介">数字人简介</h2><h3 id="数字人的定义">数字人的定义</h3><p>目前数字人缺乏一个统一的标准定义，我们从它的发展起源，从技术角度上选择一个最宽泛最简洁的标准：<strong>由计算机生成的人类。</strong></p><p>中国人工智能产业发展联盟发布的《2020年虚拟数字人发展白皮书》中给了一个更加详细的定义：虚拟数字人意指具有数字化外形的虚拟人物，除了拥有人的<strong>外观</strong>、人的<strong>行为</strong>之外、还有拥有人的<strong>思想</strong>，具有<strong>识别外界环境</strong>、并能与<strong>人交流互动</strong>的能力。</p><p>那其实这个定义里面，也描述了数字人相关的几个关键技术方向，包括：<em>渲染-外观，行为-驱动算法，思想-AI，识别外接环境-感知，与人交流互动-表达</em>。</p><h3 id="数字人的发展历史">数字人的发展历史</h3><p>在上世纪80年代，其实就有虚拟形象引入到现实世界的想法。<br>1982 年，动画片《太空堡垒》中的女角色林明美作为虚拟歌姬出道，其专辑也成功打入当时的知名音乐排行榜。日本媒体率先提出了“虚拟偶像”的称号。1984 年，世界首位虚拟电影演员“Max Headroom”诞生，出演电影，并拍摄数支广告，在英国家喻户晓。</p><p><img src="%E6%9E%97%E6%98%8E%E7%BE%8E.png" alt="林明美"></p><p>此时，虚拟人概念先行，给予虚拟形象以立体化人设，并带入大众视野。但受制于技术发展，“数字化”在这个阶段并不明显。打造虚拟人的技术以手工绘制为主，人物形象以 2 D 卡通的形式展现，展现方式以事先完成的音频和视频为主，并不具备实时交互功能。</p><p>进入 21 世纪，虚拟人的 数字化特征逐渐明显。形象创建上，虚拟数字人开始从手绘转向 CG和动捕等计算机技术。</p><p>2007 年，日本虚拟歌手“初音未来”的诞生与流行。初音未来的虚拟形象采用 CG 和动作捕捉技术。在动作捕捉技术的助力下，初音未来可以直接采用人类的表情和动作，并借助 CG 技术真实的360度渲染出来。作为虚拟歌姬，初音未来的歌喉基于 VOCALOID（电子音乐制作 的 语音合成软件）。采样于日本声优藤田咲，创作者只需要输入歌词和旋律，就能够自动形成歌曲。</p><p><img src="%E5%88%9D%E9%9F%B3%E6%9C%AA%E6%9D%A5.png" alt="初音未来"></p><p>近年来，由于各项技术的不断发展，出现了越来越多高真实度的数字人形象。</p><p>比如说2016年出现的miquela，她在ins上的出现引发了一场“真假辩论”。许多粉丝相信她是真实存在的人物，只是修图“狠”了点。直到黑客们入侵了她的账号，才最终确定了她是由 3 D 电脑动画公司制作的虚拟人。她甚至在2018年一起被美国《时代》周刊列为“25 位最有影响力的互联网人物”</p><p>同样是在2018年，由腾讯、Epic Games推出了Siren项目。Siren 的所有动作表情都由实时捕捉以及实时渲染形成，并且整个过程只有15毫秒，60帧。Siren在渲染的真实性和交互性之间找到平衡，打造了具备实时交互能力的数字虚拟人。</p><p><img src="siren.png" alt="siren"></p><h3 id="数字人的分类">数字人的分类</h3><p>数字人可以按照不同维度进行分类。</p><p>按照美术风格：</p><ul><li>2D、3D</li><li>写实、卡通、风格化</li></ul><p>按照驱动方式：</p><ul><li>真人驱动</li><li>AI驱动</li></ul><p>按照商业和功能维度：</p><ul><li>内容/IP型</li><li>功能服务型</li><li>虚拟分身</li></ul><h3 id="数字人的发展">数字人的发展</h3><p>近几年，虚拟数字人在电商、金融、影视、游戏和金融等行业都拥有不同大小的市场规模。<br>我们拿虚拟偶像的市场作为例子。虚拟偶像行业2020年中国的市场规模为34.6亿元，预计2023年将达到205.2亿元。带动的市场从2020的645.6亿元，预计2023年增长到3334.7亿元，是一个指数级的增长。</p><p>当然除了虚拟偶像数字人还有很多其他方面的应用，所以市场前景是非常可观的。下面是一个虚拟偶像市场规模及预测的分析。</p><p><img src="%E8%99%9A%E6%8B%9F%E5%81%B6%E5%83%8F%E5%B8%82%E5%9C%BA%E8%A7%84%E6%A8%A1.png" alt="虚拟偶像市场规模"></p><h2 id="数字人的制作流程简介">数字人的制作流程简介</h2><p>数字人制作大致分4个阶段：</p><ol><li><p>第一阶段（形象设计）：明确形象设计方向。</p></li><li><p>第二阶段（模型制作）：根据平面形象，进行模型搭建。<br>这里我们以可能是最为复杂的超写实数字人的制作流程进行举例，首先在lightstage里面扫描模型（扫描仪，360度单反相机阵列，300多个相机组成）。扫描出来的模型是一个点云，需要模型师去调整，抚平一些瑕疵。去除扫描的毛刺。有些部位可能拍照的时候出现遮挡（比如耳后），需要在模型软件工具中处理好。<br><img src="%E8%80%81%E9%BB%84%E6%89%AB%E6%8F%8F.png" alt="老黄扫描"><br><img src="%E8%80%81%E9%BB%84%E5%BB%BA%E6%A8%A1.png" alt="老黄建模"></p></li><li><p>第三阶段（驱动绑定）：<br>面部动画face rig绑定驱动，通过动画，人脸识别，或者AI去驱动。或者使用blendshape等技术。<br>身体躯干使用骨骼绑定，辅以动作捕捉等等。<br><img src="metahuman%E9%9D%A2%E9%83%A8%E9%A9%B1%E5%8A%A8.png" alt="metahuman(UE)面部驱动"><br><img src="%E8%80%81%E9%BB%84%E9%A9%B1%E5%8A%A8.png" alt="老黄驱动"></p></li><li><p>第四阶段（渲染）：将场景、人物放入渲染工具进行渲染输出，常用的工具包括nVidia omniverse、unreal engine等等。<br><img src="%E8%80%81%E9%BB%84%E6%A8%A1%E5%9E%8B%E6%B8%B2%E6%9F%93.png" alt="老黄模型渲染"></p></li></ol><p>目前虚幻引擎5的metahuman creator是一个很流程化且易于使用的数字人制作工具。</p><h2 id="结语">结语</h2><p>第一部分先总结到这里，在后面的部分我会更加详细的介绍一些数字人渲染技术，包括皮肤、头发的渲染以及卡通渲染等等。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>数字孪生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>虚幻引擎之基于AI的贴图生成方法</title>
    <link href="/2024/12/22/ue-ai-texture-generation/"/>
    <url>/2024/12/22/ue-ai-texture-generation/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>今年年初，由于公司部门的变动，我从原来的云服务部门调到了新成立的AI部门。<br>AI是最近最火热的东西，我虽然肯定算不上专业，但是也稍微有粗略的接触过一点点。再加上部门新成立没有什么业务上的压力，我便花了点时间去做了些预言，这个工具便是其中之一。</p><p>这个工具是为了研究如何将AIGC和3D工作流结合起来的成果。当时选了几个方向，包括AIGC贴图、AIGC模型和3D结合controlnet来辅助AIGC文生图等等。研究的过程中用Unreal Engine搭了些简单的demo，很可惜后续有真正的项目推进后，这些预研的内容也并未有进一步的推进了，觉得有些许可惜，于是便打算在这里记录一下。</p><p>同时这个项目也上传到了Git，有兴趣的欢迎查看：<a href="https://github.com/ruochenhua/UETextureGeneration">UETextureGeneration</a>。</p><h2 id="介绍">介绍</h2><h3 id="大体流程">大体流程</h3><p>这个demo的流程非常简单，参照一般文生图的流程，填写提示词、负提示词、生成步数和种子等信息。这些参数将传入给到文生图的Python脚本，脚本会运行一个大模型来创建对应的结果。</p><p><img src="run_texgen.png" alt="运行工具得到生成的贴图"></p><h3 id="安装步骤">安装步骤</h3><p>下面介绍一下这个工具所需要的准备工作。</p><ul><li><p>首先我们需要找到引擎的python地址，如C:\UnrealEngine\UE_5.3\Engine\Binaries\ThirdParty\Python3\Win64，找到这个路径的python.exe文件。虚幻引擎是以这个Python来运行Python脚本，所以我们对应的Python库需要安装在这个路径之下。</p></li><li><p>记录下上面的Python的路径，打开cmd或其他命令行工具，以:<br>“C:\UnrealEngine\UE_5.3\Engine\Binaries\ThirdParty\Python3\Win64\python.exe” -m pip install XXX</p><p>这种格式来使用pip安装对应的库。</p></li><li><p>需要安装的库包括以下这些：</p><ul><li>transformers, diffusers, accelerate（hugging face）</li><li>pytorch（<a href="https://pytorch.org/get-started/locally/%EF%BC%8C">https://pytorch.org/get-started/locally/，</a> <a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a>)</li><li>numpy</li><li>opencv-python</li></ul></li></ul><p>python的版本可能不支持最新的pytorch版本，如ue5.3使用的python 3.9.7只能支持到pytorch2.1，需要根据版本来安装合适的版本，numpy支持到1.24.1版本，opencv-python支持到4.6.0版本。</p><p>ue5.5的Python升级到了3.11，所以可以支持到更新的版本了，请在安装前检查一下，要不然很容易出现问题。</p><h3 id="文件布局">文件布局</h3><p>三个脚本放在<strong>Scripts</strong>文件夹下，分别对应着漫反射贴图生成、法线和置换贴图生成以及提升贴图分辨率三个流程。</p><p>下面简单介绍一下这个几个脚本对应的能力。</p><h3 id="漫反射贴图生成：">漫反射贴图生成：</h3><p>脚本名称：<a href="http://RunTexGen.py">RunTexGen.py</a></p><p>漫反射贴图生成使用模型：<a href="https://huggingface.co/dream-textures/texture-diffusion">texture diffusion</a></p><p>模型基于stable diffusion 2 base，通过DreamBooth微调，可通过文生图的方式生成材质的漫反射贴图，尽量不包含光照和阴影信息。</p><h3 id="法线贴图生成：">法线贴图生成：</h3><p>脚本名称：<a href="http://RunNormalGen.py">RunNormalGen.py</a></p><p>为了有更加真实的光照表现效果，贴图一般会配合法线贴图使用。<br>从漫反射贴图生成法线贴图的库有好几个，比如说<a href="https://github.com/HugoTini/DeepBump">deepbump</a>，demo使用的是<a href="https://github.com/joeyballentine/Material-Map-Generator">Material-Map-Generator(MMG)</a>，因为它还可以生成DisplacementMap和RoughnessMap，这两张贴图同样可以增强模型在3D光照环境下的表现。</p><h4 id="置换贴图：">置换贴图：</h4><p>上文提到了置换贴图（DisplacementMap），这个资源也是一个提升模型显示效果的手段。法线贴图增加模型细节是不需要修改模型本身的顶点形状的，只是通过提供更为细致的平面法线信息辅助光照计算。</p><p>置换贴图则是可以真实的修改模型的形状。</p><p>在UE中可以使用模型工具通过<strong>DisplacementMap</strong>来丰富模型的细节，也有另外一种方法<strong>视差遮挡映射（ParallaxOcclusionMapping)</strong>，我在UE中使用的是这种方法。</p><h3 id="Upscale：">Upscale：</h3><p>脚本名称：<a href="http://RunUpScale.py">RunUpScale.py</a></p><p>使用<a href="https://huggingface.co/radames/stable-diffusion-x4-upscaler-img2img">Upscale Pipeline stable-diffusion-x4-upscaler-img2img</a>，将原有的贴图分辨率从512X512提升到2048X2048，模型精度有比较大的提升，但是显存需求显著增大，并且消耗时间显著增长。</p><h2 id="使用">使用</h2><p>最简单的方式是参照下面的蓝图方式调用即可。<br><img src="texgen_bp.png" alt="脚本调用蓝图"><br><img src="texgen_bp_macro.png" alt="参数包裹函数"></p><p>最初调用的时候由于需要下载对应的模型，所以时间会相对来说久一些。并且由于是从hugging face上下载模型，可能需要梯子。<br><img src="texgen_cmd.png" alt="调用后的命令行"></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>虚幻引擎</tag>
      
      <tag>AIGC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>屏幕空间反射</title>
    <link href="/2024/12/10/screen-space-reflection/"/>
    <url>/2024/12/10/screen-space-reflection/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是屏幕空间反射">什么是屏幕空间反射</h2><p>在前面的文章的一些配图中，其实已经揭露了之前在<a href="https://github.com/ruochenhua/KongEngine">KongEngine</a>中实现的一个不小的功能点，就是<strong>屏幕空间反射（screen space reflection）</strong>。加入了屏幕空间反射能力之后，在一些光滑和带有反射材质的表面上，能够实现不错的反射效果。</p><p><img src="screen-space-reflection-in-kong.png" alt="KongEngine中的屏幕空间反射效果"></p><p>屏幕空间反射（后简称<strong>SSR</strong>）是一种在实时渲染中用于模拟物体表面反射的成熟技术。SSR 的核心原理是在<strong>屏幕空间</strong>中进行光线追踪，以此计算反射效果，而无需像传统方法那样在世界空间或物体空间中进行复杂的光线与场景求交计算。它主要利用屏幕上已有的<strong>深度图</strong>和<strong>法线图</strong>等信息，通过对这些信息的分析和处理，确定反射光线的方向和位置，进而得到反射颜色。</p><p>因为SSR不错的效果表现和相对来说比较低的性能开销，使其被广泛的应用在各个实时渲染领域，包括游戏、虚拟现实、建筑可视化等等。当然SSR的效果其实还不够完美，有很多无法解决的问题，这个在后面也会提到。但是在大多数情况下它的效果都是足够的，属于一个很<strong>高性价比</strong>的方法。</p><h2 id="如何实现屏幕空间反射">如何实现屏幕空间反射</h2><h3 id="屏幕空间反射的实现方法">屏幕空间反射的实现方法</h3><p>简单概括一下SSR的实现方法：</p><ol><li>对于屏幕上的每个像素，先获取其<strong>深度值</strong>和<strong>法线向量</strong>。</li><li>结合相机参数和屏幕坐标计算出<strong>观察向量</strong>，进而得到<strong>反射向量</strong>。</li><li>沿着反射向量在屏幕空间进行光线追踪，查找反射光线与场景中其他物体的相交点，以获取反射光线的颜色，最终将反射颜色与场景的原始颜色进行合成，得到带有反射效果的最终渲染结果。</li></ol><p>我们对于上面1、2两步应该已经不陌生了，毕竟我们在前面的文章就介绍了KongEngine接入<a href="https://ruochenhua.github.io/2024/10/19/defer-render/">延迟渲染</a>的能力，在G-Buffer中我们已经存储了屏幕空间的各种相关数据，包括深度值和法线向量。有了这些数据，按照第2点计算反射向量也是很顺理成章的事情。</p><p>对应的代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 将延迟渲染保存的数据传给SSR shader</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">CRender::SSReflectionRender</span><span class="hljs-params">()</span> <span class="hljs-type">const</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// scene normal：defer_buffer_.g_normal_</span><br><span class="hljs-comment">// scene reflection mask: defer_buffer_.g_orm_</span><br><span class="hljs-comment">// scene position: defer_buffer_.g_position_</span><br><span class="hljs-comment">// scene depth存在于normal贴图的w分量上</span><br>ssreflection_shader-&gt;<span class="hljs-built_in">Use</span>();<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, defer_buffer_.g_position_);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + <span class="hljs-number">1</span>);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, defer_buffer_.g_normal_);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + <span class="hljs-number">2</span>);<br><span class="hljs-comment">// 用给后处理的texture作为scene color</span><br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, post_process.screen_quad_texture[<span class="hljs-number">0</span>]);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + <span class="hljs-number">3</span>);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, defer_buffer_.g_orm_);<br><br>quad_shape-&gt;<span class="hljs-built_in">Draw</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>那么SSR的关键步骤，其实就在第三步，也是需要理解的重点部分。</p><h3 id="获得反射的颜色">获得反射的颜色</h3><p><img src="ssr-step3.gif" alt="SSR计算反射向量"></p><p>上面这张图大致描述了第3步的状态。图片中<strong>蓝色</strong>的向量代表了从相机向场景中的每个像素发射的观察向量，<strong>绿色</strong>的向量代表了场景中的法线向量，根据观察向量和法线向量，我们能够计算出反射向量，也就是图片中的<strong>红色</strong>向量。</p><p>我们需要得到的反射结果的颜色，基于反射向量和渲染场景中的其他物体的相交结果，这个是通过在<em>屏幕空间进行步近，判断步近后的坐标深度和深度缓存中存储的物体深度是否相交</em>来得到的。如果有相交结果，则该像素的反射颜色就是相交处的场景颜色，若超出步近范围（会预先设置一个步近长度或者步数的范围），则改点没有反射需要处理。</p><p><img src="ssr-step4.gif" alt="反射向量步近"></p><p>这个原理是非常简单易懂的，下面是这段逻辑的大致代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec2</span> tex_size = <span class="hljs-built_in">textureSize</span>(scene_position, <span class="hljs-number">0</span>).xy;<br>    <span class="hljs-type">vec2</span> tex_uv = <span class="hljs-built_in">gl_FragCoord</span>.xy / tex_size;<br><br>    <span class="hljs-comment">// 材质相关的参数</span><br>    <span class="hljs-type">vec4</span> orm = <span class="hljs-built_in">texture</span>(orm_texture, TexCoords);<br>    <span class="hljs-type">float</span> roughness = orm.y;<br>    <span class="hljs-type">float</span> metallic = orm.z;<br>    <span class="hljs-comment">// 颜色信息</span><br>    <span class="hljs-type">vec4</span> s_color = <span class="hljs-built_in">texture</span>(scene_color, TexCoords);<br>    FragColor = s_color;<br><br>    <span class="hljs-comment">// 深度和法线</span><br>    <span class="hljs-type">vec4</span> normal_depth = <span class="hljs-built_in">texture</span>(scene_normal, TexCoords);<br>    <span class="hljs-type">vec3</span> world_normal = <span class="hljs-built_in">normalize</span>(normal_depth.xyz + randVec3(<span class="hljs-built_in">fract</span>(TexCoords.x*<span class="hljs-number">12.345</span>)*<span class="hljs-built_in">sin</span>(TexCoords.y)*<span class="hljs-number">9876.31</span>)*<span class="hljs-number">0.2</span>*roughness);<br><br>    ...<br><br>&#125;<br></code></pre></td></tr></table></figure><p>上面这段代码是将gbuffer中的信息读出来，包括前面讲到的几个部分。其中法线信息world_normal和材质的粗糙度做了一个随机方向的叠加，可以稍微增加反射效果的粗糙感。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br><br>    <span class="hljs-comment">// 远近平面</span><br>    <span class="hljs-type">vec2</span> near_far = matrix_ubo.near_far.xy;<br>    <span class="hljs-type">vec3</span> world_pos = <span class="hljs-built_in">texture</span>(scene_position, TexCoords).xyz;<br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br><br>    <span class="hljs-type">mat4</span> projection = matrix_ubo.projection;<br>    <span class="hljs-type">mat4</span> view = matrix_ubo.view;<br>    <span class="hljs-type">mat4</span> vp = projection * view;    <span class="hljs-comment">// 世界坐标到裁切坐标的转换矩阵</span><br><br>    <span class="hljs-type">vec3</span> view_dir = <span class="hljs-built_in">normalize</span>(world_pos-cam_pos);<br>    <span class="hljs-type">vec3</span> rd = <span class="hljs-built_in">normalize</span>(<span class="hljs-built_in">reflect</span>(view_dir, world_normal));<br>    <br>    <span class="hljs-type">float</span> resolution = <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-type">float</span> max_step_dist = <span class="hljs-number">5.0</span>;        <br>    <span class="hljs-type">vec3</span> start_pos_world = world_pos  + rd*<span class="hljs-number">0.1</span>;<br>    <span class="hljs-type">vec3</span> end_pos_world = world_pos + max_step_dist*rd;<br><br>    <span class="hljs-comment">// 在屏幕空间上的从起始点到结束点的坐标</span><br>    <span class="hljs-type">vec4</span> start_clip = vp * <span class="hljs-type">vec4</span>(start_pos_world, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-type">vec4</span> end_clip   = vp * <span class="hljs-type">vec4</span>(end_pos_world, <span class="hljs-number">1.0</span>);<br><br>    ...<br>&#125;<br><br></code></pre></td></tr></table></figure><p>在上面的代码，我们计算出了反射向量rd，同时也为步进设定了一个范围max_step_dist，得到了反射的步进区间，接下来就是进行步进的操作了。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br>    <br>    <span class="hljs-comment">// 步进的步数</span><br>    <span class="hljs-type">int</span> step_count = <span class="hljs-number">32</span>;<br>    <span class="hljs-type">int</span> sample_count = step_count;<br>    <span class="hljs-type">float</span> delta = <span class="hljs-number">1.0</span> / sample_count;   <span class="hljs-comment">// 如果sample count为10，则delta采样为总共的1/10</span><br><br>    <span class="hljs-type">vec4</span> reflect_color = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_count; i++)<br>    &#123;<br>        <span class="hljs-type">float</span> sample_t = i*delta;<br>        <br>        <span class="hljs-comment">// 步进到达处的屏幕空间uv</span><br>        <span class="hljs-type">vec2</span> uv = <span class="hljs-type">vec2</span>(<span class="hljs-number">0</span>);<br><br>        <span class="hljs-keyword">if</span>(campareDepth(start_clip, end_clip, start_pos_world, end_pos_world, sample_t, uv))<br>        &#123;<br>            reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);        <br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br><br>    FragColor = reflect_color*metallic;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上面的步进代码中，根据设定好的步进步数迭代，campareDepth函数中将当前位置的深度和深度缓存中的数据作对比，若当前深度大于缓存中的值，则代表击中并返回对应的屏幕空间贴图对应的uv值。</p><p>最后反射的颜色和金属度相乘，金属度越高的材质反射也是越高的。在场景渲染的最后，将反射颜色和场景实际的颜色结合，就得到了基本的反射效果了。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl">FragColor = <span class="hljs-built_in">texture</span>(scene_texture, TexCoords);<br><span class="hljs-type">vec4</span> reflection_color = <span class="hljs-built_in">texture</span>(reflection_texture, TexCoords);<br><br>FragColor.rgb += reflection_color.rgb * reflection_color.a;<br></code></pre></td></tr></table></figure><p><img src="ssr_normal_s32.png" alt="SSR效果:sample数32"><br>上面是采样步数为32步时，得到的反射效果。可以看到反射效果确实出来了，但是条纹效果太过于明显。我们可以提高采样的精度，将sample的数量改为128后可以得到明显改善的结果，如下图。</p><p><img src="ssr_normal_s128.png" alt="SSR效果：sample数128"></p><h2 id="屏幕空间反射的优化">屏幕空间反射的优化</h2><p>现在我们已经有了基础的反射效果了，但是我们还是不满足不是吗。单纯提升采样精度确实能得到不错的效果，但是始终还是要考虑实际的性能的。那么有什么方法可以优化SSR的表现呢，下面会做一部分简单的介绍。</p><h3 id="粗晒和精筛">粗晒和精筛</h3><p>在上面的采样处理中，我们通过步进迭代获取到了深度超过gbuffer中的深度的位置。为了弥补采样步数不足，我们可以将采样过程分为两部分：首先是粗筛，用较低的采样精度获取到大致的区间；然后再利用二分法或者其他方法在大致区间内进行二次筛选。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br><br>    <span class="hljs-type">float</span> sample_t = i*delta;<br>    <span class="hljs-comment">// 线性插值找到当前采样的屏幕空间的点</span><br>    <span class="hljs-type">vec2</span> uv = <span class="hljs-type">vec2</span>(<span class="hljs-number">0</span>);<br><br>    <span class="hljs-keyword">if</span>(campareDepth(start_clip, end_clip, start_pos_world, end_pos_world, sample_t, uv))<br>    &#123;<br>        reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);<br>        <span class="hljs-type">int</span> split_count = <span class="hljs-number">10</span>;<br>        <span class="hljs-type">float</span> i_divide_pos = <span class="hljs-number">0.5</span>;<br>        <span class="hljs-keyword">while</span>(split_count &gt; <span class="hljs-number">0</span>)<br>        &#123;<br>            <span class="hljs-keyword">if</span>(campareDepth(start_clip, end_clip, start_pos_world, end_pos_world, (<span class="hljs-type">float</span>(i)-i_divide_pos)*delta, uv))<br>            &#123;<br>                i_divide_pos += i_divide_pos*<span class="hljs-number">0.5</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span><br>            &#123;<br>                i_divide_pos -= i_divide_pos*<span class="hljs-number">0.5</span>;<br>            &#125;<br>            split_count--;<br>        &#125;<br><br>        reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);<br>        <span class="hljs-keyword">break</span>;<br>    &#125;<br><br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>下面是这种方法的结果，可以看到效果是稍微好了些，不过如果需要再进一步的话，还是避免不了要提升采样精度。<br><img src="ssr_sample_twice.png" alt="SSR二次采样"></p><h3 id="屏幕空间步进">屏幕空间步进</h3><p>目前比较常用的优化方法，是把三维空间做光线步近替换为在屏幕空间做光线步近。<br>传统的在三维空间做光线步近，很难避免采样不均的问题，如果我们是以三维空间的的步近长度作为采样依据的话，会出现下面的问题。其中蓝色小格子代表的是像素，红色的点对应的是每个采样点对应的像素位置。</p><p><img src="ssr_over_sample.png" alt="SSR过采样"><br>当反射角度相对来说比较大，很容易出现非常多采样点对应同一个像素，进行了大量的重复运算。</p><p><img src="ssr_under_sample.png" alt="SSR欠采样"></p><p>反射角度过小的时候，有很容易出现跳过中间某些像素的情况，出现了欠采样的情况。这也是我们上面的反射效果出现了带状的原因。</p><p>在<a href="https://jcgt.org/published/0003/04/04/">Efficient GPU Screen-Space Ray Tracing</a>这篇文章提出了在屏幕空间采样的观点。通过将采样点的选择放在屏幕空间，实现采样点连续且分布均匀的效果。每个采样点不会进行重复计算，也保证了性能的最优。<br><img src="ssr_ss_sample.png" alt="SSR屏幕空间采样方法"></p><p>为了实现屏幕看见步近，代码需要做一些修改：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br><br>    <span class="hljs-type">vec3</span> start_pos_world = world_pos  + rd*<span class="hljs-number">0.1</span>;<br>    <span class="hljs-type">vec3</span> end_pos_world = world_pos + max_step_dist*rd;<br>    <span class="hljs-comment">// 在屏幕空间上的从起始点到结束点的坐标[0, resolution]</span><br>    <span class="hljs-type">vec4</span> start_clip = vp * <span class="hljs-type">vec4</span>(start_pos_world, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-type">vec4</span> end_clip   = vp * <span class="hljs-type">vec4</span>(end_pos_world, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-comment">// 在屏幕空间进行光线步进</span><br>    <span class="hljs-comment">// 起始点和结束点</span><br>    <span class="hljs-type">vec3</span> start_ndc  = start_clip.xyz / start_clip.w;<br>    <span class="hljs-type">vec3</span> end_ndc    = end_clip.xyz / end_clip.w;<br>    <span class="hljs-type">vec3</span> ndc_diff = end_ndc - start_ndc;<br><br>    <span class="hljs-comment">// ndc-&gt;屏幕坐标 [0, resolution.xy]</span><br>    <span class="hljs-type">vec3</span> start_screen  = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);<br>    start_screen.xy = (start_ndc.xy + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span> * tex_size;<br>    start_screen.z = (near_far.y - near_far.x) * <span class="hljs-number">0.5</span> * start_ndc.z + (near_far.x + near_far.y) * <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-type">vec3</span> end_screen    = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);    <br>    end_screen.xy = (end_ndc.xy + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span> * tex_size;<br>    end_screen.z = (near_far.y - near_far.x) * <span class="hljs-number">0.5</span> * end_ndc.z + (near_far.x + near_far.y) * <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-type">int</span> step_count = <span class="hljs-number">32</span>;<br><br>    <span class="hljs-type">vec3</span> screen_diff = end_screen - start_screen;<br>    <span class="hljs-type">int</span> sample_count = <span class="hljs-type">int</span>(<span class="hljs-built_in">max</span>(<span class="hljs-built_in">abs</span>(screen_diff.x), <span class="hljs-built_in">abs</span>(screen_diff.y)) * resolution) ; <span class="hljs-comment">// 大于1</span><br><br>    sample_count = <span class="hljs-built_in">min</span>(sample_count, <span class="hljs-number">64</span>);<br>    <span class="hljs-type">vec3</span> delta_screen = screen_diff / <span class="hljs-type">float</span>(sample_count);<br><br>    <span class="hljs-comment">// 如果sample count为10，则每次采样的前进的长度为总长度的1/10</span><br>    <span class="hljs-type">float</span> percentage_delta = <span class="hljs-number">1.0</span> / <span class="hljs-type">float</span>(sample_count);<br>    <span class="hljs-type">vec3</span> current_screen = start_screen;<br>    <span class="hljs-type">vec3</span> last_screen = current_screen;<br>    <span class="hljs-type">float</span> current_percentage = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> last_percentage = <span class="hljs-number">0.0</span>;<br><br>    ...<br><br></code></pre></td></tr></table></figure><p>使用屏幕空间步近，前面和原来的差不多，在获取步近的起始点和结束点的时候，需要将坐标转换为屏幕空间的坐标，也就是其中的current_screen和last_screen。</p><p>屏幕空间采样点数和<strong>采样的起始和结束位置的像素差值</strong>有关，所以和渲染输出的分辨率也是相关的。如果渲染分辨率越高，其对应所需要的采样点数可能也会增加，这里我们控制在64以内。当然如果起始点和结束点的像素差值较小，对应的采样点数也会变小，也就是对于距离相机很远的位置的采样会减少，在怎么不影响效果的情况下提升性能表现。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs glsl">    ...<br><br>    <span class="hljs-type">vec4</span> reflect_color = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_count; i++)<br>    &#123;<br>        <span class="hljs-comment">// 采样当前屏幕上的点对应场景世界空间坐标的位置</span><br>        <span class="hljs-type">vec2</span> uv = current_screen.xy / tex_size;<br><br>        <span class="hljs-comment">// 转换为贴图坐标，检查越界</span><br>        <span class="hljs-keyword">if</span>(uv.x &lt; <span class="hljs-number">0.0</span> || uv.y &lt; <span class="hljs-number">0.0</span> || uv.x &gt; <span class="hljs-number">1.0</span> || uv.y &gt; <span class="hljs-number">1.0</span>)<br>        &#123;<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>            <span class="hljs-comment">// 延迟渲染存储的屏幕对应的世界位置</span><br>            <span class="hljs-type">vec3</span> sample_world = <span class="hljs-built_in">texture</span>(scene_position, uv).xyz;<br>            <br>            <span class="hljs-type">vec4</span> sample_ndc = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">mix</span>(start_ndc, end_ndc, current_percentage), <span class="hljs-number">1.0</span>);<br>            <span class="hljs-keyword">if</span>(compareDepth(sample_ndc, uv))<br>            &#123;<br>                <span class="hljs-comment">// 初筛后再二分法检查</span><br>                <span class="hljs-type">int</span> split_count = <span class="hljs-number">5</span>;<br>                <span class="hljs-keyword">while</span>(split_count &gt; <span class="hljs-number">0</span>)<br>                &#123;<br>                    <span class="hljs-type">vec3</span> mid_screen = (last_screen + current_screen) * <span class="hljs-number">0.5</span>;<br>                    <span class="hljs-type">float</span> mid_percentage = (last_percentage + current_percentage) * <span class="hljs-number">0.5</span>;<br>                    <span class="hljs-type">vec4</span> mid_ndc = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">mix</span>(start_ndc, end_ndc, mid_percentage), <span class="hljs-number">1.0</span>);<br>                    uv = mid_screen.xy / tex_size;<br>                    <span class="hljs-keyword">if</span>(compareDepth(mid_ndc, uv))<br>                    &#123;<br>                        current_screen = mid_screen;<br>                    &#125;<br>                    <span class="hljs-keyword">else</span><br>                    &#123;<br>                        last_screen = mid_screen;<br>                    &#125;<br>                    split_count--;<br>                &#125;<br><br>                reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br><br>            last_screen = current_screen;<br>            last_percentage = current_percentage;<br>            current_screen += delta_screen;<br>            current_percentage += percentage_delta;<br>        &#125;<br>    &#125;<br><br>    FragColor = reflect_color*metallic;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><p>这里在屏幕空间采样还配合了之前的粗筛和精筛的方法，下面是使用屏幕空间采样的表现。可以看到条纹的状况被极大的缓解了。</p><p><img src="ssr_result.png" alt="SSR屏幕空间采样结果"></p><p>应用在实际场景中，SSR的效果能比较明显的提升渲染质感。<br><img src="ssr_mugshot.png" alt="SSR实际应用"></p><h2 id="总结">总结</h2><p>SSR是一种计算场景的反射效果的算法，它基于屏幕空间已有的深度图和法线图等信息，通过计算反射向量，在屏幕空间中进行光线追踪，查找反射光线与场景中其他物体的相交点，获取相交点的颜色作为反射颜色，并与原始颜色合成得到最终渲染结果。</p><p>SSR的优点是计算效率相对较高，能实时反映场景中物体的变化，适用于复杂几何形状和不规则表面，适合大规模的动态场景，无需额外的镜头或几何体。</p><p>当然，SSR也有局限性，它只能反射屏幕上可见的物体，超出屏幕边界的内容无法被反射；反射的物体可能存在失真或错误，尤其是边缘区域；依赖屏幕分辨率，高分辨率下可能对性能有较大影响</p><h3 id="SSR的优化改进算法：">SSR的优化改进算法：</h3><h4 id="SSSR（Spatially-Separated-Screen-Space-Reflection）">SSSR（Spatially Separated Screen Space Reflection）</h4><p>原理：SSSR 是对传统 SSR 技术的一种改进。它主要是基于空间分离的思想来处理屏幕空间反射。传统 SSR 在处理反射时可能会受到屏幕空间限制和采样不足等问题的影响。SSSR 通过将屏幕空间划分为不同的区域，在这些区域内分别进行更精细的反射处理。</p><p>例如，它可以根据场景中物体的距离、重要性或者反射特性等因素，对空间进行划分。对于反射效果比较复杂或者重要的区域，分配更多的资源进行反射计算，而对于相对简单或者不重要的区域，则采用较为简略的计算方式。</p><p>优点：</p><ul><li>提高反射精度：通过对特定区域的精细处理，能够有效提高反射的精度。比如在处理具有高反射率的物体表面或者复杂的光照反射场景时，可以得到更真实、细腻的反射效果。</li><li>优化性能：与传统 SSR 相比，SSSR 能够更合理地分配计算资源。它避免了在整个屏幕空间进行统一标准的反射计算，从而在一定程度上减轻了计算负担，特别是在大规模复杂场景中，可以更好地平衡反射效果和性能。</li></ul><p>局限性：</p><ul><li>空间划分的复杂性：如何合理地划分空间是一个具有挑战性的问题。如果空间划分不合理，可能会导致反射效果出现不自然的边界或者遗漏重要的反射区域。</li><li>增加算法复杂度：空间划分和不同区域的分别处理增加了算法的复杂度。这可能会导致开发和调试的难度增加，并且在某些情况下，可能会引入新的错误或者视觉瑕疵。</li></ul><h4 id="Hi-z-SSR（Hierarchical-z-Screen-Space-Reflection）">Hi-z SSR（Hierarchical - z Screen Space Reflection）</h4><p>原理：Hi - z SSR 是利用层次化的深度信息（Hierarchical-z）来改进 SSR。它构建了一个层次化的深度缓冲区，这个缓冲区可以更有效地存储和检索深度信息。在计算反射时，通过这个层次化的结构，可以快速地在不同层次的深度信息中进行搜索和采样。<br>例如，在较高层次的深度信息中，可以快速定位反射光线可能相交的大致区域，然后在较低层次的深度信息中进行更精细的搜索，就像在地图的不同比例尺中查找目标位置一样。这种层次化的搜索方式能够更高效地利用深度信息来计算反射。</p><p>优点：</p><ul><li>高效的深度搜索：层次化的深度搜索大大提高了反射光线与场景相交点的查找效率。尤其是在处理具有深度层次丰富的复杂场景时，能够快速定位反射位置，减少计算时间。</li><li>增强的反射范围：由于能够更好地利用深度信息，Hi-z SSR 可以在一定程度上缓解传统 SSR 中屏幕外反射难以处理的问题。它可以通过层次化的深度结构，对屏幕外部分场景的深度信息进行合理推测和利用，从而扩展反射的有效范围。</li></ul><p>局限性</p><ul><li><p>深度缓冲区的构建成本：构建层次化的深度缓冲区需要额外的存储空间和计算资源来生成和维护。这可能会在一些资源受限的场景或者硬件平台上带来一定的负担。</p></li><li><p>精度与性能的平衡：尽管 Hi-z SSR 提高了搜索效率，但在平衡反射精度和性能方面仍然是一个挑战。在某些情况下，过于追求效率可能会导致反射精度下降，而过度强调精度又可能会使性能开销过大。</p></li></ul><h2 id="参考资料">参考资料</h2><p><a href="https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html">https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html</a></p><p><a href="https://jcgt.org/published/0003/04/04/">https://jcgt.org/published/0003/04/04/</a></p><p><a href="https://blog.csdn.net/qjh5606/article/details/120102582?ops_request_misc=%257B%2522request%255Fid%2522%253A%25225a1434f7df5d388dc4166f4877eb172b%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=5a1434f7df5d388dc4166f4877eb172b&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-120102582-null-null.142%5Ev100%5Econtrol&amp;utm_term=Efficient%20GPU%20Screen-Space%20Ray%20Tracing&amp;spm=1018.2226.3001.4187">https://blog.csdn.net/qjh5606/article/details/120102582?ops_request_misc=%257B%2522request%255Fid%2522%253A%25225a1434f7df5d388dc4166f4877eb172b%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=5a1434f7df5d388dc4166f4877eb172b&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-120102582-null-null.142^v100^control&amp;utm_term=Efficient GPU Screen-Space Ray Tracing&amp;spm=1018.2226.3001.4187</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>软阴影的实现（PCF和PCSS）</title>
    <link href="/2024/12/08/soft-shadow/"/>
    <url>/2024/12/08/soft-shadow/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是软阴影">什么是软阴影</h2><p>在3D中实现阴影最基础的方法是使用阴影贴图shadowmap，根据shadowmap中存储的信息来判定当前渲染的像素是否在阴影当中。</p><p>阴影贴图的方法很好理解，但是仅仅基于阴影贴图的阴影效果，在阴影的边缘会有锯齿的情况出现。这往往是由于阴影贴图的分辨率不够导致的，然而一味的提升阴影贴图的分辨率也不是方法，毕竟实时渲染的性能也是需要考虑的一个方面。</p><p>那么该如何在可接受的性能表现下实现软阴影的效果呢，下面详细介绍两种方法：Percentage Closer Filtering（PCF）以及Percentage Closer Soft Shadows（PCSS）。</p><h2 id="柔和阴影边缘-PCF">柔和阴影边缘-PCF</h2><p>下面是一个普通的阴影效果：<br><img src="normal-shadow.png" alt="普通的阴影效果"><br>这个阴影贴图的分辨率是2048，这是在<a href="https://ruochenhua.github.io/2024/10/13/cascade-shadow-map/">CSM</a>的最低一级的阴影效果。可以看到阴影边缘的锯齿感非常的强烈，同时由于采样精度的问题，模型的腿上也出现了不正确的阴影区域。最简单的方法就是通过提高阴影贴图的分辨率来缓解这个问题，但是显而易见这不是最好的解决方案，而Percentage Closer Filtering（后简称PCF）可以帮助我们解决这个问题。</p><h3 id="什么是PCF">什么是PCF</h3><p>Percentage Closer Filtering（PCF）是一种在计算机图形学中用于生成软阴影的技术。它主要用于解决硬阴影（如简单的阴影映射产生的锐利阴影边缘）不符合真实场景光照效果的问题。</p><p>与简单的阴影映射不同，PCF 在判断像素是否在阴影中时，不是只比较单个点的深度。它会在像素点周围的一定区域内进行多次采样。例如，在一个以像素点为中心的小区域（通常是方形或圆形区域）内，对多个采样点进行深度比较。这些采样点的位置可以是均匀分布，也可以采用更复杂的分布方式，如泊松分布，以获得更自然的效果。</p><p>对于每个采样点，比较其深度和阴影图中的深度来判断是否在阴影中。然后统计在阴影中的采样点的比例。设采样点总数为<strong>N</strong>，处于阴影中的采样点数量为<strong>n</strong>，则阴影强度可以通过公式计算<strong>shadow=n/N</strong>得到。这个阴影强度用于确定像素最终的阴影效果。如果阴影强度为1，表示像素完全处于阴影中；如果阴影强度为0，表示像素完全不在阴影中；介于两者之间的值表示不同程度的软阴影效果。</p><h3 id="PCF的实现">PCF的实现</h3><p>转换为代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> CalculatePCFShadow(<span class="hljs-type">float</span> current_depth, <span class="hljs-type">sampler2D</span> shadow_map,  <span class="hljs-type">vec2</span> uv, <span class="hljs-type">int</span> radius)<br>&#123;<br>    <span class="hljs-type">float</span> shadow = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">vec2</span> texel_size = <span class="hljs-number">1.0</span> / <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(shadow_map, <span class="hljs-number">0</span>));<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> x = -radius; x &lt;= radius; ++x)<br>    &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> y = -radius; y &lt;= radius; ++y)<br>        &#123;<br>            <span class="hljs-type">float</span> pcf_depth = <span class="hljs-built_in">texture</span>(shadow_map, <span class="hljs-type">vec2</span>(uv + <span class="hljs-type">vec2</span>(x, y) * texel_size)).r;<br>            shadow += current_depth &gt; pcf_depth ? <span class="hljs-number">1.0</span> : <span class="hljs-number">0.0</span>;<br>        &#125;<br>    &#125;<br>    shadow /= <span class="hljs-built_in">pow</span>((<span class="hljs-number">1</span>+radius*<span class="hljs-number">2</span>),<span class="hljs-number">2.0</span>);<br>    <span class="hljs-keyword">return</span> shadow;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我使用了矩形的采样区域，可以看到其实当采样区域的半径为1的时候，采样点个数为9，阴影边缘的锯齿感已经得到了明显的改善。模型腿上也没有出现错误的阴影区域，效果大大提升。</p><p><img src="pcf-shadow-1.png" alt="PCF阴影，采样半径1"></p><p>当采样半径提升为3，采样点个数为49时，阴影的边缘软化效果更明显了，不过付出了5倍的性能消耗，提升确并没有非常明显。</p><p><img src="pcf-shadow-3.png" alt="PCF阴影，采样半径3"></p><h2 id="半影的产生-PCSS">半影的产生-PCSS</h2><h3 id="什么是本影和半影">什么是本影和半影</h3><p>在实际的场景中，我们观察阴影，会发现下面这种情况：</p><p><img src="real_shadow.png" alt="现实阴影"><br>物体的深暗影子周围还有一片区域是浅浅的暗影。深暗影子的区域我们称之为“<strong>本影</strong>”，而浅暗影子的区域我们称之为“<strong>半影</strong>”。</p><p>这种现象在体积光照（或者区域光照）的情况下很容易出现。其原因是，很多光源是有范围的，如下图假设有一个光源的大小用L1到L2，光源的右边有一个物体。</p><p><img src="umbra-principle.png" alt="本影和半影的原理"></p><p>光源最上点位L1的位置，照向物体的时候，产生的阴影范围是<strong>A区域</strong>以及下方的<strong>B区域</strong>，上方的<strong>B区域</strong>会被L1照亮；L2点产生的阴影范围是<strong>A区域</strong>和上方的<strong>B区域</strong>，下方的<strong>B区域</strong>会被L2照亮。所以我们可以看到，<strong>区域A</strong>是光源完全的光都会被挡住的区域，所以他的阴影是最深的，是为<strong>本影</strong>。而两个<strong>区域B</strong>是挡住了光源的部分区域，同时被光源的另外一部分照亮的，是为<strong>半影</strong>。</p><p><img src="umbra-contrast.png" alt="本影和半影的对照区域"></p><h3 id="什么是PCSS">什么是PCSS</h3><p>在弄明白什么是本影和半影之后，我们来介绍一下PCSS是什么。</p><p>Percentage Closer Soft Shadows（PCSS）即百分比渐近软阴影，是计算机图形学中用于生成更逼真软阴影的一种技术，它是在 Percentage Closer Filtering（PCF）基础上发展而来的。</p><p>在PCF的基础上，PCSS还额外考虑了光源、遮挡物和接收阴影的物体之间的几何关系，通过这些关系来调整用于计算阴影强度的采样区域大小。通过根据阴影的不同情况动态调整采样区域的大小，PCSS能生成更自然、更符合物理规律的软阴影。</p><p>这里是提出PCSS的<a href="https://developer.download.nvidia.com/shaderlibrary/docs/shadow_PCSS.pdf">论文</a>。</p><p>其原理总结起来就是根据采样一个区域内处于阴影的比例，来动态的调节这个区域对应的阴影的采样范围。</p><h3 id="PCSS的实现步骤">PCSS的实现步骤</h3><p>PCSS的实现步骤如下：</p><p>首先，计算平均的遮挡物距离。在阴影图中，以当前像素点为中心，在一个初始的较小采样区域内查找深度值小于当前像素点深度的采样点，这些采样点对应的物体即为遮挡物。通过计算这些遮挡物采样点深度的平均值，得到平均遮挡物距离<strong>d_blocker</strong>。</p><p><img src="get-d_blocker-1.png" alt="采样平均遮挡物距离1"></p><p>对应代码为：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> FindBlockerDepth(<span class="hljs-type">sampler2D</span> shadowmap, <span class="hljs-type">vec2</span> uv, <span class="hljs-type">float</span> d_receiver, <span class="hljs-type">float</span> radius)<br>&#123;<br>    <span class="hljs-type">float</span> blocker_depth_sum = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">int</span> blocker_count = <span class="hljs-number">0</span>;<br>    <br>    <span class="hljs-comment">// 以当前像素为中心,半径为radius的范围采样</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">float</span> y = -radius; y &lt;= radius; y++) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">float</span> x = -radius; x &lt;= radius; x++) &#123;<br>            <span class="hljs-type">vec2</span> <span class="hljs-keyword">offset</span> = <span class="hljs-type">vec2</span>(x, y) * <span class="hljs-number">1.0</span> / <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(shadowmap, <span class="hljs-number">0</span>));<br>            <span class="hljs-type">float</span> sampleDepth = TextureProjBilinear(shadowmap, uv + <span class="hljs-keyword">offset</span>);<br>            <span class="hljs-keyword">if</span> (sampleDepth &lt; d_receiver) &#123;<br>                blocker_depth_sum += sampleDepth;<br>                blocker_count++;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> blocker_count &gt; <span class="hljs-number">0</span>? blocker_depth_sum / <span class="hljs-type">float</span>(blocker_count) : <span class="hljs-number">0.0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中<strong>d_receiver</strong>为当前像素点到光源的深度值，这个值可以将当前像素点位置变换到光源的投影下得到，在处理阴影贴图的时候就需要拿到了。TextureProjBilinear是获取shadowmap深度值的方法，里面采用了双线性插值的方法，不过对PCSS来说不一定需要使用这个方法。</p><p>可以看到这个阶段，PCSS搜索了一个阴影贴图里面的区域（下图红色区域），记录下了这个区域的被阻挡范围的平均深度。</p><p><img src="get-d_blocker-2.png" alt="采样平均遮挡物距离2"></p><p>然后根据这个范围，以及三角形相似原理，估算出半影半径。</p><p><img src="penumbra.png" alt="计算半影半径"><br>其中d_receiver、d_blocker我们已知，W_light是光源的范围大小，可以根据实际情况来调整。用图上右方的公式，得出半影的采样范围W_penumbra。</p><p>代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 计算遮挡物范围半径（基于相似三角形原理）</span><br><span class="hljs-type">float</span> EstimateBlockerSearchRadius(<span class="hljs-type">vec2</span> uv, <span class="hljs-type">float</span> d_receiver, <span class="hljs-type">float</span> d_blocker, <span class="hljs-type">float</span> light_size)<br>&#123;<br>    <span class="hljs-keyword">if</span> (d_blocker == <span class="hljs-number">0.0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span>;<br>    <span class="hljs-keyword">return</span> (d_receiver - d_blocker) * (light_size / d_blocker);<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，根据估算出的半影半径，扩大采样区域，然后在这个更大的区域内进行采样，并按照 PCF 的方式计算阴影强度。这样，离光源较近或遮挡物较近的地方，半影半径较小，阴影较实；离光源较远或遮挡物较远的地方，半影半径较大，阴影较虚，从而实现了更自然的软阴影效果。</p><p>代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> shadow_sum = <span class="hljs-number">0.0</span>f;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> pcss_i = <span class="hljs-number">0</span>; pcss_i &lt; pcss_sample_count; pcss_i++)<br>&#123;<br>    <span class="hljs-comment">// 可以使用泊松采样盘等方法获取更自然的采样点位置，这里简单均匀采样</span><br>    <span class="hljs-type">vec2</span> <span class="hljs-keyword">offset</span> = <span class="hljs-type">vec2</span>(<span class="hljs-built_in">cos</span>(<span class="hljs-type">float</span>(pcss_i) * <span class="hljs-number">2.0</span> * <span class="hljs-number">3.1415926</span> / <span class="hljs-type">float</span>(pcss_sample_count)),<br>    <span class="hljs-built_in">sin</span>(<span class="hljs-type">float</span>(pcss_i) * <span class="hljs-number">2.0</span> * <span class="hljs-number">3.1415926</span> / <span class="hljs-type">float</span>(pcss_sample_count))) * blocker_radius;<br><br>    <span class="hljs-type">vec4</span> sampleLightSpacePos = <span class="hljs-type">vec4</span>(proj_coord.xy + <span class="hljs-keyword">offset</span>, proj_coord.z, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-type">float</span> sampleDepth = TextureProjBilinear(shadow_map, proj_coord.xy+<span class="hljs-keyword">offset</span>);<br>    shadow_sum += sampleDepth &lt; d_recv? <span class="hljs-number">1.0</span> : <span class="hljs-number">0.0</span>;<br>&#125;<br>shadow = shadow_sum / pcss_sample_count;<br></code></pre></td></tr></table></figure><h3 id="PCSS的效果">PCSS的效果</h3><p>下面是PCSS开启和关闭的效果对比，其中PCSS关闭下PCF的采样半径是3：<br><img src="PCSS_OFF.png" alt="PCSS关闭"></p><p><img src="PCSS_ON.png" alt="PCSS开启"></p><p>可以看到开启了PCSS的效果后，遮挡物体的阴影区域，随着离遮挡物越来越远，出现了越来越明显的半影效果，效果更加自然和真实。</p><h2 id="总结">总结</h2><h3 id="Percentage-Closer-Filtering（PCF）的作用">Percentage Closer Filtering（PCF）的作用</h3><ol><li><p>软阴影生成基础：PCF 是一种用于生成软阴影的基础技术。它基于阴影映射，在判断像素是否在阴影中时，不是只比较单个点的深度，而是在像素点周围一定区域内进行多次采样。</p></li><li><p>阴影强度计算：通过统计采样区域内处于阴影中的采样点比例来计算阴影强度。这种方式能有效避免硬阴影边缘的锯齿问题，使阴影边缘过渡更加自然，产生软阴影效果，提升了阴影的真实感。</p></li><li><p>平衡性能和效果：相对一些复杂的物理软阴影算法，PCF 较为简单，在性能和效果之间取得了较好的平衡，适用于实时渲染场景，如游戏。</p></li></ol><h3 id="Percentage-Closer-Soft-Shadows（PCSS）的作用">Percentage Closer Soft Shadows（PCSS）的作用</h3><ol><li><p>动态软阴影生成：PCSS 在 PCF 基础上进一步改进。它能够根据光源、遮挡物和接收阴影物体之间的几何关系动态调整采样区域的大小。</p></li><li><p>更自然的阴影过渡：通过计算平均遮挡物距离和估算半影半径，根据半影半径调整采样区域进行采样计算阴影强度。这样生成的软阴影更加符合物理规律，阴影从完全阴影到完全光照的过渡更加自然、真实，在需要高逼真度渲染的场景中能显著提升视觉质量。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>阴影</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>反射阴影贴图</title>
    <link href="/2024/11/24/reflective-shadow-map/"/>
    <url>/2024/11/24/reflective-shadow-map/</url>
    
    <content type="html"><![CDATA[<h2 id="反射阴影贴图简介">反射阴影贴图简介</h2><p>反射阴影贴图（Reflective Shadow Map）是实现全局光照效果的一个非常经典的方法，它是在这篇<a href="https://users.soe.ucsc.edu/~pang/160/s13/proposal/mijallen/proposal/media/p203-dachsbacher.pdf">论文</a>中被提出。</p><h3 id="直接光照和间接光照">直接光照和间接光照</h3><p>它的名字中带有“阴影贴图（Shadow Map）”几个字，所以乍看之下这个方法似乎是用来解决阴影问题，或者是提升阴影效果的。其实不然，它是用来解决<strong>间接光照</strong>的问题的方法。</p><p>在一般的场景中，光照可以大致分为两类：</p><ul><li>一类是直接光照，也就是物体被光源直接照亮的部分。这个类型的光照是比较好计算的，通过光源的入射角，物体表面的法线和材质，以及观察的方向等等，利用<strong>PBR</strong>的方法能够得到非常不错的效果，这个流程在KongEngine中已经基本实现了。</li><li>另外一个类型是间接光照，它代表的是光线经过一次甚至多次反射后照亮物体的部分。相对于直接光照，间接光照十分复杂，因为光线可能经过多次反射，想要实时的计算光的多次反射的完整路径是很难实现的。但是如果不包含间接光照的话，场景的真实度会大打折扣。在最基础的PBR渲染框架中，我们可以选择手动输入一个环境光照（Ambient Light）的颜色，可以简单的表现全局光照，但是真实性还是不够。</li></ul><p>反射阴影贴图（下面简称<strong>RSM</strong>）这个方法，就是用于解决实时模拟间接光照的问题。</p><h3 id="RSM算法基本介绍">RSM算法基本介绍</h3><p>RSM的核心思想是将被光源直接照亮的区域再次作为光源进行光照计算，这就是光的一次反射。RSM只计算一次光反射，因为一般来说光的第一次反射的能量残留相对来说是最大的，对场景来说有较为显著的影响，后面的反射对场景影响较小，为了性能考量可以忽略。</p><p>那么怎么知道光照直接亮了哪些区域呢？其实非常简单，在参考实现阴影贴图（Shadow Map）的概念，从光源视角下进行渲染，不在阴影中的区域就是被光源直接照亮的。另外，由于光线在漫反射时会被照亮区域的材质所影响（比如说白色的光线从红色的墙反射会变成红色，因为其他颜色被吸收，同时不同粗糙度的物质反射方式也不一样），以及照亮区域的位置和法线也会影响计算光反射的方向，因此我们在计算阴影贴图的时候，还需要保存照亮区域的颜色、世界位置、法线等数据。</p><p>下面是需要记录的数据的截图，从左到右分别是：深度、位置坐标、法线、颜色。<br><img src="rsm_info.png" alt="光源方向记录的数据"></p><p>因此接下来光照计算可以分为以下几步：</p><ol><li>首先从光源的位置和方向渲染场景，将光源视角的信息（深度，世界位置，世界法线等等）缓存到buffer中。</li><li>计算光照直接对环境的影响。</li><li>将第一步缓存的光源保存的信息加入到场景中光照的计算，加上阴影（阴影贴图）和间接光照（反射阴影贴图）。</li></ol><h2 id="实现反射阴影贴图的步骤">实现反射阴影贴图的步骤</h2><p>下面是在KongEngine中实现RSM的步骤。</p><h3 id="一些前期准备">一些前期准备</h3><p>RSM需要将一些信息存储到buffer中，所以很首先需要设置新的缓冲。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glGenFramebuffers</span>(<span class="hljs-number">1</span>, &amp;rsm_fbo);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, rsm_fbo);<br><br><span class="hljs-comment">// 位置数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;rsm_world_position);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_position);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, rsm_world_position, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 法线数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;rsm_world_normal);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_normal);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, rsm_world_normal, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// flux数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;rsm_world_flux);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_flux);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, rsm_world_flux, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 生成renderbuffer</span><br><span class="hljs-built_in">glGenRenderbuffers</span>(<span class="hljs-number">1</span>, &amp;rsm_depth);<br><span class="hljs-built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, rsm_depth);<br><span class="hljs-built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, SHADOW_RESOLUTION, SHADOW_RESOLUTION);<br><span class="hljs-built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, rsm_depth);<br><span class="hljs-built_in">glEnable</span>(GL_DEPTH_TEST);<br><br>GLuint g_attachments[] = &#123;GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2&#125;; <br><span class="hljs-built_in">glDrawBuffers</span>(<span class="hljs-number">3</span>, g_attachments);<br></code></pre></td></tr></table></figure><p>上面的部分用于构建RSM的缓冲，这些内容和之前的Shadowmap的流程类似，也可以考虑将其和Shadowmap的缓冲合并，不过为了方便自己理解目前是新建了一个。</p><p>另外RSM也新建了一个独立的shader</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++">map&lt;EShaderType, string&gt; shader_path_map = &#123;<br>    &#123;EShaderType::vs, CSceneLoader::<span class="hljs-built_in">ToResourcePath</span>(<span class="hljs-string">&quot;shader/shadow/reflective_shadowmap.vert&quot;</span>)&#125;,<br>    &#123;EShaderType::fs, CSceneLoader::<span class="hljs-built_in">ToResourcePath</span>(<span class="hljs-string">&quot;shader/shadow/reflective_shadowmap.frag&quot;</span>)&#125;<br>&#125;;<br>rsm_shader = <span class="hljs-built_in">make_shared</span>&lt;Shader&gt;(shader_path_map);<br></code></pre></td></tr></table></figure><p>shader的内容十分简单，<em>顶点着色器</em>简单的将顶点的世界坐标和法线传给片段着色器。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-comment">// Input vertex data, different for all executions of this shader.</span><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_pos;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_normal;<br><br><span class="hljs-comment">// Values that stay constant for the whole mesh.</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> light_space_mat;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> model;<br><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> frag_pos;<br><span class="hljs-keyword">out</span> <span class="hljs-type">vec3</span> frag_normal;<br><br><span class="hljs-type">void</span> main()&#123;<br><span class="hljs-built_in">gl_Position</span> =  light_space_mat * model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1</span>);<br>    frag_pos = model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1</span>);<br>frag_normal = <span class="hljs-built_in">normalize</span>(<span class="hljs-type">mat3</span>(<span class="hljs-built_in">transpose</span>(<span class="hljs-built_in">inverse</span>(model))) * in_normal);<br>&#125;<br></code></pre></td></tr></table></figure><p>由于这个shader是从光源视角渲染的，所以<strong>gl_Position</strong>是由光源的<strong>light_space_mat</strong>对世界坐标做变换。</p><p><em>片段着色器</em>将RSM所需的内容存储起来。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> world_pos;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> world_normal;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">2</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> world_flux;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> frag_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> frag_normal;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">vec4</span> albedo;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> light_intensity;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>world_pos = frag_pos;<br>    world_normal = <span class="hljs-type">vec4</span>(frag_normal, <span class="hljs-number">1</span>);<br>    world_flux = albedo;<span class="hljs-comment">// * light_intensity;</span><br>&#125;<br></code></pre></td></tr></table></figure><p>我们这里分别将<strong>世界坐标、世界法线和颜色</strong>存储了到了贴图中。<br>方便起见，KongEngine暂时只支持平行光源的RSM效果，点光源的目前不支持。</p><p>现在我们的平行光源已经有了RSM相关的信息了，在计算光照的时候将这些贴图信息传到光照计算的shader中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + DIRLIGHT_RSM_WORLD_POS);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_pos);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + DIRLIGHT_RSM_WORLD_NORMAL);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_normal);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + DIRLIGHT_RSM_WORLD_FLUX);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_flux);<br></code></pre></td></tr></table></figure><h3 id="间接光源的判定">间接光源的判定</h3><p>RSM的实际原理如下面两张图所示：<br><img src="rsm_principle_1.png" alt="rsm原理图1"></p><p>假如当前我们片段着色器计算的是<strong>X</strong>点的光照，在这个场景中，x点被桌子的阴影挡住了，并没有被光源直接照亮，如左图所示。所以x点的直接光照为0。</p><p>接下来是间接光照的部分。如上面所说，我们将被光源直接照亮的部分当做光源，这里先以被光源直接照射的两个点Xp和Xq来做判断。Xp点被光源照亮，他的法线是Np，光在Xp点散射后是有可能到达X点的，在数学上的判断就是Np和Xp到X连线的点乘大于0。而Xq的法线Nq和Xq到X点连线的点乘小于0，可以从图上看到光在Xq点散射后是无法到达X点的。</p><p>当然我们还知道，在计算PBR的时候，不同的材质的光线散射形状是不一致的，在图中的表现就是，光线散射后沿着XpX方向的分量，比沿着XpY方向的分量是要小的。因此间接光源的法线和两点之间的连线的点乘大小有这判定间接光源亮度的作用。</p><p>下面这张图和原理图1是一样的，强化一下理解。<br><img src="rsm_principle_2.png" alt="rsm原理图2"></p><h3 id="采样间接光源">采样间接光源</h3><p>之前说到，需要用被光源照亮的点作为间接光源。如果渲染屏幕上像素点的时候对所有照亮的点都去做判断的话，理论上是可以得到最好的效果，但是性能上会有极大的消耗；相反如果采样点过少的话，计算速度虽然是上去了但是效果会大打折扣。</p><p>因此一个优化方法是通过重要性采样。我们判断离当前渲染点越近的间接光照光源对当前点的最终效果影响就越大，因此离当前点近的间接光源采样点就会越多。并且，为了弥补远处的采样点过少可能带来的问题，引入权重的概念，随着采样点离当前点越近，权重越小。</p><p><img src="rsm_sample.png" alt="rsm采样点选择"></p><p>下面是采样点初始化的示例代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// rsm采样点初始化</span><br>std::default_random_engine e;<br><span class="hljs-function">std::uniform_real_distribution&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">u</span><span class="hljs-params">(<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>)</span></span>;<br><span class="hljs-type">float</span> pi_num = <span class="hljs-built_in">pi</span>&lt;<span class="hljs-type">float</span>&gt;();<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; rsm_sample_count; i++)<br>&#123;<br>    <span class="hljs-type">float</span> xi1 = <span class="hljs-built_in">u</span>(e);<br>    <span class="hljs-type">float</span> xi2 = <span class="hljs-built_in">u</span>(e);<br>    <br>    rsm_samples_and_weights.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">vec4</span>(xi1*<span class="hljs-built_in">sin</span>(<span class="hljs-number">2</span>*pi_num*xi2), xi1*<span class="hljs-built_in">cos</span>(<span class="hljs-number">2</span>*pi_num*xi2), xi1*xi1, <span class="hljs-number">0.0</span>));<br>&#125;<br></code></pre></td></tr></table></figure><p>结合上面的两个思想，下面是部分最终代码的呈现，位于defer_pbr.frag中。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> max_sample_radius = <span class="hljs-number">128.</span>;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; rsm_sample_count; ++i) <br>&#123;<br>    <span class="hljs-type">vec3</span> rsm_sample_and_weight = rsm_samples_and_weights[i].xyz;<br>    <span class="hljs-type">vec2</span> uv = proj_coord.xy + max_sample_radius * rsm_sample_and_weight.xy * texel_size;<br>    <span class="hljs-type">vec3</span> flux = <span class="hljs-built_in">texture</span>(rsm_world_flux, uv).rgb;<br>    <span class="hljs-type">vec3</span> x_p = <span class="hljs-built_in">texture</span>(rsm_world_pos, uv).xyz;<br>    <span class="hljs-type">vec3</span> n_p = <span class="hljs-built_in">texture</span>(rsm_world_normal, uv).xyz;<br><br>    <span class="hljs-type">vec3</span> r = <span class="hljs-built_in">normalize</span>(frag_world_pos.xyz - x_p);<br><br>    <span class="hljs-type">float</span> d2 = <span class="hljs-built_in">dot</span>(r, r);<br>    <span class="hljs-type">vec3</span> e_p = flux * (<span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">dot</span>(n_p, r)) * <span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">dot</span>(in_normal, -r))) * rsm_sample_and_weight.z;<br>    <span class="hljs-comment">//e_p *= pow(rsm_sample_offsets[i].x / d2, 2);</span><br>    env_color += e_p;<br>&#125;<br>env_color /= rsm_sample_count;<br></code></pre></td></tr></table></figure><h2 id="最终效果">最终效果</h2><p>结合了反射阴影贴图后，场景会有一些间接光照效果了，下面是同一个场景的表现效果。<br><img src="rsm_off_sphere.png" alt="rsm关闭1"><br><img src="rsm_on_sphere.png" alt="rsm开启1"></p><p>这里是另外一组。<br><img src="rsm_off_suit.png" alt="rsm关闭2"><br><img src="rsm_on_suit.png" alt="rsm开启2"></p><p>可以看到开启rsm后，靠近红色和绿色墙壁，且没有被光源直接照亮（处于阴影）的部分，被墙壁的散射光源间接点亮了。灰色的球体和人物模型“沾染”上了墙壁的颜色。这种间接光照的影响使得场景变得更加的真实。</p><p>但是，当前的rsm也并不是完美的，比如说目前rsm缺乏判定间接光源是否可达，在第二个例子中，人物模型的右肩上的间接光源呈现的是黄色，也就是红色和绿色的间接光照结合起来的颜色。但是右肩理论上不应该出现红色的分量，因为红色的部分会被身体部位阻挡。渲染点的法线应该也会影响间接光的表现。</p><p>另外就是被当成间接光源的只有被光源照亮且存储起来的部分区域，也就是说间接光源的采样范围相对来说还是比较局限的，不可能采样非常大的区域。在KongEngine中由于采用了CSM来处理阴影，RSM的范围和CSM的最小级的阴影范围采样是一致的，这种处理显然无法照顾大的场景。</p><p>场景的间接光照还需要进一步的去优化，RSM只是其中一个小部分。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>程序化地形生成-2-性能优化</title>
    <link href="/2024/11/19/ProceduralTerrainGeneration2-optimize/"/>
    <url>/2024/11/19/ProceduralTerrainGeneration2-optimize/</url>
    
    <content type="html"><![CDATA[<h2 id="性能优化的需求">性能优化的需求</h2><p>自从实现了程序化地形生成的那个<a href="https://www.shadertoy.com/view/4XByRV">ShaderToy上的Demo</a>之后，我对它的性能表现一直不太满意，随随便便跑一下我的GPU就直接拉到100%了，电脑风扇呼呼的。做了很多次大大小小的优化，最后发现瓶颈还是在对地形的光线步进计算上，不把这个问题解决掉的话这个场景的性能怎么样都无法达到令我满意的程度。</p><p>于是我一直在寻找类似的场景，寻找有什么光线步进的方法能够满足我的要求：首先它必须是要针对实时随机生成的地形，也就是说不能是针对高度图或者其他预处理过的地形数据；其次它需要快，至少能够在我这台笔记本上（3070ti显卡）能够保持50%以下的占用率；最后就是这个光线步进算法需要有一定的精度，但是要求不会很高。</p><p>最后我在ShaderToy上找到了一个非常棒的<a href="https://www.shadertoy.com/view/4slGD4">例子</a>，来自Dave_Hoskins。</p><p>Dave的Demo也是做了地形的渲染，他的场景比我复杂很多，但是这个更为复杂的场景在我的电脑上运行的时候，它的GPU占用率（分辨率768X432）只有35%左右，远低于我的demo让我大为震撼。</p><p>于是我开始研究它的光线步进的逻辑，如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// source:https://www.shadertoy.com/view/4slGD4</span><br><span class="hljs-type">float</span> BinarySubdivision(<span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> rO, <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> rD, <span class="hljs-type">vec2</span> t)<br>&#123;<br><span class="hljs-comment">// Home in on the surface by dividing by two and split...</span><br>    <span class="hljs-type">float</span> halfwayT;<br>  <br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5</span>; i++)<br>    &#123;<br><br>        halfwayT = <span class="hljs-built_in">dot</span>(t, <span class="hljs-type">vec2</span>(<span class="hljs-number">.5</span>));<br>        <span class="hljs-type">vec3</span> p = rO + halfwayT*rD;<br>        <span class="hljs-type">float</span> d = p.y - getTerrainHeight(p.xz, perlinOctaves); <br>        <span class="hljs-comment">// float d = Map(rO + halfwayT*rD); </span><br>         t = <span class="hljs-built_in">mix</span>(<span class="hljs-type">vec2</span>(t.x, halfwayT), <span class="hljs-type">vec2</span>(halfwayT, t.y), <span class="hljs-built_in">step</span>(<span class="hljs-number">0.5</span>, d));<br><br>    &#125;<br><span class="hljs-keyword">return</span> halfwayT;<br>&#125;<br><br><span class="hljs-type">bool</span> rayMarchingTerrain(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd, <span class="hljs-type">float</span> max_dist, <span class="hljs-keyword">out</span> <span class="hljs-type">float</span> res_t)<br>&#123;<br>    <span class="hljs-type">float</span> t = <span class="hljs-number">1.</span> + Hash12(g_frag_coord)*<span class="hljs-number">1.</span>;<br><span class="hljs-type">float</span> oldT = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">float</span> delta = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">bool</span> fin = <span class="hljs-literal">false</span>;<br><span class="hljs-type">bool</span> res = <span class="hljs-literal">false</span>;<br><span class="hljs-type">vec2</span> distances;<br><span class="hljs-keyword">for</span>( <span class="hljs-type">int</span> j=<span class="hljs-number">0</span>; j&lt; <span class="hljs-number">150</span>; j++ )<br>&#123;<br><span class="hljs-keyword">if</span> (fin || t &gt; <span class="hljs-number">240.0</span>) <span class="hljs-keyword">break</span>;<br><span class="hljs-type">vec3</span> p = ro + t*rd;<br><span class="hljs-comment">//if (t &gt; 240.0 || p.y &gt; 195.0) break;</span><br><span class="hljs-type">float</span> h = p.y - getTerrainHeight(p.xz, perlinOctaves); <span class="hljs-comment">// ...Get this positions height mapping.</span><br><span class="hljs-comment">// Are we inside, and close enough to fudge a hit?...</span><br><span class="hljs-keyword">if</span>( h &lt; <span class="hljs-number">0.5</span>)<br>&#123;<br>fin = <span class="hljs-literal">true</span>;<br>distances = <span class="hljs-type">vec2</span>(oldT, t);<br><span class="hljs-keyword">break</span>;<br>&#125;<br><span class="hljs-comment">// Delta ray advance - a fudge between the height returned</span><br><span class="hljs-comment">// and the distance already travelled.</span><br><span class="hljs-comment">// It&#x27;s a really fiddly compromise between speed and accuracy</span><br><span class="hljs-comment">// Too large a step and the tops of ridges get missed.</span><br>delta = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.3</span>*h) + (t*<span class="hljs-number">0.0065</span>);<br>oldT = t;<br>t += delta;<br>&#125;<br><span class="hljs-keyword">if</span> (fin) res_t = BinarySubdivision(ro, rd, distances);<br><br><span class="hljs-keyword">return</span> fin;<br>&#125;<br></code></pre></td></tr></table></figure><p>其实代码逻辑很简单，就是光线步进到的位置和当前XZ坐标的地形高度做比对，当光线步进的位置的高度和地形足够近的时候，记为击中。记录当前和上一步的t的位置，在得到最终结果的时候做一个取中间值的操作。</p><p>这个方法的精华部分是这个：<strong>delta = max(0.01, 0.3*h) + (t*0.0065);</strong>，它被用于计算光线步进下一步的距离。如果光线步进每一步距离太近，会严重影响性能；而如果一步太远，则会导致地形的精度不足，出现地表抖动甚至断裂的情况。</p><p>Dave的方法，结合了当前位置和地形的高度差h和光线步进已经经过的长度t。高度差越小，说明可能越接近地表，需要较小的步长（反之亦然）；t的影响则表示远处的地形的精度需求可以逐步降低。</p><p>下面是我原来的计算方式。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">bool</span> rayMarchingTerrain(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd, <span class="hljs-type">float</span> max_dist, <span class="hljs-keyword">out</span> <span class="hljs-type">float</span> res_t)<br>&#123;<br>    <span class="hljs-comment">// float terrain_height = sin(iTime) + 1.;    </span><br>    <span class="hljs-type">float</span> dt_min = <span class="hljs-number">0.1</span>f;<br>    <span class="hljs-type">float</span> dt_max = <span class="hljs-number">3.0</span>f;<br><br>    <span class="hljs-type">float</span> dt = <span class="hljs-number">1.0</span>;<br>    res_t = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-comment">// first pass, step 1</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = mint; t &lt; max_dist; t+=dt)<br>    &#123;<br>        <span class="hljs-type">vec3</span> p = ro+t*rd;<br>        <span class="hljs-type">float</span> terrain_height = getTerrainHeight(p.xz, perlinOctaves);<br>        <span class="hljs-keyword">if</span>(p.y &lt; terrain_height )<br>        &#123;        <br>            <span class="hljs-comment">// res_t = t - dt + dt*(last_h - last_p.y) / (p.y - last_p.y-terrain_height+last_h); </span><br>            res_t = t;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;        <br>        <span class="hljs-comment">// // closer terrain use higher accuracy        </span><br>        <span class="hljs-comment">// last_h = terrain_height;        </span><br>        <span class="hljs-comment">// last_p = p;</span><br>        dt = <span class="hljs-built_in">mix</span>(dt_min, dt_max, <span class="hljs-built_in">pow</span>(t / max_dist, <span class="hljs-number">2.0</span>));<br>    &#125;<br><br>    <span class="hljs-comment">// hit terrain</span><br>    <span class="hljs-keyword">if</span>(res_t &gt; <span class="hljs-number">0.</span>)<br>    &#123;<br>        <span class="hljs-type">float</span> last_h = <span class="hljs-number">0.0</span>;<br>        <span class="hljs-type">vec3</span> last_p = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-type">float</span> mini_dt =  <span class="hljs-built_in">max</span>(<span class="hljs-number">0.01</span>, dt * <span class="hljs-number">0.02</span>);<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = res_t - dt; t &lt; res_t + <span class="hljs-number">.01</span>; t+=mini_dt)<br>        &#123;<br>            <span class="hljs-type">vec3</span> p = ro+t*rd;<br>            <span class="hljs-type">float</span> terrain_height = getTerrainHeight(p.xz, perlinOctaves);<br>            <span class="hljs-keyword">if</span>(p.y &lt; terrain_height)<br>            &#123;        <br>                res_t = t - mini_dt + mini_dt*(last_h - last_p.y) / (p.y - last_p.y-terrain_height+last_h); <br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;        <br>            <span class="hljs-comment">// closer terrain use higher accuracy        </span><br>            last_h = terrain_height;        <br>            last_p = p;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <br>&#125;<br></code></pre></td></tr></table></figure><p>我原来的方法的思想是做两遍测试，先以一个较大步长做一次初步筛选，找到大概的光线穿过地形的区间；然后再在那个区间用较小的步长做另外因此光线步进。</p><p>这个方法的问题在于如果初筛的时候步长太大，可能会穿过一个厚度较小的地形（比如说山峰），所以初筛的步长也不能太小；第二次筛选似乎取值也偏小了，导致还是做了很多次的光线步进检测。</p><h2 id="优化结果">优化结果</h2><p>现在我将新的光线步进方法更新到了我原来的ShaderToy Demo上，在768X432的分辨率60fps的情况下，我的demo在我的电脑上的GPU占用率由80%左右降低到了35%左右，可谓是巨大的提升。</p><p>在demo的代码中，我在第一行添加了代码</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#define OLD_METHOD 0</span><br></code></pre></td></tr></table></figure><p>将<strong>OLD_METHOD</strong>改为1的话可以改为使用老方法，各位有兴趣的话可以实际修改一下代码来对比一下这两种方法的性能差异。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>程序化生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>程序化地形生成-2</title>
    <link href="/2024/11/04/ProceduralTerrainGeneration2/"/>
    <url>/2024/11/04/ProceduralTerrainGeneration2/</url>
    
    <content type="html"><![CDATA[<p>距离上一篇将程序化地形生成的<a href="https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/">教程</a>也已经过去了一段时间了。前段时间一直有其他事情需要忙，现在终于有时间继续之前未完成的工作了。</p><h2 id="丰富地形">丰富地形</h2><p>上一篇教程我们已经创建出了绵延的山脉，如下图所示：<br><img src="terrain_no_grass.png" alt="上次渲染的结果"><br>看起来似乎是有那么点意思了，但是这样的山脉效果还是太单调了。</p><p>接下来我们就计划丰富一下这个场景。</p><h3 id="增加绿植">增加绿植</h3><p>我们场景中的山光秃秃的，很像是沙漠，也很像火星上的地貌。</p><p>我想给场景增加一些层次，一些生机，因此我打算将山的一部分渲染为绿植部分。</p><p>那么如何确定哪些部分是绿植，哪些部分是裸露的山体呢？根据地形表面的法线可以做一个简单的判定：法线的y分量越大，也就是面向上的分量越大，表明这个面更平，因此有绿植是更合适的；反正则表明这个面更加陡峭，更适合作为山体表现。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> dirt_color = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.8549</span>, <span class="hljs-number">0.5255</span>, <span class="hljs-number">0.3098</span>);<br><span class="hljs-type">vec3</span> grass_color = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.3137</span>, <span class="hljs-number">0.5412</span>, <span class="hljs-number">0.0157</span>);<br><span class="hljs-comment">// ..</span><br><br><span class="hljs-keyword">if</span>(rd.y &lt; <span class="hljs-number">0.05</span> &amp;&amp; rayMarchingTerrain(ro, rd, maxt, res_t))<br>&#123;<br>    <span class="hljs-type">vec3</span> height_pos = ro+res_t*rd;<br><br>    <span class="hljs-comment">// calculate normla</span><br>    <span class="hljs-type">vec3</span> normal = getNormal(height_pos);<br>    <span class="hljs-type">float</span> grass_ratio = <span class="hljs-built_in">smoothstep</span>(<span class="hljs-number">0.7</span>, <span class="hljs-number">0.98</span>, normal.y);<br>    <span class="hljs-type">vec3</span> ground_color = <span class="hljs-built_in">mix</span>(dirt_color, grass_color, grass_ratio);<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上面是一段实例代码，我们预先设定山体和绿植的颜色，在光线步进山体的时候，获取normal，根据法线的y方向的大小（也可以用dot来判定）做smoothstep取一个合适的值作为当前平面草地的比例，最后混合山体和草地的比例。得到的结果如下：</p><p><img src="terrain_with_grass.png" alt="增加绿植"><br>这样一来场景的丰富程度一下子就提升了。</p><h2 id="天空">天空</h2><p>现在最终结果还是挺奇怪的，很大一部分的原因是场景的背景还是黑咕隆咚的。我们的大场景急需增加天空的部分。</p><h3 id="天空的颜色">天空的颜色</h3><p>天空的颜色我之前有写过一个<a href="https://ruochenhua.github.io/2024/10/15/single-scatter-atmosphere/">教程</a>，是利用单次散射的方法来计算天空大气的颜色。当然这个方法在这依然是可用的。</p><p>不过如果你说，我不想用那么复杂的方法，只想快速出效果呢？那也是很简单，给地形光线步近没有结果的像素设定为蓝色就行了，哈哈。</p><p>如果想再复杂一点，可以做一个小细节的优化。也就是在晴朗的情况下，一般靠近地平线的天的蓝色是更加浅的，所以在给天空像素上色的时候，可以根据当前像素的方向的y值作为判定，在深蓝色和浅蓝色做线性插值。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> low_sky_blue = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.5137</span>, <span class="hljs-number">0.7804</span>, <span class="hljs-number">0.9608</span>);<br><span class="hljs-type">vec3</span> high_sky_blue = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.3216</span>, <span class="hljs-number">0.4706</span>, <span class="hljs-number">0.9725</span>);<br><br><span class="hljs-type">vec3</span> sky_color = <span class="hljs-built_in">mix</span>(low_sky_blue, high_sky_blue, <span class="hljs-built_in">clamp</span>(rd.y, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>));<br></code></pre></td></tr></table></figure><p><img src="terrain_with_sky.png" alt="增加天空"></p><h3 id="雾气增强层次感">雾气增强层次感</h3><p>在增加了天空之后，我们的渲染结果有了很显著的提升，终于像室外的场景了。</p><p>不过仔细看后，还是觉得怪怪的，远处的山和天空根本不在一个图层上；山的远近层次感也不足，远处的山太清晰了。</p><p>这是因为缺少雾气的结果，雾气能够很好的增加大场景体量感，能够很好的处理场景和天空衔接的感觉。</p><p>增加雾气也十分简单，仅需根据地形光线步近的结果的大小（也就是地形离相机的距离）来计算一个比例，根据这个比例来做场景颜色和雾气颜色的插值即可。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// cal fog density, different between r,g,b so the fog has a blue hue</span><br><span class="hljs-type">vec3</span> calcFog(<span class="hljs-type">float</span> dist)<br>&#123;    <br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">exp</span>(<span class="hljs-number">-5e-3</span>*dist*<span class="hljs-type">vec3</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>));<br>&#125;<br><br><span class="hljs-comment">// ...</span><br><span class="hljs-type">vec3</span> fog_amount = calcFog(res_t);<br>color = <span class="hljs-built_in">mix</span>(<span class="hljs-type">vec3</span>(<span class="hljs-number">0.7</span>),color, fog_amount);<br></code></pre></td></tr></table></figure><p>上面这段便是雾气的计算过程。雾气的比例通过**exp(-5e-3<em>dist</em>vec3(1,2,4))**计算，得到的雾的比例用于最终颜色的线性插值。</p><p><img src="terrain_with_sky_fog.png" alt="增加雾气"><br>有了雾气的加持，我们场景的大体量感就有了，层次感也明显了很多。<br>关于雾气的更多内容，可以参考Inigo大神的<a href="https://iquilezles.org/articles/fog/">这篇文章</a>。</p><h3 id="漫反射光照细节">漫反射光照细节</h3><p>接下来我想优化一下场景整体的漫反射细节。</p><p>当前的渲染结果其实是有加一个默认的环境光**vec3(0.1)**的，主要是之前的场景太黑了。这是个临时的处理，把这个环境光去掉。<br><img src="terrain_with_sky_fog_less_ambient.png" alt="去掉写死的环境光补偿"></p><p>好了，我们再来看一下我们的场景。有没有感觉山体的阴影部分有点太黑了？是的，在现实世界中，处于阴影的场景，在大白天也会被场景的漫反射光给提亮的，这种一片漆黑的感觉是有些难看。所以接下来我们来增加一些场景中应该有的漫反射光。</p><p>首先山体之间是会有漫反射光的影响的，也就是阴影部分的山体会被不在阴影的其他山的漫反射光照亮。当然这种影响我们是无法实时计算的，要计算的东西实在是太多了。但是可以通过一个很简单的方式来提单：我们计算当前点的发现和指向光源方向的点乘，当这个结果大于0的时候，用这个乘积乘以一个小的光照并加到原本的颜色上。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl">color += (<span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">dot</span>(-light_dir, normal))*ground_color/<span class="hljs-number">10.0</span>);<br></code></pre></td></tr></table></figure><p><img src="terrain_with_sky_fog_diffuse_from_mountain.png" alt="增加地形的漫反射光"></p><p>加完地形的漫反射光后，天空其实也有各个方向的漫反射的光会影响地形的亮度。天空的漫反射光可以通过地形法线的y分量和天空颜色的一部分来计算，示例代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl">color += (normal.y + <span class="hljs-number">1.0</span>)/<span class="hljs-number">2.0</span>*low_sky_blue/<span class="hljs-number">10.0</span>;<br></code></pre></td></tr></table></figure><p><img src="terrain_with_sky_fog_diffuse_from_sky.png" alt="增加天空的漫反射光"></p><p>增加了这些漫反射细节，场景的真实度进一步得到了提升。</p><h2 id="云朵">云朵</h2><p>有了天空，再给天空上增加云的话会进一步增加场景的丰富度，下面就来介绍我给这个场景添加的两部分云的计算。</p><h3 id="高层云">高层云</h3><p>我给这个场景添加了两种云，高层云是我想模拟在高度很高的地方，云层看起来不厚并且相对静态的感觉。</p><p>高层云的纹理也是利用perlin noise来计算，由于高层的云没有厚实感其实用2D的perlin noise也足够了。</p><p>另外需要注意的是，云的纹理需要根据远近来做处理。远处的云的纹理如果太清晰的话在最终效果上会显得太过于密集。下面是高层云的示例代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 高层云的高度</span><br><span class="hljs-type">float</span> top_sky_plane = <span class="hljs-number">3000.</span>;<br><br><span class="hljs-type">vec3</span> getSkyColor(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd)<br>&#123;    <br>    <span class="hljs-type">vec3</span> hit_sky;<br>    hit_sky.y = top_sky_plane;<br>        <br>    hit_sky.xz = ro.xz + rd.xz * (top_sky_plane - ro.y)/rd.y;    <br>    <br>    <span class="hljs-comment">//降低远处云的密度，看起来效果更好</span><br>    <span class="hljs-type">float</span> hit_dist = <span class="hljs-built_in">distance</span>(hit_sky, ro);<br>    <span class="hljs-type">float</span> cloud_density_percentage = <span class="hljs-number">1.0</span>;<br>    <span class="hljs-keyword">if</span>(hit_dist &gt; cloud_view_distance)<br>    &#123;<br>        cloud_density_percentage *= <span class="hljs-built_in">exp</span>(-(hit_dist - cloud_view_distance)/ cloud_view_distance);<br>    &#125;    <br><br>    <span class="hljs-comment">// 根据云层采样点的远近处理云层的密度</span><br>    <span class="hljs-type">float</span> cloud_density = <span class="hljs-built_in">smoothstep</span>(getCloudDensity(hit_sky.xz/<span class="hljs-number">150.0</span>, <span class="hljs-number">3</span>), <span class="hljs-number">-0.99</span>, <span class="hljs-number">1.9</span>)*cloud_density_percentage * <span class="hljs-number">0.5</span>;<br>    <span class="hljs-type">float</span> res_t;<br><br>    <span class="hljs-comment">// sky color    </span><br>    <span class="hljs-type">vec3</span> sky_color = <span class="hljs-built_in">mix</span>(low_sky_blue, high_sky_blue, <span class="hljs-built_in">clamp</span>(rd.y, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>));<br>    <span class="hljs-type">vec3</span> cloud_color = <span class="hljs-type">vec3</span>(<span class="hljs-number">1.</span>);<br>    <span class="hljs-comment">// 根据云层密度得到最终的高层云和天空颜色</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">mix</span>(sky_color, cloud_color, cloud_density);<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="terrain_with_high_cloud.png" alt="增加天空高层云"></p><p>增加了高层云之后，天空就显得不那么单调了。</p><h3 id="体积云">体积云</h3><p>最后就是体积云了，体积云的部分我不会在这里详细讨论，这是一个可以讨论的比较深的话题。我这个场景的体积云效果也并不是很理想，这里仅作为一个最后的点缀，在山峰上增加一点点动态效果。</p><p>体积云的效果其实也是在一定区域内进行多个点的采样而来，这个区域内利用FBM来实现云的动态的随机效果。在这个场景内我使用了SDF来圈定体积云的范围，并且给SDF增加了随机现状来获取更好的随机效果。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> scene(<span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> pos)<br>&#123;    <br>    <span class="hljs-type">vec3</span> cloud_pos = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">15.0</span>);<br>    <br>    <span class="hljs-type">vec3</span> filter_pos = <span class="hljs-type">vec3</span>(pos.x, pos.y+iTime, pos.z+iTime);<br>    pos -= cloud_pos;<br>    <span class="hljs-type">float</span> rst = -(rm_box(pos)) + fbm_cloud(pos * <span class="hljs-number">0.1</span>+iTime*<span class="hljs-number">0.3</span>, <span class="hljs-number">5</span>);<br>    rst = rst / <span class="hljs-number">25.0</span> * <span class="hljs-built_in">max</span>(fbm_cloud(filter_pos*<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>) - <span class="hljs-number">1.2</span>, <span class="hljs-number">0.0</span>); <br>    <span class="hljs-keyword">return</span> rst;<br>&#125;<br><br><span class="hljs-type">float</span> max_cloud_dist = <span class="hljs-number">80.</span>;<br><span class="hljs-type">vec4</span> renderMidClouds(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd)<br>&#123;    <br>    <span class="hljs-type">vec4</span> res = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">float</span> depth = <span class="hljs-number">0.0</span>;    <br>    <br>    <span class="hljs-type">int</span> sample_count = <span class="hljs-number">64</span>;<br>    <span class="hljs-type">float</span> dt = max_cloud_dist / <span class="hljs-type">float</span>(sample_count);<br>    <br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_count; ++i)<br>    &#123;<br>        <span class="hljs-type">vec3</span> p = ro + depth*rd;<br>        <span class="hljs-type">float</span> density = scene(p);<br>        <span class="hljs-keyword">if</span>(density &gt; <span class="hljs-number">0.0</span>)<br>        &#123;<br>            <span class="hljs-type">float</span> diffuse = <span class="hljs-built_in">clamp</span>((scene(p) - scene(p + <span class="hljs-number">0.3</span>*light_dir))/<span class="hljs-number">0.3</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>);<br>            <span class="hljs-type">vec3</span> lin = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>) * <span class="hljs-number">1.1</span> + <span class="hljs-number">0.8</span> * <span class="hljs-type">vec3</span>(<span class="hljs-number">0.9333</span>, <span class="hljs-number">0.702</span>, <span class="hljs-number">0.5255</span>)*diffuse;<br>            <span class="hljs-type">vec4</span> color = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">mix</span>(<span class="hljs-type">vec3</span>(<span class="hljs-number">1.0</span>), <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>), density), density);<br>            color.rgb *= color.a;<br><br>            res += color * (<span class="hljs-number">1.0</span> - res.a);<br>        &#125;<br><br>        depth+=dt;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> res;<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="terrain_with_all_cloud.png" alt="增加体积云"></p><h2 id="最终效果">最终效果</h2><iframe width="640" height="360" frameborder="0" src="https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false" allowfullscreen></iframe><p>以上便是我如何实现这个场景的简单介绍了。这是我初次尝试在ShaderToy上渲染大场景，也是第一次将整个步骤拆解讲解，可能还是会有不少地方讲的不过仔细和通透，也有些遗漏。</p><p>后面我还是会继续尝试创作和讲解，希望能给人带来帮助，也有助于巩固我所学的知识。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>程序化生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>景深的简单实现</title>
    <link href="/2024/10/28/depth-of-field/"/>
    <url>/2024/10/28/depth-of-field/</url>
    
    <content type="html"><![CDATA[<h2 id="关于景深">关于景深</h2><p>景深是一个常在摄像领域出现的词，它一般指的是沿着摄像机或其他成像器的拍摄方向上，能够取得清晰图像的成像所测定的被摄物体前后距离范围。用大白话就是说，拥有浅景深的成像器拍摄出来的效果，是只有焦点附近的图像是清晰的，其他地方的图像都是模糊的；而拥有大景深则可以在离焦点很远的地方也能有清晰的图像。</p><p><img src="dof_butterfly.JPG" alt="一张浅景深的照片"></p><p>有了景深效果的图像可以有重点的突出核心想要表达的内容，不仅仅在摄影摄像的领域有非常多的应用，在游戏领域内也是应用广泛，可以表现出很独特的风格化美术效果（如八方旅人的浅景深效果）。</p><p><img src="game1.jpg" alt="八方旅人"></p><p>下面我来介绍一种基础的景深效果实现，这个方法也在最近接入了<a href="https://github.com/ruochenhua/KongEngine">KongEngine</a></p><h2 id="渲染散景">渲染散景</h2><p>浅景深的主要应用是通过调整不同焦距上物体的成像清晰程度来突出渲染画面的重点。清晰的部分我们已经掌握了，就是正常的将场景渲染出来，那不清晰的部分（或者叫做散景）也有不少的实现方式，一般是通过模糊算法来实现。</p><p>模糊的算法有很多种，比如box blur，gaussian blur等等，效果最好的是扩张模糊(dilate blur)，这也是我们会采取的方法。</p><h3 id="扩张模糊（dilate-blur">扩张模糊（dilate blur)</h3><p>扩张模糊它的主要方式，是在给定一个模糊的窗口下，取得这个窗口下的最亮的颜色记录下来，然后将这个最亮的颜色扩张到整个窗口。这样一来经过扩张模糊的画面会有一种亮晶晶，并且很柔和的效果，很适合作为散景的表现效果。</p><p>dilate blur的计算也比较简单，首先我们定义此次blur的窗口大小已经采样的间隔大小。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 窗口的大小，数值越大扩散越大，消耗越高 </span><br><span class="hljs-type">int</span> size = <span class="hljs-number">5</span>;<br><span class="hljs-comment">// 采样间隔的大小，数值越大扩散越大，效果降低</span><br><span class="hljs-type">float</span> separation = <span class="hljs-number">1.0</span>;<br></code></pre></td></tr></table></figure><p>在定义了窗口的尺寸之后，我们在窗口的范围内记录最亮的像素颜色，并保存下来。<strong>窗口的形状不限</strong>，可以是矩形，或者圆形。我们这里实现采取圆形的窗口。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 渲染场景的尺寸</span><br><span class="hljs-type">vec2</span> tex_size = <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(scene_texture, <span class="hljs-number">0</span>).xy);<br><span class="hljs-comment">// 获取场景的原本颜色</span><br>FragColor = <span class="hljs-built_in">texture</span>(scene_texture, TexCoords);<br><br><span class="hljs-keyword">if</span>(size &lt;= <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span>;<br><span class="hljs-type">float</span> mx = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">vec4</span> cmx = FragColor;<br><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = -size; i &lt;= size; ++i)<br>&#123;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = -size; j &lt;= size; ++j)<br>&#123;<br><span class="hljs-comment">// dilate的形状可以多样，如圆形，矩形等等，根据采样点的形状来决定</span><br><span class="hljs-comment">// 这里使用圆形的dilate</span><br><span class="hljs-keyword">if</span>(<span class="hljs-built_in">distance</span>(<span class="hljs-type">vec2</span>(i,j), <span class="hljs-type">vec2</span>(<span class="hljs-number">0</span>)) &gt; size) <span class="hljs-keyword">continue</span>;<br><br><span class="hljs-comment">// 采样区域内点的颜色，不要越界出去了</span><br><span class="hljs-type">vec2</span> sample_coord = TexCoords + <span class="hljs-type">vec2</span>(i, j)*separation/tex_size;<br><span class="hljs-keyword">if</span>(sample_coord.x &gt; <span class="hljs-number">1.0</span> || sample_coord.x &lt; <span class="hljs-number">0.0</span> || sample_coord.y &gt; <span class="hljs-number">1.0</span> || sample_coord.y &lt; <span class="hljs-number">0.0</span>)<br><span class="hljs-keyword">continue</span>;<br><br><span class="hljs-comment">// 拿到采样点</span><br><span class="hljs-type">vec4</span> c = <span class="hljs-built_in">texture</span>(scene_texture, sample_coord);<br><br><span class="hljs-comment">// 和目标颜色做点乘，得到一个灰度值</span><br><span class="hljs-type">float</span> mxt = <span class="hljs-built_in">dot</span>(c.rgb, <span class="hljs-type">vec3</span>(<span class="hljs-number">0.3</span>, <span class="hljs-number">0.59</span>, <span class="hljs-number">0.11</span>));<br><br><span class="hljs-comment">// 保存区域内灰度值最大的颜色</span><br><span class="hljs-keyword">if</span>(mxt &gt; mx)<br>&#123;<br>mx = mxt;<br>cmx = c;<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我们计算最亮区域的方式是通过和一个目标颜色**(0.3, 0.59, 0.11)**来做点乘，当然也可以通过和其他的目标颜色，或者其他的方式来实现。</p><p>最后，我们得到窗口区域内最亮的颜色，我们的最终颜色是原本颜色和最亮颜色的差值。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 模糊采样的颜色和原始颜色的mix上下限</span><br><span class="hljs-type">float</span> min_threshold = <span class="hljs-number">0.1</span>;<br><span class="hljs-type">float</span> max_threshold = <span class="hljs-number">0.3</span>;<br><br><span class="hljs-comment">// 最终颜色是原来颜色和区域内灰度值最大的采样颜色的混合，有上下限做限制</span><br>FragColor.rgb = <span class="hljs-built_in">mix</span>(FragColor.rgb, cmx.rgb, <span class="hljs-built_in">smoothstep</span>(min_threshold, max_threshold, mx));<br></code></pre></td></tr></table></figure><p>这里我们还是采用了一个上下限，尽量控制增亮的程度。</p><h3 id="散景的效果">散景的效果</h3><p>这里给出经过扩张模糊得到的散景效果。下面这张图是扩张模糊之前的效果。<br><img src="dilate_before.png" alt="扩张模糊前"><br>下面这张图是扩张模糊之后的效果。<br><img src="dilate_after.png" alt="扩张模糊后"></p><p>当然在实际的场景中，我们可能不会开这么大的扩散效果，此处只是作为对比。</p><h2 id="结合场景">结合场景</h2><p>好了，现在我们有原本场景的渲染效果和扩散后的效果，实现最终的景深效果需要将这两者结合起来。我们需要一种方法来决定画面上哪些部分是需要采用清晰的图像，哪些是采用模糊的图像。</p><p>为了实现这个效果我们需要获得画面上每个点的深度，或者每个点的实际世界坐标。幸运的是，我们在实现<a href="https://ruochenhua.github.io/2024/10/19/defer-render/">延迟渲染</a>的时候已经将这些存放到缓冲中去了，接下来就是实现景深效果了。</p><p>最终的代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> TexCoords;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> scene_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> dilate_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> position_texture;<br><br><span class="hljs-comment">// 焦点距离</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> focus_distance = <span class="hljs-number">3.0</span>;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">vec2</span> focus_threshold;<br><span class="hljs-comment">// 景深的上下限</span><br><span class="hljs-type">float</span> min_dist = focus_threshold.x;<br><span class="hljs-type">float</span> max_dist = focus_threshold.y;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec4</span> focus_color = <span class="hljs-built_in">texture</span>(scene_texture, TexCoords);<br>    <span class="hljs-type">vec4</span> out_of_focus_color = <span class="hljs-built_in">texture</span>(dilate_texture, TexCoords);<br>    <span class="hljs-type">vec3</span> scene_position = <span class="hljs-built_in">texture</span>(position_texture, TexCoords).xyz; <br>    <br><span class="hljs-comment">// 这里采用了画面每个点的世界坐标和相机的距离作为判定模糊的标准</span><br><span class="hljs-comment">// 当然用深度信息也是可以的，性能上也更好，这里为了代码展示更好理解</span><br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br><br>    <span class="hljs-type">float</span> blur_amout = <span class="hljs-built_in">smoothstep</span>(min_dist, max_dist, <span class="hljs-built_in">abs</span>(focus_distance - <span class="hljs-built_in">distance</span>(scene_position, cam_pos)));<br>    <br><span class="hljs-comment">// 最后的颜色是焦距内和散景的混合</span><br>    FragColor = <span class="hljs-built_in">mix</span>(focus_color, out_of_focus_color, blur_amout);<br>&#125;<br></code></pre></td></tr></table></figure><p>这段代码理解起来应该没有什么太大的难度。</p><h2 id="最终效果">最终效果</h2><p>这里展示一下最终的效果。</p><p><img src="dof_near.png" alt="近焦点"><br><img src="dof_far.png" alt="远焦点"></p><p>上面两张图分别展示了不同焦点的景深的表现结果。可以明显看到不同景深效果的加入可以很容易的将画面上想要着重表达出来的部分勾勒出来。优秀的散景效果也能给画面增加不少美感（虽然我这个测试场景也没有什么美感可言…）。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>延迟渲染实现</title>
    <link href="/2024/10/19/defer-render/"/>
    <url>/2024/10/19/defer-render/</url>
    
    <content type="html"><![CDATA[<p>想要在Kong引擎里面实现的场景慢慢复杂了起来，光源和模型的数量从原先的十以内的数量增长到几十甚至几百的数量级，是时候接入延迟渲染的方法了。</p><h2 id="延迟渲染">延迟渲染</h2><p><strong>延迟渲染</strong>（Defer Rendering），或者<strong>延迟着色法</strong>（Defer Shading），是区别于<strong>正向渲染</strong>（Forward Shading）的一种计算场景光照的方式。</p><p>正向渲染方法就是遍历场景中的每一个模型，计算一个模型的光照表现后再继续下一个模型的计算，根据深度测试的结果更新屏幕上最终像素显示的颜色。这种方法是很容易让人理解并实现的。但是当场景中的光照和模型数量变多的时候，模型重叠的区域会进行不必要的光照计算（被挡住的模型像素区域最终会被前面的模型遮挡，但是这篇被挡住的区域还是被计算了光照），而光照计算一般来说是渲染消耗的大头，这部分时间就被浪费了。</p><p>而延迟渲染的想法则是将光照计算分成两部分。第一个部分叫做<strong>几何处理阶段</strong>（Geometry Pass），它先将光照计算所需要的模型信息（顶点位置、法线、颜色、材质属性等等）先渲染到多张贴图上（消耗低），经由深度检测保留最终在屏幕上显示的模型部分的这些信息。</p><!-- wp:image {"sizeSlug":"large","align":"center"} --><figure class="wp-block-image aligncenter size-large"><img src="https://learnopengl-cn.github.io/img/05/08/deferred_g_buffer.png" alt=""/></figure><!-- /wp:image --><p>第二部分叫做<strong>光照处理阶段</strong>（Lighting Pass），根据几何处理阶段保存的信息再去进行光照计算，这样就不会将算力浪费在计算被遮挡的模型部分的光照了，从而优化渲染的性能，也有赋予了能够更加方便的实现某些效果的能力（如SSAO）。</p><!-- wp:image {"sizeSlug":"large","align":"center"} --><figure class="wp-block-image aligncenter size-large"><img src="https://learnopengl-cn.github.io/img/05/08/deferred_overview.png" alt=""/></figure><!-- /wp:image --><h2 id="G缓冲">G缓冲</h2><p>G缓冲(G-buffer)是对所有用来储存光照相关的数据，并在最后的光照处理阶段中使用的所有纹理的总称。它是我们计算最终渲染输出中的缓存和中转站，为了实现延迟渲染，G-buffer中会包含如下几张纹理的数据：模型顶点位置数据；模型法线数据；模型漫反射颜色数据；材质数据（ao，roughness，metallic）等等。有了这些数据则能够实现Kong引擎的PBR光照计算，初始化G-buffer的代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">DeferBuffer::GenerateDeferRenderTextures</span><span class="hljs-params">(<span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, g_buffer_);<br><br><span class="hljs-comment">// 将当前视野的数据用贴图缓存</span><br><span class="hljs-comment">// 位置数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_position_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_position_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, g_position_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 法线数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_normal_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_normal_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, g_normal_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 顶点颜色数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_albedo_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_albedo_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, g_albedo_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// orm数据（ao，roughness，metallic）</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_orm_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_orm_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT3, GL_TEXTURE_2D, g_orm_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 生成renderbuffer</span><br><span class="hljs-built_in">glGenRenderbuffers</span>(<span class="hljs-number">1</span>, &amp;g_rbo_);<br><span class="hljs-built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, g_rbo_);<br><span class="hljs-built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, width, height);<br><span class="hljs-built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, g_rbo_);<br><span class="hljs-built_in">glEnable</span>(GL_DEPTH_TEST);<br><br><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> attachments[<span class="hljs-number">4</span>] = &#123;GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3&#125;;<br><span class="hljs-built_in">glDrawBuffers</span>(<span class="hljs-number">4</span>, attachments);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>可以从上面的代码看到，我们利用了多渲染目标（multiple render targets）可以一次处理并输出到多个缓冲（GL_COLOR_ATTACHMENT0到3）。简化的几何处理着色器示例代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// defer_geometry_pass.frag</span><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gPosition;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gNormal;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">2</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gAlbedo;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">3</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gORM;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> frag_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> frag_normal;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> frag_uv;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">vec4</span> albedo;    <span class="hljs-comment">// color</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> metallic;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> roughness;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> ao;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-comment">// 深度信息存储到position贴图的w值中</span><br>    gPosition = frag_pos;<br>    gNormal = <span class="hljs-type">vec4</span>(frag_normal, <span class="hljs-number">1.0</span>);<br>    gAlbedo = albedo;<br>    gORM = <span class="hljs-type">vec4</span>(ao, roughness, metallic, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>上方的代码将我们所需要的世界坐标下的顶点坐标信息、法线信息、漫反射颜色和材质信息输出到了四张贴图。带着这四张贴图的信息，我们进入下一个阶段，光照处理阶段。下面是个简化的光照处理着色器代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec3</span> frag_pos = <span class="hljs-built_in">texture</span>(position_texture, TexCoords).xyz;<br>    <span class="hljs-type">vec3</span> frag_normal = <span class="hljs-built_in">texture</span>(normal_texture, TexCoords).rgb;<br>    <span class="hljs-type">vec4</span> env_albedo = <span class="hljs-built_in">texture</span>(albedo_texture, TexCoords);<br><br>    <span class="hljs-type">vec3</span> orm = <span class="hljs-built_in">texture</span>(orm_texture, TexCoords).rgb;<br>    <span class="hljs-type">float</span> ao = orm.x;<br>    <span class="hljs-type">float</span> env_roughness = orm.y;<br>    <span class="hljs-type">float</span> env_metallic = orm.z;<br><br>    <span class="hljs-type">vec3</span> view = <span class="hljs-built_in">normalize</span>(cam_pos - frag_pos);  <span class="hljs-comment">//to_view</span><br><br>    <span class="hljs-type">vec3</span> light_color = CalcLight(light_info, frag_normal, view,  frag_pos, material);<br><br>    <span class="hljs-type">vec3</span> color = ambient + light_color;<br>    FragColor = <span class="hljs-type">vec4</span>(color, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="结合延迟和正向渲染">结合延迟和正向渲染</h2><p>延迟渲染实现起来其实还是比较简单明了的，但是需要注意的是，有些材质并不能通过延迟渲染实现，比如说半透明这种需要进行alpha混合的材质，因此就会出现需要结合延迟渲染和正向渲染的情况。</p><p>结合延迟渲染和正向渲染的时候，一般来说是先处理延迟渲染的部分。在处理完延迟渲染后，将延迟渲染的G-buffer的深度缓冲复制到最后输出屏幕的深度缓冲上（我这里最后会继续后处理，所以是会输出到后处理的FrameBuffer上）。如此一来，正向渲染的物体才可以和延迟渲染的场景有正确的深度遮挡结合，否则会出现正向渲染的物体永远在上的情况。实例代码如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 需要将延迟渲染的深度缓冲复制到后面的后处理buffer上</span><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_READ_FRAMEBUFFER, defer_buffer_.g_buffer_);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_DRAW_FRAMEBUFFER, post_process.<span class="hljs-built_in">GetScreenFrameBuffer</span>());<br><span class="hljs-built_in">glBlitFramebuffer</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, window_size.x, window_size.y, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, window_size.x, window_size.y, GL_DEPTH_BUFFER_BIT, <br>GL_NEAREST);<br></code></pre></td></tr></table></figure><h2 id="延迟渲染的效能提升">延迟渲染的效能提升</h2><p>之前提过，延迟渲染最大的好处之一便是能够提升渲染的效率，这里大概做一个粗略的测试。下方是一个包含着1000个人物模型和200个点光源的场景，如果按照正常的正向渲染，这个场景在我的笔记本上的帧率大概在35左右：</p><p><img src="no_defer_render.png" alt="非延迟渲染"></p><p>当使用延迟渲染的情况下，该场景的帧率可以提升到170左右：</p><p><img src="defer_render.png" alt="延迟渲染"></p><p>当然上方这是个比较极端的场景，实际场景上可能不会有这么复杂的光源，以及模型可能不会像测试场景这样重叠，所以差距可能不会像测试场景那般明显。但是一般来说延迟渲染对渲染场景的性能提升会是比较客观的。</p><h3 id="基于延迟渲染的延伸">基于延迟渲染的延伸</h3><p>延迟渲染的好处之一不仅仅体现在性能上，由于延迟渲染将很多有用的信息存储下来，基于延迟渲染我们可以实现非常多其他的效果。比如说屏幕空间环境光遮蔽SSAO（如下图）以及屏幕空间反射SSR等等，我计划在后面的文章详细介绍一下。</p><p><img src="ssao.png" alt="SSAO效果"></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于单次散射的天空大气渲染方法</title>
    <link href="/2024/10/15/single-scatter-atmosphere/"/>
    <url>/2024/10/15/single-scatter-atmosphere/</url>
    
    <content type="html"><![CDATA[<p>最近KongEngine实现了IBL(Image Based Lighting)，可以将HDR环境贴图映射作为3D场景的环境。</p><p><img src="kong-screen-shot.png" alt="KongEngine的IBL效果"></p><p>在实现了IBL之后我又产生了一个想法，能否实现类似UE中的大气环境的渲染效果呢？我尝试去寻找答案，发现如果要完全复刻UE中的效果确实需要一定的功夫的，但是最基础的天空大气渲染并没有想象中那么复杂，于是我便花了点时间在KongEngine中实现了这个功能。</p><p><img src="single-scatter-atmosphere.png" alt="KongEngine天空大气效果"></p><p>我打算将这个方法的基础思想和实现在此简单记录一下。</p><h2 id="单次散射模型">单次散射模型</h2><p>星球的大气层是一种参与性介质，和在真空环境不同，光在大气层中传播的时候会因为大气中的微小颗粒（水、灰尘等等）发生散射（折射、反射）和吸收等情况。因此我们看向空中的一个点的时候，这个点的颜色是光经过多次散射得到的结果。</p><p>光到达我们眼睛之前经过多少次反射和折射是不一定的，在实时渲染的需求下计算太多次光的变化显然也是不显示的。最简单的方法，是使用单次散射模型：我们假定光在进入我们眼睛之前，有且只发生了一次散射。光一般在第一次散射的时候，还会有最多的能量剩余，后面的多次散射能力相对少，对最后效果的呈现也影响不大，因此这种模型可以在保证性能的情况下，还有不错的效果。</p><p><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_02.png" alt=""></p><p>除了散射，光在传播的时候会被大气吸收。一般来说，如果在一个均匀的介质中传播的话，光的被吸收的部分和介质的密度，以及传播的路径长度正相关。放到单散射模型的例子中，就是需要计算光在散射前和散射后的路径上，被吸收了多少能量。<br><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_07.png" alt=""></p><p>按照上面的图，假设相机在A点，观察方向为AB，其中有一束光在P点发生散射后沿着PA进入相机。如果我们知道了光线损耗和距离相关的公式，那么似乎是只要计算出CP和PA的长度，在带入公式后就可以得到光该路径上传播后的最终能量了。</p><p><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_10a.png" alt=""></p><p>但是对于大气层来说，它的密度并不是均匀的，而是和大气层距离地面的高度相关。所以在计算CP段光线损耗的时候，我们需要将这段距离分为多个小段，每个小段的损耗公式带入对应平均高度，在最后将所有结果相加才。小段划分的越密集，则结果越准确。</p><p>如果我们还要考虑大气中的其他因素，比如说大气中的云层，在这些区域中光的损耗就不仅仅是和高度相关了。</p><p>另外一点就是，当我们考虑AB方向的光线时，它的最终效果，是在大气层内的所有AB连线上面的点的散射结果的总和（P0、P1、P2…Pn），因此我们也同样的需要对AB线段进行分段采样并将结果叠加。AB线段上的每一个采样结果按照上面所描述的计算单一P点的方式。</p><p><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_08a.png" alt=""></p><p>以上便是大气单次散射模型的基本思路。</p><h2 id="散射的计算">散射的计算</h2><p>之前我们提到了计算光的散射，这里我们介绍一下散射的相关计算。会提及一些公式，但是不会做过多的数学推导工作，对推导过程感兴趣的可以看一下文章中的参考资料。</p><p>一般来说，天空大气的散射主要包括两种，分别是<strong>瑞利散射</strong>和<strong>米氏散射</strong>。</p><ul><li>瑞利散射是当光线通过介质中的微小颗粒或分子时发生的散射现象。由于颗粒或分子的尺寸远小于光的波长，不同波长的光线会以不同的角度散射，一个最经典的案例就是因为蓝色的波长是较短的，所以蓝色很容易发生瑞利散射，导致天空呈现蓝色。</li><li>米氏散射则一般由空气中含有的较大颗粒的介质，如气溶胶、灰尘、水滴等引起。和瑞利散射不同的是，米氏散射和光的波长关系并不大。<br><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_13.png" alt=""></li></ul><p>那么根据前面的模型思路，光在P点上发生了散射，其中一部分能量沿着PA方向进入相机的实现。获取这一部分能量的计算函数被称之为<strong>相位函数（Phase Function）</strong>。相位函数是用来描述，当光线发生散射的情况时，某个方向（一般是和原光线方向的夹角）占原光线的能量的比例。瑞利散射和米氏散射的相位函数是不同的，同一种散射的相位函数也会有不同的方法进行拟合，这里我不想去做过多的公式推导的工作，有兴趣的可以去查看<a href="https://patapom.com/topics/Revision2013/Revision%202013%20-%20Real-time%20Volumetric%20Rendering%20Course%20Notes.pdf">参考资料</a>的推导过程。</p><p>下方是瑞利散射的相位函数，theta是原光线方向和目标方向的夹角：</p><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mtable displaystyle="true" columnalign="right left right" columnspacing="0em 2em" rowspacing="3pt">    <mtr>      <mtd>        <mi>P</mi>        <mo stretchy="false">(</mo>        <mi>&#x3B8;</mi>        <mo stretchy="false">)</mo>      </mtd>              <mtd>        <mi></mi>        <mo>=</mo>        <mfrac>          <mn>3</mn>          <mrow>            <mn>16</mn>            <mi>&#x3C0;</mi>          </mrow>        </mfrac>        <mo stretchy="false">(</mo>        <mn>1</mn>        <mo>+</mo>        <mi>c</mi>        <mi>o</mi>        <msup>          <mi>s</mi>          <mn>2</mn>        </msup>        <mi>&#x3B8;</mi>        <mo stretchy="false">)</mo>      </mtd>    </mtr>  </mtable></math><!-- /wp:html --><!-- wp:paragraph --><p>下方是米氏散射的相位函数，这里使用的是<a href="https://omlc.org/classroom/ece532/class3/hg.html">Henyey-Greenstein函数</a>来近似。</p><!-- /wp:paragraph --><!-- wp:html --><p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mi>P</mi>  <mo stretchy="false">(</mo>  <mi>θ</mi>  <mo stretchy="false">)</mo>  <mo>=</mo>  <mfrac>    <mrow>      <mn>1</mn>      <mo>−</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>    <mrow>      <mn>4</mn>      <mi>π</mi>      <mo stretchy="false">(</mo>      <mn>1</mn>      <mo>+</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>      <mo>−</mo>      <mn>2</mn>      <mi>g</mi>      <mi>c</mi>      <mi>o</mi>      <mi>s</mi>      <mo stretchy="false">(</mo>      <mi>θ</mi>      <mo stretchy="false">)</mo>      <msup>        <mo stretchy="false">)</mo>        <mrow>          <mn>3</mn>          <mrow>            <mo>/</mo>          </mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>  </mfrac></math></p><!-- /wp:html --><!-- wp:paragraph --><p>好了，现在我们知道了如何计算光线在P点的散射行为。剩下的工作就是需要计算光线在传播过程的损耗了。这一部分的计算方法称之为<strong>衰减系数</strong>，或者<strong>消光系数</strong>。消光系数中的一部分，需要对光线在传播的路线的长度和空气密度进行积分。在程序中的表示就是将光的传播路径分为小段，将每一小段的长度和平均密度（或者小段中点的介质密度）相乘而得到，这个结果我们称之为<strong>光学距离（Optical Depth）</strong>。</p><!-- /wp:paragraph --><!-- wp:paragraph --><p>衰减系数的计算公式如下，红色部分代表的是在海拔为h的散射系数。他可以分解为在海平面上的散射系数乘以在海拔h的介质密度。</p><!-- /wp:paragraph --><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mstyle mathcolor="#00AAFF">    <mi>T</mi>    <mo stretchy="false">(</mo>    <mi>P</mi>    <mi>A</mi>    <mo stretchy="false">)</mo>  </mstyle>  <mo>=</mo><mstyle mathcolor="#00AA00">  <mi>exp</mi></mstyle>  <mrow data-mjx-texclass="ORD">    <mo>&#x2212;</mo>    <msubsup>      <mo data-mjx-texclass="OP">&#x222B;</mo>      <mi>P</mi>      <mi>A</mi>    </msubsup>    <mrow data-mjx-texclass="ORD">      <mstyle mathcolor="Red">        <mi>&#x3B2;</mi>        <mo stretchy="false">(</mo>        <mi>&#x3BB;</mi>        <mo>,</mo>        <mi>h</mi>        <mo stretchy="false">)</mo>      </mstyle>    </mrow>    <mi>d</mi>    <mi>s</mi>  </mrow></math><!-- /wp:html --><!-- wp:paragraph --><p>分解出来后得到的结果如下，其中红色的部分代表的意思是在海平面的散射系数，是一个常量，黄色部分代表了在海拔为h的介质的密度。这个公式的积分便是针对AP路线上的介质密度，其结果也就是光学距离。</p><!-- /wp:paragraph --><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mstyle mathcolor="#00AAFF">    <mi>T</mi>    <mo stretchy="false">(</mo>    <mi>P</mi>    <mi>A</mi>    <mo stretchy="false">)</mo>  </mstyle>  <mo>=</mo>    <mstyle mathcolor="#00AA00">      <mi>exp</mi>    </mstyle>  <mrow data-mjx-texclass="ORD">    <mo>&#x2212;</mo>    <mstyle mathcolor="Red">      <mi>&#x3B2;</mi>      <mo stretchy="false">(</mo>      <mi>&#x3BB;</mi>      <mo stretchy="false">)</mo>    </mstyle>    <msubsup>      <mo data-mjx-texclass="OP">&#x222B;</mo>      <mi>P</mi>      <mi>A</mi>    </msubsup>    <mrow data-mjx-texclass="ORD">      <mstyle mathcolor="Gold">        <mi>&#x3C1;</mi>        <mo stretchy="false">(</mo>        <mi>h</mi>        <mo stretchy="false">)</mo>      </mstyle>    </mrow>    <mi>d</mi>    <mi>s</mi>  </mrow></math><!-- /wp:html --><!-- wp:paragraph --><p>介质密度的计算公式如下，其中H代表的是一个基准海拔，是一个常量。不同散射的基准海拔有所不同，瑞利散射的基准海拔是*8500*，而米氏散射的基准海拔是*1200*。</p><!-- /wp:paragraph --><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mstyle mathcolor="Gold">    <mi>&#x3C1;</mi>    <mo stretchy="false">(</mo>    <mi>h</mi>    <mo stretchy="false">)</mo>  </mstyle>  <mo>=</mo>  <mi>exp</mi>  <mo stretchy="false">(</mo>  <mo>&#x2212;</mo>  <mfrac>    <mi>h</mi>    <mi>H</mi>  </mfrac>  <mo stretchy="false">)</mo></math><!-- /wp:html --><p>自此，我们关于单次散射的天空大气渲染方法的基本预备知识已经了解的差不多了，接下来介绍shader的相关代码。</p><h2 id="Shader代码">Shader代码</h2><p>首先，为了计算AB、PC等视线和光线在大气层内的传播距离，我们需要一个函数来计算射线和球体的相交情况。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec2</span> ray_sphere_intersection(<span class="hljs-type">vec3</span> ray_origin, <span class="hljs-type">vec3</span> ray_direction, <span class="hljs-type">vec3</span> sphere_center, <span class="hljs-type">float</span> sphere_radius)<br>&#123;<br>    <span class="hljs-comment">// ray-sphere intersection that assumes</span><br>    <span class="hljs-type">float</span> a = <span class="hljs-built_in">dot</span>(ray_direction, ray_direction);<br>    <span class="hljs-type">vec3</span> oc = ray_origin - sphere_center;<br>    <span class="hljs-type">float</span> b = <span class="hljs-number">2.0</span> * <span class="hljs-built_in">dot</span>(ray_direction, oc);<br>    <span class="hljs-type">float</span> c = <span class="hljs-built_in">dot</span>(oc, oc) - (sphere_radius * sphere_radius);<br>    <span class="hljs-type">float</span> d = (b*b) - <span class="hljs-number">4.0</span>*a*c;<br><br>    <span class="hljs-comment">// 返回击中结果，y小于x代表无结果</span><br>    <span class="hljs-keyword">if</span> (d &lt; <span class="hljs-number">0.0</span>) <span class="hljs-keyword">return</span> <span class="hljs-type">vec2</span>(<span class="hljs-number">1e10</span>,<span class="hljs-number">-1e10</span>);<br>    <span class="hljs-comment">// 击中的话有两个相同或者不同的结果</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-type">vec2</span>(<br>        (-b - <span class="hljs-built_in">sqrt</span>(d))/(<span class="hljs-number">2.0</span>*a),<br>        (-b + <span class="hljs-built_in">sqrt</span>(d))/(<span class="hljs-number">2.0</span>*a)<br>    );<br>&#125;<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>好了，那有了这个辅助公式，我们正式开始计算大气的颜色。首先，按照之前的理论，我们要计算视线向量在大气层内的长度，所以我们对射线方向和大气层，以及射线方向和星球表面做射线检测。得到视线在大气层内的长度后，根据我们预设的想要采样的步数（iSteps），计算出每次采样的长度ds。</p><!-- /wp:paragraph --><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs glsl">ray_dir = <span class="hljs-built_in">normalize</span>(ray_dir);<br><br><span class="hljs-comment">// 视线和大气层大小的尺寸的射线检测</span><br><span class="hljs-comment">// x为大气入射点的距离、y为大气出射点的距离（x==y代表光线和大气球体相切，x&gt;y代表光线不经过大气）</span><br><span class="hljs-type">vec2</span> atmos_hit = ray_sphere_intersection(ray_origin, ray_dir, rAtmos);<br><span class="hljs-comment">// 未击中，返回0</span><br><span class="hljs-keyword">if</span> (atmos_hit.x &gt; atmos_hit.y) <span class="hljs-keyword">return</span> <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br><br>    <span class="hljs-comment">// 视线和星球做射线检测，取得近处的检测结果（远处的那个光被星球本体遮挡）</span><br><span class="hljs-type">vec2</span> planet_hit = ray_sphere_intersection(ray_origin, ray_dir, planet_radius);<br><span class="hljs-type">float</span> light_distance = atmos_hit.y;<br><br><span class="hljs-comment">// hit the planet</span><br><span class="hljs-keyword">if</span>(planet_hit.x &lt; planet_hit.y &amp;&amp; planet_hit.x &gt; <span class="hljs-number">0.1</span>)<br>&#123;<br>    light_distance = planet_hit.x;<br>&#125;<br><br><span class="hljs-comment">// light sample length</span><br><span class="hljs-type">float</span> ds = light_distance / <span class="hljs-type">float</span>(iSteps);<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>那么接下来，便是进入采样的循环。循环有两层，外面的循环是计算<strong>视线方向上的每个采样点的光能量</strong>，而计算这个点的光能量也需要一个循环，这个循环是用于采样该点和光源之间的连线在大气层内的线段（也就是之前图片的PC段）的光学距离。根据前面提到的公式，光学距离乘以海平面的散射系数便可以得到光的衰减系数，因此jSteps循环可以得到光线在进入大气层后，传播到达视线上的采样点（P0、P1...Pn点）的衰减所剩下的能量。</p><!-- /wp:paragraph --><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// Initialize the primary ray time.</span><br><span class="hljs-type">float</span> iTime = <span class="hljs-number">0.0</span>;<br><br><span class="hljs-comment">// Initialize accumulators for Rayleigh and Mie scattering.</span><br><span class="hljs-type">vec3</span> total_scatter_rlh = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br><span class="hljs-type">vec3</span> total_scatter_mie = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// Initialize optical depth accumulators for the primary ray.</span><br><span class="hljs-type">float</span> total_od_rlh = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">float</span> total_od_mie = <span class="hljs-number">0.0</span>;<br><br><span class="hljs-comment">// 对每个视线上的采样点循环</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; iSteps; i++) &#123;<br>    <span class="hljs-comment">// 获取到采样点的位置</span><br>    <span class="hljs-type">vec3</span> iPos = ray_origin + ray_dir * (iTime + ds * <span class="hljs-number">0.5</span>);<br><br>    <span class="hljs-comment">// 在当前点向太阳的位置做射线检测，以大气的半径为球体。.y是代表大气的出射点，j_steps代表采样数</span><br>    <span class="hljs-type">float</span> jStepSize = ray_sphere_intersection(iPos, pSun, rAtmos).y / <span class="hljs-type">float</span>(jSteps);<br><br>    <span class="hljs-type">float</span> jTime = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> jOdRlh = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> jOdMie = <span class="hljs-number">0.0</span>;<br><br>    <span class="hljs-comment">// 在当前采样到大气入射点的距离上，采样计算</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; jSteps; j++) &#123;<br>        <span class="hljs-comment">// 计算采样点到光源的衰减</span><br>        <span class="hljs-type">vec3</span> jPos = iPos + pSun * (jTime + jStepSize * <span class="hljs-number">0.5</span>);<br><br>        <span class="hljs-type">float</span> jHeight = <span class="hljs-built_in">length</span>(jPos-planet_center) - planet_radius;<br><br>        <span class="hljs-comment">// Accumulate the optical depth.</span><br>        jOdRlh += get_atmos_density(jHeight, scale_height_rlh) * jStepSize;<br>        jOdMie += get_atmos_density(jHeight, scale_height_mie) * jStepSize;<br><br>        <span class="hljs-comment">// Increment the secondary ray time.</span><br>        jTime += jStepSize;<br>    &#125;<br><br>    <span class="hljs-comment">// 观察点和星球表面距离</span><br>    <span class="hljs-type">float</span> surface_height = <span class="hljs-built_in">length</span>(iPos-planet_center) - planet_radius;<br><br>    <span class="hljs-comment">// 计算这一步的散射的光学深度结果</span><br>    <span class="hljs-type">float</span> od_step_rlh = get_atmos_density(surface_height, scale_height_rlh) * ds;<br>    <span class="hljs-type">float</span> od_step_mie = get_atmos_density(surface_height, scale_height_mie) * ds;<br>    <br>    total_od_rlh += od_step_rlh;<br>    total_od_mie += od_step_mie;<br><br>    <span class="hljs-comment">// 计算衰减系数，光在经过一定距离后衰减剩下来的比例。</span><br>    <span class="hljs-type">vec3</span> attn = <span class="hljs-built_in">exp</span>(-(kMie * (total_od_mie + jOdMie) + kRlh * (total_od_rlh + jOdRlh)));<br><br>    <span class="hljs-comment">// Accumulate scattering.</span><br>    total_scatter_rlh += od_step_rlh * attn;<br>    total_scatter_mie += od_step_mie * attn;<br><br>    <span class="hljs-comment">// Increment the primary ray time.</span><br>    iTime += ds;<br>&#125;<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>计算瑞利散射和米氏散射的大气密度的代码如下所示，其中scale_height在计算瑞利散射的时候带入的是8500，米氏散射则带入1200。</p><!-- /wp:paragraph --><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 获取大气密度</span><br><span class="hljs-comment">// 传入位置离海平面的高度，以及散射的相关基准高度</span><br><span class="hljs-comment">// 大气中任意一点的散射系数的计算，简化拆解为散射在海平面的散射系数，乘以基于海平面高度的该散射的大气密度计算公式</span><br><span class="hljs-type">float</span> get_atmos_density(<span class="hljs-type">float</span> height_to_sea_level, <span class="hljs-type">float</span> scale_height)<br>&#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">exp</span>(-height_to_sea_level / scale_height);<br>&#125;<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>将iSteps循环的结果累加起来，我们便得到了视线上（AB）的每个采样点的光能量传播到达相机（A点）经过衰减的能量的和。那么还剩一个部分，就是光在P点进行散射的时候，光也损失掉了一部分能量，这个过程可以通过乘以米氏散射和瑞利散射的相位函数来计算。因为每个采样点P的结果都需要乘以相位函数，所以我们可以将它提取到最外面，乘以光的能量的总和即可。</p><!-- /wp:paragraph --><!-- wp:paragraph --><p>不过需要注意的是，前面的公式提到了，相位函数是和光线入射方向和目标方向的夹角相关的，所以如果我们<strong>默认太阳光源是平行光</strong>的话，这个夹角对每个采样点来说是一样的，所以可以将相位函数提取到最外层。如果认为这个夹角对每个采样点不一样的话，那也许还是应该老老实实在计算每个采样点的光的时候单独去处理。</p><!-- /wp:paragraph --><p>最终的结果除了乘以相位函数，还需要乘以海平面的散射系数，结果如下。</p></p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 计算并返回最终颜色</span><br><span class="hljs-comment">// iSun是光源（太阳）的颜色</span><br><span class="hljs-keyword">return</span> iSun * (pRlh * kRlh * total_scatter_rlh + pMie * kMie * total_scatter_mie);<br></code></pre></td></tr></table></figure><p>下面是得到的结果：</p><iframe src="single-scatter-atmosphere.mp4" scrolling="no" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><h2 id="参考资料">参考资料</h2><ul><li><a href="https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/">https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/</a></li><li><a href="https://www.xianlongok.site/post/8e5d3b12/">https://www.xianlongok.site/post/8e5d3b12/</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>级联阴影贴图实现</title>
    <link href="/2024/10/13/cascade-shadow-map/"/>
    <url>/2024/10/13/cascade-shadow-map/</url>
    
    <content type="html"><![CDATA[<h2 id="阴影贴图的局限">阴影贴图的局限</h2><p>阴影贴图（shadow map）是3D场景中实现阴影效果的基础手段，它通过预先将光线方向的场景深度存储到贴图中，在渲染的时候取每个场景中的点到光源的距离和深度贴图作比较，来判定该点是否在阴影当中。</p><p>但是在较大的场景中，使用阴影贴图会有几个明显的不足：</p><ol><li>阴影贴图只能覆盖部分场景，在渲染较大的场景的时候（如大世界），远处的场景基本上无法被阴影贴图所覆盖。</li><li>贴图的分辨率是有限的，太大的分辨率会对性能造成非常大的影响。但是在覆盖较大场景的时候，贴图分辨率不足会导致阴影模糊，效果不佳。</li><li>阴影贴图的实现一开始其实并没有考虑玩家相机的视椎体，也就是说在玩家没有看的地方也会渲染阴影贴图，这对渲染资源来说显然是个浪费。</li></ol><p>KongEngine计划在后面接入大地形的渲染，借此机会接入了级联阴影贴图的能力。<br>实现方法参考了<a href="https://learnopengl.com/Guest-Articles/2021/CSM">LearnOpenGL的教程</a>。</p><h2 id="级联阴影贴图的实现">级联阴影贴图的实现</h2><p>级联阴影贴图的基本概念包括如下几点：</p><ol><li>将玩家的视椎体划分为几段，每一段视椎体构建一张阴影贴图覆盖，这个阴影贴图完美贴合从光源方向投射到这段视椎体中心点的正交投影。</li><li>和模型LOD的理念类似，离相机近的阴影贴图需要采用较高精度，而离相机远的阴影贴图可以使用低精度。</li><li>将多级阴影贴图传入最后的光照计算着色器，根据每个点所处视椎体的分段不同采用对应不同的阴影贴图计算光照。</li></ol><p>听起来挺简单的对吧，那我们一步一步来。</p><h3 id="视椎体分段">视椎体分段</h3><p>上面说到我们需要将视椎体分为几段，在每一段视椎体覆盖一张阴影贴图，并计算出这张贴图的从光源方向看向视椎体中心点的正交投影的矩阵，也就是Light projection matrix和Light view matrix。这个矩阵需要紧密贴合这段视椎体，为此我们需要得到视椎体的顶点的世界坐标，得到顶点的min、max和视椎体的中心点。</p><p>我们从相机的视椎体出发，当处于视椎体范围上的顶点的世界坐标经过projection矩阵和view矩阵转换后，xyz都会被映射到[-1,1]范围的屏幕空间坐标。矩阵转换是可逆的，也就是说取屏幕空间坐标为[-1, 1]边界的八个顶点，经过视椎体的projection矩阵和view矩阵的逆矩阵转换后，就能得到边界顶点的世界空间坐标。在代码里面的实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">std::vector&lt;glm::vec4&gt; <span class="hljs-title">CDirectionalLightComponent::GetFrustumCornersWorldSpace</span><span class="hljs-params">(<span class="hljs-type">const</span> glm::mat4&amp; proj_view)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> inv = glm::<span class="hljs-built_in">inverse</span>(proj_view);<br><br>    <span class="hljs-comment">// 顶点的世界坐标在projection和view matrix的转换下的坐标范围是[-1,1]</span><br>    <span class="hljs-comment">// 那么将在[-1,1]这个边界的八个顶点坐标乘以projection和view matrix的逆矩阵则可以得到视锥体边界的顶点的世界坐标</span><br>    vector&lt;vec4&gt; frustum_corners;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; i++)<br>    &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">2</span>; j++)<br>        &#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; <span class="hljs-number">2</span>; k++)<br>            &#123;<br>                <span class="hljs-type">const</span> vec4 pt = inv * <span class="hljs-built_in">vec4</span>(<span class="hljs-number">2.0f</span>*i<span class="hljs-number">-1.0f</span>,<span class="hljs-number">2.0f</span>*j<span class="hljs-number">-1.0f</span>,<span class="hljs-number">2.0f</span>*k<span class="hljs-number">-1.0f</span>, <span class="hljs-number">1.0f</span>);<br>                frustum_corners.<span class="hljs-built_in">push_back</span>(pt / pt.w);<br>            &#125;<br>        &#125;   <br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> frustum_corners;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们得到了视椎体角落的顶点世界坐标，我们希望阴影贴图能够如下图一般贴合每一段视椎体。那么我们需要计算视椎体的中心顶点坐标，中心顶点在计算view矩阵的时候需要用到；我们需要计算在xyz轴上顶点坐标的最大和最小值，这些数值在计算projection矩阵的时候会被用到。</p><p><img src="https://learnopengl.com/img/guest/2021/CSM/frustum_fitting.png" alt="级联阴影贴图由远及近"></p><p>计算中心点的代码十分简单，将视椎体角落的坐标相加后再除以数量即可，代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++">vec3 center = <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0.0f</span>);<br><span class="hljs-keyword">for</span>(<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; v : corners)<br>&#123;<br>    center += <span class="hljs-built_in">vec3</span>(v);<br>&#125;<br>center /= corners.<span class="hljs-built_in">size</span>();   <span class="hljs-comment">// 获取视锥体的中心点</span><br><br><span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> light_view = <span class="hljs-built_in">lookAt</span>(center-light_dir, center, <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0.0f</span>, <span class="hljs-number">1.0f</span>, <span class="hljs-number">0.0f</span>));<br></code></pre></td></tr></table></figure><p>计算贴合视椎体的范围则是比较并记录各个顶点在xyz轴的最大值和最小值，方法如下。这里提一下在z轴方向和一个参数z_mult进行了处理，其意义是阴影的投射源是有可能在视椎体范围之外的，如果不考虑这一部分的影响的话可能在阴影过度的时候会非常生硬，并且丢掉一些本来该显示的阴影导致渲染错误。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span> min_x = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">max</span>();<br><span class="hljs-type">float</span> min_y = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">max</span>();<br><span class="hljs-type">float</span> min_z = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">max</span>();<br><span class="hljs-type">float</span> max_x = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">lowest</span>();<br><span class="hljs-type">float</span> max_y = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">lowest</span>();<br><span class="hljs-type">float</span> max_z = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">lowest</span>();<br><span class="hljs-keyword">for</span> (<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; v : corners)<br>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> trf = light_view * v;<br>    min_x = std::<span class="hljs-built_in">min</span>(min_x, trf.x);<br>    max_x = std::<span class="hljs-built_in">max</span>(max_x, trf.x);<br>    min_y = std::<span class="hljs-built_in">min</span>(min_y, trf.y);<br>    max_y = std::<span class="hljs-built_in">max</span>(max_y, trf.y);<br>    min_z = std::<span class="hljs-built_in">min</span>(min_z, trf.z);<br>    max_z = std::<span class="hljs-built_in">max</span>(max_z, trf.z);<br>&#125;<br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">float</span> z_mult = <span class="hljs-number">10.0f</span>;<br><span class="hljs-keyword">if</span> (min_z &lt; <span class="hljs-number">0</span>)<br>&#123;<br>    min_z *= z_mult;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br>    min_z /= z_mult;<br>&#125;<br><span class="hljs-keyword">if</span> (max_z &lt; <span class="hljs-number">0</span>)<br>&#123;<br>    max_z /= z_mult;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br>    max_z *= z_mult;<br>&#125;<br><br><span class="hljs-type">const</span> mat4 light_projection = <span class="hljs-built_in">ortho</span>(min_x, max_x, min_y, max_y, min_z, max_z);<br></code></pre></td></tr></table></figure><h3 id="计算级联阴影贴图">计算级联阴影贴图</h3><p>一般的阴影贴图我们采用的是GL_TEXTURE_2D，而级联阴影贴图我们需要传入多张贴图，因此对应的贴图类型会变为GL_TEXTURE_2D_ARRAY。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;csm_texture);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D_ARRAY, csm_texture);<br><span class="hljs-built_in">glTexImage3D</span>(GL_TEXTURE_2D_ARRAY, <span class="hljs-number">0</span>, GL_DEPTH_COMPONENT32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, (<span class="hljs-type">int</span>)csm_distances.<span class="hljs-built_in">size</span>()<span class="hljs-number">+1</span>, <span class="hljs-number">0</span>, GL_DEPTH_COMPONENT, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER);<br><span class="hljs-built_in">glTexParameterfv</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_BORDER_COLOR, border_color);<br><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, shadowmap_fbo);<br><span class="hljs-built_in">glFramebufferTexture</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, csm_texture, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">glDrawBuffer</span>(GL_NONE);<br><span class="hljs-built_in">glReadBuffer</span>(GL_NONE);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>除此之外，我们需要一次性渲染多张贴图，我们参考点光源阴影贴图使用geometry shader的做法，将顶点映射到不同的视椎体分段的光源的投影。代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">triangles</span>, <span class="hljs-keyword">invocations</span> = <span class="hljs-number">6</span>) <span class="hljs-keyword">in</span>;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">triangle_strip</span>, <span class="hljs-keyword">max_vertices</span> = <span class="hljs-number">3</span>) <span class="hljs-keyword">out</span>;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> light_space_matrix[<span class="hljs-number">16</span>];<br><br><br><span class="hljs-type">void</span> main()<br>&#123;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">3</span>; ++i)<br>&#123;<br><span class="hljs-built_in">gl_Position</span> = light_space_matrix[<span class="hljs-built_in">gl_InvocationID</span>] * <span class="hljs-built_in">gl_in</span>[i].<span class="hljs-built_in">gl_Position</span>;<br><span class="hljs-built_in">gl_Layer</span> = <span class="hljs-built_in">gl_InvocationID</span>;<br><span class="hljs-built_in">EmitVertex</span>();<br>&#125;<br><span class="hljs-built_in">EndPrimitive</span>();<br>&#125; <br></code></pre></td></tr></table></figure><p>这里新增的<strong>invocations = 6</strong>代表了这个Shader可以被实例化，每个实例同时平行进行运算，实例的个数为6。内置的<strong>gl_InvocationID</strong>代表了当前处理的是哪一个实例，我们将其赋值到<strong>gl_Layer</strong>。其余的阴影贴图渲染步骤和普通的阴影贴图类似。</p><p>下面几张图所示展示的，就是从近到远的几个级联阴影贴图的表现：<br><img src="csm_near.png" alt=""><br><img src="csm_mid.png" alt=""><br><img src="csm_far.png" alt=""></p><h3 id="使用级联阴影贴图">使用级联阴影贴图</h3><p>级联阴影贴图的使用和阴影贴图是类似的，由于传入给光照Shader的是GL_TEXTURE_2D_ARRAY，需要使用vec3来索引贴图数据的，vec3的z值代表的是Layer索引。</p><p>Layer代表的是使用哪一个视椎体分段的阴影贴图，取决于当前像素和相机的距离。取得对应的Layer参数后带入texcoord的z值读取对应的阴影贴图的值。示例代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 计算阴影</span><br><span class="hljs-type">float</span> ShadowCalculation_DirLight(<span class="hljs-type">vec4</span> frag_world_pos, <span class="hljs-type">vec3</span> to_light_dir, <span class="hljs-type">vec3</span> in_normal)<br>&#123;<br>    <span class="hljs-comment">// 获取像素和相机的距离，也就是view转换后的z值</span><br>    <span class="hljs-type">vec4</span> frag_pos_view_space = matrix_ubo.view * frag_world_pos;<br>    <span class="hljs-type">float</span> depthValue = <span class="hljs-built_in">abs</span>(frag_pos_view_space.z);<br><br>    <span class="hljs-comment">// 根据距离和每段视椎体分段的距离区间，获取Layer值</span><br>    <span class="hljs-type">int</span> layer = <span class="hljs-number">-1</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; csm_level_count; ++i)<br>    &#123;<br>        <span class="hljs-keyword">if</span> (depthValue &lt; csm_distances[i])<br>        &#123;<br>            layer = i;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (layer == <span class="hljs-number">-1</span>)<br>    &#123;<br>        layer = csm_level_count;<br>    &#125;<br>    <span class="hljs-comment">// 下面的和应用普通阴影贴图的一致</span><br>    <span class="hljs-comment">// 转换到-1,1的范围，再转到0,1的范围</span><br>    <span class="hljs-type">vec4</span> frag_pos_light_space = light_space_matrices[layer] * frag_world_pos;<br>    <span class="hljs-comment">// perform perspective divide</span><br>    <span class="hljs-type">vec3</span> proj_coord = frag_pos_light_space.xyz / frag_pos_light_space.w;<br>    <span class="hljs-comment">// transform to [0,1] range</span><br>    proj_coord = proj_coord * <span class="hljs-number">0.5</span> + <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-comment">// get depth of current fragment from light&#x27;s perspective</span><br>    <span class="hljs-type">float</span> current_depth = proj_coord.z;<br><br>    <span class="hljs-comment">// keep the shadow at 0.0 when outside the far_plane region of the light&#x27;s frustum.</span><br>    <span class="hljs-keyword">if</span> (current_depth &gt; <span class="hljs-number">1.0</span>)<br>    &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span>;<br>    &#125;<br><br>    <span class="hljs-comment">// PCF</span><br>    <span class="hljs-type">float</span> shadow = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">vec2</span> texel_size = <span class="hljs-number">1.0</span> / <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(shadow_map, <span class="hljs-number">0</span>));<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> x = <span class="hljs-number">-1</span>; x &lt;= <span class="hljs-number">1</span>; ++x)<br>    &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> y = <span class="hljs-number">-1</span>; y &lt;= <span class="hljs-number">1</span>; ++y)<br>        &#123;<br>            <span class="hljs-type">float</span> pcf_depth = <span class="hljs-built_in">texture</span>(shadow_map, <span class="hljs-type">vec3</span>(proj_coord.xy + <span class="hljs-type">vec2</span>(x, y) * texel_size, layer)).r;<br>            shadow += current_depth &gt; pcf_depth ? <span class="hljs-number">1.0</span> : <span class="hljs-number">0.0</span>;<br>        &#125;<br>    &#125;<br>    shadow /= <span class="hljs-number">9.0</span>;<br>        <br>    <span class="hljs-keyword">return</span> shadow;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="效果对比">效果对比</h2><h3 id="原先的阴影贴图">原先的阴影贴图</h3><p>原先的阴影贴图只能覆盖有限的场景：<br><img src="sm_near.png" alt=""></p><p>提升覆盖范围后，阴影的质量则会出现下降：<br><img src="sm_far.png" alt=""></p><h3 id="级联阴影贴图">级联阴影贴图</h3><p>采用级联阴影贴图可以覆盖很大的场景，并且在可控的性能消耗下仍然有不错的显示智联。<br><img src="csm_result.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>程序化地形生成-1</title>
    <link href="/2024/10/11/ProceduralTerrainGeneration/"/>
    <url>/2024/10/11/ProceduralTerrainGeneration/</url>
    
    <content type="html"><![CDATA[<p><a href="https://www.shadertoy.com/">ShaderToy</a>是一个很有趣的网站，它上面有着非常多的渲染案例分享，最近一段时间我也是沉迷了。在看了不少大佬的作品之后，不禁手痒。前一段时间看了Inigo大佬的一个<a href="https://www.shadertoy.com/view/4ttSWf">教程案例</a>，想着把这个效果自己来实现一次，因此就有了今天的这篇文章。</p><p>我最终的成品也放到了shadertoy上面，有兴趣的同学可以一起讨论参考一下。看起来还不错对吧，虽然还有不少地方需要完善，但这个demo已经实现了我心中的大部分效果，包括无限的基于噪音的地形生成、地形阴影、雾气、云等等。</p><iframe width="640" height="360" frameborder="0" src="https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false" allowfullscreen></iframe><p>那么下面，就让我来一步步说明这个demo的实现过程吧。</p><h2 id="基础知识">基础知识</h2><h3 id="在ST上渲染地形">在ST上渲染地形</h3><p>对ShaderToy上运行的Shader代码，对应着可编程渲染管线的片段着色器(或者叫像素着色器)。片段着色器主要是是图形光栅化后的像素信息，所以渲染3D场景需要进行一些额外的步骤。</p><p>ShaderToy的程序一般是这样的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">mainImage</span><span class="hljs-params">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>...<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>fragColor</strong>是输出，代表这这个像素的最终颜色；<strong>fragCoord</strong>是输入，代表这个像素点的xy坐标。ShaderToy提供了固定变量<strong>iResolution</strong>用来表示整个屏幕的xy的分辨率。</p><p>为了渲染3D物体，我们需要采用ray cast/marching的方法，构建一个相机的位置作为光线射出的起点<strong>ro</strong>，再根据当前像素点的坐标和ro的差获得光线射出的方向<strong>rd</strong>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">mainImage</span><span class="hljs-params">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>    vec2 uv = fragCoord / iResolution.xy;<br><span class="hljs-comment">// 以屏幕中心为（0,0）</span><br>    uv = uv * <span class="hljs-number">2.0</span> - <span class="hljs-number">1.0</span>;<br><span class="hljs-comment">// 缩放x，在画面拉伸的时候保证比例正确</span><br>    uv.x *= iResolution.x/iResolution.y;<br><span class="hljs-comment">// 原点位置</span><br>    vec3 ro = vec3(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-1</span>);<br>    <span class="hljs-comment">// 射线方向</span><br>    vec3 rd = normalize(vec3(uv, <span class="hljs-number">2</span>));<br><br>fragColor = rayMarching(ro, rd);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="和地形相交">和地形相交</h3><p>在shadertoy中渲染3D物体，一般是使用raymarching方法配合SDFs来渲染3D的物体。SDF（Signed Distance Field）是一种物体的隐式表达，用于存储和计算点到图形表面的最近距离。经由一个起点和一个方向，可以用SDF来达到低消耗的射线检测效果。</p><p>这里可以参考Inigo对SDF的介绍的介绍：<a href="https://iquilezles.org/articles/distfunctions/">https://iquilezles.org/articles/distfunctions/</a></p><p>地形的渲染也是类似的，我们通过ray marching方法来找到距离地形最近的点，以此来获取地形的形状。但是和SDF不同的是，我们无法很轻易的判断射线当前距离地形的最近距离，尤其是当我们的地形完全是通过噪音来随机生成的时候，这变成了一个不可能完成的任务。所以在判断地形相交的时候，只能回归到笨办法，一步一步慢慢的往前“挪”，<em>若当前的顶点在地形之下，而之前的一个迭代在地形之上的话</em>，那我们就找到了击中地表的区间段。<br><img src="https://iquilezles.org/articles/terrainmarching/gfx02.png" alt="射线和地表相交"></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">bool</span> <span class="hljs-title function_">rayMarch</span><span class="hljs-params">(vec3 ro, vec3 rd, out <span class="hljs-type">float</span> <span class="hljs-type">hit_t</span>)</span><br>&#123;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> dt = <span class="hljs-number">0.01f</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> <span class="hljs-type">min_t</span> = <span class="hljs-number">1e-3</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> <span class="hljs-type">max_t</span> = <span class="hljs-number">1e3</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = <span class="hljs-type">min_t</span>; t &lt; <span class="hljs-type">max_t</span>; t+=dt)<br>&#123;<br><span class="hljs-type">const</span> vec3 p = ro+rd*t;<br><span class="hljs-keyword">if</span>(p.y &lt; f(p.x, p.z));<br>&#123;<br><span class="hljs-comment">// 取中间点减小误差</span><br><span class="hljs-type">hit_t</span> = t - <span class="hljs-number">0.5f</span>*dt;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>这个方法简单易懂，但显而易见在性能上并不是最优的，尤其是涉及到范围很大的地形的时候，dt的值如果取得太小，那么渲染完成一个场景的时间将会非常的长，消耗巨大；而若是dt的值取得太大，则很有可能会出现取值错误的情况。</p><p>当场景距离我们足够远的时候，由于透视的原因，近大远小，远处的场景精度对于观察者来说是越来越不重要了，因此dt的值可以随着光线步近而逐渐组建增大，动态变化。在合适的dt取值和变化曲线下，能够满足精度和性能的要求。Inigo给出的方法是类似这样的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//其他和上方代码一致</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = <span class="hljs-type">min_t</span>; t&lt;<span class="hljs-type">max_t</span>; t+=dt)<br>&#123;<br>    <span class="hljs-type">const</span> vec3 p = ro+rd*t;<br>    <span class="hljs-type">const</span> <span class="hljs-type">float</span> h = f(p.xz);<br>    <span class="hljs-keyword">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class="hljs-type">hit_t</span> = t - <span class="hljs-number">0.5f</span>*dt;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>    dt=<span class="hljs-number">0.01f</span>*t;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br></code></pre></td></tr></table></figure><p>t的起始值和dt的增长倍数可以自己尝试选择一个合适的值。</p><p>另外，如果我们能对最终渲染的效果有所了解的话，可以通过过滤掉很多不需要做射线检测的情况来极大的提升性能。如果我们最终的效果是一个在空中的相机，天空和地面占据画面各一半的话，那么上半部分的画面（通过rd.y&gt;0判断）是可以完全跳过射线检测的。或者通过增加min_t的值来减少前期昂贵且不必要的性能消耗。</p><p>在相交点的取值上，也可以进一步优化。原来仅仅是取两次光线步近的平均值，我们可以额外获取两次步近时位置的地形高度，用高度变化的连线和光线步近的线段做相交的判定取交点。这样得到的值将会更加精确。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//其他和上方代码一致</span><br><span class="hljs-type">float</span> lh = <span class="hljs-number">0.0f</span>;<br><span class="hljs-type">float</span> ly = <span class="hljs-number">0.0f</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = <span class="hljs-type">min_t</span>; t&lt;<span class="hljs-type">max_t</span>; t+=dt)<br>&#123;<br>    <span class="hljs-type">const</span> vec3 p = ro+rd*t;<br>    <span class="hljs-type">const</span> <span class="hljs-type">float</span> h = f(p.xz);<br>    <span class="hljs-keyword">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class="hljs-comment">// 计算两个线段的相交点</span><br>        <span class="hljs-type">hit_t</span> = t - dt + dt*(lh-ly)/(p.y-ly-h+lh);<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>    dt=<span class="hljs-number">0.01f</span>*t;<br>    lh = h;<br>    ly = p.y;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br></code></pre></td></tr></table></figure><p>至此，我们就可以在ShaderToy渲染出地形了。</p><h2 id="地形生成">地形生成</h2><h3 id="生成的基础：噪音">生成的基础：噪音</h3><p>当我们提到噪音，往往会很生活化的把噪音和声音连接起来，从声学的角度来说是正确的。噪音其实可以用来表示所有通过振幅（amplitude）和频率（frequency）描述的波动，它可以是声音，它可以是辐射，也可以是其他的任意一种波动。</p><p>在数学课上，我们学过正弦、余弦等三角函数，sin和cos其实就是一种噪音的表现方式。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> amplitude = <span class="hljs-number">1.0</span>;<br><span class="hljs-type">float</span> frequencey = <span class="hljs-number">1.0</span>;<br><span class="hljs-type">float</span> y = amplitude * <span class="hljs-built_in">sin</span>(frequency * x);<br></code></pre></td></tr></table></figure><p>就像上面的代码所示，通过改变amplitude和frequency，我们可以改变sin波形的状态。</p><p>噪音在很多程序化生成算法中都有着举足轻重的地位。</p><h3 id="分形布朗运动">分形布朗运动</h3><p>噪音是一种波，它是可以相互叠加的。两个相同的sin波形叠加会形成振幅更加强大的sin波形，而频率相差π/2的两个sin波形叠加后会相互抵消。</p><p>在地形随机生成中，为了最终的结果噪音有着更好的随机性和更好的细节，将会循环多次计算噪音，循环的次数为我们称之为octave。每次循环的同一个噪音以一定倍数（lacunarity）升高频率，同时以一定比例（gain）降低振幅，最终将每个噪音计算的结果叠加得到一个最终的噪音，这个噪音的生成技术叫做“分形布朗运动”（fractal brownian motion，fbm）。</p><p>下面是分形布朗运动的一个简单的代码演示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> <span class="hljs-title function_">fbm</span><span class="hljs-params">(vec2 uv, <span class="hljs-type">float</span> frequency, <span class="hljs-type">float</span> amplitude, <span class="hljs-type">int</span> octave)</span><br>&#123;<br><span class="hljs-type">float</span> lacunarity = <span class="hljs-number">2.0</span>;<br><span class="hljs-type">float</span> gain = <span class="hljs-number">0.5</span>;<br><span class="hljs-type">float</span> noise_val = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">float</span> amp = amplitude;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> index = <span class="hljs-number">0</span>; index &lt; octave; ++index)<br>&#123;<br>nose_val += noiseInterpolate(uv * frequency) * amp;<br>amp *= gain;<br>frequency *= lacunarity;<br>&#125;<br><br><span class="hljs-keyword">return</span> noise_val;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中noiseInterpolate可以是perlin noise或者是simplex noise等任意一种噪音算法。<br>demo中的地形生成和云层的生成，也使用了该技术。关于FBM除了上面简单的使用还有很多其他的变种，这里我们就不扩展了，后面有机会的话可以专门介绍一下。</p><h3 id="地形的基础表现">地形的基础表现</h3><p>这里我将地形部分拆解出来。demo的地形计算使用了perlin noise，octave数量达到了11。更多的octave数量会给地形带来更多的细节，但是一般来说后面的效果收益会越来越少。下方是octave数量分布为5和11下的地形的形状对比。<br><img src="shadertoy_oc5_noshadow.png" alt=""><br><img src="shadertoy_oc11_noshadow.png" alt=""></p><p>除了每次叠加噪音会进行频率和振幅的变化，为了获得更好的随机性，以及进一步减少噪音可能出现的重复pattern，可以将噪音进行旋转（也就是将传入的uv或者是坐标乘以一个默认的旋转矩阵）后再叠加到原来的噪音上。</p><p>我们也需要地形的法线来和光源结合，渲染出地形的明暗部分。获得法线的方法有很多种，可以采样当前计算的地形上点的x轴和z轴（这里假定y轴为up）方向不远的一两个点，和目标点相减得到切线和副切线方向，通过叉乘得到目标点的法线。亦或是采样其他点后通过中心差分法求得目标点的法线。</p><h3 id="阴影">阴影</h3><p>仅仅通过法线来渲染地形的明部和暗部是不够的，我们还需要计算地形投射在地表上的阴影。地形的阴影计算原理非常简单，就是将地形上渲染的目标点，沿着光源方向进行射线检测，如果和地形相交的话，那该点就是处于阴影之下。理想情况下，射线检测的距离当然是实际上光源和地形上的点的距离，但是往往由于性能的原因，我们需要缩短这个距离。<em>实际的检测距离可以结合当前点的高度以及地形可能的最高位置进行计算</em>。</p><p>在判断当前点处于阴影的时候，计算最终颜色的时候需要再乘以一个阴影的系数。<br><img src="shadertoy_oc11_hardshadow.png" alt="硬阴影"></p><p>为了提升效果，我们通常不希望阴影的边缘非常生硬，而是希望有一种柔软的过度，这种更加符合现实的表现。实现这种软阴影的方法可能有很多种，这里采用的是Inigo教程的一种方法。</p><p>上面提到判定阴影是通过从地形上面的点向光源方向做射线检测得到的，如果和地形相交则该点处于阴影当中，若不相交，则需要再取一个值，这值是地形向着光源方向移动距离t长度的位置，它和地形高度的差值d和距离t的比值的最小值，乘以某个常数X（10~32等等，可以自己尝试合适的范围）后经过smoothstep限制在（0,1）范围内。这个值作为阴影系数放入光照计算后就可以得到不错的软阴影效果。<br><img src="calc_soft_shadow.png" alt="软阴影"></p><p>通过下面的对比图我们可以看到，在加入了软阴影计算后，地形阴影的边缘有了一种较为平滑的过度，显得没那么生硬了。想要更改软阴影的表现的话可以通过修改常数X。<br><img src="shadertoy_terrain.png" alt=""></p><h2 id="结语">结语</h2><p>好了，我们已经得到了一个基础的程序化生成地形的效果了，但是它看起来还是有些单调。地形的深度表现、天空、云彩等等应该如何表现呢？</p><p>无需着急，我们将会在后面的文章中对它进行进一步的优化。</p><h3 id="参考资料">参考资料</h3><p><a href="https://thebookofshaders.com/13/?lan=ch">https://thebookofshaders.com/13/?lan=ch</a><br><a href="https://iquilezles.org/articles/morenoise">https://iquilezles.org/articles/morenoise</a><br><a href="https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g">https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>程序化生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>个人博客启动</title>
    <link href="/2024/10/09/StartMyBlog/"/>
    <url>/2024/10/09/StartMyBlog/</url>
    
    <content type="html"><![CDATA[<p>晚上好。</p><p>还是打算在个人的github.io继续更新自己的技术博客了。<a href="qrc-eye.com">原网站</a>本来是打算用于和朋友一起写点东西上去的，结果现在倒是变成了只有我自己的碎碎念，着实不太好。</p><p>最近一段时间会尽快的将我的部分文章搬运过来，一些琐碎的文章暂时就不管了。</p>]]></content>
    
    
    <categories>
      
      <category>生活杂谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>生活</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
