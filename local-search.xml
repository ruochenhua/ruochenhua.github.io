<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>水面效果-2</title>
    <link href="/2025/01/19/water-effect-2/"/>
    <url>/2025/01/19/water-effect-2/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在之前的文章，我们已经结合了反射纹理和折射纹理，有了一个初步的水面效果了。今天这篇文章我们会继续深入，优化水面的效果。</p><h1 id="菲涅尔现象"><a href="#菲涅尔现象" class="headerlink" title="菲涅尔现象"></a>菲涅尔现象</h1><p>如果你对基于物理的渲染管线（PBR）比较熟悉的话，那很有可能你已经知道菲涅尔现象（Fresnel Effect）是什么了。简单的来说，当光线照射到两种不同介质（例如从空气照射到玻璃或者从水照射到空气）的分界面时，一部分光会被反射，一部分光会折射进入另一种介质。菲涅尔反射描述了<strong>反射光和折射光的比例与光线入射角之间的关系</strong>。</p><p>根据菲涅尔方程（Fresnel equations），反射率会随着入射角的变化而变化。当光线垂直（入射角为 0°）入射到界面时，反射率是一个固定的值；而当入射角增大时，反射率会逐渐增大。当入射角接近 90°（掠射角）时，反射率趋近于 1，几乎所有的光都会被反射。</p><p>在渲染水面时，<strong>当视线垂直于水面，可以看到水下一定的深度，此时光大部分折射进入水中，反射的较少。但当视线与水面夹角很小时（接近平行于水面看），水面就像一面镜子，反射很强</strong>。这就是菲涅尔现象在起作用。</p><p>下面的两张截图表现了这个效果。</p><p><img src="/2025/01/19/water-effect-2/water-fresnel-parallel.png" alt="视线平行水面，水面像一面镜子反射场景"></p><p><img src="/2025/01/19/water-effect-2/water-fresnel-horizontal.png" alt="视线垂直水面，可以更多的看到水面下的场景"></p><p>那么该如何实现这种效果呢，很简单，在渲染的时候，我们可以根据视线和水面的夹角来调整反射纹理和折射纹理的混合参数。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs glsl">   <span class="hljs-comment">// ....</span><br><br>   <span class="hljs-comment">// 获取视线方向</span><br><span class="hljs-type">vec3</span> view_vector = <span class="hljs-built_in">normalize</span>(cam_pos-frag_pos); <br><br>   <span class="hljs-comment">// 利用点乘计算视线和水面的夹角，限制在0到1之间</span><br><span class="hljs-type">float</span> fresnel_blend = <span class="hljs-built_in">clamp</span>(<span class="hljs-built_in">dot</span>(water_normal, view_vector), <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>);<br>   <br>   <span class="hljs-comment">// 这里的pow操作是调整效果，可以根据需求使用</span><br>fresnel_blend = <span class="hljs-built_in">pow</span>(fresnel_blend, <span class="hljs-number">2.2</span>);<br><br>   <span class="hljs-type">vec4</span> color = <span class="hljs-built_in">mix</span>(reflection_color, refraction_color, fresnel_blend);<br><br>   <span class="hljs-comment">// ....</span><br></code></pre></td></tr></table></figure><h1 id="水面的动态"><a href="#水面的动态" class="headerlink" title="水面的动态"></a>水面的动态</h1><p>好了，我们的水面现在看起来很棒，但是太过于平静了。现在的水面就像是一面镜子，一块玻璃，现实中的水面会因为风或者其他接触物的影响有波纹或者扰动产生，我们需要想办法增加这种效果。</p><p>水的动态效果模拟其实是一个很深的研究课题，像虚幻引擎的water插件的水面模拟采用了<strong>gerstner wave</strong>，通过不同频率、波长的波的叠加来实现复杂的水面效果（其实这就和地形生成的FBM类似，详情可以参考<a href="https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/">这篇文章</a>）。如果想要做的更加真实一点，可以采用Navior-Stroker方程来模拟，这是一个经典的用于模拟水体的方法，可以带来更加真实的效果，当然消耗也更大。</p><p>我们今天就来介绍一种最为简单的方法，利用贴图来实现这个效果。</p><h2 id="dudv-map"><a href="#dudv-map" class="headerlink" title="dudv map"></a>dudv map</h2><p>我们在这里需要使用一种叫做dudv map的资源，常见的dudv map如下：</p><p><img src="/2025/01/19/water-effect-2/waterDUDV.png" alt="dudv map"></p><p>dudv map是用来辅助表现水面的扰动程度的，如果你有基础的渲染知识的话应该知道法线贴图（normal map），其实dudv map和法线贴图的思路是类似的。</p><p>我们可以看到dudv map整体是呈黄色，因为dudv map主要是包含了X轴（红色）和Y轴（绿色）的数据，黄色是由这两种颜色组合而来。使用dudv map的方法可以参考下面的代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><br><span class="hljs-meta">#version 450 compatibility</span><br><span class="hljs-meta">#extension GL_ARB_shading_language_include : require</span><br><span class="hljs-meta">#include &quot;/common/common.glsl&quot;</span><br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> out_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> out_normal;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> out_texcoord;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> clip_space;<br><br><span class="hljs-keyword">layout</span> (<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> reflection_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> refraction_texture;<br><span class="hljs-comment">// 输入dudv map</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> dudv_map;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br><span class="hljs-type">vec2</span> ndc = clip_space.xy / clip_space.w;<br>ndc = ndc / <span class="hljs-number">2.0</span> + <span class="hljs-type">vec2</span>(<span class="hljs-number">0.5</span>);<br><span class="hljs-type">vec2</span> reflection_coord = <span class="hljs-type">vec2</span>(ndc.x, -ndc.y);<br><span class="hljs-type">vec2</span> refraction_coord = ndc;<br><br>    <span class="hljs-comment">// 利用dudv map来制造水面扰动</span><br><span class="hljs-type">vec2</span> distorted_texcoords = <span class="hljs-built_in">texture</span>(dudv_map, <span class="hljs-type">vec2</span>(out_texcoord.x, out_texcoord.y)).rg * <span class="hljs-number">0.1</span>;<br>distorted_texcoords = out_texcoord + <span class="hljs-type">vec2</span>(distorted_texcoords.x, distorted_texcoords.y + move_factor);<br><span class="hljs-type">vec2</span> total_distort = (<span class="hljs-built_in">texture</span>(dudv_map, distorted_texcoords).rg * <span class="hljs-number">2.0</span> - <span class="hljs-number">1.0</span>) * wave_strength;<br><br>reflection_coord += total_distort;<br>reflection_coord.x = <span class="hljs-built_in">clamp</span>(reflection_coord.x, <span class="hljs-number">0.001</span>, <span class="hljs-number">0.999</span>);<br>reflection_coord.y = <span class="hljs-built_in">clamp</span>(reflection_coord.y, <span class="hljs-number">-0.999</span>, <span class="hljs-number">-0.001</span>);<br><br>refraction_coord += total_distort;<br>refraction_coord = <span class="hljs-built_in">clamp</span>(refraction_coord, <span class="hljs-number">0.001</span>, <span class="hljs-number">0.999</span>);<br><br><span class="hljs-type">vec4</span> reflection_color = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">texture</span>(reflection_texture, reflection_coord).xyz, <span class="hljs-number">1.0</span>);<br><span class="hljs-type">vec4</span> refraction_color = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">texture</span>(refraction_texture, refraction_coord).xyz, <span class="hljs-number">1.0</span>);<br><br><span class="hljs-type">vec3</span> view_vector = <span class="hljs-built_in">normalize</span>(matrix_ubo.cam_pos.xyz-out_pos);<br><span class="hljs-type">float</span> fresnel_blend = <span class="hljs-built_in">clamp</span>(<span class="hljs-built_in">dot</span>(out_normal, view_vector), <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>);<br>fresnel_blend = <span class="hljs-built_in">pow</span>(fresnel_blend, <span class="hljs-number">2.2</span>);<br><br><span class="hljs-type">vec4</span> color = <br><span class="hljs-built_in">mix</span>(reflection_color, refraction_color, fresnel_blend);<br><br>FragColor = color;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>dudv map主要用于制造水面的扰动效果，实现的效果如下：<br><img src="/2025/01/19/water-effect-2/water-with-dudv.png" alt="dudv map的效果"></p><p>哇，已经很有感觉了。当然最好在计算distorted_texcoords的时候增加一个随着时间变化的变量，加上动态效果的话会更有真实感。</p><h2 id="法线贴图"><a href="#法线贴图" class="headerlink" title="法线贴图"></a>法线贴图</h2><p>在上面我们已经提到了法线贴图，在渲染水面的时候其实也可以使用法线贴图来增加实感效果。</p><p><img src="/2025/01/19/water-effect-2/waterNormal.png" alt="法线贴图"></p><p>一个比较好的法线贴图使用的地方是在水面高光的渲染上，现在的水面有了扰动，但是和光源的交互还是相对较弱的。增加了高光后可以进一步加强水面的实感表现。</p><p><img src="/2025/01/19/water-effect-2/water-no-specular.png" alt="没有水面高光"></p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><br>....<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> normal_map;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br><br>    ......<br><br><span class="hljs-type">vec3</span> specular_highlights = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);<br>    <span class="hljs-comment">// 检查光源</span><br><span class="hljs-keyword">if</span>(light_info_ubo.has_dir_light.r != <span class="hljs-number">0</span>)<br>&#123;<br><span class="hljs-type">vec4</span> normal_map_color = <span class="hljs-built_in">texture</span>(normal_map, distorted_texcoords);<br><span class="hljs-type">vec3</span> normal = <span class="hljs-built_in">normalize</span>(<span class="hljs-type">vec3</span>(normal_map_color.r * <span class="hljs-number">2.0</span> - <span class="hljs-number">1.0</span>, normal_map_color.b, normal_map_color.g * <span class="hljs-number">2.0</span> - <span class="hljs-number">1.0</span>));<br><br><span class="hljs-comment">//fresnel_blend = clamp(dot(normal, view_vector), 0.0, 1.0);</span><br><br><span class="hljs-type">vec3</span> light_dir = light_info_ubo.directional_light.light_dir.xyz;<br><span class="hljs-type">vec3</span> light_color = light_info_ubo.directional_light.light_color.xyz;<br><br>        <span class="hljs-comment">// 高光的简单计算</span><br><span class="hljs-type">vec3</span> reflected_light = <span class="hljs-built_in">reflect</span>(light_dir, normal);<br><span class="hljs-type">float</span> specular = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">dot</span>(reflected_light, view_vector), <span class="hljs-number">0.0</span>);<br><span class="hljs-type">float</span> shine_damper = <span class="hljs-number">100.0</span>;<br>specular = <span class="hljs-built_in">pow</span>(specular, shine_damper);<br><br><span class="hljs-type">float</span> reflectivity = <span class="hljs-number">1.5</span>;<br>specular_highlights = light_color * specular * reflectivity;<br>&#125;<br><br>    .....<br><br>    <span class="hljs-type">vec4</span> blue_color = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">1.0</span>); <span class="hljs-comment">// add some blue color</span><br><span class="hljs-type">vec4</span> color = <span class="hljs-built_in">mix</span>(<br><span class="hljs-built_in">mix</span>(reflection_color, refraction_color, fresnel_blend)<br>, blue_color<br>, <span class="hljs-number">0.1</span>) + <span class="hljs-type">vec4</span>(specular_highlights, <span class="hljs-number">0.0</span>);        <span class="hljs-comment">// 将高光加到场景中</span><br><br>FragColor = color;<br>&#125;<br><br></code></pre></td></tr></table></figure><p><img src="/2025/01/19/water-effect-2/water-with-specular.png" alt="增加水面高光"></p><p>水面终于有了波光粼粼的效果了。</p><p>在上面的代码中，我在最后增加了一点点蓝色的tint，增加表现效果。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>好了，这就是一个简单的水面效果渲染的流程了。这个流程很简单易懂，但是有这不错的效果，希望能够对大家有所帮助。</p><h1 id="what’s-more？"><a href="#what’s-more？" class="headerlink" title="what’s more？"></a>what’s more？</h1><p>当然水的渲染，或者说模拟是个很深入的话题，除了我前面提到的gerstner wave和navior-stroke方法，还有很多其他的内容，比如说可以根据水的深度来让深水区的颜色有更深的蓝色晕染，浅水区的颜色更加透明。后续有时间可能会找其中的一两种优化方法再来讨论一下。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.youtube.com/watch?v=HusvGeEDU_U&list=PLRIWtICgwaX23jiqVByUs0bqhnalNTNZh&ab_channel=ThinMatrix">ThinMatrix’s OpenGL water guide</a></p><p><a href="https://medium.com/@vincehnguyen/simplest-way-to-render-pretty-water-in-opengl-7bce40cbefbe">Simplest way to render pretty water in OpenGL</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>水</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>水面效果-1</title>
    <link href="/2025/01/12/water-effect-1/"/>
    <url>/2025/01/12/water-effect-1/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在经过了逐步的迭代，KongEngine中已经接入了不错的地形和体积云效果（体积云的相关文章我还在整理计划当中，打算后续和IBL连着一起写），所谓好山好水好风光，有了山和云，接下来我的计划便是将水的渲染纳入KongEngine的能力中。</p><p><img src="/2025/01/12/water-effect-1/kong_terrain_cloud.png" alt="KongEngine的地形效果"></p><h1 id="水面的渲染"><a href="#水面的渲染" class="headerlink" title="水面的渲染"></a>水面的渲染</h1><p>下面我们来介绍如何实现一个简单的水面渲染效果。</p><h2 id="水面渲染的构成"><a href="#水面渲染的构成" class="headerlink" title="水面渲染的构成"></a>水面渲染的构成</h2><p>水面的渲染主要由两部分构成：<strong>反射和折射</strong>，分别对应着水面之上和之下的内容。我在之前已经有文章分享过屏幕空间反射（SSR）的实现细节，但是对于水面来说，反射的范围一般来说是会更大的，包含的内容也会更多。如果仅仅是只能反射屏幕空间的内容的话渲染效果其实并不理想，因此对于水面我们这里使用另外一种方式来实现反射效果。</p><h2 id="基础能力"><a href="#基础能力" class="headerlink" title="基础能力"></a>基础能力</h2><p>为了实现水面的渲染，需要下面几个基础能力的帮助。</p><h3 id="帧缓冲对象（Framebuffer-Objects）"><a href="#帧缓冲对象（Framebuffer-Objects）" class="headerlink" title="帧缓冲对象（Framebuffer Objects）"></a>帧缓冲对象（Framebuffer Objects）</h3><p>在实现前面的很多渲染效果的过程中，我们多次使用了帧缓冲对象，应该对这个很了解了。我们使用的延迟渲染技术就和帧缓冲对象是分不开的。</p><p>如果不熟悉这个的同学可以去翻看一下前面的文章，简单的来说帧缓冲对象能让我们将场景内容渲染到它上面，经过处理后再输出到屏幕。</p><p>为了实现水面的反射和折射，我们需要两个FBO来分别存储反射和折射的纹理。由于KongEngine使用了延迟渲染的架构（包括地形我已经将它的渲染改为支持延迟渲染了），因此目前<strong>折射</strong>的纹理我直接使用的是延迟渲染的FBO，当然其实这并不是最准确的，至于为什么我将会在下面的部分解释。</p><p>为了表现反射，我们假定原来的场景如下图所示。<br><img src="/2025/01/12/water-effect-1/water-scene.png" alt="一个包含水面的场景"></p><p>右侧的相机向左边看去，它的视线和水面相交的时地方，反射的内容会需要呈现岸上的场景。那么我们应该如何获取到岸上的景色呢，很简单，根据视线的方向和水面的法线，我们可以计算出反射向量，而这个向量相当于将相机按照水平面镜像的结果，如下图所示。</p><p><img src="/2025/01/12/water-effect-1/water-scene-mirror-camera.png" alt="镜像相机"></p><p>用镜像相机得到的渲染得出的纹理作为水面反射的内容表现。</p><h3 id="裁切平面"><a href="#裁切平面" class="headerlink" title="裁切平面"></a>裁切平面</h3><p><em>水面的反射用来表现水面之上的场景，水面的折射用于表现水面只下的场景</em>。那么理论上来说我按照上面所述的方法渲染反射，很有可能会包含到水下的内容，这样反射的纹理就不对了。</p><p>因此在渲染反射和折射的内容时需要利用裁切平面，分别将水面之下和水面之上的内容裁切掉。</p><p>在OpenGL中，可以使用Clip Distance来实现这个功能，首先需要在C++中启用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glEnable</span>(GL_CLIP_DISTANCE0)<br></code></pre></td></tr></table></figure><p>在vertex shader中里面，通过改变*gl_ClipDistance[0]*的值来告诉opengl哪些顶点是要被裁切掉的。当gl_ClipDistance[0]的值小于0，表明这个顶点需要被裁切掉；相反，大于0则代表该顶点需要保留。</p><p><em>在KongEngine的实现中，由于直接使用了延迟渲染的帧缓冲内容，所以这里并没有做平面裁切，因此折射和反射的表现其实会有一些问题。</em></p><h3 id="投影纹理映射"><a href="#投影纹理映射" class="headerlink" title="投影纹理映射"></a>投影纹理映射</h3><p>当我们有了水面的反射和折射的纹理后，我们接下来将这两张纹理应用于水面上就可以了。。。吗？</p><p><img src="/2025/01/12/water-effect-1/water-normal-texcoord.png" alt="直接使用纹理"></p><p>上面这张图，nanosuit的脚底下本来是水面的，现在这个表现是因为直接将纹理按照水平面四边形（Quad）的纹理坐标贴了上去。为了得到正确的结果，我们需要用<strong>投影纹理映射将水面模型的3D的坐标映射到屏幕的2D坐标上</strong>。</p><p><img src="/2025/01/12/water-effect-1/coord-trans.png" alt="坐标转换"></p><p>上面是一张来自<a href="https://antongerdelan.net/opengl/raycasting.html#:~:text=Overview,is%20usually%20called%20ray%20casting.">Anton Gerdelan的关于坐标系转换的图示</a>。我们需要以水面模型的屏幕空间的坐标来采样纹理，在vertex shader里面，水面的模型顶点已经经过了转换到达了<strong>齐次裁切空间（Homogeneous Clip Space）</strong>。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><br><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_pos;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_normal;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">2</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> in_texcoord;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> model;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> view;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> projection;<br><br><br><span class="hljs-comment">// out vec3 normal_world;</span><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec3</span> out_pos;<br><span class="hljs-keyword">out</span> <span class="hljs-type">vec3</span> out_normal;<br><span class="hljs-keyword">out</span> <span class="hljs-type">vec2</span> out_texcoord;<br><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> clip_space;<br><br><span class="hljs-keyword">const</span> <span class="hljs-type">float</span> tiling = <span class="hljs-number">6.0</span>;<br><br><span class="hljs-type">void</span> main()&#123;<br><span class="hljs-built_in">gl_Position</span> = projection * view * model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1.0</span>);<br>    clip_space = <span class="hljs-built_in">gl_Position</span>;<br>    out_pos = (model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1.0</span>)).xyz;<br><span class="hljs-comment">//</span><br>    out_normal = <span class="hljs-built_in">normalize</span>(<span class="hljs-type">mat3</span>(<span class="hljs-built_in">transpose</span>(<span class="hljs-built_in">inverse</span>(model))) * in_normal);<br>out_texcoord = in_texcoord * tiling;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>其中clip_space是水面顶点的eye space坐标，将会输入到fragment shader中。<br>我们需要通过以下步骤获得屏幕空间的采样坐标：</p><ol><li><p>将坐标从<em>齐次裁切空间</em>转换到<em>标准设备空间（Normalized Device Space）</em></p><ul><li>转换的方法是将x、y的坐标除以w。</li></ul></li><li><p>将坐标从<em>标准设备空间</em>转换到<em>采样空间</em>，也就是屏幕空间</p><ul><li>需要将坐标的范围从[-1,1]映射到[0,1]，方法就是对坐标乘以0.5后再加0.5。</li></ul></li></ol><p>下面是fragment shader的示例代码。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> out_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> out_normal;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> out_texcoord;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> clip_space;<br><br><span class="hljs-keyword">layout</span> (<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> reflection_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> refraction_texture;<br><br><br><span class="hljs-type">void</span> main()<br>&#123;<br><span class="hljs-type">vec2</span> ndc = clip_space.xy / clip_space.w;<br>ndc = ndc / <span class="hljs-number">2.0</span> + <span class="hljs-type">vec2</span>(<span class="hljs-number">0.5</span>);<br><br><span class="hljs-type">vec2</span> reflection_coord = <span class="hljs-type">vec2</span>(ndc.x, -ndc.y);    <span class="hljs-comment">// 反射的垂直方向坐标是反的，所以y是负的。</span><br><span class="hljs-type">vec2</span> refraction_coord = ndc;<br><br><span class="hljs-type">vec4</span> rfr = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">texture</span>(refraction_texture, refraction_coord).xyz, <span class="hljs-number">1.0</span>);<br><span class="hljs-type">vec4</span> rfl = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">texture</span>(reflection_texture, reflection_coord).xyz, <span class="hljs-number">1.0</span>);<br><br>FragColor = <span class="hljs-built_in">mix</span>(rfr, rfl , <span class="hljs-number">0.785</span>);<br><span class="hljs-keyword">return</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>得到的结果如下图所示。</p><p><img src="/2025/01/12/water-effect-1/water-effect-correct.png" alt="正确的水面纹理效果"></p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>至此，其实我们已经初步实现了水面的效果了。从上面的效果图来看其实也颇有模有样，但是距离真正的结束还差的远呢。在后面的文章我会继续补充水面渲染的内容，最终我们的效果会如下图一般。</p><p><img src="/2025/01/12/water-effect-1/kong_water.png" alt="最终的水面效果"></p><p>如何实现这个效果就敬请期待后续的内容了。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.youtube.com/watch?v=HusvGeEDU_U&list=PLRIWtICgwaX23jiqVByUs0bqhnalNTNZh&ab_channel=ThinMatrix">ThinMatrix’s OpenGL water guide</a></p><p><a href="https://medium.com/@vincehnguyen/simplest-way-to-render-pretty-water-in-opengl-7bce40cbefbe">Simplest way to render pretty water in OpenGL</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>水</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数字人仿真的渲染技术（四）</title>
    <link href="/2025/01/09/digital-human-render-4/"/>
    <url>/2025/01/09/digital-human-render-4/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这篇文章是我在OGEEK上做过的《浅谈数字人仿真的渲染技术》分享的最后一部分，这一部分的内容主要包含的内容是<strong>非真实感渲染（Non-photorealistic Rendering, NPR）</strong>技术，通常这项技术会被用在渲染卡通风格的内容。</p><h1 id="非真实感渲染"><a href="#非真实感渲染" class="headerlink" title="非真实感渲染"></a>非真实感渲染</h1><p>前面的渲染技术一般都是用于高真实度数字人的渲染，接下来我们来介绍一下NPR。</p><h2 id="什么是NPR"><a href="#什么是NPR" class="headerlink" title="什么是NPR"></a>什么是NPR</h2><p><strong>NPR</strong>，我们一般指的是<strong>非真实感渲染（Non-photorealistic Rendering）</strong>，它是相对于<strong>真实渲染（Photorealistic Rendering）</strong>的。</p><p>真实感渲染的目的在于渲染出照片级别的高真实度画面；而非真实感渲染，他的目的多种多样，它可以模拟艺术化的绘制风格，呈现出手绘的效果。</p><p>这是游戏”犬神“的画面，它的渲染模拟出一种独特的水墨风格。<br><img src="/2025/01/09/digital-human-render-4/okami.png" alt="犬神"></p><p>这是游戏”荒野之息“的画面，它就有点类似于日本动画的风格。<br><img src="/2025/01/09/digital-human-render-4/zelda.png" alt="塞尔达传说-荒野之息"></p><p>他们显然不是想游戏画面看起来和显示世界一模一样的，所以利用NPR来突出自己独特的美术基调，展现不同的美术风格，从而吸引玩家。</p><h2 id="NPR在数字人的体现"><a href="#NPR在数字人的体现" class="headerlink" title="NPR在数字人的体现"></a>NPR在数字人的体现</h2><p>在数字人的概念在互联网中异常火热的时候，业界也出现了很多热门虚拟数字人或虚拟偶像，如下面这张图里面列举的一些例子。</p><p><img src="/2025/01/09/digital-human-render-4/npr-digi-human.png" alt="NPR与数字人"></p><p>最左边的的Miquela（美国），以及最右边的AYAYI（燃麦科技）是主打写实，超写实风格的数字人。<br>中间的四个，分别是洛天依，初音，鹿鸣和暖暖，她们的美术风格其实都多多少少有带点二次元风格，如果大家有关注虚拟主播这个行业的话，其实很多虚拟主播都是带着二次元风格的化身（皮套）。</p><p>二次元风格，或者卡通风格的渲染，都属于NPR的渲染风格。NPR在数字人的应用上也是很广泛的。</p><p>当然，非真实感是一个非常宽泛的定义，我们这里不会去展开太多，今天我们只关注于其中的卡通渲染，针对这个领域来介绍一些相关的渲染技术。</p><h1 id="卡通渲染"><a href="#卡通渲染" class="headerlink" title="卡通渲染"></a>卡通渲染</h1><p><strong>卡通渲染</strong>是NPR领域应用最广的渲染技术之一，那么他和真实感渲染有很多地方是不一样的，其中最主要的两点，就是<strong>描边处理</strong>，和<strong>艺术化着色</strong>。</p><p>接下来我们就来重点聊一聊这两个方面。</p><h2 id="描边"><a href="#描边" class="headerlink" title="描边"></a>描边</h2><p>首先来介绍一下描边处理。</p><p>描边几乎是所有非真实渲染都要实现的效果，它比较容易呈现出一种手绘的视觉风格。目前主流使用的描边技术包括几类，分别是<strong>基于几何的生成方法</strong>，<strong>基于视角的勾边</strong>，<strong>基于图像处理的勾边</strong>。这三种方法之间也可以混合使用。我们今天也会主要介绍这三种描边。</p><h3 id="基于几何的生成方法"><a href="#基于几何的生成方法" class="headerlink" title="基于几何的生成方法"></a>基于几何的生成方法</h3><p>首先我们来介绍一些基于几何生成的描边方法。</p><p>这个方法的特点是，描边本身是一个单独的几何体，这个几何体通过特殊的方式渲染出来，结合原本渲染的模型，可以达到描边的效果。</p><p>基于几何的描边需要有两个渲染pass。</p><ol><li><p>在第一个Pass中只渲染背面的面片。在第一个Pass进行描边处理时，我们可以利用顶点着色器将物体本身沿法线方向进行一定的扩展，得到一个<em>比原来模型略大一些的模型</em>来实现物体的轮廓可见的效果，这种方法一般被称为<strong>Shell method</strong>或者<strong>Halo method</strong>；用这个扩大的模型来实现描边的效果。<br>也可以使用另外一种叫做<strong>z-bias</strong>的方法，也是绘制模型背面，但不膨胀模型，而是把背面顶点的Z值稍微向前偏移一点点，使得背面的些许部分显示出来形成描边效果。但是这种方法比较不可控，实现的效果较Shell method差很多。</p></li><li><p>然后第二个Pass中对模型进行正常的渲染。</p></li></ol><p>下面的这张图是一个大致的原理介绍。</p><p><img src="/2025/01/09/digital-human-render-4/outline-geo-based.png" alt="基于几何的描边方法"></p><p>几何生成方法描边的优点是实现简单，可以得到轮廓均匀的描边效果，对大部分模型都有效。<br>同样该方法也有很多的缺点：无法用来描边棱角分明的模型，比如立方体；一般只能用来勾勒物体的外部轮廓(Silhouette)而无法绘制物体内部的轮廓(Contour)；需要处理双倍的Mesh数量，性能不友好。</p><h3 id="基于视角的勾边"><a href="#基于视角的勾边" class="headerlink" title="基于视角的勾边"></a>基于视角的勾边</h3><p>接下来介绍基于视角的勾边，这部分的计算依赖于我们的一个直觉观察：当我们的视线和某个表面相切时，这个表面上的像素点往往就是模型的边缘，基于这个观察，我们可以用视线的向量和模型法线向量的点乘来估计一个像素的“边缘程度”，当边缘程度超过一定阈值的时候，就判定其为描边区域。</p><p>当然，这个值也可以用来作为纹理坐标去采样一张预定义的“轮廓纹理”。</p><p>基于视角的描边，处理起来相对比较简单，但是最大的缺点是线宽粗细差别较大，不易控制。</p><p><img src="/2025/01/09/digital-human-render-4/outline-view-based.png" alt="基于视角的描边"></p><h3 id="基于图像处理的勾边"><a href="#基于图像处理的勾边" class="headerlink" title="基于图像处理的勾边"></a>基于图像处理的勾边</h3><p>最后是基于图像处理的描边，这类方法的实现可以说更接近于“边缘”这一概念的本质定义。</p><p>什么是“边缘”呢？边缘就是在深度或者法线上不连续的位置。为了获取边缘，我们只需要在图片上找到不连续的位置即可，因此，我们一般将深度信息和法线信息的形式传入，运用边缘检测算法去寻找这些像素。</p><p>这类方法的优点是描边的线宽一致，适应性广，大部分的边缘检测都可以利用该方法，缺点是需要额外的法线和深度信息。</p><p>由于近年来流行的<strong>延迟渲染框架</strong>，法线和深度本来就是G-Buffer的一部分，因此往往不需要额外绘制法线和深度的信息。</p><p>如果没有G-Buffer，需要单独获取深度图和法线图，会有额外的性能消耗。而且对于深度和法线变化很小的地方，可能无法检测出来，比如桌上的纸张。</p><p>其实除了边缘，基于图像处理还可以根据<strong>漫反射颜色的变化</strong>，<strong>光照区域的变化</strong>，甚至<strong>自定义模板</strong>等等来自定义想要处理的勾边。</p><p><img src="/2025/01/09/digital-human-render-4/outline-image-process.png" alt="基于图像处理的描边"></p><p>边缘检测的算法这里不深入去拓展了，提一下比较主流的有sobel算子，robert算子，prewitt算子等等。可以去参考图像识别、处理相关的知识。</p><h2 id="艺术化着色"><a href="#艺术化着色" class="headerlink" title="艺术化着色"></a>艺术化着色</h2><p>然后我们再来聊一聊另外一个重点部分，就是艺术化着色。</p><p>艺术化着色很考验美术的能力，好的着色效果需要有好的美术风格和造型，当然这里我们就不深入讨论这块了（程序员审美），我们还是简单介绍一下比较常用来实现艺术化着色的技术。</p><p>这里主要介绍两个方式，即卡通着色和基于色调的着色。</p><h3 id="卡通着色"><a href="#卡通着色" class="headerlink" title="卡通着色"></a>卡通着色</h3><p>卡通渲染的着色方式是<strong>Cel Shading或者Toon Shading</strong>，Cel来自于Celluloid，是传统卡通的制作材料，Toon来自于卡通Cartoon。</p><p>他们的基本思想就是降低色阶，与现实环境丰富的色阶相比，卡通渲染尽量减少使用的色阶，从而实现手工着色的效果。</p><p>下面这张图的场景是采用了PBR，可以看到他的色阶是非常多的，阴影，高光过度很平滑。</p><p><img src="/2025/01/09/digital-human-render-4/cartoon-pbr.png" alt="PBR场景"></p><p>这张图的场景我们降低了色阶，体现比较明显的是橙色的球的阴影部分，稍微有点卡通的风格了。</p><p><img src="/2025/01/09/digital-human-render-4/cartoon-lower.png" alt="降低色阶"></p><p>这张图片则是进一步降低了色阶，可以看到有一种很强烈的手工着色的感觉，有种古早卡通的风格。</p><p><img src="/2025/01/09/digital-human-render-4/cartoon-lowest.png" alt="进一步降低色阶"></p><p>实现这种效果的方法很多，一般计算光照的时候，有一个步骤会根据模型法线和光线法线的点乘，得到一个数值，这个数值会影响最终光照的效果。在PBR中这个数值的影响是连续的，但是在NPR中，我们可以提前定义一个分段函数，这个分段函数定义一个数字区间的颜色值。</p><p>打个比方这个球，可以点乘结果大于0.85用亮橘色，小于0.5用黑色，中间可以继续分段。如果想要平滑过渡的效果，也可以在函数的分段中用平滑计算的方式获取一个插值。</p><p><img src="/2025/01/09/digital-human-render-4/npr-coloring.png" alt="NPR着色分段"></p><p>目前来说大部分的卡通渲染，会将N和L的点乘结果对应到一张<strong>Ramp Texture</strong>上， 如下图所示，根据ramp texture上的颜色数据上颜色。这样美术就可以比较方便的控制想要的颜色效果。</p><p><img src="/2025/01/09/digital-human-render-4/ramp-texture.png" alt="ramp texture"></p><p>下面这张图是对应ramp texture对应的效果。</p><p><img src="/2025/01/09/digital-human-render-4/ramp-texture-effect.png" alt="ramp texture对应的效果"></p><p>另外为了模拟PBR中光线和视角相关的效果(菲涅尔项)，还需要视角相关的信息。通过法线和视线方向的点乘得到另一个纹理坐标在ramp texture上取值，ramp texture的制作也需要考虑相关的因素。</p><p><img src="/2025/01/09/digital-human-render-4/ramp-texture-fresnel.png" alt="ramp texture菲涅尔项"></p><h3 id="基于色调的着色"><a href="#基于色调的着色" class="headerlink" title="基于色调的着色"></a>基于色调的着色</h3><p>最后我们简单介绍一下tone based shading，他的主要思想是首先由美术指定冷色调和暖色调，比如说冷色调设定为蓝色，暖色调设定为橙色。而最终模型着色将根据法线和光线的夹角，在这两个色调的基础上进行插值。</p><p>下面是基于色调着色的公式。<br><img src="/2025/01/09/digital-human-render-4/tone-base-shading.png" alt="基于色调的着色公式"></p><p>这里公式里面的l是光线照射方向，和我们前面BRDF等公式里面的光线方向相反。这里可以看到，公式计算中法线和光线向量的点乘越低，暖色调的比例就越高，冷色调的比例就越低，反之亦然。</p><h2 id="what’s-more"><a href="#what’s-more" class="headerlink" title="what’s more"></a>what’s more</h2><p>当然，目前我们说介绍的这些，也只是对NPR的一个最基础的介绍了，为了更好的效果，很多细节需要优化。<br>比如说可能会有更加风格化的高光和阴影，如下图所示。</p><p><img src="/2025/01/09/digital-human-render-4/highlight-shadow.png" alt="风格化的高光和阴影"></p><p>以及还需要将环境光照的影响考虑进来。</p><p>还有就是现在很多产品选择的在NPR中使用PBR，就比如说我们前面在PBR里面介绍的kajiya-kay的头发高光计算方法，比如说很多二次元风格的模型会在皮肤眼睛等部位同样使用次表面散射的模型。</p><p><img src="/2025/01/09/digital-human-render-4/NPR-kajiya-kay.png" alt="在NPR中结合Kajiya-Kay"></p><h1 id="未来数字人技术的展望"><a href="#未来数字人技术的展望" class="headerlink" title="未来数字人技术的展望"></a>未来数字人技术的展望</h1><p>最后稍微讲一下我们对未来数字人技术的展望吧。</p><p>首先由于其渲染的复杂度和性能消耗，高保真类型的数字人可能会更趋近于在云端渲染，包括我们的端云渲染平台andeverse，大家可以关注一下。云渲染可以利用云端的强大的分布式硬件，以及高速网络， 实现在一般设备上的真实人物表现。</p><p>同时今年大热的AI技术成果爆发，也让我们不禁想去探索AI辅助的数字人生产制作流程。它能对整个生产管线的效率和效果有多大的提升。</p><p>另外其实皮肤的效果是否还有更进一步的解决办法，因为目前实时渲染还是采用一种近似方法。皮肤下面其实离毛细血管是比较近的，在人类在表现激动情绪的时候会有脸红等肤色的变化的细节。这些细节的完善，可以帮助我们进一步提升写实类人物的渲染，从而走出恐怖谷。</p><p><img src="/2025/01/09/digital-human-render-4/metahuman.png" alt="metahuman"></p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>《浅谈数字人渲染技术》的内容终于总结完了，这个分享我准备了很久，ppt在交付前一再精简，最后还是有55页，也是整整拆分成四篇文章才勉强将里面的内容将完。</p><p>这次分享也给了我很多的启发，让我熟悉了数字人渲染的相关技术，以及整个产业的发展。里面的内容广泛而深入，这几篇浅显的文章既希望能够帮助到有需要的人，也是我对自己的一次小小的总结。</p><p>希望后面有机会能够进一步深入这个领域。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>数字孪生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数字人仿真的渲染技术（三）</title>
    <link href="/2025/01/06/digital-human-render-3/"/>
    <url>/2025/01/06/digital-human-render-3/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这篇文章是我在OGEEK上做过的《浅谈数字人仿真的渲染技术》分享的第三部分，在这一部分我会着重介绍数字人的毛发渲染的技术。</p><h1 id="毛发"><a href="#毛发" class="headerlink" title="毛发"></a>毛发</h1><p>在前面的内容，我们大致了解了一些皮肤相关的技术，接下来我们再简单了解一些毛发的渲染算法。</p><p>和皮肤一样，其实毛发的构造比我们预想的也要复杂许多，它包括表皮的<em>角质层</em>，角质层里面的<em>皮质</em>，以及<em>发髓</em>。</p><p><img src="/2025/01/06/digital-human-render-3/hair-structure.png" alt="头发的结构"></p><p>角质层有坑坑洼洼的表面，而且头发的坑坑洼洼具有较为统一的指向性，从发根指向发尾，简化后的头发模型如下图所示。</p><p><img src="/2025/01/06/digital-human-render-3/simple-hair-structure.png" alt="头发的简化结构"></p><h2 id="Kajiya-Kay模型"><a href="#Kajiya-Kay模型" class="headerlink" title="Kajiya-Kay模型"></a>Kajiya-Kay模型</h2><p>下面我们来了解一下可能是游戏中毛发渲染最常用的毛发渲染模型，<strong>Kajiya-kay模型</strong>。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>首先需要说明的是，Kajiya-Kay模型是一个<strong>基于经验</strong>的模型，也就是说这个模型并不是根据头发的物理结构得出的，所以会有一些并不真实的地方。</p><p>作为一个1989年的shading model，它具有算法简单，便于理解，计算量小。且头发的主高光的性价比高，效果明显。</p><p>那么kajiya-kay模型的一个核心就是各向异性高光，不知道有没有对各向异性不熟悉的朋友，这里简单说明一下，各向异性就是物体的某些特征根据方向的不同而有所变化。</p><p>如下图所示，头发在微观层面的一小段我们把它简化为一个圆柱体，圆柱体的一个截面的normal均匀分布。但是这个normal都是从横截面的中心向外扩散的，不会出现沿着这个圆柱体的法线，其实这就是一种各向异性的体现。</p><p><img src="/2025/01/06/digital-human-render-3/normal-to-fiber.png" alt="头发的法线"></p><p>我们渲染头发的时候，单个像素里面是一根或者多根极其短且细的头发，按照普通的模型一般是获取单个像素的一个唯一法线的值，但是头发可能在一个像素里面存在着n个法线，法线的不唯一性导致不能再简单的用一个固定法线值去模拟了。</p><p>因此根据经验，kajiya-kay算法采用了一种近似的方法。头发的发根到发尾的方向是这跟头发的<strong>切线方向</strong>，这个方向对于头发来说是统一的，同时也方便美术去制作，因为在一个圆柱体截面上，切线的方向都是一致的。</p><p>如下图所示，L是光线方向在头发某点切线T方向上的分量，我们需要的法线N，它满足垂直于切线，且与L，T同平面，且点乘光线L大于0的方向，我们可以用这个作为N法线来近似高光所需要的法线。只要能够获取到发线，就可以按照我们前面提到的方法计算出这个点的高光了。</p><p><img src="/2025/01/06/digital-human-render-3/kajiya-get-normal.png" alt="法线的计算"></p><p>我们是通过切线，光线和视线的方向来得到法线，kajiya-kay模型的公式其实也变成了和切线相关的.</p><p>这里大概贴一下kajiya-kay模型的公式，这里我们不去推导这个公式。主要是大家可以看到公式的参数是和切线T，以及半程向量H（光线向量和视线向量的中间）相关的。</p><p><img src="/2025/01/06/digital-human-render-3/kajiya-kay.png" alt="Kajiya-Kay公式"></p><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><p>这里我们放一个高光的对比效果，黑球上的高光是普通的高光计算，绿球则是带有各向异性计算出来的高光，可以看见绿球的高光有种我们叫天使环的效果，这也是人物头发高光经常会出现的效果。</p><p><img src="/2025/01/06/digital-human-render-3/kajiya-kay-result.png" alt="Kajiya-Kay效果"></p><p>为了更加贴近头发我们添加一个头发的法线贴图看看效果，同时也给个纹理。</p><p><img src="/2025/01/06/digital-human-render-3/kajiya-kay-normal-result.png" alt="添加了法线贴图的Kajiya-kay效果"></p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>但是其实仅仅出现天使环效果也不够理想，这是因为Kajiya-Kay模型只是基于经验而不是真正的物理。</p><p>经过观察头发的高光，法线一般是有一个主要高光的，这个主要是受光源颜色的影响，大部分时候是白色。另外一个是受头发颜色的影响，会生成次一点的带颜色高光的。这个其实是有物理意义的，也就是光进入头发里面传输然后透射出来造成的效果。</p><p><img src="/2025/01/06/digital-human-render-3/kajiya-kay-optimize.png" alt="优化Kajiya-Kay"></p><p>所以现在一般kajiya-kay会加上两个高光的优化。这个效果有时会被称为近似Marschner模型。</p><p>这里我们提到了一个Marschner模型，这个是基于物理建模的毛发渲染模型，我们后续再详细介绍。</p><p>如何实现上述的双层高光效果呢？其实也很简单，就是<em>算两个高光，然后偏移其中一个</em>就好了。</p><p>我们前面看过kajiya-kay的公式，公式的参数是切线和半程向量。按照切线从发根指向发梢，我们在切线上加上像素点的法线并归一化，其实就相当于将切线沿着头发上移或者下移了。</p><p><img src="/2025/01/06/digital-human-render-3/hair-tangent.png" alt="头发切线方向"></p><p>同时我们增加一个扰动的偏移贴图，可以让高光更有沿着发丝等表面的感觉。<br>左下是偏移贴图，右边是增加了高光偏移和偏移贴图的最终效果，可以看出效果有质的提升。</p><p><img src="/2025/01/06/digital-human-render-3/kajiya-kay-optimize-result.png" alt="优化Kajiya-Kay的效果"></p><p>不过kajika-kay模型虽然久经沙场，但它始终是基于经验的，他的模型过于简单。<br>并且kajika-kay模型假设头发纤维是光滑的圆柱体，而我们之前见到过头发真正的表面是粗糙的鳞片组成的不规则几何体，所以有很多细节是不够准确的。</p><p>接下来我们来简单介绍一下基于物理的marschner模型。</p><h2 id="Marschner模型"><a href="#Marschner模型" class="headerlink" title="Marschner模型"></a>Marschner模型</h2><p>Marschner’s Model是基于头发纤维的结构，进行了相对准确的物理分析并得出的计算方法。</p><p>头发纤维从微观角度来看，实际上是一个从外到内有很多层的结构，它的最外层像鳞片一样，光线在穿过层层头发纤维内部的过程中也会发生折射，反射等，因此我们看到的最终头发呈现的颜色实际上是多条光路综合作用的结果。</p><p>该模型将毛发的光照分为三个部分</p><ul><li>反射：主高光，刚刚kajiya-kay算法其实主要处理的就是这部分，但是marschner模型会考虑头发的角质层的结构，所以说高光是更加有方向性的</li><li>传输-传输：光线照射并穿透毛囊，然后从另一边照射出去。这是光线在一定发量中的散射过程。</li><li>传输-反射-传输路线，光线进入毛囊，从内表面边界反射出来，然后再照射出来。这样产生的是次高光。这也是我们在kajiya-kay近似marschner处理中所做的工作</li></ul><p><img src="/2025/01/06/digital-human-render-3/Marschner-model.png" alt="Marschner模型"></p><p>其他的光线分量对视觉效果影响比重比较小，我们在实时渲染一般就忽略了。</p><p>由于头发的复杂造型，为了便于分析光线的散射，一般把头发上光的散射行为分为两类，即<strong>纵向散射</strong>和<strong>方位角散射</strong>。</p><p><img src="/2025/01/06/digital-human-render-3/marschner-diffuse.png" alt="Marschner模型的散射"></p><p><strong>纵向散射</strong>是沿着头发发根到发尾的散射，对于光滑的圆柱体，给定入射方向，反射方向确定的，如下图，但是头发纤维的表面是比较粗糙的，因此并不会发生精确的镜面反射，于是我们就需要一个函数来估计在给定的出射方向（观察方向）上，到底有多少比例的光线射出。这个函数和入射L1、出射方向L2有关，我们用M(L1,L2)来表示，可以简单的认为M就是一个高斯分布的概率密度函数。</p><p><strong>方位角散射</strong>是表示垂直于发丝方向的散射角度和能量的变化，这期间可能会发生比较多的折射和透射，我们也可以用一个函数来估计发生方位角散射时给定出射方向上光线的比例，这个函数除了和入射方向、出射方向投影在圆柱法平面的方位角有关，还和头发内部的折射率n有关，我们用N函数来表示。</p><p>那么每一个光路，R，TT，TRT，都包含了纵向散射和方向角散射，所以我们可以得出一个BSDF模型的公式，即Sp &#x3D; Mp * Np, p &#x3D; R,TT,TRT，</p><p><img src="/2025/01/06/digital-human-render-3/bsdf-model.png" alt="BSDF模型"></p><p>M和N的数值，一般是预处理做成两张LUT，在实时渲染点时候方便直接查找。这里和我们在皮肤渲染的方式有一些类似。不过这种方法一般只支持一种头发颜色和粗糙度。</p><p><img src="/2025/01/06/digital-human-render-3/bsdf-lut.png" alt="BSDF查找表"></p><p>当然，Marschner模型的关键，也就是M和N函数的计算会涉及比较深入的数学推导和物理原理，今天这里我们就不深入了，有兴趣的同学可以看一下steve  marschner的论文。</p><p>绝大部分的现代渲染器，包括虚幻引擎，目前使用的也是marschner模型来做毛发渲染。</p><h1 id="其他领域"><a href="#其他领域" class="headerlink" title="其他领域"></a>其他领域</h1><p>目前，我们只是浅谈了一些写实数字人的部位的渲染技术，但是还有很多部位是需要特殊处理的。</p><p>比如说作为心灵窗口的眼睛，有非常复杂的生态构造，且充满了液体。在渲染上也会遇到光线的反射散射折射。</p><p>牙齿其实也需要用到次表面散射的模型，他的材质会有一种玉石的散射效果。</p><p>这些部分其实都可以展开来讲。今天时间有限，我们暂时不深入去探讨。有兴趣并且对UE有了解的同学可以去看一下UE的metahuman工程。</p><p><img src="/2025/01/06/digital-human-render-3/ue-metahuman-face.png" alt="人脸的其他部分"></p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>今天这篇文章简短的介绍了一下数字人毛发渲染的技术，后面的分享将会介绍<strong>非真实感渲染（Non-photorealistic Rendering, NPR）</strong>技术，通常这项技术会被用在渲染卡通风格的内容。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>数字孪生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数字人仿真的渲染技术（二）</title>
    <link href="/2025/01/04/digital-human-render-2/"/>
    <url>/2025/01/04/digital-human-render-2/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>新年好。这是接着上次关于数字人渲染技术的第二部分，今天的这部分的分享，我会开始介绍一些关于数字人渲染的实际技术。</p><h1 id="数字人渲染技术介绍"><a href="#数字人渲染技术介绍" class="headerlink" title="数字人渲染技术介绍"></a>数字人渲染技术介绍</h1><p>接下来我们来聊一下数字人渲染技术方面的课题，我本身其实在这方面也不是什么大牛，在这里只是把一些我所学到的东西分享给大家。本次也不涉及到过深的技术讨论，如果想要对某个算法的细节想做更深的探讨，我们可以做后续的讨论。</p><p>在这里我提前预告一下，接下来的分享会包括哪些方面。</p><p>首先是会介绍一些数字人常用的渲染技术，比如皮肤，头发的渲染技术。在介绍这些渲染技术的时候，我主要会解释一下这个算法的构成，他是基于哪些理论而得出的算法，他的流程大致是怎样的，以及效果的一些展示。</p><p>本次分享不会包括的方面有：</p><ul><li><p>数学公式推导，当今很多渲染的算法都会遵循实际的物理意义，大多包含较为复杂的数学公式的推导，以辅助实现最后的算法。我们今天的分享是浅谈，所以不会讲的那么深，要是专注于数学公式推导的话会花上非常多的时间，门槛也会提升很多，这块并不是今天的目的。</p></li><li><p>另外一个是不会Review相关的Shader代码或者材质蓝图连线，今天主要是希望大家理解好概念就好，代码这些在理解了概念后自己动手去写可以进一步帮助理解。</p></li></ul><h2 id="基于物理的渲染方式（Physically-Based-Rendering-PBR）"><a href="#基于物理的渲染方式（Physically-Based-Rendering-PBR）" class="headerlink" title="基于物理的渲染方式（Physically Based Rendering - PBR）"></a>基于物理的渲染方式（Physically Based Rendering - PBR）</h2><p>首先我们来看一下基于物理的渲染方式，也就是我们所说的PBR，这种方式一般是用于渲染写实、高保真类型风格的数字人。</p><p>这里我大概介绍一下PBR的概念。PBR的是基于物理的渲染，他的定义是利用真实世界的原理和理论，通过各种数学方法推导或者简化或者模拟出一系列的渲染方程，来输出拟真的画面。</p><p><img src="/2025/01/04/digital-human-render-2/pbr_sample.png" alt="PBR对比传统渲染方法"></p><p>上面两张图是PBR和传统的shader的比较。在PBR出现之前，若想渲染出一张高质量的图，需要机械化的死记各种参数，然后基于烘焙贴图来实现的，并且通常环境光、物体位置必须保持不变。这些缺点在高质量的实时渲染里面显然是不能接受的。</p><p>而使用PBR这种渲染方式的话，我们需要分析物体自身物理属性然后给材质设定正确的光照参数，无论物体位置、光照如何改变，都有很好的效果。</p><p>但是PBR并不是纯粹的物理渲染，目前PBR还没办法用和现实一模一样的物理规律来实现渲染效果，这其中有硬件条件的限制（GPU，人眼5亿到10亿个像素的信息量），也有知识水平的限制，光照建模没办法达到和现实一模一样，所以在效果和性能上会需要做取舍。</p><h3 id="BRDF"><a href="#BRDF" class="headerlink" title="BRDF"></a>BRDF</h3><p>这里稍微做个补充，这段在原先的PPT中是没有包括的。</p><p>PBR的一个很经典的方法就是BRDF模型。</p><p><strong>BRDF</strong>的是双向反射分布函数（Bidirectional Reflectance Distribution Function）的英文缩写。<em>它从本质上描述了光线如何在物体表面反射，是一个用于量化给定入射方向的光在某个出射方向上的反射比例的函数。</em></p><p>具体来说，它定义为出射方向的反射辐射率<strong>r0</strong>（radiance）与入射方向的辐照度<strong>r1</strong>（irradiance）的比值，基于入射光方向，和观察（出射）方向。</p><p>例如，假设有一束光从某个方向照射到一个物体表面（这是入射方向），我们从另一个方向观察这个物体表面反射出来的光（这是出射方向），BRDF 就可以告诉我们从这个观察方向看到的反射光的强度和特性与入射光的关系。</p><p>有很多具体实现BRDF的方法，如<em>Cook-Torrance模型</em>、<em>Disney模型</em>等等。BRDF很适用于渲染非透明的物体，如墙壁、木头等等，对于人的皮肤，玉石等带有透明的材质则不太合适。这些材质需要用到<strong>次表面散射（BSSRDF）模型</strong>。</p><h3 id="PBR-皮肤"><a href="#PBR-皮肤" class="headerlink" title="PBR-皮肤"></a>PBR-皮肤</h3><p>好了，简单理解一下PBR的一些概念后，我们现在来介绍一下写实风格的数字人的皮肤渲染。</p><p>皮肤的渲染一直是渲染领域的难点之一：皮肤具有许多微妙的视觉特征，而观察者对皮肤的外观，特别是脸部的外观会非常敏感（恐怖谷）。皮肤的真实感渲染模型须包括皱纹，毛孔，雀斑等细节，而真实还原人体皮肤上的这些细节则是一个较大的挑战。</p><p><img src="/2025/01/04/digital-human-render-2/layers_of_skin.png" alt="皮肤多层结构"></p><p>皮肤作为一种属性复杂的材质，不同于简单的材质表面比如说水泥墙这些，其物理结构由<strong>多层结构</strong>组成，其表面油脂层主要贡献了皮肤光照的<em>反射</em>部分，而油脂层下面的表皮层和真皮层则贡献了的<em>次表面散射</em>部分，而且还有一部分光会<em>透射</em>过皮肤的边缘或者很薄的地方。</p><p>这三个方面组成了皮肤渲染的主要因素，我们今天也着重介绍这三部分的一些计算方法。</p><h4 id="镜面反射"><a href="#镜面反射" class="headerlink" title="镜面反射"></a>镜面反射</h4><p>在皮肤渲染中，高光这部分主要是皮肤的油脂层贡献的。高光的算法可以使用基本的**<a href="https://zhuanlan.zhihu.com/p/715918965">cook Torrance brdf模型</a>**的高光计算部分，因为时间比较紧张，我们就不花时间介绍了。这是最经典PBR算法之一了，如果大家网上搜BRDF就很容易能能够找到。大致思路是高光表现会依据平面的粗糙度，观测角度等不同而不同。如下方图所示。</p><p><img src="/2025/01/04/digital-human-render-2/Cook-Torrance-BRDF.png" alt="Cook-Torrance BRDF"></p><p>但是直接用BRDF计算皮肤高光一般并不能获得最好的效果，因为皮肤是一个复合的表面，他的突出部分和凹陷部分的粗糙度是不一样的。导致有两个粗糙参数，也就有两个高光需要表示。</p><p>所以虚幻引擎等某些渲染器会使用一个叫做<em>双镜叶高光</em>的技术。<strong>镜叶 lobe</strong>，也是如下图所示，其实就是光在某一个粗糙度平面下的一个分布状态。</p><p>![镜叶]](specular-lobe.png)</p><p>下面这张图是UE里面默认的高光混合的参数，通过混合两个粗糙度的高光表现，可以达到更贴近人脸皮肤的效果:</p><p><img src="/2025/01/04/digital-human-render-2/skin-specular.png" alt="皮肤高光"></p><h4 id="次表面散射-BSSRDF"><a href="#次表面散射-BSSRDF" class="headerlink" title="次表面散射(BSSRDF)"></a>次表面散射(BSSRDF)</h4><p>计算完高光后，我们之前提到，光线接触到皮肤时，有大约94%被皮肤各层散射，只有大约6%被反射。<br>我们可以看下对比图，前面我们提到的BRDF，其实主要就是假设光线的反射基于图a的现象，入射点和出射点是同一个，光在这个地方发生漫反射:</p><p><img src="/2025/01/04/digital-human-render-2/diffuse-comparison.png" alt="反射对比"></p><p>但其实光线在进入皮肤后的真实情况是更接近图b的，光线会进入我们的皮肤，通过油脂层到下面的表皮层和真皮层，会进行一阵游走，然后最终有一部分光线会被反射出来。</p><p>实际上几乎所有材质都存在次表面散射现象，区别只在于材质散射密度分布的集中程度，如果绝大部分能量都集中在入射点附近，就表示附近像素对当前像素的光照贡献不明显，可以忽略，则在渲染时我们就用漫反射代替，如果该函数分布比较均匀，附近像素对当前像素的光照贡献明显，则需要单独计算次表面散射。</p><p>为了模拟这种光线表现，提出了<strong>BSSRDF</strong>。</p><p><img src="/2025/01/04/digital-human-render-2/BSSRDF.png" alt="BSSRDF"></p><p>BSSRDF描述的是，对于当前出射点和出射方向，某个入射点和入射方向的光线能量对其结果的贡献。<br>我们观察点是固定的po，已知需要的出射方向，根据这些条件获取周围点对他的光照贡献（w：omega）。</p><p>如果我们想要按照真实世界，实时的模拟出每一束光在皮肤材质中的路线，从而获取到每一束光的正确出射点和角度的话，是难道很大的。BSSRDF的意义在于快速的近似真实世界的效果，为了平衡性能和效果，我们假设了4个前提：</p><ul><li>物体是一个曲率为0的平面。</li><li>平面的厚度和大小都是无限。</li><li>内部的介质参数是均匀的。</li><li>光线永远是从垂直方向入射表面。</li></ul><p>基于这些前提，我们就可以单纯以像素的距离作为权重，距离当前像素近的入射光照，贡献就大，反之距离远的，贡献小。对应的也就是公式上的R(||pi-po||)这部分。</p><p><img src="/2025/01/04/digital-human-render-2/BSSRDF-1.png" alt="BSSRDF-1"></p><p>当然真正人体表面的皮肤是不满足与上面四点的，但是考虑到实时渲染的性能，单纯按照两个点的距离的近似可以达到能接受的效果。</p><p>用来描述光在物体内部的散射或者扩散的行为，就是公式中R那个部分，这个分布函数我们叫做<em>散射剖面（diffusion profile）</em>，也有叫<em>扩散剖面</em>的。</p><p>计算散射剖面的算法有很多种，常见的有<strong>偶极子，多极子，高斯和拟合</strong>等等。这里内容比较深，由于时间的关系我们暂时不做详细介绍了。</p><p>同时，由于是单纯的根据距离来获得光照的权重，我们可以预处理散射剖面，做成一张lookup table，在实时渲染的时候直接查找对应的值，以加速渲染。<br>可以看一下这张图，reflectance（反射率）根据距离的变化，而且rgb三原色是分开计算的.</p><p><img src="/2025/01/04/digital-human-render-2/reflectance-lookup-table.png" alt="反射率参照表"></p><h4 id="基于模糊的算法"><a href="#基于模糊的算法" class="headerlink" title="基于模糊的算法"></a>基于模糊的算法</h4><p>计算次表面散射的光照的时候，当前像素的光照会受到周边像素的影响，而这个影响的程度我们是以距离来决定的。那其实换个角度想想，这是不是就是我们把原来当前像素的漫反射，抹匀到了周边，因为光的能量经过次表面散射分散到了周边的像素。这其实就是一个模糊操作，从数学角度上，都是做卷积处理。所以就有了基于模糊的皮肤渲染算法。</p><p>那么根据施加模糊的空间，分为了<em>纹理空间模糊</em>和<em>屏幕空间模糊</em>：</p><h5 id="纹理空间模糊"><a href="#纹理空间模糊" class="headerlink" title="纹理空间模糊"></a>纹理空间模糊</h5><p>纹理空间模糊他的一般步骤大概是：</p><ol><li>首先需要获得一张拉伸校正贴图，一般是会预计算这张帖图，主要是为了表示每个Texel（纹素）需要进行多大范围的模糊。</li><li>然后渲染出模型的光照，漫反射，然后将模型的光照展开到纹理空间。</li><li>将这张图根据拉伸校正贴图所标定的范围，进行模糊处理，保存成一张或者多张纹理贴图。</li><li>最终渲染的时候，我们会获取依据这些贴图，然后按照某些特定的权重将它们混合，得到最后的漫反射结果</li></ol><p><img src="/2025/01/04/digital-human-render-2/texture-space-blur.png" alt="纹理空间模糊"></p><p>在纹理空间模糊的好处很明显：比较正确，不会穿帮，可以进行低精度的绘制再利用硬件插值来辅助Blur，模糊的方法也很多。</p><p>但缺点也很明显：主要是背面也同样要绘制，而且美术需要处理好纹理不然会有接缝问题。</p><h5 id="屏幕空间模糊"><a href="#屏幕空间模糊" class="headerlink" title="屏幕空间模糊"></a>屏幕空间模糊</h5><p>那么屏幕空间模糊就比较好理解了，就是在屏幕空间对皮肤的光照结果进行模糊。<br><img src="/2025/01/04/digital-human-render-2/screen-space-blur.png" alt="屏幕空间模糊"></p><p>需要注意一下边界问题，不能模糊出界了，处理的时候可以根据深度等作为模板处理。<br>下面的图是皮肤在纹理空间和屏幕空间的模糊的效果的不同。</p><p><img src="/2025/01/04/digital-human-render-2/blur-camparison.png" alt="模糊比较"></p><h4 id="透射"><a href="#透射" class="headerlink" title="透射"></a>透射</h4><p>最后我们简单讲一下透射，透射和次表面散射的区别是透射的光一般是从另外一面照射过来的，而次表面散射我们一般是按照光源和我们的观察点在模型的同一侧。像是我们手指边缘，或者耳垂部分，是比较容易出现这种现象的。</p><p>我们一般计算透射的方式的步骤包括三步：</p><ol><li>计算光照在进入半透明介质时的强度</li><li>计算光线在介质中经过的路径</li><li>根据路径长度和BTDF来计算出射光线的强度</li></ol><p>那这里我们又要提出一个BXXXDF了，也就是BTDF，其中的T就代表透射。他和BRDF较为类似，只不过光源是从另外一面穿出来的。</p><p><img src="/2025/01/04/digital-human-render-2/BTDF.png" alt="BTDF"></p><p>当然由于光在另外一面穿到前面来，光的强度会有损失，光也会在皮肤出现次表面散射，不过BTDF作为一种近似算法在实时渲染中一般只简化为一个和光线路径长度的函数。</p><p>不过一般来说皮肤渲染上透射出现的区域也是比较小的。</p><h3 id="UE里面的皮肤着色模型"><a href="#UE里面的皮肤着色模型" class="headerlink" title="UE里面的皮肤着色模型"></a>UE里面的皮肤着色模型</h3><p>皮肤的渲染算法我们目前就介绍到这里了，当然作为浅谈我们只是稍微触及了一些皮毛，想要做出更好更加真实的皮肤效果还有很多地方可以深入。</p><p><img src="/2025/01/04/digital-human-render-2/ue-skin.png" alt="UE皮肤着色模型"></p><p>这里我大概介绍一下UE，可能很多同学自己做项目也是用的UE。UE的皮肤材质有很多种着色类型，在材质的着色类型可以选择，一般来说皮肤的材质会默认是<strong>次表面轮廓类型</strong>，这是效果最好的着色模型，像是metahuman的皮肤材质着色也是这种类型。</p><p><strong>次表面</strong>就是我们前面讲的基于次表面散射的着色模型，因为次表面散射也可以用作冰川等材质，所以如果选择次表面着色模型且针对皮肤想要有更好的效果的话，需要自己进行调整。</p><p>最后<strong>预整合皮肤</strong>也是我们之前提到的优化方法之一，他精度比次表面略低但是性能开销也低。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>写实风格的皮肤渲染技术就分享到这了，不知不觉文章的长度已经超长了，剩下的部分只能放到后续的文章了。下次的分享的主要内容将会是头发的渲染。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>数字孪生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数字人仿真的渲染技术（一）</title>
    <link href="/2024/12/28/digital-human-render-1/"/>
    <url>/2024/12/28/digital-human-render-1/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在2022年12月，我受邀在OGEEK上做过一次关于数字人渲染技术的分享，名为《浅谈数字人仿真的渲染技术》。为了这次分享我查阅了大量资料做了很多准备，但是很不幸的是在分享的前两天我便感染了新冠，身体开始发烧外加喉咙开始隐隐作痛。为了不影响OGEEK的流程我便在病情还未恶化的时候将分享提前录了下来，以播片的形式参加。</p><p>这段经历确实还挺难忘，近期又翻到了这篇准备的PPT，和演讲的录屏，于是想将这部分内容做个记录，整理成文章分享出来。</p><p>由于PPT内容还是比较多的，哪怕是精简后的版本也还有50多页，于是乎会准备做成一个系列，当初精简掉的部分可能也会想办法补充回来，让内容尽量的充分。</p><h1 id="数字人简介"><a href="#数字人简介" class="headerlink" title="数字人简介"></a>数字人简介</h1><h2 id="数字人的定义"><a href="#数字人的定义" class="headerlink" title="数字人的定义"></a>数字人的定义</h2><p>目前数字人缺乏一个统一的标准定义，我们从它的发展起源，从技术角度上选择一个最宽泛最简洁的标准：<strong>由计算机生成的人类。</strong></p><p>中国人工智能产业发展联盟发布的《2020年虚拟数字人发展白皮书》中给了一个更加详细的定义：虚拟数字人意指具有数字化外形的虚拟人物，除了拥有人的<strong>外观</strong>、人的<strong>行为</strong>之外、还有拥有人的<strong>思想</strong>，具有<strong>识别外界环境</strong>、并能与<strong>人交流互动</strong>的能力。</p><p>那其实这个定义里面，也描述了数字人相关的几个关键技术方向，包括：<em>渲染-外观，行为-驱动算法，思想-AI，识别外接环境-感知，与人交流互动-表达</em>。</p><h2 id="数字人的发展历史"><a href="#数字人的发展历史" class="headerlink" title="数字人的发展历史"></a>数字人的发展历史</h2><p>在上世纪80年代，其实就有虚拟形象引入到现实世界的想法。<br>1982 年，动画片《太空堡垒》中的女角色林明美作为虚拟歌姬出道，其专辑也成功打入当时的知名音乐排行榜。日本媒体率先提出了“虚拟偶像”的称号。1984 年，世界首位虚拟电影演员“Max Headroom”诞生，出演电影，并拍摄数支广告，在英国家喻户晓。</p><p><img src="/2024/12/28/digital-human-render-1/%E6%9E%97%E6%98%8E%E7%BE%8E.png" alt="林明美"></p><p>此时，虚拟人概念先行，给予虚拟形象以立体化人设，并带入大众视野。但受制于技术发展，“数字化”在这个阶段并不明显。打造虚拟人的技术以手工绘制为主，人物形象以 2 D 卡通的形式展现，展现方式以事先完成的音频和视频为主，并不具备实时交互功能。</p><p>进入 21 世纪，虚拟人的 数字化特征逐渐明显。形象创建上，虚拟数字人开始从手绘转向 CG和动捕等计算机技术。</p><p>2007 年，日本虚拟歌手“初音未来”的诞生与流行。初音未来的虚拟形象采用 CG 和动作捕捉技术。在动作捕捉技术的助力下，初音未来可以直接采用人类的表情和动作，并借助 CG 技术真实的360度渲染出来。作为虚拟歌姬，初音未来的歌喉基于 VOCALOID（电子音乐制作 的 语音合成软件）。采样于日本声优藤田咲，创作者只需要输入歌词和旋律，就能够自动形成歌曲。</p><p><img src="/2024/12/28/digital-human-render-1/%E5%88%9D%E9%9F%B3%E6%9C%AA%E6%9D%A5.png" alt="初音未来"></p><p>近年来，由于各项技术的不断发展，出现了越来越多高真实度的数字人形象。</p><p>比如说2016年出现的miquela，她在ins上的出现引发了一场“真假辩论”。许多粉丝相信她是真实存在的人物，只是修图“狠”了点。直到黑客们入侵了她的账号，才最终确定了她是由 3 D 电脑动画公司制作的虚拟人。她甚至在2018年一起被美国《时代》周刊列为“25 位最有影响力的互联网人物”</p><p>同样是在2018年，由腾讯、Epic Games推出了Siren项目。Siren 的所有动作表情都由实时捕捉以及实时渲染形成，并且整个过程只有15毫秒，60帧。Siren在渲染的真实性和交互性之间找到平衡，打造了具备实时交互能力的数字虚拟人。</p><p><img src="/2024/12/28/digital-human-render-1/siren.png" alt="siren"></p><h2 id="数字人的分类"><a href="#数字人的分类" class="headerlink" title="数字人的分类"></a>数字人的分类</h2><p>数字人可以按照不同维度进行分类。</p><p>按照美术风格：</p><ul><li>2D、3D</li><li>写实、卡通、风格化</li></ul><p>按照驱动方式：</p><ul><li>真人驱动</li><li>AI驱动</li></ul><p>按照商业和功能维度：</p><ul><li>内容&#x2F;IP型</li><li>功能服务型</li><li>虚拟分身</li></ul><h2 id="数字人的发展"><a href="#数字人的发展" class="headerlink" title="数字人的发展"></a>数字人的发展</h2><p>近几年，虚拟数字人在电商、金融、影视、游戏和金融等行业都拥有不同大小的市场规模。<br>我们拿虚拟偶像的市场作为例子。虚拟偶像行业2020年中国的市场规模为34.6亿元，预计2023年将达到205.2亿元。带动的市场从2020的645.6亿元，预计2023年增长到3334.7亿元，是一个指数级的增长。</p><p>当然除了虚拟偶像数字人还有很多其他方面的应用，所以市场前景是非常可观的。下面是一个虚拟偶像市场规模及预测的分析。</p><p><img src="/2024/12/28/digital-human-render-1/%E8%99%9A%E6%8B%9F%E5%81%B6%E5%83%8F%E5%B8%82%E5%9C%BA%E8%A7%84%E6%A8%A1.png" alt="虚拟偶像市场规模"></p><h1 id="数字人的制作流程简介"><a href="#数字人的制作流程简介" class="headerlink" title="数字人的制作流程简介"></a>数字人的制作流程简介</h1><p>数字人制作大致分4个阶段：</p><ol><li><p>第一阶段（形象设计）：明确形象设计方向。</p></li><li><p>第二阶段（模型制作）：根据平面形象，进行模型搭建。<br>这里我们以可能是最为复杂的超写实数字人的制作流程进行举例，首先在lightstage里面扫描模型（扫描仪，360度单反相机阵列，300多个相机组成）。扫描出来的模型是一个点云，需要模型师去调整，抚平一些瑕疵。去除扫描的毛刺。有些部位可能拍照的时候出现遮挡（比如耳后），需要在模型软件工具中处理好。<br><img src="/2024/12/28/digital-human-render-1/%E8%80%81%E9%BB%84%E6%89%AB%E6%8F%8F.png" alt="老黄扫描"><br><img src="/2024/12/28/digital-human-render-1/%E8%80%81%E9%BB%84%E5%BB%BA%E6%A8%A1.png" alt="老黄建模"></p></li><li><p>第三阶段（驱动绑定）：<br>面部动画face rig绑定驱动，通过动画，人脸识别，或者AI去驱动。或者使用blendshape等技术。<br>身体躯干使用骨骼绑定，辅以动作捕捉等等。<br><img src="/2024/12/28/digital-human-render-1/metahuman%E9%9D%A2%E9%83%A8%E9%A9%B1%E5%8A%A8.png" alt="metahuman(UE)面部驱动"><br><img src="/2024/12/28/digital-human-render-1/%E8%80%81%E9%BB%84%E9%A9%B1%E5%8A%A8.png" alt="老黄驱动"></p></li><li><p>第四阶段（渲染）：将场景、人物放入渲染工具进行渲染输出，常用的工具包括nVidia omniverse、unreal engine等等。<br><img src="/2024/12/28/digital-human-render-1/%E8%80%81%E9%BB%84%E6%A8%A1%E5%9E%8B%E6%B8%B2%E6%9F%93.png" alt="老黄模型渲染"></p></li></ol><p>目前虚幻引擎5的metahuman creator是一个很流程化且易于使用的数字人制作工具。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>第一部分先总结到这里，在后面的部分我会更加详细的介绍一些数字人渲染技术，包括皮肤、头发的渲染以及卡通渲染等等。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>数字孪生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>虚幻引擎5基于AI的贴图生成方法</title>
    <link href="/2024/12/22/ue-ai-texture-generation/"/>
    <url>/2024/12/22/ue-ai-texture-generation/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>今年年初，由于公司部门的变动，我从原来的云服务部门调到了新成立的AI部门。<br>AI是最近最火热的东西，我虽然肯定算不上专业，但是也稍微有粗略的接触过一点点。再加上部门新成立没有什么业务上的压力，我便花了点时间去做了些预言，这个工具便是其中之一。</p><p>这个工具是为了研究如何将AIGC和3D工作流结合起来的成果。当时选了几个方向，包括AIGC贴图、AIGC模型和3D结合controlnet来辅助AIGC文生图等等。研究的过程中用Unreal Engine搭了些简单的demo，很可惜后续有真正的项目推进后，这些预研的内容也并未有进一步的推进了，觉得有些许可惜，于是便打算在这里记录一下。</p><p>同时这个项目也上传到了Git，有兴趣的欢迎查看：<a href="https://github.com/ruochenhua/UETextureGeneration">UETextureGeneration</a>。</p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><h2 id="大体流程"><a href="#大体流程" class="headerlink" title="大体流程"></a>大体流程</h2><p>这个demo的流程非常简单，参照一般文生图的流程，填写提示词、负提示词、生成步数和种子等信息。这些参数将传入给到文生图的Python脚本，脚本会运行一个大模型来创建对应的结果。</p><p><img src="/2024/12/22/ue-ai-texture-generation/run_texgen.png" alt="运行工具得到生成的贴图"></p><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>下面介绍一下这个工具所需要的准备工作。</p><ul><li><p>首先我们需要找到引擎的python地址，如C:\UnrealEngine\UE_5.3\Engine\Binaries\ThirdParty\Python3\Win64，找到这个路径的python.exe文件。虚幻引擎是以这个Python来运行Python脚本，所以我们对应的Python库需要安装在这个路径之下。</p></li><li><p>记录下上面的Python的路径，打开cmd或其他命令行工具，以:<br>   “C:\UnrealEngine\UE_5.3\Engine\Binaries\ThirdParty\Python3\Win64\python.exe” -m pip install XXX </p><p>   这种格式来使用pip安装对应的库。</p></li><li><p>需要安装的库包括以下这些：</p><ul><li>transformers, diffusers, accelerate（hugging face）    </li><li>pytorch（<a href="https://pytorch.org/get-started/locally/%EF%BC%8C">https://pytorch.org/get-started/locally/，</a> <a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a>)</li><li>numpy</li><li>opencv-python</li></ul></li></ul><p>python的版本可能不支持最新的pytorch版本，如ue5.3使用的python 3.9.7只能支持到pytorch2.1，需要根据版本来安装合适的版本，numpy支持到1.24.1版本，opencv-python支持到4.6.0版本。</p><p>ue5.5的Python升级到了3.11，所以可以支持到更新的版本了，请在安装前检查一下，要不然很容易出现问题。</p><h2 id="文件布局"><a href="#文件布局" class="headerlink" title="文件布局"></a>文件布局</h2><p>三个脚本放在<strong>Scripts</strong>文件夹下，分别对应着漫反射贴图生成、法线和置换贴图生成以及提升贴图分辨率三个流程。</p><p>下面简单介绍一下这个几个脚本对应的能力。</p><h2 id="漫反射贴图生成："><a href="#漫反射贴图生成：" class="headerlink" title="漫反射贴图生成："></a>漫反射贴图生成：</h2><p>脚本名称：RunTexGen.py</p><p>漫反射贴图生成使用模型：<a href="https://huggingface.co/dream-textures/texture-diffusion">texture diffusion</a></p><p>模型基于stable diffusion 2 base，通过DreamBooth微调，可通过文生图的方式生成材质的漫反射贴图，尽量不包含光照和阴影信息。</p><h2 id="法线贴图生成："><a href="#法线贴图生成：" class="headerlink" title="法线贴图生成："></a>法线贴图生成：</h2><p>脚本名称：RunNormalGen.py</p><p>为了有更加真实的光照表现效果，贴图一般会配合法线贴图使用。<br>从漫反射贴图生成法线贴图的库有好几个，比如说<a href="https://github.com/HugoTini/DeepBump">deepbump</a>，demo使用的是<a href="https://github.com/joeyballentine/Material-Map-Generator">Material-Map-Generator(MMG)</a>，因为它还可以生成DisplacementMap和RoughnessMap，这两张贴图同样可以增强模型在3D光照环境下的表现。</p><h3 id="置换贴图："><a href="#置换贴图：" class="headerlink" title="置换贴图："></a>置换贴图：</h3><p>上文提到了置换贴图（DisplacementMap），这个资源也是一个提升模型显示效果的手段。法线贴图增加模型细节是不需要修改模型本身的顶点形状的，只是通过提供更为细致的平面法线信息辅助光照计算。</p><p>置换贴图则是可以真实的修改模型的形状。</p><p>在UE中可以使用模型工具通过<strong>DisplacementMap</strong>来丰富模型的细节，也有另外一种方法**视差遮挡映射（ParallaxOcclusionMapping)**，我在UE中使用的是这种方法。</p><h2 id="Upscale："><a href="#Upscale：" class="headerlink" title="Upscale："></a>Upscale：</h2><p>脚本名称：RunUpScale.py</p><p>使用<a href="https://huggingface.co/radames/stable-diffusion-x4-upscaler-img2img">Upscale Pipeline stable-diffusion-x4-upscaler-img2img</a>，将原有的贴图分辨率从512X512提升到2048X2048，模型精度有比较大的提升，但是显存需求显著增大，并且消耗时间显著增长。</p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>最简单的方式是参照下面的蓝图方式调用即可。<br><img src="/2024/12/22/ue-ai-texture-generation/texgen_bp.png" alt="脚本调用蓝图"><br><img src="/2024/12/22/ue-ai-texture-generation/texgen_bp_macro.png" alt="参数包裹函数"></p><p>最初调用的时候由于需要下载对应的模型，所以时间会相对来说久一些。并且由于是从hugging face上下载模型，可能需要梯子。<br><img src="/2024/12/22/ue-ai-texture-generation/texgen_cmd.png" alt="调用后的命令行"></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>虚幻引擎</tag>
      
      <tag>AIGC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>屏幕空间反射</title>
    <link href="/2024/12/10/screen-space-reflection/"/>
    <url>/2024/12/10/screen-space-reflection/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是屏幕空间反射"><a href="#什么是屏幕空间反射" class="headerlink" title="什么是屏幕空间反射"></a>什么是屏幕空间反射</h1><p>在前面的文章的一些配图中，其实已经揭露了之前在<a href="https://github.com/ruochenhua/KongEngine">KongEngine</a>中实现的一个不小的功能点，就是<strong>屏幕空间反射（screen space reflection）</strong>。加入了屏幕空间反射能力之后，在一些光滑和带有反射材质的表面上，能够实现不错的反射效果。</p><p><img src="/2024/12/10/screen-space-reflection/screen-space-reflection-in-kong.png" alt="KongEngine中的屏幕空间反射效果"></p><p>屏幕空间反射（后简称<strong>SSR</strong>）是一种在实时渲染中用于模拟物体表面反射的成熟技术。SSR 的核心原理是在<strong>屏幕空间</strong>中进行光线追踪，以此计算反射效果，而无需像传统方法那样在世界空间或物体空间中进行复杂的光线与场景求交计算。它主要利用屏幕上已有的<strong>深度图</strong>和<strong>法线图</strong>等信息，通过对这些信息的分析和处理，确定反射光线的方向和位置，进而得到反射颜色。</p><p>因为SSR不错的效果表现和相对来说比较低的性能开销，使其被广泛的应用在各个实时渲染领域，包括游戏、虚拟现实、建筑可视化等等。当然SSR的效果其实还不够完美，有很多无法解决的问题，这个在后面也会提到。但是在大多数情况下它的效果都是足够的，属于一个很<strong>高性价比</strong>的方法。</p><h1 id="如何实现屏幕空间反射"><a href="#如何实现屏幕空间反射" class="headerlink" title="如何实现屏幕空间反射"></a>如何实现屏幕空间反射</h1><h2 id="屏幕空间反射的实现方法"><a href="#屏幕空间反射的实现方法" class="headerlink" title="屏幕空间反射的实现方法"></a>屏幕空间反射的实现方法</h2><p>简单概括一下SSR的实现方法：</p><ol><li>对于屏幕上的每个像素，先获取其<strong>深度值</strong>和<strong>法线向量</strong>。</li><li>结合相机参数和屏幕坐标计算出<strong>观察向量</strong>，进而得到<strong>反射向量</strong>。    </li><li>沿着反射向量在屏幕空间进行光线追踪，查找反射光线与场景中其他物体的相交点，以获取反射光线的颜色，最终将反射颜色与场景的原始颜色进行合成，得到带有反射效果的最终渲染结果。</li></ol><p>我们对于上面1、2两步应该已经不陌生了，毕竟我们在前面的文章就介绍了KongEngine接入<a href="https://ruochenhua.github.io/2024/10/19/defer-render/">延迟渲染</a>的能力，在G-Buffer中我们已经存储了屏幕空间的各种相关数据，包括深度值和法线向量。有了这些数据，按照第2点计算反射向量也是很顺理成章的事情。</p><p>对应的代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 将延迟渲染保存的数据传给SSR shader</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">CRender::SSReflectionRender</span><span class="hljs-params">()</span> <span class="hljs-type">const</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-comment">// scene normal：defer_buffer_.g_normal_</span><br><span class="hljs-comment">// scene reflection mask: defer_buffer_.g_orm_</span><br><span class="hljs-comment">// scene position: defer_buffer_.g_position_</span><br><span class="hljs-comment">// scene depth存在于normal贴图的w分量上</span><br>ssreflection_shader-&gt;<span class="hljs-built_in">Use</span>();<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, defer_buffer_.g_position_);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + <span class="hljs-number">1</span>);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, defer_buffer_.g_normal_);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + <span class="hljs-number">2</span>);<br><span class="hljs-comment">// 用给后处理的texture作为scene color</span><br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, post_process.screen_quad_texture[<span class="hljs-number">0</span>]);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + <span class="hljs-number">3</span>);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, defer_buffer_.g_orm_);<br><br>quad_shape-&gt;<span class="hljs-built_in">Draw</span>();<br>&#125;<br></code></pre></td></tr></table></figure><p>那么SSR的关键步骤，其实就在第三步，也是需要理解的重点部分。</p><h2 id="获得反射的颜色"><a href="#获得反射的颜色" class="headerlink" title="获得反射的颜色"></a>获得反射的颜色</h2><p><img src="/2024/12/10/screen-space-reflection/ssr-step3.gif" alt="SSR计算反射向量"></p><p>上面这张图大致描述了第3步的状态。图片中<strong>蓝色</strong>的向量代表了从相机向场景中的每个像素发射的观察向量，<strong>绿色</strong>的向量代表了场景中的法线向量，根据观察向量和法线向量，我们能够计算出反射向量，也就是图片中的<strong>红色</strong>向量。</p><p>我们需要得到的反射结果的颜色，基于反射向量和渲染场景中的其他物体的相交结果，这个是通过在<em>屏幕空间进行步近，判断步近后的坐标深度和深度缓存中存储的物体深度是否相交</em>来得到的。如果有相交结果，则该像素的反射颜色就是相交处的场景颜色，若超出步近范围（会预先设置一个步近长度或者步数的范围），则改点没有反射需要处理。</p><p><img src="/2024/12/10/screen-space-reflection/ssr-step4.gif" alt="反射向量步近"></p><p>这个原理是非常简单易懂的，下面是这段逻辑的大致代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec2</span> tex_size = <span class="hljs-built_in">textureSize</span>(scene_position, <span class="hljs-number">0</span>).xy;<br>    <span class="hljs-type">vec2</span> tex_uv = <span class="hljs-built_in">gl_FragCoord</span>.xy / tex_size;<br><br>    <span class="hljs-comment">// 材质相关的参数</span><br>    <span class="hljs-type">vec4</span> orm = <span class="hljs-built_in">texture</span>(orm_texture, TexCoords);<br>    <span class="hljs-type">float</span> roughness = orm.y;<br>    <span class="hljs-type">float</span> metallic = orm.z;<br>    <span class="hljs-comment">// 颜色信息</span><br>    <span class="hljs-type">vec4</span> s_color = <span class="hljs-built_in">texture</span>(scene_color, TexCoords);<br>    FragColor = s_color;<br><br>    <span class="hljs-comment">// 深度和法线</span><br>    <span class="hljs-type">vec4</span> normal_depth = <span class="hljs-built_in">texture</span>(scene_normal, TexCoords);<br>    <span class="hljs-type">vec3</span> world_normal = <span class="hljs-built_in">normalize</span>(normal_depth.xyz + randVec3(<span class="hljs-built_in">fract</span>(TexCoords.x*<span class="hljs-number">12.345</span>)*<span class="hljs-built_in">sin</span>(TexCoords.y)*<span class="hljs-number">9876.31</span>)*<span class="hljs-number">0.2</span>*roughness);<br><br>    ...<br><br>&#125;<br></code></pre></td></tr></table></figure><p>上面这段代码是将gbuffer中的信息读出来，包括前面讲到的几个部分。其中法线信息world_normal和材质的粗糙度做了一个随机方向的叠加，可以稍微增加反射效果的粗糙感。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br><br>    <span class="hljs-comment">// 远近平面</span><br>    <span class="hljs-type">vec2</span> near_far = matrix_ubo.near_far.xy;<br>    <span class="hljs-type">vec3</span> world_pos = <span class="hljs-built_in">texture</span>(scene_position, TexCoords).xyz;<br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br><br>    <span class="hljs-type">mat4</span> projection = matrix_ubo.projection;<br>    <span class="hljs-type">mat4</span> view = matrix_ubo.view;<br>    <span class="hljs-type">mat4</span> vp = projection * view;    <span class="hljs-comment">// 世界坐标到裁切坐标的转换矩阵</span><br><br>    <span class="hljs-type">vec3</span> view_dir = <span class="hljs-built_in">normalize</span>(world_pos-cam_pos);<br>    <span class="hljs-type">vec3</span> rd = <span class="hljs-built_in">normalize</span>(<span class="hljs-built_in">reflect</span>(view_dir, world_normal));<br>    <br>    <span class="hljs-type">float</span> resolution = <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-type">float</span> max_step_dist = <span class="hljs-number">5.0</span>;        <br>    <span class="hljs-type">vec3</span> start_pos_world = world_pos  + rd*<span class="hljs-number">0.1</span>;<br>    <span class="hljs-type">vec3</span> end_pos_world = world_pos + max_step_dist*rd;<br><br>    <span class="hljs-comment">// 在屏幕空间上的从起始点到结束点的坐标</span><br>    <span class="hljs-type">vec4</span> start_clip = vp * <span class="hljs-type">vec4</span>(start_pos_world, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-type">vec4</span> end_clip   = vp * <span class="hljs-type">vec4</span>(end_pos_world, <span class="hljs-number">1.0</span>);<br><br>    ...<br>&#125;<br><br></code></pre></td></tr></table></figure><p>在上面的代码，我们计算出了反射向量rd，同时也为步进设定了一个范围max_step_dist，得到了反射的步进区间，接下来就是进行步进的操作了。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br>    <br>    <span class="hljs-comment">// 步进的步数</span><br>    <span class="hljs-type">int</span> step_count = <span class="hljs-number">32</span>;<br>    <span class="hljs-type">int</span> sample_count = step_count;<br>    <span class="hljs-type">float</span> delta = <span class="hljs-number">1.0</span> / sample_count;   <span class="hljs-comment">// 如果sample count为10，则delta采样为总共的1/10</span><br><br>    <span class="hljs-type">vec4</span> reflect_color = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_count; i++)<br>    &#123;<br>        <span class="hljs-type">float</span> sample_t = i*delta;<br>        <br>        <span class="hljs-comment">// 步进到达处的屏幕空间uv</span><br>        <span class="hljs-type">vec2</span> uv = <span class="hljs-type">vec2</span>(<span class="hljs-number">0</span>);<br><br>        <span class="hljs-keyword">if</span>(campareDepth(start_clip, end_clip, start_pos_world, end_pos_world, sample_t, uv))<br>        &#123;<br>            reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);        <br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br><br>    FragColor = reflect_color*metallic;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上面的步进代码中，根据设定好的步进步数迭代，campareDepth函数中将当前位置的深度和深度缓存中的数据作对比，若当前深度大于缓存中的值，则代表击中并返回对应的屏幕空间贴图对应的uv值。</p><p>最后反射的颜色和金属度相乘，金属度越高的材质反射也是越高的。在场景渲染的最后，将反射颜色和场景实际的颜色结合，就得到了基本的反射效果了。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl">FragColor = <span class="hljs-built_in">texture</span>(scene_texture, TexCoords);<br><span class="hljs-type">vec4</span> reflection_color = <span class="hljs-built_in">texture</span>(reflection_texture, TexCoords);<br><br>FragColor.rgb += reflection_color.rgb * reflection_color.a;<br></code></pre></td></tr></table></figure><p><img src="/2024/12/10/screen-space-reflection/ssr_normal_s32.png" alt="SSR效果:sample数32"><br>上面是采样步数为32步时，得到的反射效果。可以看到反射效果确实出来了，但是条纹效果太过于明显。我们可以提高采样的精度，将sample的数量改为128后可以得到明显改善的结果，如下图。</p><p><img src="/2024/12/10/screen-space-reflection/ssr_normal_s128.png" alt="SSR效果：sample数128"></p><h1 id="屏幕空间反射的优化"><a href="#屏幕空间反射的优化" class="headerlink" title="屏幕空间反射的优化"></a>屏幕空间反射的优化</h1><p>现在我们已经有了基础的反射效果了，但是我们还是不满足不是吗。单纯提升采样精度确实能得到不错的效果，但是始终还是要考虑实际的性能的。那么有什么方法可以优化SSR的表现呢，下面会做一部分简单的介绍。</p><h2 id="粗晒和精筛"><a href="#粗晒和精筛" class="headerlink" title="粗晒和精筛"></a>粗晒和精筛</h2><p>在上面的采样处理中，我们通过步进迭代获取到了深度超过gbuffer中的深度的位置。为了弥补采样步数不足，我们可以将采样过程分为两部分：首先是粗筛，用较低的采样精度获取到大致的区间；然后再利用二分法或者其他方法在大致区间内进行二次筛选。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br><br>    <span class="hljs-type">float</span> sample_t = i*delta;<br>    <span class="hljs-comment">// 线性插值找到当前采样的屏幕空间的点</span><br>    <span class="hljs-type">vec2</span> uv = <span class="hljs-type">vec2</span>(<span class="hljs-number">0</span>);<br><br>    <span class="hljs-keyword">if</span>(campareDepth(start_clip, end_clip, start_pos_world, end_pos_world, sample_t, uv))<br>    &#123;<br>        reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);<br>        <span class="hljs-type">int</span> split_count = <span class="hljs-number">10</span>;<br>        <span class="hljs-type">float</span> i_divide_pos = <span class="hljs-number">0.5</span>;<br>        <span class="hljs-keyword">while</span>(split_count &gt; <span class="hljs-number">0</span>)<br>        &#123;<br>            <span class="hljs-keyword">if</span>(campareDepth(start_clip, end_clip, start_pos_world, end_pos_world, (<span class="hljs-type">float</span>(i)-i_divide_pos)*delta, uv))<br>            &#123;<br>                i_divide_pos += i_divide_pos*<span class="hljs-number">0.5</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span><br>            &#123;<br>                i_divide_pos -= i_divide_pos*<span class="hljs-number">0.5</span>;<br>            &#125;<br>            split_count--;<br>        &#125;<br><br>        reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);<br>        <span class="hljs-keyword">break</span>;<br>    &#125;<br><br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>下面是这种方法的结果，可以看到效果是稍微好了些，不过如果需要再进一步的话，还是避免不了要提升采样精度。<br><img src="/2024/12/10/screen-space-reflection/ssr_sample_twice.png" alt="SSR二次采样"></p><h2 id="屏幕空间步进"><a href="#屏幕空间步进" class="headerlink" title="屏幕空间步进"></a>屏幕空间步进</h2><p>目前比较常用的优化方法，是把三维空间做光线步近替换为在屏幕空间做光线步近。<br>传统的在三维空间做光线步近，很难避免采样不均的问题，如果我们是以三维空间的的步近长度作为采样依据的话，会出现下面的问题。其中蓝色小格子代表的是像素，红色的点对应的是每个采样点对应的像素位置。</p><p><img src="/2024/12/10/screen-space-reflection/ssr_over_sample.png" alt="SSR过采样"><br>当反射角度相对来说比较大，很容易出现非常多采样点对应同一个像素，进行了大量的重复运算。</p><p><img src="/2024/12/10/screen-space-reflection/ssr_under_sample.png" alt="SSR欠采样"></p><p>反射角度过小的时候，有很容易出现跳过中间某些像素的情况，出现了欠采样的情况。这也是我们上面的反射效果出现了带状的原因。</p><p>在<a href="https://jcgt.org/published/0003/04/04/">Efficient GPU Screen-Space Ray Tracing</a>这篇文章提出了在屏幕空间采样的观点。通过将采样点的选择放在屏幕空间，实现采样点连续且分布均匀的效果。每个采样点不会进行重复计算，也保证了性能的最优。<br><img src="/2024/12/10/screen-space-reflection/ssr_ss_sample.png" alt="SSR屏幕空间采样方法"></p><p>为了实现屏幕看见步近，代码需要做一些修改：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs glsl">&#123;<br>    ...<br><br>    <span class="hljs-type">vec3</span> start_pos_world = world_pos  + rd*<span class="hljs-number">0.1</span>;<br>    <span class="hljs-type">vec3</span> end_pos_world = world_pos + max_step_dist*rd;<br>    <span class="hljs-comment">// 在屏幕空间上的从起始点到结束点的坐标[0, resolution]</span><br>    <span class="hljs-type">vec4</span> start_clip = vp * <span class="hljs-type">vec4</span>(start_pos_world, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-type">vec4</span> end_clip   = vp * <span class="hljs-type">vec4</span>(end_pos_world, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-comment">// 在屏幕空间进行光线步进</span><br>    <span class="hljs-comment">// 起始点和结束点</span><br>    <span class="hljs-type">vec3</span> start_ndc  = start_clip.xyz / start_clip.w;<br>    <span class="hljs-type">vec3</span> end_ndc    = end_clip.xyz / end_clip.w;<br>    <span class="hljs-type">vec3</span> ndc_diff = end_ndc - start_ndc;<br><br>    <span class="hljs-comment">// ndc-&gt;屏幕坐标 [0, resolution.xy]</span><br>    <span class="hljs-type">vec3</span> start_screen  = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);<br>    start_screen.xy = (start_ndc.xy + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span> * tex_size;<br>    start_screen.z = (near_far.y - near_far.x) * <span class="hljs-number">0.5</span> * start_ndc.z + (near_far.x + near_far.y) * <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-type">vec3</span> end_screen    = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);    <br>    end_screen.xy = (end_ndc.xy + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span> * tex_size;<br>    end_screen.z = (near_far.y - near_far.x) * <span class="hljs-number">0.5</span> * end_ndc.z + (near_far.x + near_far.y) * <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-type">int</span> step_count = <span class="hljs-number">32</span>;<br><br>    <span class="hljs-type">vec3</span> screen_diff = end_screen - start_screen;<br>    <span class="hljs-type">int</span> sample_count = <span class="hljs-type">int</span>(<span class="hljs-built_in">max</span>(<span class="hljs-built_in">abs</span>(screen_diff.x), <span class="hljs-built_in">abs</span>(screen_diff.y)) * resolution) ; <span class="hljs-comment">// 大于1</span><br><br>    sample_count = <span class="hljs-built_in">min</span>(sample_count, <span class="hljs-number">64</span>);<br>    <span class="hljs-type">vec3</span> delta_screen = screen_diff / <span class="hljs-type">float</span>(sample_count);<br><br>    <span class="hljs-comment">// 如果sample count为10，则每次采样的前进的长度为总长度的1/10</span><br>    <span class="hljs-type">float</span> percentage_delta = <span class="hljs-number">1.0</span> / <span class="hljs-type">float</span>(sample_count);<br>    <span class="hljs-type">vec3</span> current_screen = start_screen;<br>    <span class="hljs-type">vec3</span> last_screen = current_screen;<br>    <span class="hljs-type">float</span> current_percentage = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> last_percentage = <span class="hljs-number">0.0</span>;<br><br>    ...<br><br></code></pre></td></tr></table></figure><p>使用屏幕空间步近，前面和原来的差不多，在获取步近的起始点和结束点的时候，需要将坐标转换为屏幕空间的坐标，也就是其中的current_screen和last_screen。</p><p>屏幕空间采样点数和<strong>采样的起始和结束位置的像素差值</strong>有关，所以和渲染输出的分辨率也是相关的。如果渲染分辨率越高，其对应所需要的采样点数可能也会增加，这里我们控制在64以内。当然如果起始点和结束点的像素差值较小，对应的采样点数也会变小，也就是对于距离相机很远的位置的采样会减少，在怎么不影响效果的情况下提升性能表现。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs glsl">    ...<br><br>    <span class="hljs-type">vec4</span> reflect_color = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_count; i++)<br>    &#123;<br>        <span class="hljs-comment">// 采样当前屏幕上的点对应场景世界空间坐标的位置</span><br>        <span class="hljs-type">vec2</span> uv = current_screen.xy / tex_size;<br><br>        <span class="hljs-comment">// 转换为贴图坐标，检查越界</span><br>        <span class="hljs-keyword">if</span>(uv.x &lt; <span class="hljs-number">0.0</span> || uv.y &lt; <span class="hljs-number">0.0</span> || uv.x &gt; <span class="hljs-number">1.0</span> || uv.y &gt; <span class="hljs-number">1.0</span>)<br>        &#123;<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>            <span class="hljs-comment">// 延迟渲染存储的屏幕对应的世界位置</span><br>            <span class="hljs-type">vec3</span> sample_world = <span class="hljs-built_in">texture</span>(scene_position, uv).xyz;<br>            <br>            <span class="hljs-type">vec4</span> sample_ndc = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">mix</span>(start_ndc, end_ndc, current_percentage), <span class="hljs-number">1.0</span>);<br>            <span class="hljs-keyword">if</span>(compareDepth(sample_ndc, uv))<br>            &#123;<br>                <span class="hljs-comment">// 初筛后再二分法检查</span><br>                <span class="hljs-type">int</span> split_count = <span class="hljs-number">5</span>;<br>                <span class="hljs-keyword">while</span>(split_count &gt; <span class="hljs-number">0</span>)<br>                &#123;<br>                    <span class="hljs-type">vec3</span> mid_screen = (last_screen + current_screen) * <span class="hljs-number">0.5</span>;<br>                    <span class="hljs-type">float</span> mid_percentage = (last_percentage + current_percentage) * <span class="hljs-number">0.5</span>;<br>                    <span class="hljs-type">vec4</span> mid_ndc = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">mix</span>(start_ndc, end_ndc, mid_percentage), <span class="hljs-number">1.0</span>);<br>                    uv = mid_screen.xy / tex_size;<br>                    <span class="hljs-keyword">if</span>(compareDepth(mid_ndc, uv))<br>                    &#123;<br>                        current_screen = mid_screen;<br>                    &#125;<br>                    <span class="hljs-keyword">else</span><br>                    &#123;<br>                        last_screen = mid_screen;<br>                    &#125;<br>                    split_count--;<br>                &#125;<br><br>                reflect_color = <span class="hljs-built_in">texture</span>(scene_color, uv);<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br><br>            last_screen = current_screen;<br>            last_percentage = current_percentage;<br>            current_screen += delta_screen;<br>            current_percentage += percentage_delta;<br>        &#125;<br>    &#125;<br><br>    FragColor = reflect_color*metallic;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><p>这里在屏幕空间采样还配合了之前的粗筛和精筛的方法，下面是使用屏幕空间采样的表现。可以看到条纹的状况被极大的缓解了。</p><p><img src="/2024/12/10/screen-space-reflection/ssr_result.png" alt="SSR屏幕空间采样结果"></p><p>应用在实际场景中，SSR的效果能比较明显的提升渲染质感。<br><img src="/2024/12/10/screen-space-reflection/ssr_mugshot.png" alt="SSR实际应用"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>SSR是一种计算场景的反射效果的算法，它基于屏幕空间已有的深度图和法线图等信息，通过计算反射向量，在屏幕空间中进行光线追踪，查找反射光线与场景中其他物体的相交点，获取相交点的颜色作为反射颜色，并与原始颜色合成得到最终渲染结果。</p><p>SSR的优点是计算效率相对较高，能实时反映场景中物体的变化，适用于复杂几何形状和不规则表面，适合大规模的动态场景，无需额外的镜头或几何体。</p><p>当然，SSR也有局限性，它只能反射屏幕上可见的物体，超出屏幕边界的内容无法被反射；反射的物体可能存在失真或错误，尤其是边缘区域；依赖屏幕分辨率，高分辨率下可能对性能有较大影响</p><h2 id="SSR的优化改进算法："><a href="#SSR的优化改进算法：" class="headerlink" title="SSR的优化改进算法："></a>SSR的优化改进算法：</h2><h3 id="SSSR（Spatially-Separated-Screen-Space-Reflection）"><a href="#SSSR（Spatially-Separated-Screen-Space-Reflection）" class="headerlink" title="SSSR（Spatially Separated Screen Space Reflection）"></a>SSSR（Spatially Separated Screen Space Reflection）</h3><p>原理：SSSR 是对传统 SSR 技术的一种改进。它主要是基于空间分离的思想来处理屏幕空间反射。传统 SSR 在处理反射时可能会受到屏幕空间限制和采样不足等问题的影响。SSSR 通过将屏幕空间划分为不同的区域，在这些区域内分别进行更精细的反射处理。</p><p>例如，它可以根据场景中物体的距离、重要性或者反射特性等因素，对空间进行划分。对于反射效果比较复杂或者重要的区域，分配更多的资源进行反射计算，而对于相对简单或者不重要的区域，则采用较为简略的计算方式。</p><p>优点：</p><ul><li>提高反射精度：通过对特定区域的精细处理，能够有效提高反射的精度。比如在处理具有高反射率的物体表面或者复杂的光照反射场景时，可以得到更真实、细腻的反射效果。</li><li>优化性能：与传统 SSR 相比，SSSR 能够更合理地分配计算资源。它避免了在整个屏幕空间进行统一标准的反射计算，从而在一定程度上减轻了计算负担，特别是在大规模复杂场景中，可以更好地平衡反射效果和性能。</li></ul><p>局限性：</p><ul><li>空间划分的复杂性：如何合理地划分空间是一个具有挑战性的问题。如果空间划分不合理，可能会导致反射效果出现不自然的边界或者遗漏重要的反射区域。</li><li>增加算法复杂度：空间划分和不同区域的分别处理增加了算法的复杂度。这可能会导致开发和调试的难度增加，并且在某些情况下，可能会引入新的错误或者视觉瑕疵。</li></ul><h3 id="Hi-z-SSR（Hierarchical-z-Screen-Space-Reflection）"><a href="#Hi-z-SSR（Hierarchical-z-Screen-Space-Reflection）" class="headerlink" title="Hi-z SSR（Hierarchical - z Screen Space Reflection）"></a>Hi-z SSR（Hierarchical - z Screen Space Reflection）</h3><p>原理：Hi - z SSR 是利用层次化的深度信息（Hierarchical-z）来改进 SSR。它构建了一个层次化的深度缓冲区，这个缓冲区可以更有效地存储和检索深度信息。在计算反射时，通过这个层次化的结构，可以快速地在不同层次的深度信息中进行搜索和采样。<br>例如，在较高层次的深度信息中，可以快速定位反射光线可能相交的大致区域，然后在较低层次的深度信息中进行更精细的搜索，就像在地图的不同比例尺中查找目标位置一样。这种层次化的搜索方式能够更高效地利用深度信息来计算反射。</p><p>优点：</p><ul><li>高效的深度搜索：层次化的深度搜索大大提高了反射光线与场景相交点的查找效率。尤其是在处理具有深度层次丰富的复杂场景时，能够快速定位反射位置，减少计算时间。</li><li>增强的反射范围：由于能够更好地利用深度信息，Hi-z SSR 可以在一定程度上缓解传统 SSR 中屏幕外反射难以处理的问题。它可以通过层次化的深度结构，对屏幕外部分场景的深度信息进行合理推测和利用，从而扩展反射的有效范围。</li></ul><p>局限性</p><ul><li><p>深度缓冲区的构建成本：构建层次化的深度缓冲区需要额外的存储空间和计算资源来生成和维护。这可能会在一些资源受限的场景或者硬件平台上带来一定的负担。</p></li><li><p>精度与性能的平衡：尽管 Hi-z SSR 提高了搜索效率，但在平衡反射精度和性能方面仍然是一个挑战。在某些情况下，过于追求效率可能会导致反射精度下降，而过度强调精度又可能会使性能开销过大。</p></li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html">https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html</a></p><p><a href="https://jcgt.org/published/0003/04/04/">https://jcgt.org/published/0003/04/04/</a></p><p><a href="https://blog.csdn.net/qjh5606/article/details/120102582?ops_request_misc=%257B%2522request%255Fid%2522%253A%25225a1434f7df5d388dc4166f4877eb172b%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=5a1434f7df5d388dc4166f4877eb172b&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-120102582-null-null.142%5Ev100%5Econtrol&utm_term=Efficient%20GPU%20Screen-Space%20Ray%20Tracing&spm=1018.2226.3001.4187">https://blog.csdn.net/qjh5606/article/details/120102582?ops_request_misc=%257B%2522request%255Fid%2522%253A%25225a1434f7df5d388dc4166f4877eb172b%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=5a1434f7df5d388dc4166f4877eb172b&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-120102582-null-null.142^v100^control&amp;utm_term=Efficient%20GPU%20Screen-Space%20Ray%20Tracing&amp;spm=1018.2226.3001.4187</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>软阴影的实现（PCF和PCSS）</title>
    <link href="/2024/12/08/soft-shadow/"/>
    <url>/2024/12/08/soft-shadow/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是软阴影"><a href="#什么是软阴影" class="headerlink" title="什么是软阴影"></a>什么是软阴影</h1><p>在3D中实现阴影最基础的方法是使用阴影贴图shadowmap，根据shadowmap中存储的信息来判定当前渲染的像素是否在阴影当中。</p><p>阴影贴图的方法很好理解，但是仅仅基于阴影贴图的阴影效果，在阴影的边缘会有锯齿的情况出现。这往往是由于阴影贴图的分辨率不够导致的，然而一味的提升阴影贴图的分辨率也不是方法，毕竟实时渲染的性能也是需要考虑的一个方面。</p><p>那么该如何在可接受的性能表现下实现软阴影的效果呢，下面详细介绍两种方法：Percentage Closer Filtering（PCF）以及Percentage Closer Soft Shadows（PCSS）。</p><h1 id="柔和阴影边缘-PCF"><a href="#柔和阴影边缘-PCF" class="headerlink" title="柔和阴影边缘-PCF"></a>柔和阴影边缘-PCF</h1><p>下面是一个普通的阴影效果：<br><img src="/2024/12/08/soft-shadow/normal-shadow.png" alt="普通的阴影效果"><br>这个阴影贴图的分辨率是2048，这是在<a href="https://ruochenhua.github.io/2024/10/13/cascade-shadow-map/">CSM</a>的最低一级的阴影效果。可以看到阴影边缘的锯齿感非常的强烈，同时由于采样精度的问题，模型的腿上也出现了不正确的阴影区域。最简单的方法就是通过提高阴影贴图的分辨率来缓解这个问题，但是显而易见这不是最好的解决方案，而Percentage Closer Filtering（后简称PCF）可以帮助我们解决这个问题。</p><h2 id="什么是PCF"><a href="#什么是PCF" class="headerlink" title="什么是PCF"></a>什么是PCF</h2><p>Percentage Closer Filtering（PCF）是一种在计算机图形学中用于生成软阴影的技术。它主要用于解决硬阴影（如简单的阴影映射产生的锐利阴影边缘）不符合真实场景光照效果的问题。</p><p>与简单的阴影映射不同，PCF 在判断像素是否在阴影中时，不是只比较单个点的深度。它会在像素点周围的一定区域内进行多次采样。例如，在一个以像素点为中心的小区域（通常是方形或圆形区域）内，对多个采样点进行深度比较。这些采样点的位置可以是均匀分布，也可以采用更复杂的分布方式，如泊松分布，以获得更自然的效果。</p><p>对于每个采样点，比较其深度和阴影图中的深度来判断是否在阴影中。然后统计在阴影中的采样点的比例。设采样点总数为<strong>N</strong>，处于阴影中的采样点数量为<strong>n</strong>，则阴影强度可以通过公式计算<strong>shadow&#x3D;n&#x2F;N</strong>得到。这个阴影强度用于确定像素最终的阴影效果。如果阴影强度为1，表示像素完全处于阴影中；如果阴影强度为0，表示像素完全不在阴影中；介于两者之间的值表示不同程度的软阴影效果。</p><h2 id="PCF的实现"><a href="#PCF的实现" class="headerlink" title="PCF的实现"></a>PCF的实现</h2><p>转换为代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> CalculatePCFShadow(<span class="hljs-type">float</span> current_depth, <span class="hljs-type">sampler2D</span> shadow_map,  <span class="hljs-type">vec2</span> uv, <span class="hljs-type">int</span> radius)<br>&#123;<br>    <span class="hljs-type">float</span> shadow = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">vec2</span> texel_size = <span class="hljs-number">1.0</span> / <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(shadow_map, <span class="hljs-number">0</span>));<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> x = -radius; x &lt;= radius; ++x)<br>    &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> y = -radius; y &lt;= radius; ++y)<br>        &#123;<br>            <span class="hljs-type">float</span> pcf_depth = <span class="hljs-built_in">texture</span>(shadow_map, <span class="hljs-type">vec2</span>(uv + <span class="hljs-type">vec2</span>(x, y) * texel_size)).r;<br>            shadow += current_depth &gt; pcf_depth ? <span class="hljs-number">1.0</span> : <span class="hljs-number">0.0</span>;<br>        &#125;<br>    &#125;<br>    shadow /= <span class="hljs-built_in">pow</span>((<span class="hljs-number">1</span>+radius*<span class="hljs-number">2</span>),<span class="hljs-number">2.0</span>);<br>    <span class="hljs-keyword">return</span> shadow;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我使用了矩形的采样区域，可以看到其实当采样区域的半径为1的时候，采样点个数为9，阴影边缘的锯齿感已经得到了明显的改善。模型腿上也没有出现错误的阴影区域，效果大大提升。</p><p><img src="/2024/12/08/soft-shadow/pcf-shadow-1.png" alt="PCF阴影，采样半径1"></p><p>当采样半径提升为3，采样点个数为49时，阴影的边缘软化效果更明显了，不过付出了5倍的性能消耗，提升确并没有非常明显。</p><p><img src="/2024/12/08/soft-shadow/pcf-shadow-3.png" alt="PCF阴影，采样半径3"> </p><h1 id="半影的产生-PCSS"><a href="#半影的产生-PCSS" class="headerlink" title="半影的产生-PCSS"></a>半影的产生-PCSS</h1><h2 id="什么是本影和半影"><a href="#什么是本影和半影" class="headerlink" title="什么是本影和半影"></a>什么是本影和半影</h2><p>在实际的场景中，我们观察阴影，会发现下面这种情况：</p><p><img src="/2024/12/08/soft-shadow/real_shadow.png" alt="现实阴影"><br>物体的深暗影子周围还有一片区域是浅浅的暗影。深暗影子的区域我们称之为“<strong>本影</strong>”，而浅暗影子的区域我们称之为“<strong>半影</strong>”。</p><p>这种现象在体积光照（或者区域光照）的情况下很容易出现。其原因是，很多光源是有范围的，如下图假设有一个光源的大小用L1到L2，光源的右边有一个物体。</p><p><img src="/2024/12/08/soft-shadow/umbra-principle.png" alt="本影和半影的原理"></p><p>光源最上点位L1的位置，照向物体的时候，产生的阴影范围是<strong>A区域</strong>以及下方的<strong>B区域</strong>，上方的<strong>B区域</strong>会被L1照亮；L2点产生的阴影范围是<strong>A区域</strong>和上方的<strong>B区域</strong>，下方的<strong>B区域</strong>会被L2照亮。所以我们可以看到，<strong>区域A</strong>是光源完全的光都会被挡住的区域，所以他的阴影是最深的，是为<strong>本影</strong>。而两个<strong>区域B</strong>是挡住了光源的部分区域，同时被光源的另外一部分照亮的，是为<strong>半影</strong>。</p><p><img src="/2024/12/08/soft-shadow/umbra-contrast.png" alt="本影和半影的对照区域"></p><h2 id="什么是PCSS"><a href="#什么是PCSS" class="headerlink" title="什么是PCSS"></a>什么是PCSS</h2><p>在弄明白什么是本影和半影之后，我们来介绍一下PCSS是什么。</p><p>Percentage Closer Soft Shadows（PCSS）即百分比渐近软阴影，是计算机图形学中用于生成更逼真软阴影的一种技术，它是在 Percentage Closer Filtering（PCF）基础上发展而来的。</p><p>在PCF的基础上，PCSS还额外考虑了光源、遮挡物和接收阴影的物体之间的几何关系，通过这些关系来调整用于计算阴影强度的采样区域大小。通过根据阴影的不同情况动态调整采样区域的大小，PCSS能生成更自然、更符合物理规律的软阴影。</p><p>这里是提出PCSS的<a href="https://developer.download.nvidia.com/shaderlibrary/docs/shadow_PCSS.pdf">论文</a>。</p><p>其原理总结起来就是根据采样一个区域内处于阴影的比例，来动态的调节这个区域对应的阴影的采样范围。</p><h2 id="PCSS的实现步骤"><a href="#PCSS的实现步骤" class="headerlink" title="PCSS的实现步骤"></a>PCSS的实现步骤</h2><p>PCSS的实现步骤如下：</p><p>首先，计算平均的遮挡物距离。在阴影图中，以当前像素点为中心，在一个初始的较小采样区域内查找深度值小于当前像素点深度的采样点，这些采样点对应的物体即为遮挡物。通过计算这些遮挡物采样点深度的平均值，得到平均遮挡物距离<strong>d_blocker</strong>。</p><p><img src="/2024/12/08/soft-shadow/get-d_blocker-1.png" alt="采样平均遮挡物距离1"></p><p>对应代码为：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> FindBlockerDepth(<span class="hljs-type">sampler2D</span> shadowmap, <span class="hljs-type">vec2</span> uv, <span class="hljs-type">float</span> d_receiver, <span class="hljs-type">float</span> radius)<br>&#123;<br>    <span class="hljs-type">float</span> blocker_depth_sum = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">int</span> blocker_count = <span class="hljs-number">0</span>;<br>    <br>    <span class="hljs-comment">// 以当前像素为中心,半径为radius的范围采样</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">float</span> y = -radius; y &lt;= radius; y++) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">float</span> x = -radius; x &lt;= radius; x++) &#123;<br>            <span class="hljs-type">vec2</span> <span class="hljs-keyword">offset</span> = <span class="hljs-type">vec2</span>(x, y) * <span class="hljs-number">1.0</span> / <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(shadowmap, <span class="hljs-number">0</span>));<br>            <span class="hljs-type">float</span> sampleDepth = TextureProjBilinear(shadowmap, uv + <span class="hljs-keyword">offset</span>);<br>            <span class="hljs-keyword">if</span> (sampleDepth &lt; d_receiver) &#123;<br>                blocker_depth_sum += sampleDepth;<br>                blocker_count++;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> blocker_count &gt; <span class="hljs-number">0</span>? blocker_depth_sum / <span class="hljs-type">float</span>(blocker_count) : <span class="hljs-number">0.0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中<strong>d_receiver</strong>为当前像素点到光源的深度值，这个值可以将当前像素点位置变换到光源的投影下得到，在处理阴影贴图的时候就需要拿到了。TextureProjBilinear是获取shadowmap深度值的方法，里面采用了双线性插值的方法，不过对PCSS来说不一定需要使用这个方法。</p><p>可以看到这个阶段，PCSS搜索了一个阴影贴图里面的区域（下图红色区域），记录下了这个区域的被阻挡范围的平均深度。</p><p><img src="/2024/12/08/soft-shadow/get-d_blocker-2.png" alt="采样平均遮挡物距离2"></p><p>然后根据这个范围，以及三角形相似原理，估算出半影半径。</p><p><img src="/2024/12/08/soft-shadow/penumbra.png" alt="计算半影半径"><br>其中d_receiver、d_blocker我们已知，W_light是光源的范围大小，可以根据实际情况来调整。用图上右方的公式，得出半影的采样范围W_penumbra。</p><p>代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 计算遮挡物范围半径（基于相似三角形原理）</span><br><span class="hljs-type">float</span> EstimateBlockerSearchRadius(<span class="hljs-type">vec2</span> uv, <span class="hljs-type">float</span> d_receiver, <span class="hljs-type">float</span> d_blocker, <span class="hljs-type">float</span> light_size)<br>&#123;<br>    <span class="hljs-keyword">if</span> (d_blocker == <span class="hljs-number">0.0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span>;<br>    <span class="hljs-keyword">return</span> (d_receiver - d_blocker) * (light_size / d_blocker);<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，根据估算出的半影半径，扩大采样区域，然后在这个更大的区域内进行采样，并按照 PCF 的方式计算阴影强度。这样，离光源较近或遮挡物较近的地方，半影半径较小，阴影较实；离光源较远或遮挡物较远的地方，半影半径较大，阴影较虚，从而实现了更自然的软阴影效果。</p><p>代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> shadow_sum = <span class="hljs-number">0.0</span>f;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> pcss_i = <span class="hljs-number">0</span>; pcss_i &lt; pcss_sample_count; pcss_i++)<br>&#123;<br>    <span class="hljs-comment">// 可以使用泊松采样盘等方法获取更自然的采样点位置，这里简单均匀采样</span><br>    <span class="hljs-type">vec2</span> <span class="hljs-keyword">offset</span> = <span class="hljs-type">vec2</span>(<span class="hljs-built_in">cos</span>(<span class="hljs-type">float</span>(pcss_i) * <span class="hljs-number">2.0</span> * <span class="hljs-number">3.1415926</span> / <span class="hljs-type">float</span>(pcss_sample_count)),<br>    <span class="hljs-built_in">sin</span>(<span class="hljs-type">float</span>(pcss_i) * <span class="hljs-number">2.0</span> * <span class="hljs-number">3.1415926</span> / <span class="hljs-type">float</span>(pcss_sample_count))) * blocker_radius;<br><br>    <span class="hljs-type">vec4</span> sampleLightSpacePos = <span class="hljs-type">vec4</span>(proj_coord.xy + <span class="hljs-keyword">offset</span>, proj_coord.z, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-type">float</span> sampleDepth = TextureProjBilinear(shadow_map, proj_coord.xy+<span class="hljs-keyword">offset</span>);<br>    shadow_sum += sampleDepth &lt; d_recv? <span class="hljs-number">1.0</span> : <span class="hljs-number">0.0</span>;<br>&#125;<br>shadow = shadow_sum / pcss_sample_count;<br></code></pre></td></tr></table></figure><h2 id="PCSS的效果"><a href="#PCSS的效果" class="headerlink" title="PCSS的效果"></a>PCSS的效果</h2><p>下面是PCSS开启和关闭的效果对比，其中PCSS关闭下PCF的采样半径是3：<br><img src="/2024/12/08/soft-shadow/PCSS_OFF.png" alt="PCSS关闭"></p><p><img src="/2024/12/08/soft-shadow/PCSS_ON.png" alt="PCSS开启"></p><p>可以看到开启了PCSS的效果后，遮挡物体的阴影区域，随着离遮挡物越来越远，出现了越来越明显的半影效果，效果更加自然和真实。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="Percentage-Closer-Filtering（PCF）的作用"><a href="#Percentage-Closer-Filtering（PCF）的作用" class="headerlink" title="Percentage Closer Filtering（PCF）的作用"></a>Percentage Closer Filtering（PCF）的作用</h2><ol><li><p>软阴影生成基础：PCF 是一种用于生成软阴影的基础技术。它基于阴影映射，在判断像素是否在阴影中时，不是只比较单个点的深度，而是在像素点周围一定区域内进行多次采样。</p></li><li><p>阴影强度计算：通过统计采样区域内处于阴影中的采样点比例来计算阴影强度。这种方式能有效避免硬阴影边缘的锯齿问题，使阴影边缘过渡更加自然，产生软阴影效果，提升了阴影的真实感。</p></li><li><p>平衡性能和效果：相对一些复杂的物理软阴影算法，PCF 较为简单，在性能和效果之间取得了较好的平衡，适用于实时渲染场景，如游戏。</p></li></ol><h2 id="Percentage-Closer-Soft-Shadows（PCSS）的作用"><a href="#Percentage-Closer-Soft-Shadows（PCSS）的作用" class="headerlink" title="Percentage Closer Soft Shadows（PCSS）的作用"></a>Percentage Closer Soft Shadows（PCSS）的作用</h2><ol><li><p>动态软阴影生成：PCSS 在 PCF 基础上进一步改进。它能够根据光源、遮挡物和接收阴影物体之间的几何关系动态调整采样区域的大小。</p></li><li><p>更自然的阴影过渡：通过计算平均遮挡物距离和估算半影半径，根据半影半径调整采样区域进行采样计算阴影强度。这样生成的软阴影更加符合物理规律，阴影从完全阴影到完全光照的过渡更加自然、真实，在需要高逼真度渲染的场景中能显著提升视觉质量。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>阴影</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>反射阴影贴图</title>
    <link href="/2024/11/24/reflective-shadow-map/"/>
    <url>/2024/11/24/reflective-shadow-map/</url>
    
    <content type="html"><![CDATA[<h1 id="反射阴影贴图简介"><a href="#反射阴影贴图简介" class="headerlink" title="反射阴影贴图简介"></a>反射阴影贴图简介</h1><p>反射阴影贴图（Reflective Shadow Map）是实现全局光照效果的一个非常经典的方法，它是在这篇<a href="https://users.soe.ucsc.edu/~pang/160/s13/proposal/mijallen/proposal/media/p203-dachsbacher.pdf">论文</a>中被提出。</p><h2 id="直接光照和间接光照"><a href="#直接光照和间接光照" class="headerlink" title="直接光照和间接光照"></a>直接光照和间接光照</h2><p>它的名字中带有“阴影贴图（Shadow Map）”几个字，所以乍看之下这个方法似乎是用来解决阴影问题，或者是提升阴影效果的。其实不然，它是用来解决<strong>间接光照</strong>的问题的方法。</p><p>在一般的场景中，光照可以大致分为两类：</p><ul><li>一类是直接光照，也就是物体被光源直接照亮的部分。这个类型的光照是比较好计算的，通过光源的入射角，物体表面的法线和材质，以及观察的方向等等，利用<strong>PBR</strong>的方法能够得到非常不错的效果，这个流程在KongEngine中已经基本实现了。</li><li>另外一个类型是间接光照，它代表的是光线经过一次甚至多次反射后照亮物体的部分。相对于直接光照，间接光照十分复杂，因为光线可能经过多次反射，想要实时的计算光的多次反射的完整路径是很难实现的。但是如果不包含间接光照的话，场景的真实度会大打折扣。在最基础的PBR渲染框架中，我们可以选择手动输入一个环境光照（Ambient Light）的颜色，可以简单的表现全局光照，但是真实性还是不够。</li></ul><p>反射阴影贴图（下面简称<strong>RSM</strong>）这个方法，就是用于解决实时模拟间接光照的问题。</p><h2 id="RSM算法基本介绍"><a href="#RSM算法基本介绍" class="headerlink" title="RSM算法基本介绍"></a>RSM算法基本介绍</h2><p>RSM的核心思想是将被光源直接照亮的区域再次作为光源进行光照计算，这就是光的一次反射。RSM只计算一次光反射，因为一般来说光的第一次反射的能量残留相对来说是最大的，对场景来说有较为显著的影响，后面的反射对场景影响较小，为了性能考量可以忽略。</p><p>那么怎么知道光照直接亮了哪些区域呢？其实非常简单，在参考实现阴影贴图（Shadow Map）的概念，从光源视角下进行渲染，不在阴影中的区域就是被光源直接照亮的。另外，由于光线在漫反射时会被照亮区域的材质所影响（比如说白色的光线从红色的墙反射会变成红色，因为其他颜色被吸收，同时不同粗糙度的物质反射方式也不一样），以及照亮区域的位置和法线也会影响计算光反射的方向，因此我们在计算阴影贴图的时候，还需要保存照亮区域的颜色、世界位置、法线等数据。</p><p>下面是需要记录的数据的截图，从左到右分别是：深度、位置坐标、法线、颜色。<br><img src="/2024/11/24/reflective-shadow-map/rsm_info.png" alt="光源方向记录的数据"></p><p>因此接下来光照计算可以分为以下几步：</p><ol><li>首先从光源的位置和方向渲染场景，将光源视角的信息（深度，世界位置，世界法线等等）缓存到buffer中。</li><li>计算光照直接对环境的影响。</li><li>将第一步缓存的光源保存的信息加入到场景中光照的计算，加上阴影（阴影贴图）和间接光照（反射阴影贴图）。</li></ol><h1 id="实现反射阴影贴图的步骤"><a href="#实现反射阴影贴图的步骤" class="headerlink" title="实现反射阴影贴图的步骤"></a>实现反射阴影贴图的步骤</h1><p>下面是在KongEngine中实现RSM的步骤。</p><h2 id="一些前期准备"><a href="#一些前期准备" class="headerlink" title="一些前期准备"></a>一些前期准备</h2><p>RSM需要将一些信息存储到buffer中，所以很首先需要设置新的缓冲。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glGenFramebuffers</span>(<span class="hljs-number">1</span>, &amp;rsm_fbo);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, rsm_fbo);<br><br><span class="hljs-comment">// 位置数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;rsm_world_position);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_position);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, rsm_world_position, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 法线数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;rsm_world_normal);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_normal);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, rsm_world_normal, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// flux数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;rsm_world_flux);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_flux);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, rsm_world_flux, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 生成renderbuffer</span><br><span class="hljs-built_in">glGenRenderbuffers</span>(<span class="hljs-number">1</span>, &amp;rsm_depth);<br><span class="hljs-built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, rsm_depth);<br><span class="hljs-built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, SHADOW_RESOLUTION, SHADOW_RESOLUTION);<br><span class="hljs-built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, rsm_depth);<br><span class="hljs-built_in">glEnable</span>(GL_DEPTH_TEST);<br><br>GLuint g_attachments[] = &#123;GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2&#125;; <br><span class="hljs-built_in">glDrawBuffers</span>(<span class="hljs-number">3</span>, g_attachments);<br></code></pre></td></tr></table></figure><p>上面的部分用于构建RSM的缓冲，这些内容和之前的Shadowmap的流程类似，也可以考虑将其和Shadowmap的缓冲合并，不过为了方便自己理解目前是新建了一个。</p><p>另外RSM也新建了一个独立的shader</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++">map&lt;EShaderType, string&gt; shader_path_map = &#123;<br>    &#123;EShaderType::vs, CSceneLoader::<span class="hljs-built_in">ToResourcePath</span>(<span class="hljs-string">&quot;shader/shadow/reflective_shadowmap.vert&quot;</span>)&#125;,<br>    &#123;EShaderType::fs, CSceneLoader::<span class="hljs-built_in">ToResourcePath</span>(<span class="hljs-string">&quot;shader/shadow/reflective_shadowmap.frag&quot;</span>)&#125;<br>&#125;;<br>rsm_shader = <span class="hljs-built_in">make_shared</span>&lt;Shader&gt;(shader_path_map);<br></code></pre></td></tr></table></figure><p>shader的内容十分简单，<em>顶点着色器</em>简单的将顶点的世界坐标和法线传给片段着色器。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-comment">// Input vertex data, different for all executions of this shader.</span><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_pos;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> in_normal;<br><br><span class="hljs-comment">// Values that stay constant for the whole mesh.</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> light_space_mat;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> model;<br><br><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> frag_pos;<br><span class="hljs-keyword">out</span> <span class="hljs-type">vec3</span> frag_normal;<br><br><span class="hljs-type">void</span> main()&#123;<br><span class="hljs-built_in">gl_Position</span> =  light_space_mat * model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1</span>);<br>    frag_pos = model * <span class="hljs-type">vec4</span>(in_pos, <span class="hljs-number">1</span>);<br>frag_normal = <span class="hljs-built_in">normalize</span>(<span class="hljs-type">mat3</span>(<span class="hljs-built_in">transpose</span>(<span class="hljs-built_in">inverse</span>(model))) * in_normal);<br>&#125;<br></code></pre></td></tr></table></figure><p>由于这个shader是从光源视角渲染的，所以<strong>gl_Position</strong>是由光源的<strong>light_space_mat</strong>对世界坐标做变换。</p><p><em>片段着色器</em>将RSM所需的内容存储起来。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> world_pos;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> world_normal;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">2</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> world_flux;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> frag_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> frag_normal;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">vec4</span> albedo;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> light_intensity;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>world_pos = frag_pos;<br>    world_normal = <span class="hljs-type">vec4</span>(frag_normal, <span class="hljs-number">1</span>);<br>    world_flux = albedo;<span class="hljs-comment">// * light_intensity;</span><br>&#125;<br></code></pre></td></tr></table></figure><p>我们这里分别将<strong>世界坐标、世界法线和颜色</strong>存储了到了贴图中。<br>方便起见，KongEngine暂时只支持平行光源的RSM效果，点光源的目前不支持。</p><p>现在我们的平行光源已经有了RSM相关的信息了，在计算光照的时候将这些贴图信息传到光照计算的shader中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + DIRLIGHT_RSM_WORLD_POS);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_pos);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + DIRLIGHT_RSM_WORLD_NORMAL);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_normal);<br><span class="hljs-built_in">glActiveTexture</span>(GL_TEXTURE0 + DIRLIGHT_RSM_WORLD_FLUX);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, rsm_world_flux);<br></code></pre></td></tr></table></figure><h2 id="间接光源的判定"><a href="#间接光源的判定" class="headerlink" title="间接光源的判定"></a>间接光源的判定</h2><p>RSM的实际原理如下面两张图所示：<br><img src="/2024/11/24/reflective-shadow-map/rsm_principle_1.png" alt="rsm原理图1"></p><p>假如当前我们片段着色器计算的是<strong>X</strong>点的光照，在这个场景中，x点被桌子的阴影挡住了，并没有被光源直接照亮，如左图所示。所以x点的直接光照为0。</p><p>接下来是间接光照的部分。如上面所说，我们将被光源直接照亮的部分当做光源，这里先以被光源直接照射的两个点Xp和Xq来做判断。Xp点被光源照亮，他的法线是Np，光在Xp点散射后是有可能到达X点的，在数学上的判断就是Np和Xp到X连线的点乘大于0。而Xq的法线Nq和Xq到X点连线的点乘小于0，可以从图上看到光在Xq点散射后是无法到达X点的。</p><p>当然我们还知道，在计算PBR的时候，不同的材质的光线散射形状是不一致的，在图中的表现就是，光线散射后沿着XpX方向的分量，比沿着XpY方向的分量是要小的。因此间接光源的法线和两点之间的连线的点乘大小有这判定间接光源亮度的作用。</p><p>下面这张图和原理图1是一样的，强化一下理解。<br><img src="/2024/11/24/reflective-shadow-map/rsm_principle_2.png" alt="rsm原理图2"></p><h2 id="采样间接光源"><a href="#采样间接光源" class="headerlink" title="采样间接光源"></a>采样间接光源</h2><p>之前说到，需要用被光源照亮的点作为间接光源。如果渲染屏幕上像素点的时候对所有照亮的点都去做判断的话，理论上是可以得到最好的效果，但是性能上会有极大的消耗；相反如果采样点过少的话，计算速度虽然是上去了但是效果会大打折扣。</p><p>因此一个优化方法是通过重要性采样。我们判断离当前渲染点越近的间接光照光源对当前点的最终效果影响就越大，因此离当前点近的间接光源采样点就会越多。并且，为了弥补远处的采样点过少可能带来的问题，引入权重的概念，随着采样点离当前点越近，权重越小。</p><p><img src="/2024/11/24/reflective-shadow-map/rsm_sample.png" alt="rsm采样点选择"></p><p>下面是采样点初始化的示例代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// rsm采样点初始化</span><br>std::default_random_engine e;<br><span class="hljs-function">std::uniform_real_distribution&lt;<span class="hljs-type">float</span>&gt; <span class="hljs-title">u</span><span class="hljs-params">(<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>)</span></span>;<br><span class="hljs-type">float</span> pi_num = <span class="hljs-built_in">pi</span>&lt;<span class="hljs-type">float</span>&gt;();<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; rsm_sample_count; i++)<br>&#123;<br>    <span class="hljs-type">float</span> xi1 = <span class="hljs-built_in">u</span>(e);<br>    <span class="hljs-type">float</span> xi2 = <span class="hljs-built_in">u</span>(e);<br>    <br>    rsm_samples_and_weights.<span class="hljs-built_in">push_back</span>(<span class="hljs-built_in">vec4</span>(xi1*<span class="hljs-built_in">sin</span>(<span class="hljs-number">2</span>*pi_num*xi2), xi1*<span class="hljs-built_in">cos</span>(<span class="hljs-number">2</span>*pi_num*xi2), xi1*xi1, <span class="hljs-number">0.0</span>));<br>&#125;<br></code></pre></td></tr></table></figure><p>结合上面的两个思想，下面是部分最终代码的呈现，位于defer_pbr.frag中。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> max_sample_radius = <span class="hljs-number">128.</span>;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; rsm_sample_count; ++i) <br>&#123;<br>    <span class="hljs-type">vec3</span> rsm_sample_and_weight = rsm_samples_and_weights[i].xyz;<br>    <span class="hljs-type">vec2</span> uv = proj_coord.xy + max_sample_radius * rsm_sample_and_weight.xy * texel_size;<br>    <span class="hljs-type">vec3</span> flux = <span class="hljs-built_in">texture</span>(rsm_world_flux, uv).rgb;<br>    <span class="hljs-type">vec3</span> x_p = <span class="hljs-built_in">texture</span>(rsm_world_pos, uv).xyz;<br>    <span class="hljs-type">vec3</span> n_p = <span class="hljs-built_in">texture</span>(rsm_world_normal, uv).xyz;<br><br>    <span class="hljs-type">vec3</span> r = <span class="hljs-built_in">normalize</span>(frag_world_pos.xyz - x_p);<br><br>    <span class="hljs-type">float</span> d2 = <span class="hljs-built_in">dot</span>(r, r);<br>    <span class="hljs-type">vec3</span> e_p = flux * (<span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">dot</span>(n_p, r)) * <span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">dot</span>(in_normal, -r))) * rsm_sample_and_weight.z;<br>    <span class="hljs-comment">//e_p *= pow(rsm_sample_offsets[i].x / d2, 2);</span><br>    env_color += e_p;<br>&#125;<br>env_color /= rsm_sample_count;<br></code></pre></td></tr></table></figure><h1 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h1><p>结合了反射阴影贴图后，场景会有一些间接光照效果了，下面是同一个场景的表现效果。<br><img src="/2024/11/24/reflective-shadow-map/rsm_off_sphere.png" alt="rsm关闭1"><br><img src="/2024/11/24/reflective-shadow-map/rsm_on_sphere.png" alt="rsm开启1"></p><p>这里是另外一组。<br><img src="/2024/11/24/reflective-shadow-map/rsm_off_suit.png" alt="rsm关闭2"><br><img src="/2024/11/24/reflective-shadow-map/rsm_on_suit.png" alt="rsm开启2"></p><p>可以看到开启rsm后，靠近红色和绿色墙壁，且没有被光源直接照亮（处于阴影）的部分，被墙壁的散射光源间接点亮了。灰色的球体和人物模型“沾染”上了墙壁的颜色。这种间接光照的影响使得场景变得更加的真实。</p><p>但是，当前的rsm也并不是完美的，比如说目前rsm缺乏判定间接光源是否可达，在第二个例子中，人物模型的右肩上的间接光源呈现的是黄色，也就是红色和绿色的间接光照结合起来的颜色。但是右肩理论上不应该出现红色的分量，因为红色的部分会被身体部位阻挡。渲染点的法线应该也会影响间接光的表现。</p><p>另外就是被当成间接光源的只有被光源照亮且存储起来的部分区域，也就是说间接光源的采样范围相对来说还是比较局限的，不可能采样非常大的区域。在KongEngine中由于采用了CSM来处理阴影，RSM的范围和CSM的最小级的阴影范围采样是一致的，这种处理显然无法照顾大的场景。</p><p>场景的间接光照还需要进一步的去优化，RSM只是其中一个小部分。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>程序化地形生成-2-性能优化</title>
    <link href="/2024/11/19/ProceduralTerrainGeneration2-optimize/"/>
    <url>/2024/11/19/ProceduralTerrainGeneration2-optimize/</url>
    
    <content type="html"><![CDATA[<h1 id="性能优化的需求"><a href="#性能优化的需求" class="headerlink" title="性能优化的需求"></a>性能优化的需求</h1><p>自从实现了程序化地形生成的那个<a href="https://www.shadertoy.com/view/4XByRV">ShaderToy上的Demo</a>之后，我对它的性能表现一直不太满意，随随便便跑一下我的GPU就直接拉到100%了，电脑风扇呼呼的。做了很多次大大小小的优化，最后发现瓶颈还是在对地形的光线步进计算上，不把这个问题解决掉的话这个场景的性能怎么样都无法达到令我满意的程度。</p><p>于是我一直在寻找类似的场景，寻找有什么光线步进的方法能够满足我的要求：首先它必须是要针对实时随机生成的地形，也就是说不能是针对高度图或者其他预处理过的地形数据；其次它需要快，至少能够在我这台笔记本上（3070ti显卡）能够保持50%以下的占用率；最后就是这个光线步进算法需要有一定的精度，但是要求不会很高。</p><p>最后我在ShaderToy上找到了一个非常棒的<a href="https://www.shadertoy.com/view/4slGD4">例子</a>，来自Dave_Hoskins。</p><p>Dave的Demo也是做了地形的渲染，他的场景比我复杂很多，但是这个更为复杂的场景在我的电脑上运行的时候，它的GPU占用率（分辨率768X432）只有35%左右，远低于我的demo让我大为震撼。</p><p>于是我开始研究它的光线步进的逻辑，如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// source:https://www.shadertoy.com/view/4slGD4</span><br><span class="hljs-type">float</span> BinarySubdivision(<span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> rO, <span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> rD, <span class="hljs-type">vec2</span> t)<br>&#123;<br><span class="hljs-comment">// Home in on the surface by dividing by two and split...</span><br>    <span class="hljs-type">float</span> halfwayT;<br>  <br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5</span>; i++)<br>    &#123;<br><br>        halfwayT = <span class="hljs-built_in">dot</span>(t, <span class="hljs-type">vec2</span>(<span class="hljs-number">.5</span>));<br>        <span class="hljs-type">vec3</span> p = rO + halfwayT*rD;<br>        <span class="hljs-type">float</span> d = p.y - getTerrainHeight(p.xz, perlinOctaves); <br>        <span class="hljs-comment">// float d = Map(rO + halfwayT*rD); </span><br>         t = <span class="hljs-built_in">mix</span>(<span class="hljs-type">vec2</span>(t.x, halfwayT), <span class="hljs-type">vec2</span>(halfwayT, t.y), <span class="hljs-built_in">step</span>(<span class="hljs-number">0.5</span>, d));<br><br>    &#125;<br><span class="hljs-keyword">return</span> halfwayT;<br>&#125;<br><br><span class="hljs-type">bool</span> rayMarchingTerrain(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd, <span class="hljs-type">float</span> max_dist, <span class="hljs-keyword">out</span> <span class="hljs-type">float</span> res_t)<br>&#123;<br>    <span class="hljs-type">float</span> t = <span class="hljs-number">1.</span> + Hash12(g_frag_coord)*<span class="hljs-number">1.</span>;<br><span class="hljs-type">float</span> oldT = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">float</span> delta = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">bool</span> fin = <span class="hljs-literal">false</span>;<br><span class="hljs-type">bool</span> res = <span class="hljs-literal">false</span>;<br><span class="hljs-type">vec2</span> distances;<br><span class="hljs-keyword">for</span>( <span class="hljs-type">int</span> j=<span class="hljs-number">0</span>; j&lt; <span class="hljs-number">150</span>; j++ )<br>&#123;<br><span class="hljs-keyword">if</span> (fin || t &gt; <span class="hljs-number">240.0</span>) <span class="hljs-keyword">break</span>;<br><span class="hljs-type">vec3</span> p = ro + t*rd;<br><span class="hljs-comment">//if (t &gt; 240.0 || p.y &gt; 195.0) break;</span><br><span class="hljs-type">float</span> h = p.y - getTerrainHeight(p.xz, perlinOctaves); <span class="hljs-comment">// ...Get this positions height mapping.</span><br><span class="hljs-comment">// Are we inside, and close enough to fudge a hit?...</span><br><span class="hljs-keyword">if</span>( h &lt; <span class="hljs-number">0.5</span>)<br>&#123;<br>fin = <span class="hljs-literal">true</span>;<br>distances = <span class="hljs-type">vec2</span>(oldT, t);<br><span class="hljs-keyword">break</span>;<br>&#125;<br><span class="hljs-comment">// Delta ray advance - a fudge between the height returned</span><br><span class="hljs-comment">// and the distance already travelled.</span><br><span class="hljs-comment">// It&#x27;s a really fiddly compromise between speed and accuracy</span><br><span class="hljs-comment">// Too large a step and the tops of ridges get missed.</span><br>delta = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.3</span>*h) + (t*<span class="hljs-number">0.0065</span>);<br>oldT = t;<br>t += delta;<br>&#125;<br><span class="hljs-keyword">if</span> (fin) res_t = BinarySubdivision(ro, rd, distances);<br><br><span class="hljs-keyword">return</span> fin;<br>&#125;<br></code></pre></td></tr></table></figure><p>其实代码逻辑很简单，就是光线步进到的位置和当前XZ坐标的地形高度做比对，当光线步进的位置的高度和地形足够近的时候，记为击中。记录当前和上一步的t的位置，在得到最终结果的时候做一个取中间值的操作。</p><p>这个方法的精华部分是这个：**delta &#x3D; max(0.01, 0.3*h) + (t*0.0065);**，它被用于计算光线步进下一步的距离。如果光线步进每一步距离太近，会严重影响性能；而如果一步太远，则会导致地形的精度不足，出现地表抖动甚至断裂的情况。</p><p>Dave的方法，结合了当前位置和地形的高度差h和光线步进已经经过的长度t。高度差越小，说明可能越接近地表，需要较小的步长（反之亦然）；t的影响则表示远处的地形的精度需求可以逐步降低。</p><p>下面是我原来的计算方式。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">bool</span> rayMarchingTerrain(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd, <span class="hljs-type">float</span> max_dist, <span class="hljs-keyword">out</span> <span class="hljs-type">float</span> res_t)<br>&#123;<br>    <span class="hljs-comment">// float terrain_height = sin(iTime) + 1.;    </span><br>    <span class="hljs-type">float</span> dt_min = <span class="hljs-number">0.1</span>f;<br>    <span class="hljs-type">float</span> dt_max = <span class="hljs-number">3.0</span>f;<br><br>    <span class="hljs-type">float</span> dt = <span class="hljs-number">1.0</span>;<br>    res_t = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-comment">// first pass, step 1</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = mint; t &lt; max_dist; t+=dt)<br>    &#123;<br>        <span class="hljs-type">vec3</span> p = ro+t*rd;<br>        <span class="hljs-type">float</span> terrain_height = getTerrainHeight(p.xz, perlinOctaves);<br>        <span class="hljs-keyword">if</span>(p.y &lt; terrain_height )<br>        &#123;        <br>            <span class="hljs-comment">// res_t = t - dt + dt*(last_h - last_p.y) / (p.y - last_p.y-terrain_height+last_h); </span><br>            res_t = t;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;        <br>        <span class="hljs-comment">// // closer terrain use higher accuracy        </span><br>        <span class="hljs-comment">// last_h = terrain_height;        </span><br>        <span class="hljs-comment">// last_p = p;</span><br>        dt = <span class="hljs-built_in">mix</span>(dt_min, dt_max, <span class="hljs-built_in">pow</span>(t / max_dist, <span class="hljs-number">2.0</span>));<br>    &#125;<br><br>    <span class="hljs-comment">// hit terrain</span><br>    <span class="hljs-keyword">if</span>(res_t &gt; <span class="hljs-number">0.</span>)<br>    &#123;<br>        <span class="hljs-type">float</span> last_h = <span class="hljs-number">0.0</span>;<br>        <span class="hljs-type">vec3</span> last_p = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-type">float</span> mini_dt =  <span class="hljs-built_in">max</span>(<span class="hljs-number">0.01</span>, dt * <span class="hljs-number">0.02</span>);<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = res_t - dt; t &lt; res_t + <span class="hljs-number">.01</span>; t+=mini_dt)<br>        &#123;<br>            <span class="hljs-type">vec3</span> p = ro+t*rd;<br>            <span class="hljs-type">float</span> terrain_height = getTerrainHeight(p.xz, perlinOctaves);<br>            <span class="hljs-keyword">if</span>(p.y &lt; terrain_height)<br>            &#123;        <br>                res_t = t - mini_dt + mini_dt*(last_h - last_p.y) / (p.y - last_p.y-terrain_height+last_h); <br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;        <br>            <span class="hljs-comment">// closer terrain use higher accuracy        </span><br>            last_h = terrain_height;        <br>            last_p = p;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <br>&#125;<br></code></pre></td></tr></table></figure><p>我原来的方法的思想是做两遍测试，先以一个较大步长做一次初步筛选，找到大概的光线穿过地形的区间；然后再在那个区间用较小的步长做另外因此光线步进。</p><p>这个方法的问题在于如果初筛的时候步长太大，可能会穿过一个厚度较小的地形（比如说山峰），所以初筛的步长也不能太小；第二次筛选似乎取值也偏小了，导致还是做了很多次的光线步进检测。</p><h1 id="优化结果"><a href="#优化结果" class="headerlink" title="优化结果"></a>优化结果</h1><p>现在我将新的光线步进方法更新到了我原来的ShaderToy Demo上，在768X432的分辨率60fps的情况下，我的demo在我的电脑上的GPU占用率由80%左右降低到了35%左右，可谓是巨大的提升。</p><p>在demo的代码中，我在第一行添加了代码</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#define OLD_METHOD 0</span><br></code></pre></td></tr></table></figure><p>将<strong>OLD_METHOD</strong>改为1的话可以改为使用老方法，各位有兴趣的话可以实际修改一下代码来对比一下这两种方法的性能差异。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>程序化生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>程序化地形生成-2</title>
    <link href="/2024/11/04/ProceduralTerrainGeneration2/"/>
    <url>/2024/11/04/ProceduralTerrainGeneration2/</url>
    
    <content type="html"><![CDATA[<p>距离上一篇将程序化地形生成的<a href="https://ruochenhua.github.io/2024/10/11/ProceduralTerrainGeneration/">教程</a>也已经过去了一段时间了。前段时间一直有其他事情需要忙，现在终于有时间继续之前未完成的工作了。</p><h1 id="丰富地形"><a href="#丰富地形" class="headerlink" title="丰富地形"></a>丰富地形</h1><p>上一篇教程我们已经创建出了绵延的山脉，如下图所示：<br><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_no_grass.png" alt="上次渲染的结果"><br>看起来似乎是有那么点意思了，但是这样的山脉效果还是太单调了。</p><p>接下来我们就计划丰富一下这个场景。</p><h2 id="增加绿植"><a href="#增加绿植" class="headerlink" title="增加绿植"></a>增加绿植</h2><p>我们场景中的山光秃秃的，很像是沙漠，也很像火星上的地貌。</p><p>我想给场景增加一些层次，一些生机，因此我打算将山的一部分渲染为绿植部分。</p><p>那么如何确定哪些部分是绿植，哪些部分是裸露的山体呢？根据地形表面的法线可以做一个简单的判定：法线的y分量越大，也就是面向上的分量越大，表明这个面更平，因此有绿植是更合适的；反正则表明这个面更加陡峭，更适合作为山体表现。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> dirt_color = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.8549</span>, <span class="hljs-number">0.5255</span>, <span class="hljs-number">0.3098</span>);<br><span class="hljs-type">vec3</span> grass_color = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.3137</span>, <span class="hljs-number">0.5412</span>, <span class="hljs-number">0.0157</span>);<br><span class="hljs-comment">// ..</span><br><br><span class="hljs-keyword">if</span>(rd.y &lt; <span class="hljs-number">0.05</span> &amp;&amp; rayMarchingTerrain(ro, rd, maxt, res_t))<br>&#123;<br>    <span class="hljs-type">vec3</span> height_pos = ro+res_t*rd;<br><br>    <span class="hljs-comment">// calculate normla</span><br>    <span class="hljs-type">vec3</span> normal = getNormal(height_pos);<br>    <span class="hljs-type">float</span> grass_ratio = <span class="hljs-built_in">smoothstep</span>(<span class="hljs-number">0.7</span>, <span class="hljs-number">0.98</span>, normal.y);<br>    <span class="hljs-type">vec3</span> ground_color = <span class="hljs-built_in">mix</span>(dirt_color, grass_color, grass_ratio);<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上面是一段实例代码，我们预先设定山体和绿植的颜色，在光线步进山体的时候，获取normal，根据法线的y方向的大小（也可以用dot来判定）做smoothstep取一个合适的值作为当前平面草地的比例，最后混合山体和草地的比例。得到的结果如下：</p><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_grass.png" alt="增加绿植"><br>这样一来场景的丰富程度一下子就提升了。</p><h1 id="天空"><a href="#天空" class="headerlink" title="天空"></a>天空</h1><p>现在最终结果还是挺奇怪的，很大一部分的原因是场景的背景还是黑咕隆咚的。我们的大场景急需增加天空的部分。</p><h2 id="天空的颜色"><a href="#天空的颜色" class="headerlink" title="天空的颜色"></a>天空的颜色</h2><p>天空的颜色我之前有写过一个<a href="https://ruochenhua.github.io/2024/10/15/single-scatter-atmosphere/">教程</a>，是利用单次散射的方法来计算天空大气的颜色。当然这个方法在这依然是可用的。</p><p>不过如果你说，我不想用那么复杂的方法，只想快速出效果呢？那也是很简单，给地形光线步近没有结果的像素设定为蓝色就行了，哈哈。</p><p>如果想再复杂一点，可以做一个小细节的优化。也就是在晴朗的情况下，一般靠近地平线的天的蓝色是更加浅的，所以在给天空像素上色的时候，可以根据当前像素的方向的y值作为判定，在深蓝色和浅蓝色做线性插值。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec3</span> low_sky_blue = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.5137</span>, <span class="hljs-number">0.7804</span>, <span class="hljs-number">0.9608</span>);<br><span class="hljs-type">vec3</span> high_sky_blue = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.3216</span>, <span class="hljs-number">0.4706</span>, <span class="hljs-number">0.9725</span>);<br><br><span class="hljs-type">vec3</span> sky_color = <span class="hljs-built_in">mix</span>(low_sky_blue, high_sky_blue, <span class="hljs-built_in">clamp</span>(rd.y, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>));<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky.png" alt="增加天空"></p><h2 id="雾气增强层次感"><a href="#雾气增强层次感" class="headerlink" title="雾气增强层次感"></a>雾气增强层次感</h2><p>在增加了天空之后，我们的渲染结果有了很显著的提升，终于像室外的场景了。</p><p>不过仔细看后，还是觉得怪怪的，远处的山和天空根本不在一个图层上；山的远近层次感也不足，远处的山太清晰了。</p><p>这是因为缺少雾气的结果，雾气能够很好的增加大场景体量感，能够很好的处理场景和天空衔接的感觉。</p><p>增加雾气也十分简单，仅需根据地形光线步近的结果的大小（也就是地形离相机的距离）来计算一个比例，根据这个比例来做场景颜色和雾气颜色的插值即可。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// cal fog density, different between r,g,b so the fog has a blue hue</span><br><span class="hljs-type">vec3</span> calcFog(<span class="hljs-type">float</span> dist)<br>&#123;    <br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">exp</span>(<span class="hljs-number">-5e-3</span>*dist*<span class="hljs-type">vec3</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>));<br>&#125;<br><br><span class="hljs-comment">// ...</span><br><span class="hljs-type">vec3</span> fog_amount = calcFog(res_t);<br>color = <span class="hljs-built_in">mix</span>(<span class="hljs-type">vec3</span>(<span class="hljs-number">0.7</span>),color, fog_amount);<br></code></pre></td></tr></table></figure><p>上面这段便是雾气的计算过程。雾气的比例通过*<em>exp(-5e-3</em>dist*vec3(1,2,4))**计算，得到的雾的比例用于最终颜色的线性插值。</p><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog.png" alt="增加雾气"><br>有了雾气的加持，我们场景的大体量感就有了，层次感也明显了很多。<br>关于雾气的更多内容，可以参考Inigo大神的<a href="https://iquilezles.org/articles/fog/">这篇文章</a>。</p><h2 id="漫反射光照细节"><a href="#漫反射光照细节" class="headerlink" title="漫反射光照细节"></a>漫反射光照细节</h2><p>接下来我想优化一下场景整体的漫反射细节。</p><p>当前的渲染结果其实是有加一个默认的环境光**vec3(0.1)**的，主要是之前的场景太黑了。这是个临时的处理，把这个环境光去掉。<br><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_less_ambient.png" alt="去掉写死的环境光补偿"></p><p>好了，我们再来看一下我们的场景。有没有感觉山体的阴影部分有点太黑了？是的，在现实世界中，处于阴影的场景，在大白天也会被场景的漫反射光给提亮的，这种一片漆黑的感觉是有些难看。所以接下来我们来增加一些场景中应该有的漫反射光。</p><p>首先山体之间是会有漫反射光的影响的，也就是阴影部分的山体会被不在阴影的其他山的漫反射光照亮。当然这种影响我们是无法实时计算的，要计算的东西实在是太多了。但是可以通过一个很简单的方式来提单：我们计算当前点的发现和指向光源方向的点乘，当这个结果大于0的时候，用这个乘积乘以一个小的光照并加到原本的颜色上。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl">color += (<span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">dot</span>(-light_dir, normal))*ground_color/<span class="hljs-number">10.0</span>);<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_mountain.png" alt="增加地形的漫反射光"></p><p>加完地形的漫反射光后，天空其实也有各个方向的漫反射的光会影响地形的亮度。天空的漫反射光可以通过地形法线的y分量和天空颜色的一部分来计算，示例代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs glsl">color += (normal.y + <span class="hljs-number">1.0</span>)/<span class="hljs-number">2.0</span>*low_sky_blue/<span class="hljs-number">10.0</span>;<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_sky_fog_diffuse_from_sky.png" alt="增加天空的漫反射光"></p><p>增加了这些漫反射细节，场景的真实度进一步得到了提升。</p><h1 id="云朵"><a href="#云朵" class="headerlink" title="云朵"></a>云朵</h1><p>有了天空，再给天空上增加云的话会进一步增加场景的丰富度，下面就来介绍我给这个场景添加的两部分云的计算。</p><h2 id="高层云"><a href="#高层云" class="headerlink" title="高层云"></a>高层云</h2><p>我给这个场景添加了两种云，高层云是我想模拟在高度很高的地方，云层看起来不厚并且相对静态的感觉。</p><p>高层云的纹理也是利用perlin noise来计算，由于高层的云没有厚实感其实用2D的perlin noise也足够了。</p><p>另外需要注意的是，云的纹理需要根据远近来做处理。远处的云的纹理如果太清晰的话在最终效果上会显得太过于密集。下面是高层云的示例代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 高层云的高度</span><br><span class="hljs-type">float</span> top_sky_plane = <span class="hljs-number">3000.</span>;<br><br><span class="hljs-type">vec3</span> getSkyColor(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd)<br>&#123;    <br>    <span class="hljs-type">vec3</span> hit_sky;<br>    hit_sky.y = top_sky_plane;<br>        <br>    hit_sky.xz = ro.xz + rd.xz * (top_sky_plane - ro.y)/rd.y;    <br>    <br>    <span class="hljs-comment">//降低远处云的密度，看起来效果更好</span><br>    <span class="hljs-type">float</span> hit_dist = <span class="hljs-built_in">distance</span>(hit_sky, ro);<br>    <span class="hljs-type">float</span> cloud_density_percentage = <span class="hljs-number">1.0</span>;<br>    <span class="hljs-keyword">if</span>(hit_dist &gt; cloud_view_distance)<br>    &#123;<br>        cloud_density_percentage *= <span class="hljs-built_in">exp</span>(-(hit_dist - cloud_view_distance)/ cloud_view_distance);<br>    &#125;    <br><br>    <span class="hljs-comment">// 根据云层采样点的远近处理云层的密度</span><br>    <span class="hljs-type">float</span> cloud_density = <span class="hljs-built_in">smoothstep</span>(getCloudDensity(hit_sky.xz/<span class="hljs-number">150.0</span>, <span class="hljs-number">3</span>), <span class="hljs-number">-0.99</span>, <span class="hljs-number">1.9</span>)*cloud_density_percentage * <span class="hljs-number">0.5</span>;<br>    <span class="hljs-type">float</span> res_t;<br><br>    <span class="hljs-comment">// sky color    </span><br>    <span class="hljs-type">vec3</span> sky_color = <span class="hljs-built_in">mix</span>(low_sky_blue, high_sky_blue, <span class="hljs-built_in">clamp</span>(rd.y, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>));<br>    <span class="hljs-type">vec3</span> cloud_color = <span class="hljs-type">vec3</span>(<span class="hljs-number">1.</span>);<br>    <span class="hljs-comment">// 根据云层密度得到最终的高层云和天空颜色</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">mix</span>(sky_color, cloud_color, cloud_density);<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_high_cloud.png" alt="增加天空高层云"></p><p>增加了高层云之后，天空就显得不那么单调了。</p><h2 id="体积云"><a href="#体积云" class="headerlink" title="体积云"></a>体积云</h2><p>最后就是体积云了，体积云的部分我不会在这里详细讨论，这是一个可以讨论的比较深的话题。我这个场景的体积云效果也并不是很理想，这里仅作为一个最后的点缀，在山峰上增加一点点动态效果。</p><p>体积云的效果其实也是在一定区域内进行多个点的采样而来，这个区域内利用FBM来实现云的动态的随机效果。在这个场景内我使用了SDF来圈定体积云的范围，并且给SDF增加了随机现状来获取更好的随机效果。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">float</span> scene(<span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> pos)<br>&#123;    <br>    <span class="hljs-type">vec3</span> cloud_pos = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">15.0</span>);<br>    <br>    <span class="hljs-type">vec3</span> filter_pos = <span class="hljs-type">vec3</span>(pos.x, pos.y+iTime, pos.z+iTime);<br>    pos -= cloud_pos;<br>    <span class="hljs-type">float</span> rst = -(rm_box(pos)) + fbm_cloud(pos * <span class="hljs-number">0.1</span>+iTime*<span class="hljs-number">0.3</span>, <span class="hljs-number">5</span>);<br>    rst = rst / <span class="hljs-number">25.0</span> * <span class="hljs-built_in">max</span>(fbm_cloud(filter_pos*<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>) - <span class="hljs-number">1.2</span>, <span class="hljs-number">0.0</span>); <br>    <span class="hljs-keyword">return</span> rst;<br>&#125;<br><br><span class="hljs-type">float</span> max_cloud_dist = <span class="hljs-number">80.</span>;<br><span class="hljs-type">vec4</span> renderMidClouds(<span class="hljs-type">vec3</span> ro, <span class="hljs-type">vec3</span> rd)<br>&#123;    <br>    <span class="hljs-type">vec4</span> res = <span class="hljs-type">vec4</span>(<span class="hljs-number">0.0</span>);<br>    <span class="hljs-type">float</span> depth = <span class="hljs-number">0.0</span>;    <br>    <br>    <span class="hljs-type">int</span> sample_count = <span class="hljs-number">64</span>;<br>    <span class="hljs-type">float</span> dt = max_cloud_dist / <span class="hljs-type">float</span>(sample_count);<br>    <br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_count; ++i)<br>    &#123;<br>        <span class="hljs-type">vec3</span> p = ro + depth*rd;<br>        <span class="hljs-type">float</span> density = scene(p);<br>        <span class="hljs-keyword">if</span>(density &gt; <span class="hljs-number">0.0</span>)<br>        &#123;<br>            <span class="hljs-type">float</span> diffuse = <span class="hljs-built_in">clamp</span>((scene(p) - scene(p + <span class="hljs-number">0.3</span>*light_dir))/<span class="hljs-number">0.3</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>);<br>            <span class="hljs-type">vec3</span> lin = <span class="hljs-type">vec3</span>(<span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.8</span>) * <span class="hljs-number">1.1</span> + <span class="hljs-number">0.8</span> * <span class="hljs-type">vec3</span>(<span class="hljs-number">0.9333</span>, <span class="hljs-number">0.702</span>, <span class="hljs-number">0.5255</span>)*diffuse;<br>            <span class="hljs-type">vec4</span> color = <span class="hljs-type">vec4</span>(<span class="hljs-built_in">mix</span>(<span class="hljs-type">vec3</span>(<span class="hljs-number">1.0</span>), <span class="hljs-type">vec3</span>(<span class="hljs-number">0.0</span>), density), density);<br>            color.rgb *= color.a;<br><br>            res += color * (<span class="hljs-number">1.0</span> - res.a);<br>        &#125;<br><br>        depth+=dt;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> res;<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/2024/11/04/ProceduralTerrainGeneration2/terrain_with_all_cloud.png" alt="增加体积云"></p><h1 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h1><iframe width="640" height="360" frameborder="0" src="https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false" allowfullscreen></iframe><p>以上便是我如何实现这个场景的简单介绍了。这是我初次尝试在ShaderToy上渲染大场景，也是第一次将整个步骤拆解讲解，可能还是会有不少地方讲的不过仔细和通透，也有些遗漏。</p><p>后面我还是会继续尝试创作和讲解，希望能给人带来帮助，也有助于巩固我所学的知识。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>程序化生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>景深的简单实现</title>
    <link href="/2024/10/28/depth-of-field/"/>
    <url>/2024/10/28/depth-of-field/</url>
    
    <content type="html"><![CDATA[<h1 id="关于景深"><a href="#关于景深" class="headerlink" title="关于景深"></a>关于景深</h1><p>景深是一个常在摄像领域出现的词，它一般指的是沿着摄像机或其他成像器的拍摄方向上，能够取得清晰图像的成像所测定的被摄物体前后距离范围。用大白话就是说，拥有浅景深的成像器拍摄出来的效果，是只有焦点附近的图像是清晰的，其他地方的图像都是模糊的；而拥有大景深则可以在离焦点很远的地方也能有清晰的图像。</p><p><img src="/2024/10/28/depth-of-field/dof_butterfly.JPG" alt="一张浅景深的照片"></p><p>有了景深效果的图像可以有重点的突出核心想要表达的内容，不仅仅在摄影摄像的领域有非常多的应用，在游戏领域内也是应用广泛，可以表现出很独特的风格化美术效果（如八方旅人的浅景深效果）。</p><p><img src="/2024/10/28/depth-of-field/game1.jpg" alt="八方旅人"></p><p>下面我来介绍一种基础的景深效果实现，这个方法也在最近接入了<a href="https://github.com/ruochenhua/KongEngine">KongEngine</a></p><h1 id="渲染散景"><a href="#渲染散景" class="headerlink" title="渲染散景"></a>渲染散景</h1><p>浅景深的主要应用是通过调整不同焦距上物体的成像清晰程度来突出渲染画面的重点。清晰的部分我们已经掌握了，就是正常的将场景渲染出来，那不清晰的部分（或者叫做散景）也有不少的实现方式，一般是通过模糊算法来实现。</p><p>模糊的算法有很多种，比如box blur，gaussian blur等等，效果最好的是扩张模糊(dilate blur)，这也是我们会采取的方法。</p><h2 id="扩张模糊（dilate-blur"><a href="#扩张模糊（dilate-blur" class="headerlink" title="扩张模糊（dilate blur)"></a>扩张模糊（dilate blur)</h2><p>扩张模糊它的主要方式，是在给定一个模糊的窗口下，取得这个窗口下的最亮的颜色记录下来，然后将这个最亮的颜色扩张到整个窗口。这样一来经过扩张模糊的画面会有一种亮晶晶，并且很柔和的效果，很适合作为散景的表现效果。</p><p>dilate blur的计算也比较简单，首先我们定义此次blur的窗口大小已经采样的间隔大小。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 窗口的大小，数值越大扩散越大，消耗越高 </span><br><span class="hljs-type">int</span> size = <span class="hljs-number">5</span>;<br><span class="hljs-comment">// 采样间隔的大小，数值越大扩散越大，效果降低</span><br><span class="hljs-type">float</span> separation = <span class="hljs-number">1.0</span>;<br></code></pre></td></tr></table></figure><p>在定义了窗口的尺寸之后，我们在窗口的范围内记录最亮的像素颜色，并保存下来。<strong>窗口的形状不限</strong>，可以是矩形，或者圆形。我们这里实现采取圆形的窗口。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 渲染场景的尺寸</span><br><span class="hljs-type">vec2</span> tex_size = <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(scene_texture, <span class="hljs-number">0</span>).xy);<br><span class="hljs-comment">// 获取场景的原本颜色</span><br>FragColor = <span class="hljs-built_in">texture</span>(scene_texture, TexCoords);<br><br><span class="hljs-keyword">if</span>(size &lt;= <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span>;<br><span class="hljs-type">float</span> mx = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">vec4</span> cmx = FragColor;<br><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = -size; i &lt;= size; ++i)<br>&#123;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = -size; j &lt;= size; ++j)<br>&#123;<br><span class="hljs-comment">// dilate的形状可以多样，如圆形，矩形等等，根据采样点的形状来决定</span><br><span class="hljs-comment">// 这里使用圆形的dilate</span><br><span class="hljs-keyword">if</span>(<span class="hljs-built_in">distance</span>(<span class="hljs-type">vec2</span>(i,j), <span class="hljs-type">vec2</span>(<span class="hljs-number">0</span>)) &gt; size) <span class="hljs-keyword">continue</span>;<br><br><span class="hljs-comment">// 采样区域内点的颜色，不要越界出去了</span><br><span class="hljs-type">vec2</span> sample_coord = TexCoords + <span class="hljs-type">vec2</span>(i, j)*separation/tex_size;<br><span class="hljs-keyword">if</span>(sample_coord.x &gt; <span class="hljs-number">1.0</span> || sample_coord.x &lt; <span class="hljs-number">0.0</span> || sample_coord.y &gt; <span class="hljs-number">1.0</span> || sample_coord.y &lt; <span class="hljs-number">0.0</span>)<br><span class="hljs-keyword">continue</span>;<br><br><span class="hljs-comment">// 拿到采样点</span><br><span class="hljs-type">vec4</span> c = <span class="hljs-built_in">texture</span>(scene_texture, sample_coord);<br><br><span class="hljs-comment">// 和目标颜色做点乘，得到一个灰度值</span><br><span class="hljs-type">float</span> mxt = <span class="hljs-built_in">dot</span>(c.rgb, <span class="hljs-type">vec3</span>(<span class="hljs-number">0.3</span>, <span class="hljs-number">0.59</span>, <span class="hljs-number">0.11</span>));<br><br><span class="hljs-comment">// 保存区域内灰度值最大的颜色</span><br><span class="hljs-keyword">if</span>(mxt &gt; mx)<br>&#123;<br>mx = mxt;<br>cmx = c;<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我们计算最亮区域的方式是通过和一个目标颜色**(0.3, 0.59, 0.11)**来做点乘，当然也可以通过和其他的目标颜色，或者其他的方式来实现。</p><p>最后，我们得到窗口区域内最亮的颜色，我们的最终颜色是原本颜色和最亮颜色的差值。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 模糊采样的颜色和原始颜色的mix上下限</span><br><span class="hljs-type">float</span> min_threshold = <span class="hljs-number">0.1</span>;<br><span class="hljs-type">float</span> max_threshold = <span class="hljs-number">0.3</span>;<br><br><span class="hljs-comment">// 最终颜色是原来颜色和区域内灰度值最大的采样颜色的混合，有上下限做限制</span><br>FragColor.rgb = <span class="hljs-built_in">mix</span>(FragColor.rgb, cmx.rgb, <span class="hljs-built_in">smoothstep</span>(min_threshold, max_threshold, mx));<br></code></pre></td></tr></table></figure><p>这里我们还是采用了一个上下限，尽量控制增亮的程度。</p><h2 id="散景的效果"><a href="#散景的效果" class="headerlink" title="散景的效果"></a>散景的效果</h2><p>这里给出经过扩张模糊得到的散景效果。下面这张图是扩张模糊之前的效果。<br><img src="/2024/10/28/depth-of-field/dilate_before.png" alt="扩张模糊前"><br>下面这张图是扩张模糊之后的效果。<br><img src="/2024/10/28/depth-of-field/dilate_after.png" alt="扩张模糊后"></p><p>当然在实际的场景中，我们可能不会开这么大的扩散效果，此处只是作为对比。</p><h1 id="结合场景"><a href="#结合场景" class="headerlink" title="结合场景"></a>结合场景</h1><p>好了，现在我们有原本场景的渲染效果和扩散后的效果，实现最终的景深效果需要将这两者结合起来。我们需要一种方法来决定画面上哪些部分是需要采用清晰的图像，哪些是采用模糊的图像。</p><p>为了实现这个效果我们需要获得画面上每个点的深度，或者每个点的实际世界坐标。幸运的是，我们在实现<a href="https://ruochenhua.github.io/2024/10/19/defer-render/">延迟渲染</a>的时候已经将这些存放到缓冲中去了，接下来就是实现景深效果了。</p><p>最终的代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> FragColor;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> TexCoords;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> scene_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> dilate_texture;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">sampler2D</span> position_texture;<br><br><span class="hljs-comment">// 焦点距离</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> focus_distance = <span class="hljs-number">3.0</span>;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">vec2</span> focus_threshold;<br><span class="hljs-comment">// 景深的上下限</span><br><span class="hljs-type">float</span> min_dist = focus_threshold.x;<br><span class="hljs-type">float</span> max_dist = focus_threshold.y;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec4</span> focus_color = <span class="hljs-built_in">texture</span>(scene_texture, TexCoords);<br>    <span class="hljs-type">vec4</span> out_of_focus_color = <span class="hljs-built_in">texture</span>(dilate_texture, TexCoords);<br>    <span class="hljs-type">vec3</span> scene_position = <span class="hljs-built_in">texture</span>(position_texture, TexCoords).xyz; <br>    <br><span class="hljs-comment">// 这里采用了画面每个点的世界坐标和相机的距离作为判定模糊的标准</span><br><span class="hljs-comment">// 当然用深度信息也是可以的，性能上也更好，这里为了代码展示更好理解</span><br>    <span class="hljs-type">vec3</span> cam_pos = matrix_ubo.cam_pos.xyz;<br><br>    <span class="hljs-type">float</span> blur_amout = <span class="hljs-built_in">smoothstep</span>(min_dist, max_dist, <span class="hljs-built_in">abs</span>(focus_distance - <span class="hljs-built_in">distance</span>(scene_position, cam_pos)));<br>    <br><span class="hljs-comment">// 最后的颜色是焦距内和散景的混合</span><br>    FragColor = <span class="hljs-built_in">mix</span>(focus_color, out_of_focus_color, blur_amout);<br>&#125;<br></code></pre></td></tr></table></figure><p>这段代码理解起来应该没有什么太大的难度。</p><h1 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h1><p>这里展示一下最终的效果。</p><p><img src="/2024/10/28/depth-of-field/dof_near.png" alt="近焦点"><br><img src="/2024/10/28/depth-of-field/dof_far.png" alt="远焦点"></p><p>上面两张图分别展示了不同焦点的景深的表现结果。可以明显看到不同景深效果的加入可以很容易的将画面上想要着重表达出来的部分勾勒出来。优秀的散景效果也能给画面增加不少美感（虽然我这个测试场景也没有什么美感可言…）。</p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>延迟渲染实现</title>
    <link href="/2024/10/19/defer-render/"/>
    <url>/2024/10/19/defer-render/</url>
    
    <content type="html"><![CDATA[<p>想要在Kong引擎里面实现的场景慢慢复杂了起来，光源和模型的数量从原先的十以内的数量增长到几十甚至几百的数量级，是时候接入延迟渲染的方法了。</p><h1 id="延迟渲染"><a href="#延迟渲染" class="headerlink" title="延迟渲染"></a>延迟渲染</h1><p><strong>延迟渲染</strong>（Defer Rendering），或者<strong>延迟着色法</strong>（Defer Shading），是区别于<strong>正向渲染</strong>（Forward Shading）的一种计算场景光照的方式。</p><p>正向渲染方法就是遍历场景中的每一个模型，计算一个模型的光照表现后再继续下一个模型的计算，根据深度测试的结果更新屏幕上最终像素显示的颜色。这种方法是很容易让人理解并实现的。但是当场景中的光照和模型数量变多的时候，模型重叠的区域会进行不必要的光照计算（被挡住的模型像素区域最终会被前面的模型遮挡，但是这篇被挡住的区域还是被计算了光照），而光照计算一般来说是渲染消耗的大头，这部分时间就被浪费了。</p><p>而延迟渲染的想法则是将光照计算分成两部分。第一个部分叫做<strong>几何处理阶段</strong>（Geometry Pass），它先将光照计算所需要的模型信息（顶点位置、法线、颜色、材质属性等等）先渲染到多张贴图上（消耗低），经由深度检测保留最终在屏幕上显示的模型部分的这些信息。</p><!-- wp:image {"sizeSlug":"large","align":"center"} --><figure class="wp-block-image aligncenter size-large"><img src="https://learnopengl-cn.github.io/img/05/08/deferred_g_buffer.png" alt=""/></figure><!-- /wp:image --><p>第二部分叫做<strong>光照处理阶段</strong>（Lighting Pass），根据几何处理阶段保存的信息再去进行光照计算，这样就不会将算力浪费在计算被遮挡的模型部分的光照了，从而优化渲染的性能，也有赋予了能够更加方便的实现某些效果的能力（如SSAO）。</p><!-- wp:image {"sizeSlug":"large","align":"center"} --><figure class="wp-block-image aligncenter size-large"><img src="https://learnopengl-cn.github.io/img/05/08/deferred_overview.png" alt=""/></figure><!-- /wp:image --><h1 id="G缓冲"><a href="#G缓冲" class="headerlink" title="G缓冲"></a>G缓冲</h1><p>G缓冲(G-buffer)是对所有用来储存光照相关的数据，并在最后的光照处理阶段中使用的所有纹理的总称。它是我们计算最终渲染输出中的缓存和中转站，为了实现延迟渲染，G-buffer中会包含如下几张纹理的数据：模型顶点位置数据；模型法线数据；模型漫反射颜色数据；材质数据（ao，roughness，metallic）等等。有了这些数据则能够实现Kong引擎的PBR光照计算，初始化G-buffer的代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">DeferBuffer::GenerateDeferRenderTextures</span><span class="hljs-params">(<span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, g_buffer_);<br><br><span class="hljs-comment">// 将当前视野的数据用贴图缓存</span><br><span class="hljs-comment">// 位置数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_position_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_position_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, g_position_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 法线数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_normal_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_normal_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA32F, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_FLOAT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, g_normal_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 顶点颜色数据</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_albedo_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_albedo_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, g_albedo_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// orm数据（ao，roughness，metallic）</span><br><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;g_orm_);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D, g_orm_);<br><span class="hljs-built_in">glTexImage2D</span>(GL_TEXTURE_2D, <span class="hljs-number">0</span>, GL_RGBA, width, height, <span class="hljs-number">0</span>, GL_RGBA, GL_UNSIGNED_INT, <span class="hljs-literal">NULL</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glFramebufferTexture2D</span>(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT3, GL_TEXTURE_2D, g_orm_, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 生成renderbuffer</span><br><span class="hljs-built_in">glGenRenderbuffers</span>(<span class="hljs-number">1</span>, &amp;g_rbo_);<br><span class="hljs-built_in">glBindRenderbuffer</span>(GL_RENDERBUFFER, g_rbo_);<br><span class="hljs-built_in">glRenderbufferStorage</span>(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, width, height);<br><span class="hljs-built_in">glFramebufferRenderbuffer</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, g_rbo_);<br><span class="hljs-built_in">glEnable</span>(GL_DEPTH_TEST);<br><br><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> attachments[<span class="hljs-number">4</span>] = &#123;GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1, GL_COLOR_ATTACHMENT2, GL_COLOR_ATTACHMENT3&#125;;<br><span class="hljs-built_in">glDrawBuffers</span>(<span class="hljs-number">4</span>, attachments);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>可以从上面的代码看到，我们利用了多渲染目标（multiple render targets）可以一次处理并输出到多个缓冲（GL_COLOR_ATTACHMENT0到3）。简化的几何处理着色器示例代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// defer_geometry_pass.frag</span><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">0</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gPosition;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">1</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gNormal;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">2</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gAlbedo;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">location</span> = <span class="hljs-number">3</span>) <span class="hljs-keyword">out</span> <span class="hljs-type">vec4</span> gORM;<br><br><span class="hljs-keyword">in</span> <span class="hljs-type">vec4</span> frag_pos;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec3</span> frag_normal;<br><span class="hljs-keyword">in</span> <span class="hljs-type">vec2</span> frag_uv;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">vec4</span> albedo;    <span class="hljs-comment">// color</span><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> metallic;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> roughness;<br><span class="hljs-keyword">uniform</span> <span class="hljs-type">float</span> ao;<br><br><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-comment">// 深度信息存储到position贴图的w值中</span><br>    gPosition = frag_pos;<br>    gNormal = <span class="hljs-type">vec4</span>(frag_normal, <span class="hljs-number">1.0</span>);<br>    gAlbedo = albedo;<br>    gORM = <span class="hljs-type">vec4</span>(ao, roughness, metallic, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>上方的代码将我们所需要的世界坐标下的顶点坐标信息、法线信息、漫反射颜色和材质信息输出到了四张贴图。带着这四张贴图的信息，我们进入下一个阶段，光照处理阶段。下面是个简化的光照处理着色器代码：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">void</span> main()<br>&#123;<br>    <span class="hljs-type">vec3</span> frag_pos = <span class="hljs-built_in">texture</span>(position_texture, TexCoords).xyz;<br>    <span class="hljs-type">vec3</span> frag_normal = <span class="hljs-built_in">texture</span>(normal_texture, TexCoords).rgb;<br>    <span class="hljs-type">vec4</span> env_albedo = <span class="hljs-built_in">texture</span>(albedo_texture, TexCoords);<br><br>    <span class="hljs-type">vec3</span> orm = <span class="hljs-built_in">texture</span>(orm_texture, TexCoords).rgb;<br>    <span class="hljs-type">float</span> ao = orm.x;<br>    <span class="hljs-type">float</span> env_roughness = orm.y;<br>    <span class="hljs-type">float</span> env_metallic = orm.z;<br><br>    <span class="hljs-type">vec3</span> view = <span class="hljs-built_in">normalize</span>(cam_pos - frag_pos);  <span class="hljs-comment">//to_view</span><br><br>    <span class="hljs-type">vec3</span> light_color = CalcLight(light_info, frag_normal, view,  frag_pos, material);<br><br>    <span class="hljs-type">vec3</span> color = ambient + light_color;<br>    FragColor = <span class="hljs-type">vec4</span>(color, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="结合延迟和正向渲染"><a href="#结合延迟和正向渲染" class="headerlink" title="结合延迟和正向渲染"></a>结合延迟和正向渲染</h1><p>延迟渲染实现起来其实还是比较简单明了的，但是需要注意的是，有些材质并不能通过延迟渲染实现，比如说半透明这种需要进行alpha混合的材质，因此就会出现需要结合延迟渲染和正向渲染的情况。</p><p>结合延迟渲染和正向渲染的时候，一般来说是先处理延迟渲染的部分。在处理完延迟渲染后，将延迟渲染的G-buffer的深度缓冲复制到最后输出屏幕的深度缓冲上（我这里最后会继续后处理，所以是会输出到后处理的FrameBuffer上）。如此一来，正向渲染的物体才可以和延迟渲染的场景有正确的深度遮挡结合，否则会出现正向渲染的物体永远在上的情况。实例代码如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 需要将延迟渲染的深度缓冲复制到后面的后处理buffer上</span><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_READ_FRAMEBUFFER, defer_buffer_.g_buffer_);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_DRAW_FRAMEBUFFER, post_process.<span class="hljs-built_in">GetScreenFrameBuffer</span>());<br><span class="hljs-built_in">glBlitFramebuffer</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, window_size.x, window_size.y, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, window_size.x, window_size.y, GL_DEPTH_BUFFER_BIT, <br>GL_NEAREST);<br></code></pre></td></tr></table></figure><h1 id="延迟渲染的效能提升"><a href="#延迟渲染的效能提升" class="headerlink" title="延迟渲染的效能提升"></a>延迟渲染的效能提升</h1><p>之前提过，延迟渲染最大的好处之一便是能够提升渲染的效率，这里大概做一个粗略的测试。下方是一个包含着1000个人物模型和200个点光源的场景，如果按照正常的正向渲染，这个场景在我的笔记本上的帧率大概在35左右：</p><p><img src="/2024/10/19/defer-render/no_defer_render.png" alt="非延迟渲染"></p><p>当使用延迟渲染的情况下，该场景的帧率可以提升到170左右：</p><p><img src="/2024/10/19/defer-render/defer_render.png" alt="延迟渲染"></p><p>当然上方这是个比较极端的场景，实际场景上可能不会有这么复杂的光源，以及模型可能不会像测试场景这样重叠，所以差距可能不会像测试场景那般明显。但是一般来说延迟渲染对渲染场景的性能提升会是比较客观的。</p><h2 id="基于延迟渲染的延伸"><a href="#基于延迟渲染的延伸" class="headerlink" title="基于延迟渲染的延伸"></a>基于延迟渲染的延伸</h2><p>延迟渲染的好处之一不仅仅体现在性能上，由于延迟渲染将很多有用的信息存储下来，基于延迟渲染我们可以实现非常多其他的效果。比如说屏幕空间环境光遮蔽SSAO（如下图）以及屏幕空间反射SSR等等，我计划在后面的文章详细介绍一下。</p><p><img src="/2024/10/19/defer-render/ssao.png" alt="SSAO效果"></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于单次散射的天空大气渲染方法</title>
    <link href="/2024/10/15/single-scatter-atmosphere/"/>
    <url>/2024/10/15/single-scatter-atmosphere/</url>
    
    <content type="html"><![CDATA[<p>最近KongEngine实现了IBL(Image Based Lighting)，可以将HDR环境贴图映射作为3D场景的环境。</p><p><img src="/2024/10/15/single-scatter-atmosphere/kong-screen-shot.png" alt="KongEngine的IBL效果"></p><p>在实现了IBL之后我又产生了一个想法，能否实现类似UE中的大气环境的渲染效果呢？我尝试去寻找答案，发现如果要完全复刻UE中的效果确实需要一定的功夫的，但是最基础的天空大气渲染并没有想象中那么复杂，于是我便花了点时间在KongEngine中实现了这个功能。</p><p><img src="/2024/10/15/single-scatter-atmosphere/single-scatter-atmosphere.png" alt="KongEngine天空大气效果"></p><p>我打算将这个方法的基础思想和实现在此简单记录一下。</p><h1 id="单次散射模型"><a href="#单次散射模型" class="headerlink" title="单次散射模型"></a>单次散射模型</h1><p>星球的大气层是一种参与性介质，和在真空环境不同，光在大气层中传播的时候会因为大气中的微小颗粒（水、灰尘等等）发生散射（折射、反射）和吸收等情况。因此我们看向空中的一个点的时候，这个点的颜色是光经过多次散射得到的结果。</p><p>光到达我们眼睛之前经过多少次反射和折射是不一定的，在实时渲染的需求下计算太多次光的变化显然也是不显示的。最简单的方法，是使用单次散射模型：我们假定光在进入我们眼睛之前，有且只发生了一次散射。光一般在第一次散射的时候，还会有最多的能量剩余，后面的多次散射能力相对少，对最后效果的呈现也影响不大，因此这种模型可以在保证性能的情况下，还有不错的效果。</p><p><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_02.png"></p><p>除了散射，光在传播的时候会被大气吸收。一般来说，如果在一个均匀的介质中传播的话，光的被吸收的部分和介质的密度，以及传播的路径长度正相关。放到单散射模型的例子中，就是需要计算光在散射前和散射后的路径上，被吸收了多少能量。<br><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_07.png"></p><p>按照上面的图，假设相机在A点，观察方向为AB，其中有一束光在P点发生散射后沿着PA进入相机。如果我们知道了光线损耗和距离相关的公式，那么似乎是只要计算出CP和PA的长度，在带入公式后就可以得到光该路径上传播后的最终能量了。</p><p><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_10a.png"></p><p>但是对于大气层来说，它的密度并不是均匀的，而是和大气层距离地面的高度相关。所以在计算CP段光线损耗的时候，我们需要将这段距离分为多个小段，每个小段的损耗公式带入对应平均高度，在最后将所有结果相加才。小段划分的越密集，则结果越准确。</p><p>如果我们还要考虑大气中的其他因素，比如说大气中的云层，在这些区域中光的损耗就不仅仅是和高度相关了。</p><p>另外一点就是，当我们考虑AB方向的光线时，它的最终效果，是在大气层内的所有AB连线上面的点的散射结果的总和（P0、P1、P2…Pn），因此我们也同样的需要对AB线段进行分段采样并将结果叠加。AB线段上的每一个采样结果按照上面所描述的计算单一P点的方式。</p><p><img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_08a.png"></p><p>以上便是大气单次散射模型的基本思路。</p><h1 id="散射的计算"><a href="#散射的计算" class="headerlink" title="散射的计算"></a>散射的计算</h1><p>之前我们提到了计算光的散射，这里我们介绍一下散射的相关计算。会提及一些公式，但是不会做过多的数学推导工作，对推导过程感兴趣的可以看一下文章中的参考资料。</p><p>一般来说，天空大气的散射主要包括两种，分别是<strong>瑞利散射</strong>和<strong>米氏散射</strong>。</p><ul><li>瑞利散射是当光线通过介质中的微小颗粒或分子时发生的散射现象。由于颗粒或分子的尺寸远小于光的波长，不同波长的光线会以不同的角度散射，一个最经典的案例就是因为蓝色的波长是较短的，所以蓝色很容易发生瑞利散射，导致天空呈现蓝色。</li><li>米氏散射则一般由空气中含有的较大颗粒的介质，如气溶胶、灰尘、水滴等引起。和瑞利散射不同的是，米氏散射和光的波长关系并不大。<br> <img src="https://www.alanzucconi.com/wp-content/uploads/2017/09/scattering_13.png"></li></ul><p>那么根据前面的模型思路，光在P点上发生了散射，其中一部分能量沿着PA方向进入相机的实现。获取这一部分能量的计算函数被称之为<strong>相位函数（Phase Function）</strong>。相位函数是用来描述，当光线发生散射的情况时，某个方向（一般是和原光线方向的夹角）占原光线的能量的比例。瑞利散射和米氏散射的相位函数是不同的，同一种散射的相位函数也会有不同的方法进行拟合，这里我不想去做过多的公式推导的工作，有兴趣的可以去查看<a href="https://patapom.com/topics/Revision2013/Revision%202013%20-%20Real-time%20Volumetric%20Rendering%20Course%20Notes.pdf">参考资料</a>的推导过程。</p><p>下方是瑞利散射的相位函数，theta是原光线方向和目标方向的夹角：</p><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mtable displaystyle="true" columnalign="right left right" columnspacing="0em 2em" rowspacing="3pt">    <mtr>      <mtd>        <mi>P</mi>        <mo stretchy="false">(</mo>        <mi>&#x3B8;</mi>        <mo stretchy="false">)</mo>      </mtd>              <mtd>        <mi></mi>        <mo>=</mo>        <mfrac>          <mn>3</mn>          <mrow>            <mn>16</mn>            <mi>&#x3C0;</mi>          </mrow>        </mfrac>        <mo stretchy="false">(</mo>        <mn>1</mn>        <mo>+</mo>        <mi>c</mi>        <mi>o</mi>        <msup>          <mi>s</mi>          <mn>2</mn>        </msup>        <mi>&#x3B8;</mi>        <mo stretchy="false">)</mo>      </mtd>    </mtr>  </mtable></math><!-- /wp:html --><!-- wp:paragraph --><p>下方是米氏散射的相位函数，这里使用的是<a href="https://omlc.org/classroom/ece532/class3/hg.html">Henyey-Greenstein函数</a>来近似。</p><!-- /wp:paragraph --><!-- wp:html --><p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mi>P</mi>  <mo stretchy="false">(</mo>  <mi>&#x3B8;</mi>  <mo stretchy="false">)</mo>  <mo>&#x3D;</mo>  <mfrac>    <mrow>      <mn>1</mn>      <mo>&#x2212;</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>    <mrow>      <mn>4</mn>      <mi>&#x3C0;</mi>      <mo stretchy="false">(</mo>      <mn>1</mn>      <mo>+</mo>      <msup>        <mi>g</mi>        <mrow>          <mn>2</mn>        </mrow>      </msup>      <mo>&#x2212;</mo>      <mn>2</mn>      <mi>g</mi>      <mi>c</mi>      <mi>o</mi>      <mi>s</mi>      <mo stretchy="false">(</mo>      <mi>&#x3B8;</mi>      <mo stretchy="false">)</mo>      <msup>        <mo stretchy="false">)</mo>        <mrow>          <mn>3</mn>          <mrow>            <mo>&#x2F;</mo>          </mrow>          <mn>2</mn>        </mrow>      </msup>    </mrow>  </mfrac></math></p><!-- /wp:html --><!-- wp:paragraph --><p>好了，现在我们知道了如何计算光线在P点的散射行为。剩下的工作就是需要计算光线在传播过程的损耗了。这一部分的计算方法称之为<strong>衰减系数</strong>，或者<strong>消光系数</strong>。消光系数中的一部分，需要对光线在传播的路线的长度和空气密度进行积分。在程序中的表示就是将光的传播路径分为小段，将每一小段的长度和平均密度（或者小段中点的介质密度）相乘而得到，这个结果我们称之为<strong>光学距离（Optical Depth）</strong>。</p><!-- /wp:paragraph --><!-- wp:paragraph --><p>衰减系数的计算公式如下，红色部分代表的是在海拔为h的散射系数。他可以分解为在海平面上的散射系数乘以在海拔h的介质密度。</p><!-- /wp:paragraph --><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mstyle mathcolor="#00AAFF">    <mi>T</mi>    <mo stretchy="false">(</mo>    <mi>P</mi>    <mi>A</mi>    <mo stretchy="false">)</mo>  </mstyle>  <mo>=</mo><mstyle mathcolor="#00AA00">  <mi>exp</mi></mstyle>  <mrow data-mjx-texclass="ORD">    <mo>&#x2212;</mo>    <msubsup>      <mo data-mjx-texclass="OP">&#x222B;</mo>      <mi>P</mi>      <mi>A</mi>    </msubsup>    <mrow data-mjx-texclass="ORD">      <mstyle mathcolor="Red">        <mi>&#x3B2;</mi>        <mo stretchy="false">(</mo>        <mi>&#x3BB;</mi>        <mo>,</mo>        <mi>h</mi>        <mo stretchy="false">)</mo>      </mstyle>    </mrow>    <mi>d</mi>    <mi>s</mi>  </mrow></math><!-- /wp:html --><!-- wp:paragraph --><p>分解出来后得到的结果如下，其中红色的部分代表的意思是在海平面的散射系数，是一个常量，黄色部分代表了在海拔为h的介质的密度。这个公式的积分便是针对AP路线上的介质密度，其结果也就是光学距离。</p><!-- /wp:paragraph --><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mstyle mathcolor="#00AAFF">    <mi>T</mi>    <mo stretchy="false">(</mo>    <mi>P</mi>    <mi>A</mi>    <mo stretchy="false">)</mo>  </mstyle>  <mo>=</mo>    <mstyle mathcolor="#00AA00">      <mi>exp</mi>    </mstyle>  <mrow data-mjx-texclass="ORD">    <mo>&#x2212;</mo>    <mstyle mathcolor="Red">      <mi>&#x3B2;</mi>      <mo stretchy="false">(</mo>      <mi>&#x3BB;</mi>      <mo stretchy="false">)</mo>    </mstyle>    <msubsup>      <mo data-mjx-texclass="OP">&#x222B;</mo>      <mi>P</mi>      <mi>A</mi>    </msubsup>    <mrow data-mjx-texclass="ORD">      <mstyle mathcolor="Gold">        <mi>&#x3C1;</mi>        <mo stretchy="false">(</mo>        <mi>h</mi>        <mo stretchy="false">)</mo>      </mstyle>    </mrow>    <mi>d</mi>    <mi>s</mi>  </mrow></math><!-- /wp:html --><!-- wp:paragraph --><p>介质密度的计算公式如下，其中H代表的是一个基准海拔，是一个常量。不同散射的基准海拔有所不同，瑞利散射的基准海拔是*8500*，而米氏散射的基准海拔是*1200*。</p><!-- /wp:paragraph --><!-- wp:html --><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mstyle mathcolor="Gold">    <mi>&#x3C1;</mi>    <mo stretchy="false">(</mo>    <mi>h</mi>    <mo stretchy="false">)</mo>  </mstyle>  <mo>=</mo>  <mi>exp</mi>  <mo stretchy="false">(</mo>  <mo>&#x2212;</mo>  <mfrac>    <mi>h</mi>    <mi>H</mi>  </mfrac>  <mo stretchy="false">)</mo></math><!-- /wp:html --><p>自此，我们关于单次散射的天空大气渲染方法的基本预备知识已经了解的差不多了，接下来介绍shader的相关代码。</p><h1 id="Shader代码"><a href="#Shader代码" class="headerlink" title="Shader代码"></a>Shader代码</h1><p>首先，为了计算AB、PC等视线和光线在大气层内的传播距离，我们需要一个函数来计算射线和球体的相交情况。</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-type">vec2</span> ray_sphere_intersection(<span class="hljs-type">vec3</span> ray_origin, <span class="hljs-type">vec3</span> ray_direction, <span class="hljs-type">vec3</span> sphere_center, <span class="hljs-type">float</span> sphere_radius)<br>&#123;<br>    <span class="hljs-comment">// ray-sphere intersection that assumes</span><br>    <span class="hljs-type">float</span> a = <span class="hljs-built_in">dot</span>(ray_direction, ray_direction);<br>    <span class="hljs-type">vec3</span> oc = ray_origin - sphere_center;<br>    <span class="hljs-type">float</span> b = <span class="hljs-number">2.0</span> * <span class="hljs-built_in">dot</span>(ray_direction, oc);<br>    <span class="hljs-type">float</span> c = <span class="hljs-built_in">dot</span>(oc, oc) - (sphere_radius * sphere_radius);<br>    <span class="hljs-type">float</span> d = (b*b) - <span class="hljs-number">4.0</span>*a*c;<br><br>    <span class="hljs-comment">// 返回击中结果，y小于x代表无结果</span><br>    <span class="hljs-keyword">if</span> (d &lt; <span class="hljs-number">0.0</span>) <span class="hljs-keyword">return</span> <span class="hljs-type">vec2</span>(<span class="hljs-number">1e10</span>,<span class="hljs-number">-1e10</span>);<br>    <span class="hljs-comment">// 击中的话有两个相同或者不同的结果</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-type">vec2</span>(<br>        (-b - <span class="hljs-built_in">sqrt</span>(d))/(<span class="hljs-number">2.0</span>*a),<br>        (-b + <span class="hljs-built_in">sqrt</span>(d))/(<span class="hljs-number">2.0</span>*a)<br>    );<br>&#125;<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>好了，那有了这个辅助公式，我们正式开始计算大气的颜色。首先，按照之前的理论，我们要计算视线向量在大气层内的长度，所以我们对射线方向和大气层，以及射线方向和星球表面做射线检测。得到视线在大气层内的长度后，根据我们预设的想要采样的步数（iSteps），计算出每次采样的长度ds。</p><!-- /wp:paragraph --><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs glsl">ray_dir = <span class="hljs-built_in">normalize</span>(ray_dir);<br><br><span class="hljs-comment">// 视线和大气层大小的尺寸的射线检测</span><br><span class="hljs-comment">// x为大气入射点的距离、y为大气出射点的距离（x==y代表光线和大气球体相切，x&gt;y代表光线不经过大气）</span><br><span class="hljs-type">vec2</span> atmos_hit = ray_sphere_intersection(ray_origin, ray_dir, rAtmos);<br><span class="hljs-comment">// 未击中，返回0</span><br><span class="hljs-keyword">if</span> (atmos_hit.x &gt; atmos_hit.y) <span class="hljs-keyword">return</span> <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br><br>    <span class="hljs-comment">// 视线和星球做射线检测，取得近处的检测结果（远处的那个光被星球本体遮挡）</span><br><span class="hljs-type">vec2</span> planet_hit = ray_sphere_intersection(ray_origin, ray_dir, planet_radius);<br><span class="hljs-type">float</span> light_distance = atmos_hit.y;<br><br><span class="hljs-comment">// hit the planet</span><br><span class="hljs-keyword">if</span>(planet_hit.x &lt; planet_hit.y &amp;&amp; planet_hit.x &gt; <span class="hljs-number">0.1</span>)<br>&#123;<br>    light_distance = planet_hit.x;<br>&#125;<br><br><span class="hljs-comment">// light sample length</span><br><span class="hljs-type">float</span> ds = light_distance / <span class="hljs-type">float</span>(iSteps);<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>那么接下来，便是进入采样的循环。循环有两层，外面的循环是计算<strong>视线方向上的每个采样点的光能量</strong>，而计算这个点的光能量也需要一个循环，这个循环是用于采样该点和光源之间的连线在大气层内的线段（也就是之前图片的PC段）的光学距离。根据前面提到的公式，光学距离乘以海平面的散射系数便可以得到光的衰减系数，因此jSteps循环可以得到光线在进入大气层后，传播到达视线上的采样点（P0、P1...Pn点）的衰减所剩下的能量。</p><!-- /wp:paragraph --><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// Initialize the primary ray time.</span><br><span class="hljs-type">float</span> iTime = <span class="hljs-number">0.0</span>;<br><br><span class="hljs-comment">// Initialize accumulators for Rayleigh and Mie scattering.</span><br><span class="hljs-type">vec3</span> total_scatter_rlh = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br><span class="hljs-type">vec3</span> total_scatter_mie = <span class="hljs-type">vec3</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// Initialize optical depth accumulators for the primary ray.</span><br><span class="hljs-type">float</span> total_od_rlh = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">float</span> total_od_mie = <span class="hljs-number">0.0</span>;<br><br><span class="hljs-comment">// 对每个视线上的采样点循环</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; iSteps; i++) &#123;<br>    <span class="hljs-comment">// 获取到采样点的位置</span><br>    <span class="hljs-type">vec3</span> iPos = ray_origin + ray_dir * (iTime + ds * <span class="hljs-number">0.5</span>);<br><br>    <span class="hljs-comment">// 在当前点向太阳的位置做射线检测，以大气的半径为球体。.y是代表大气的出射点，j_steps代表采样数</span><br>    <span class="hljs-type">float</span> jStepSize = ray_sphere_intersection(iPos, pSun, rAtmos).y / <span class="hljs-type">float</span>(jSteps);<br><br>    <span class="hljs-type">float</span> jTime = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> jOdRlh = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">float</span> jOdMie = <span class="hljs-number">0.0</span>;<br><br>    <span class="hljs-comment">// 在当前采样到大气入射点的距离上，采样计算</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; jSteps; j++) &#123;<br>        <span class="hljs-comment">// 计算采样点到光源的衰减</span><br>        <span class="hljs-type">vec3</span> jPos = iPos + pSun * (jTime + jStepSize * <span class="hljs-number">0.5</span>);<br><br>        <span class="hljs-type">float</span> jHeight = <span class="hljs-built_in">length</span>(jPos-planet_center) - planet_radius;<br><br>        <span class="hljs-comment">// Accumulate the optical depth.</span><br>        jOdRlh += get_atmos_density(jHeight, scale_height_rlh) * jStepSize;<br>        jOdMie += get_atmos_density(jHeight, scale_height_mie) * jStepSize;<br><br>        <span class="hljs-comment">// Increment the secondary ray time.</span><br>        jTime += jStepSize;<br>    &#125;<br><br>    <span class="hljs-comment">// 观察点和星球表面距离</span><br>    <span class="hljs-type">float</span> surface_height = <span class="hljs-built_in">length</span>(iPos-planet_center) - planet_radius;<br><br>    <span class="hljs-comment">// 计算这一步的散射的光学深度结果</span><br>    <span class="hljs-type">float</span> od_step_rlh = get_atmos_density(surface_height, scale_height_rlh) * ds;<br>    <span class="hljs-type">float</span> od_step_mie = get_atmos_density(surface_height, scale_height_mie) * ds;<br>    <br>    total_od_rlh += od_step_rlh;<br>    total_od_mie += od_step_mie;<br><br>    <span class="hljs-comment">// 计算衰减系数，光在经过一定距离后衰减剩下来的比例。</span><br>    <span class="hljs-type">vec3</span> attn = <span class="hljs-built_in">exp</span>(-(kMie * (total_od_mie + jOdMie) + kRlh * (total_od_rlh + jOdRlh)));<br><br>    <span class="hljs-comment">// Accumulate scattering.</span><br>    total_scatter_rlh += od_step_rlh * attn;<br>    total_scatter_mie += od_step_mie * attn;<br><br>    <span class="hljs-comment">// Increment the primary ray time.</span><br>    iTime += ds;<br>&#125;<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>计算瑞利散射和米氏散射的大气密度的代码如下所示，其中scale_height在计算瑞利散射的时候带入的是8500，米氏散射则带入1200。</p><!-- /wp:paragraph --><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 获取大气密度</span><br><span class="hljs-comment">// 传入位置离海平面的高度，以及散射的相关基准高度</span><br><span class="hljs-comment">// 大气中任意一点的散射系数的计算，简化拆解为散射在海平面的散射系数，乘以基于海平面高度的该散射的大气密度计算公式</span><br><span class="hljs-type">float</span> get_atmos_density(<span class="hljs-type">float</span> height_to_sea_level, <span class="hljs-type">float</span> scale_height)<br>&#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">exp</span>(-height_to_sea_level / scale_height);<br>&#125;<br></code></pre></td></tr></table></figure><!-- wp:paragraph --><p>将iSteps循环的结果累加起来，我们便得到了视线上（AB）的每个采样点的光能量传播到达相机（A点）经过衰减的能量的和。那么还剩一个部分，就是光在P点进行散射的时候，光也损失掉了一部分能量，这个过程可以通过乘以米氏散射和瑞利散射的相位函数来计算。因为每个采样点P的结果都需要乘以相位函数，所以我们可以将它提取到最外面，乘以光的能量的总和即可。</p><!-- /wp:paragraph --><!-- wp:paragraph --><p>不过需要注意的是，前面的公式提到了，相位函数是和光线入射方向和目标方向的夹角相关的，所以如果我们<strong>默认太阳光源是平行光</strong>的话，这个夹角对每个采样点来说是一样的，所以可以将相位函数提取到最外层。如果认为这个夹角对每个采样点不一样的话，那也许还是应该老老实实在计算每个采样点的光的时候单独去处理。</p><!-- /wp:paragraph --><p>最终的结果除了乘以相位函数，还需要乘以海平面的散射系数，结果如下。</p></p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 计算并返回最终颜色</span><br><span class="hljs-comment">// iSun是光源（太阳）的颜色</span><br><span class="hljs-keyword">return</span> iSun * (pRlh * kRlh * total_scatter_rlh + pMie * kMie * total_scatter_mie);<br></code></pre></td></tr></table></figure><p>下面是得到的结果：</p><iframe src="single-scatter-atmosphere.mp4" scrolling="no" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/">https://www.alanzucconi.com/2017/10/10/atmospheric-scattering-1/</a></li><li><a href="https://www.xianlongok.site/post/8e5d3b12/">https://www.xianlongok.site/post/8e5d3b12/</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>级联阴影贴图实现</title>
    <link href="/2024/10/13/cascade-shadow-map/"/>
    <url>/2024/10/13/cascade-shadow-map/</url>
    
    <content type="html"><![CDATA[<h1 id="阴影贴图的局限"><a href="#阴影贴图的局限" class="headerlink" title="阴影贴图的局限"></a>阴影贴图的局限</h1><p>阴影贴图（shadow map）是3D场景中实现阴影效果的基础手段，它通过预先将光线方向的场景深度存储到贴图中，在渲染的时候取每个场景中的点到光源的距离和深度贴图作比较，来判定该点是否在阴影当中。</p><p>但是在较大的场景中，使用阴影贴图会有几个明显的不足：</p><ol><li>阴影贴图只能覆盖部分场景，在渲染较大的场景的时候（如大世界），远处的场景基本上无法被阴影贴图所覆盖。</li><li>贴图的分辨率是有限的，太大的分辨率会对性能造成非常大的影响。但是在覆盖较大场景的时候，贴图分辨率不足会导致阴影模糊，效果不佳。</li><li>阴影贴图的实现一开始其实并没有考虑玩家相机的视椎体，也就是说在玩家没有看的地方也会渲染阴影贴图，这对渲染资源来说显然是个浪费。</li></ol><p>KongEngine计划在后面接入大地形的渲染，借此机会接入了级联阴影贴图的能力。<br>实现方法参考了<a href="https://learnopengl.com/Guest-Articles/2021/CSM">LearnOpenGL的教程</a>。</p><h1 id="级联阴影贴图的实现"><a href="#级联阴影贴图的实现" class="headerlink" title="级联阴影贴图的实现"></a>级联阴影贴图的实现</h1><p>级联阴影贴图的基本概念包括如下几点：</p><ol><li>将玩家的视椎体划分为几段，每一段视椎体构建一张阴影贴图覆盖，这个阴影贴图完美贴合从光源方向投射到这段视椎体中心点的正交投影。</li><li>和模型LOD的理念类似，离相机近的阴影贴图需要采用较高精度，而离相机远的阴影贴图可以使用低精度。</li><li>将多级阴影贴图传入最后的光照计算着色器，根据每个点所处视椎体的分段不同采用对应不同的阴影贴图计算光照。</li></ol><p>听起来挺简单的对吧，那我们一步一步来。</p><h2 id="视椎体分段"><a href="#视椎体分段" class="headerlink" title="视椎体分段"></a>视椎体分段</h2><p>上面说到我们需要将视椎体分为几段，在每一段视椎体覆盖一张阴影贴图，并计算出这张贴图的从光源方向看向视椎体中心点的正交投影的矩阵，也就是Light projection matrix和Light view matrix。这个矩阵需要紧密贴合这段视椎体，为此我们需要得到视椎体的顶点的世界坐标，得到顶点的min、max和视椎体的中心点。</p><p>我们从相机的视椎体出发，当处于视椎体范围上的顶点的世界坐标经过projection矩阵和view矩阵转换后，xyz都会被映射到[-1,1]范围的屏幕空间坐标。矩阵转换是可逆的，也就是说取屏幕空间坐标为[-1, 1]边界的八个顶点，经过视椎体的projection矩阵和view矩阵的逆矩阵转换后，就能得到边界顶点的世界空间坐标。在代码里面的实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">std::vector&lt;glm::vec4&gt; <span class="hljs-title">CDirectionalLightComponent::GetFrustumCornersWorldSpace</span><span class="hljs-params">(<span class="hljs-type">const</span> glm::mat4&amp; proj_view)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> inv = glm::<span class="hljs-built_in">inverse</span>(proj_view);<br><br>    <span class="hljs-comment">// 顶点的世界坐标在projection和view matrix的转换下的坐标范围是[-1,1]</span><br>    <span class="hljs-comment">// 那么将在[-1,1]这个边界的八个顶点坐标乘以projection和view matrix的逆矩阵则可以得到视锥体边界的顶点的世界坐标</span><br>    vector&lt;vec4&gt; frustum_corners;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; i++)<br>    &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">2</span>; j++)<br>        &#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; <span class="hljs-number">2</span>; k++)<br>            &#123;<br>                <span class="hljs-type">const</span> vec4 pt = inv * <span class="hljs-built_in">vec4</span>(<span class="hljs-number">2.0f</span>*i<span class="hljs-number">-1.0f</span>,<span class="hljs-number">2.0f</span>*j<span class="hljs-number">-1.0f</span>,<span class="hljs-number">2.0f</span>*k<span class="hljs-number">-1.0f</span>, <span class="hljs-number">1.0f</span>);<br>                frustum_corners.<span class="hljs-built_in">push_back</span>(pt / pt.w);<br>            &#125;<br>        &#125;   <br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> frustum_corners;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们得到了视椎体角落的顶点世界坐标，我们希望阴影贴图能够如下图一般贴合每一段视椎体。那么我们需要计算视椎体的中心顶点坐标，中心顶点在计算view矩阵的时候需要用到；我们需要计算在xyz轴上顶点坐标的最大和最小值，这些数值在计算projection矩阵的时候会被用到。</p><p><img src="https://learnopengl.com/img/guest/2021/CSM/frustum_fitting.png" alt="级联阴影贴图由远及近"></p><p>计算中心点的代码十分简单，将视椎体角落的坐标相加后再除以数量即可，代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++">vec3 center = <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0.0f</span>);<br><span class="hljs-keyword">for</span>(<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; v : corners)<br>&#123;<br>    center += <span class="hljs-built_in">vec3</span>(v);<br>&#125;<br>center /= corners.<span class="hljs-built_in">size</span>();   <span class="hljs-comment">// 获取视锥体的中心点</span><br><br><span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> light_view = <span class="hljs-built_in">lookAt</span>(center-light_dir, center, <span class="hljs-built_in">vec3</span>(<span class="hljs-number">0.0f</span>, <span class="hljs-number">1.0f</span>, <span class="hljs-number">0.0f</span>));<br></code></pre></td></tr></table></figure><p>计算贴合视椎体的范围则是比较并记录各个顶点在xyz轴的最大值和最小值，方法如下。这里提一下在z轴方向和一个参数z_mult进行了处理，其意义是阴影的投射源是有可能在视椎体范围之外的，如果不考虑这一部分的影响的话可能在阴影过度的时候会非常生硬，并且丢掉一些本来该显示的阴影导致渲染错误。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span> min_x = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">max</span>();<br><span class="hljs-type">float</span> min_y = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">max</span>();<br><span class="hljs-type">float</span> min_z = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">max</span>();<br><span class="hljs-type">float</span> max_x = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">lowest</span>();<br><span class="hljs-type">float</span> max_y = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">lowest</span>();<br><span class="hljs-type">float</span> max_z = std::numeric_limits&lt;<span class="hljs-type">float</span>&gt;::<span class="hljs-built_in">lowest</span>();<br><span class="hljs-keyword">for</span> (<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; v : corners)<br>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> trf = light_view * v;<br>    min_x = std::<span class="hljs-built_in">min</span>(min_x, trf.x);<br>    max_x = std::<span class="hljs-built_in">max</span>(max_x, trf.x);<br>    min_y = std::<span class="hljs-built_in">min</span>(min_y, trf.y);<br>    max_y = std::<span class="hljs-built_in">max</span>(max_y, trf.y);<br>    min_z = std::<span class="hljs-built_in">min</span>(min_z, trf.z);<br>    max_z = std::<span class="hljs-built_in">max</span>(max_z, trf.z);<br>&#125;<br><span class="hljs-keyword">constexpr</span> <span class="hljs-type">float</span> z_mult = <span class="hljs-number">10.0f</span>;<br><span class="hljs-keyword">if</span> (min_z &lt; <span class="hljs-number">0</span>)<br>&#123;<br>    min_z *= z_mult;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br>    min_z /= z_mult;<br>&#125;<br><span class="hljs-keyword">if</span> (max_z &lt; <span class="hljs-number">0</span>)<br>&#123;<br>    max_z /= z_mult;<br>&#125;<br><span class="hljs-keyword">else</span><br>&#123;<br>    max_z *= z_mult;<br>&#125;<br><br><span class="hljs-type">const</span> mat4 light_projection = <span class="hljs-built_in">ortho</span>(min_x, max_x, min_y, max_y, min_z, max_z);<br></code></pre></td></tr></table></figure><h2 id="计算级联阴影贴图"><a href="#计算级联阴影贴图" class="headerlink" title="计算级联阴影贴图"></a>计算级联阴影贴图</h2><p>一般的阴影贴图我们采用的是GL_TEXTURE_2D，而级联阴影贴图我们需要传入多张贴图，因此对应的贴图类型会变为GL_TEXTURE_2D_ARRAY。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">glGenTextures</span>(<span class="hljs-number">1</span>, &amp;csm_texture);<br><span class="hljs-built_in">glBindTexture</span>(GL_TEXTURE_2D_ARRAY, csm_texture);<br><span class="hljs-built_in">glTexImage3D</span>(GL_TEXTURE_2D_ARRAY, <span class="hljs-number">0</span>, GL_DEPTH_COMPONENT32F, SHADOW_RESOLUTION, SHADOW_RESOLUTION, (<span class="hljs-type">int</span>)csm_distances.<span class="hljs-built_in">size</span>()<span class="hljs-number">+1</span>, <span class="hljs-number">0</span>, GL_DEPTH_COMPONENT, GL_FLOAT, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MAG_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MIN_FILTER, GL_NEAREST);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);<br><span class="hljs-built_in">glTexParameteri</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER);<br><span class="hljs-built_in">glTexParameterfv</span>(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_BORDER_COLOR, border_color);<br><br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, shadowmap_fbo);<br><span class="hljs-built_in">glFramebufferTexture</span>(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, csm_texture, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">glDrawBuffer</span>(GL_NONE);<br><span class="hljs-built_in">glReadBuffer</span>(GL_NONE);<br><span class="hljs-built_in">glBindFramebuffer</span>(GL_FRAMEBUFFER, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>除此之外，我们需要一次性渲染多张贴图，我们参考点光源阴影贴图使用geometry shader的做法，将顶点映射到不同的视椎体分段的光源的投影。代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-meta">#version 450 compatibility</span><br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">triangles</span>, <span class="hljs-keyword">invocations</span> = <span class="hljs-number">6</span>) <span class="hljs-keyword">in</span>;<br><span class="hljs-keyword">layout</span>(<span class="hljs-keyword">triangle_strip</span>, <span class="hljs-keyword">max_vertices</span> = <span class="hljs-number">3</span>) <span class="hljs-keyword">out</span>;<br><br><span class="hljs-keyword">uniform</span> <span class="hljs-type">mat4</span> light_space_matrix[<span class="hljs-number">16</span>];<br><br><br><span class="hljs-type">void</span> main()<br>&#123;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">3</span>; ++i)<br>&#123;<br><span class="hljs-built_in">gl_Position</span> = light_space_matrix[<span class="hljs-built_in">gl_InvocationID</span>] * <span class="hljs-built_in">gl_in</span>[i].<span class="hljs-built_in">gl_Position</span>;<br><span class="hljs-built_in">gl_Layer</span> = <span class="hljs-built_in">gl_InvocationID</span>;<br><span class="hljs-built_in">EmitVertex</span>();<br>&#125;<br><span class="hljs-built_in">EndPrimitive</span>();<br>&#125; <br></code></pre></td></tr></table></figure><p>这里新增的<strong>invocations &#x3D; 6</strong>代表了这个Shader可以被实例化，每个实例同时平行进行运算，实例的个数为6。内置的<strong>gl_InvocationID</strong>代表了当前处理的是哪一个实例，我们将其赋值到<strong>gl_Layer</strong>。其余的阴影贴图渲染步骤和普通的阴影贴图类似。</p><p>下面几张图所示展示的，就是从近到远的几个级联阴影贴图的表现：<br><img src="/2024/10/13/cascade-shadow-map/csm_near.png"><br><img src="/2024/10/13/cascade-shadow-map/csm_mid.png"><br><img src="/2024/10/13/cascade-shadow-map/csm_far.png"></p><h2 id="使用级联阴影贴图"><a href="#使用级联阴影贴图" class="headerlink" title="使用级联阴影贴图"></a>使用级联阴影贴图</h2><p>级联阴影贴图的使用和阴影贴图是类似的，由于传入给光照Shader的是GL_TEXTURE_2D_ARRAY，需要使用vec3来索引贴图数据的，vec3的z值代表的是Layer索引。</p><p>Layer代表的是使用哪一个视椎体分段的阴影贴图，取决于当前像素和相机的距离。取得对应的Layer参数后带入texcoord的z值读取对应的阴影贴图的值。示例代码如下：</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs glsl"><span class="hljs-comment">// 计算阴影</span><br><span class="hljs-type">float</span> ShadowCalculation_DirLight(<span class="hljs-type">vec4</span> frag_world_pos, <span class="hljs-type">vec3</span> to_light_dir, <span class="hljs-type">vec3</span> in_normal)<br>&#123;<br>    <span class="hljs-comment">// 获取像素和相机的距离，也就是view转换后的z值</span><br>    <span class="hljs-type">vec4</span> frag_pos_view_space = matrix_ubo.view * frag_world_pos;<br>    <span class="hljs-type">float</span> depthValue = <span class="hljs-built_in">abs</span>(frag_pos_view_space.z);<br><br>    <span class="hljs-comment">// 根据距离和每段视椎体分段的距离区间，获取Layer值</span><br>    <span class="hljs-type">int</span> layer = <span class="hljs-number">-1</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; csm_level_count; ++i)<br>    &#123;<br>        <span class="hljs-keyword">if</span> (depthValue &lt; csm_distances[i])<br>        &#123;<br>            layer = i;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (layer == <span class="hljs-number">-1</span>)<br>    &#123;<br>        layer = csm_level_count;<br>    &#125;<br>    <span class="hljs-comment">// 下面的和应用普通阴影贴图的一致</span><br>    <span class="hljs-comment">// 转换到-1,1的范围，再转到0,1的范围</span><br>    <span class="hljs-type">vec4</span> frag_pos_light_space = light_space_matrices[layer] * frag_world_pos;<br>    <span class="hljs-comment">// perform perspective divide</span><br>    <span class="hljs-type">vec3</span> proj_coord = frag_pos_light_space.xyz / frag_pos_light_space.w;<br>    <span class="hljs-comment">// transform to [0,1] range</span><br>    proj_coord = proj_coord * <span class="hljs-number">0.5</span> + <span class="hljs-number">0.5</span>;<br><br>    <span class="hljs-comment">// get depth of current fragment from light&#x27;s perspective</span><br>    <span class="hljs-type">float</span> current_depth = proj_coord.z;<br><br>    <span class="hljs-comment">// keep the shadow at 0.0 when outside the far_plane region of the light&#x27;s frustum.</span><br>    <span class="hljs-keyword">if</span> (current_depth &gt; <span class="hljs-number">1.0</span>)<br>    &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span>;<br>    &#125;<br><br>    <span class="hljs-comment">// PCF</span><br>    <span class="hljs-type">float</span> shadow = <span class="hljs-number">0.0</span>;<br>    <span class="hljs-type">vec2</span> texel_size = <span class="hljs-number">1.0</span> / <span class="hljs-type">vec2</span>(<span class="hljs-built_in">textureSize</span>(shadow_map, <span class="hljs-number">0</span>));<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> x = <span class="hljs-number">-1</span>; x &lt;= <span class="hljs-number">1</span>; ++x)<br>    &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> y = <span class="hljs-number">-1</span>; y &lt;= <span class="hljs-number">1</span>; ++y)<br>        &#123;<br>            <span class="hljs-type">float</span> pcf_depth = <span class="hljs-built_in">texture</span>(shadow_map, <span class="hljs-type">vec3</span>(proj_coord.xy + <span class="hljs-type">vec2</span>(x, y) * texel_size, layer)).r;<br>            shadow += current_depth &gt; pcf_depth ? <span class="hljs-number">1.0</span> : <span class="hljs-number">0.0</span>;<br>        &#125;<br>    &#125;<br>    shadow /= <span class="hljs-number">9.0</span>;<br>        <br>    <span class="hljs-keyword">return</span> shadow;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="效果对比"><a href="#效果对比" class="headerlink" title="效果对比"></a>效果对比</h1><h2 id="原先的阴影贴图"><a href="#原先的阴影贴图" class="headerlink" title="原先的阴影贴图"></a>原先的阴影贴图</h2><p>原先的阴影贴图只能覆盖有限的场景：<br><img src="/2024/10/13/cascade-shadow-map/sm_near.png"></p><p>提升覆盖范围后，阴影的质量则会出现下降：<br><img src="/2024/10/13/cascade-shadow-map/sm_far.png"></p><h2 id="级联阴影贴图"><a href="#级联阴影贴图" class="headerlink" title="级联阴影贴图"></a>级联阴影贴图</h2><p>采用级联阴影贴图可以覆盖很大的场景，并且在可控的性能消耗下仍然有不错的显示智联。<br><img src="/2024/10/13/cascade-shadow-map/csm_result.png"></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>程序化地形生成-1</title>
    <link href="/2024/10/11/ProceduralTerrainGeneration/"/>
    <url>/2024/10/11/ProceduralTerrainGeneration/</url>
    
    <content type="html"><![CDATA[<p><a href="https://www.shadertoy.com/">ShaderToy</a>是一个很有趣的网站，它上面有着非常多的渲染案例分享，最近一段时间我也是沉迷了。在看了不少大佬的作品之后，不禁手痒。前一段时间看了Inigo大佬的一个<a href="https://www.shadertoy.com/view/4ttSWf">教程案例</a>，想着把这个效果自己来实现一次，因此就有了今天的这篇文章。</p><p>我最终的成品也放到了shadertoy上面，有兴趣的同学可以一起讨论参考一下。看起来还不错对吧，虽然还有不少地方需要完善，但这个demo已经实现了我心中的大部分效果，包括无限的基于噪音的地形生成、地形阴影、雾气、云等等。</p><iframe width="640" height="360" frameborder="0" src="https://www.shadertoy.com/embed/4XByRV?gui=true&t=10&paused=true&muted=false" allowfullscreen></iframe><p>那么下面，就让我来一步步说明这个demo的实现过程吧。</p><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="在ST上渲染地形"><a href="#在ST上渲染地形" class="headerlink" title="在ST上渲染地形"></a>在ST上渲染地形</h2><p>对ShaderToy上运行的Shader代码，对应着可编程渲染管线的片段着色器(或者叫像素着色器)。片段着色器主要是是图形光栅化后的像素信息，所以渲染3D场景需要进行一些额外的步骤。</p><p>ShaderToy的程序一般是这样的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">mainImage</span><span class="hljs-params">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>...<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>fragColor</strong>是输出，代表这这个像素的最终颜色；<strong>fragCoord</strong>是输入，代表这个像素点的xy坐标。ShaderToy提供了固定变量<strong>iResolution</strong>用来表示整个屏幕的xy的分辨率。</p><p>为了渲染3D物体，我们需要采用ray cast&#x2F;marching的方法，构建一个相机的位置作为光线射出的起点<strong>ro</strong>，再根据当前像素点的坐标和ro的差获得光线射出的方向<strong>rd</strong>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">mainImage</span><span class="hljs-params">(out vec4 fragColor, in vec2 fragCoord)</span><br>&#123;<br>    vec2 uv = fragCoord / iResolution.xy;<br><span class="hljs-comment">// 以屏幕中心为（0,0）</span><br>    uv = uv * <span class="hljs-number">2.0</span> - <span class="hljs-number">1.0</span>;<br><span class="hljs-comment">// 缩放x，在画面拉伸的时候保证比例正确</span><br>    uv.x *= iResolution.x/iResolution.y;<br><span class="hljs-comment">// 原点位置</span><br>    vec3 ro = vec3(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-1</span>);<br>    <span class="hljs-comment">// 射线方向</span><br>    vec3 rd = normalize(vec3(uv, <span class="hljs-number">2</span>));<br><br>fragColor = rayMarching(ro, rd);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="和地形相交"><a href="#和地形相交" class="headerlink" title="和地形相交"></a>和地形相交</h2><p>在shadertoy中渲染3D物体，一般是使用raymarching方法配合SDFs来渲染3D的物体。SDF（Signed Distance Field）是一种物体的隐式表达，用于存储和计算点到图形表面的最近距离。经由一个起点和一个方向，可以用SDF来达到低消耗的射线检测效果。</p><p>这里可以参考Inigo对SDF的介绍的介绍：<a href="https://iquilezles.org/articles/distfunctions/">https://iquilezles.org/articles/distfunctions/</a></p><p>地形的渲染也是类似的，我们通过ray marching方法来找到距离地形最近的点，以此来获取地形的形状。但是和SDF不同的是，我们无法很轻易的判断射线当前距离地形的最近距离，尤其是当我们的地形完全是通过噪音来随机生成的时候，这变成了一个不可能完成的任务。所以在判断地形相交的时候，只能回归到笨办法，一步一步慢慢的往前“挪”，<em>若当前的顶点在地形之下，而之前的一个迭代在地形之上的话</em>，那我们就找到了击中地表的区间段。<br><img src="https://iquilezles.org/articles/terrainmarching/gfx02.png" alt="射线和地表相交"></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">bool</span> <span class="hljs-title function_">rayMarch</span><span class="hljs-params">(vec3 ro, vec3 rd, out <span class="hljs-type">float</span> <span class="hljs-type">hit_t</span>)</span><br>&#123;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> dt = <span class="hljs-number">0.01f</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> <span class="hljs-type">min_t</span> = <span class="hljs-number">1e-3</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> <span class="hljs-type">max_t</span> = <span class="hljs-number">1e3</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = <span class="hljs-type">min_t</span>; t &lt; <span class="hljs-type">max_t</span>; t+=dt)<br>&#123;<br><span class="hljs-type">const</span> vec3 p = ro+rd*t;<br><span class="hljs-keyword">if</span>(p.y &lt; f(p.x, p.z));<br>&#123;<br><span class="hljs-comment">// 取中间点减小误差</span><br><span class="hljs-type">hit_t</span> = t - <span class="hljs-number">0.5f</span>*dt;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>这个方法简单易懂，但显而易见在性能上并不是最优的，尤其是涉及到范围很大的地形的时候，dt的值如果取得太小，那么渲染完成一个场景的时间将会非常的长，消耗巨大；而若是dt的值取得太大，则很有可能会出现取值错误的情况。</p><p>当场景距离我们足够远的时候，由于透视的原因，近大远小，远处的场景精度对于观察者来说是越来越不重要了，因此dt的值可以随着光线步近而逐渐组建增大，动态变化。在合适的dt取值和变化曲线下，能够满足精度和性能的要求。Inigo给出的方法是类似这样的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//其他和上方代码一致</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = <span class="hljs-type">min_t</span>; t&lt;<span class="hljs-type">max_t</span>; t+=dt)<br>&#123;<br>    <span class="hljs-type">const</span> vec3 p = ro+rd*t;<br>    <span class="hljs-type">const</span> <span class="hljs-type">float</span> h = f(p.xz);<br>    <span class="hljs-keyword">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class="hljs-type">hit_t</span> = t - <span class="hljs-number">0.5f</span>*dt;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>    dt=<span class="hljs-number">0.01f</span>*t;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br></code></pre></td></tr></table></figure><p>t的起始值和dt的增长倍数可以自己尝试选择一个合适的值。</p><p>另外，如果我们能对最终渲染的效果有所了解的话，可以通过过滤掉很多不需要做射线检测的情况来极大的提升性能。如果我们最终的效果是一个在空中的相机，天空和地面占据画面各一半的话，那么上半部分的画面（通过rd.y&gt;0判断）是可以完全跳过射线检测的。或者通过增加min_t的值来减少前期昂贵且不必要的性能消耗。</p><p>在相交点的取值上，也可以进一步优化。原来仅仅是取两次光线步近的平均值，我们可以额外获取两次步近时位置的地形高度，用高度变化的连线和光线步近的线段做相交的判定取交点。这样得到的值将会更加精确。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//其他和上方代码一致</span><br><span class="hljs-type">float</span> lh = <span class="hljs-number">0.0f</span>;<br><span class="hljs-type">float</span> ly = <span class="hljs-number">0.0f</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">float</span> t = <span class="hljs-type">min_t</span>; t&lt;<span class="hljs-type">max_t</span>; t+=dt)<br>&#123;<br>    <span class="hljs-type">const</span> vec3 p = ro+rd*t;<br>    <span class="hljs-type">const</span> <span class="hljs-type">float</span> h = f(p.xz);<br>    <span class="hljs-keyword">if</span>(p.y&lt;h)<br>    &#123;<br>        <span class="hljs-comment">// 计算两个线段的相交点</span><br>        <span class="hljs-type">hit_t</span> = t - dt + dt*(lh-ly)/(p.y-ly-h+lh);<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>    dt=<span class="hljs-number">0.01f</span>*t;<br>    lh = h;<br>    ly = p.y;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br></code></pre></td></tr></table></figure><p>至此，我们就可以在ShaderToy渲染出地形了。</p><h1 id="地形生成"><a href="#地形生成" class="headerlink" title="地形生成"></a>地形生成</h1><h2 id="生成的基础：噪音"><a href="#生成的基础：噪音" class="headerlink" title="生成的基础：噪音"></a>生成的基础：噪音</h2><p>当我们提到噪音，往往会很生活化的把噪音和声音连接起来，从声学的角度来说是正确的。噪音其实可以用来表示所有通过振幅（amplitude）和频率（frequency）描述的波动，它可以是声音，它可以是辐射，也可以是其他的任意一种波动。</p><p>在数学课上，我们学过正弦、余弦等三角函数，sin和cos其实就是一种噪音的表现方式。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> amplitude = <span class="hljs-number">1.0</span>;<br><span class="hljs-type">float</span> frequencey = <span class="hljs-number">1.0</span>;<br><span class="hljs-type">float</span> y = amplitude * <span class="hljs-built_in">sin</span>(frequency * x);<br></code></pre></td></tr></table></figure><p>就像上面的代码所示，通过改变amplitude和frequency，我们可以改变sin波形的状态。</p><p>噪音在很多程序化生成算法中都有着举足轻重的地位。</p><h2 id="分形布朗运动"><a href="#分形布朗运动" class="headerlink" title="分形布朗运动"></a>分形布朗运动</h2><p>噪音是一种波，它是可以相互叠加的。两个相同的sin波形叠加会形成振幅更加强大的sin波形，而频率相差π&#x2F;2的两个sin波形叠加后会相互抵消。</p><p>在地形随机生成中，为了最终的结果噪音有着更好的随机性和更好的细节，将会循环多次计算噪音，循环的次数为我们称之为octave。每次循环的同一个噪音以一定倍数（lacunarity）升高频率，同时以一定比例（gain）降低振幅，最终将每个噪音计算的结果叠加得到一个最终的噪音，这个噪音的生成技术叫做“分形布朗运动”（fractal brownian motion，fbm）。</p><p>下面是分形布朗运动的一个简单的代码演示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> <span class="hljs-title function_">fbm</span><span class="hljs-params">(vec2 uv, <span class="hljs-type">float</span> frequency, <span class="hljs-type">float</span> amplitude, <span class="hljs-type">int</span> octave)</span><br>&#123;<br><span class="hljs-type">float</span> lacunarity = <span class="hljs-number">2.0</span>;<br><span class="hljs-type">float</span> gain = <span class="hljs-number">0.5</span>;<br><span class="hljs-type">float</span> noise_val = <span class="hljs-number">0.0</span>;<br><span class="hljs-type">float</span> amp = amplitude;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> index = <span class="hljs-number">0</span>; index &lt; octave; ++index)<br>&#123;<br>nose_val += noiseInterpolate(uv * frequency) * amp;<br>amp *= gain;<br>frequency *= lacunarity;<br>&#125;<br><br><span class="hljs-keyword">return</span> noise_val;<br>&#125;<br></code></pre></td></tr></table></figure><p>其中noiseInterpolate可以是perlin noise或者是simplex noise等任意一种噪音算法。<br>demo中的地形生成和云层的生成，也使用了该技术。关于FBM除了上面简单的使用还有很多其他的变种，这里我们就不扩展了，后面有机会的话可以专门介绍一下。</p><h2 id="地形的基础表现"><a href="#地形的基础表现" class="headerlink" title="地形的基础表现"></a>地形的基础表现</h2><p>这里我将地形部分拆解出来。demo的地形计算使用了perlin noise，octave数量达到了11。更多的octave数量会给地形带来更多的细节，但是一般来说后面的效果收益会越来越少。下方是octave数量分布为5和11下的地形的形状对比。<br><img src="/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc5_noshadow.png"><br><img src="/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_noshadow.png"></p><p>除了每次叠加噪音会进行频率和振幅的变化，为了获得更好的随机性，以及进一步减少噪音可能出现的重复pattern，可以将噪音进行旋转（也就是将传入的uv或者是坐标乘以一个默认的旋转矩阵）后再叠加到原来的噪音上。</p><p>我们也需要地形的法线来和光源结合，渲染出地形的明暗部分。获得法线的方法有很多种，可以采样当前计算的地形上点的x轴和z轴（这里假定y轴为up）方向不远的一两个点，和目标点相减得到切线和副切线方向，通过叉乘得到目标点的法线。亦或是采样其他点后通过中心差分法求得目标点的法线。</p><h2 id="阴影"><a href="#阴影" class="headerlink" title="阴影"></a>阴影</h2><p>仅仅通过法线来渲染地形的明部和暗部是不够的，我们还需要计算地形投射在地表上的阴影。地形的阴影计算原理非常简单，就是将地形上渲染的目标点，沿着光源方向进行射线检测，如果和地形相交的话，那该点就是处于阴影之下。理想情况下，射线检测的距离当然是实际上光源和地形上的点的距离，但是往往由于性能的原因，我们需要缩短这个距离。<em>实际的检测距离可以结合当前点的高度以及地形可能的最高位置进行计算</em>。</p><p>在判断当前点处于阴影的时候，计算最终颜色的时候需要再乘以一个阴影的系数。<br><img src="/2024/10/11/ProceduralTerrainGeneration/shadertoy_oc11_hardshadow.png" alt="硬阴影"></p><p>为了提升效果，我们通常不希望阴影的边缘非常生硬，而是希望有一种柔软的过度，这种更加符合现实的表现。实现这种软阴影的方法可能有很多种，这里采用的是Inigo教程的一种方法。</p><p>上面提到判定阴影是通过从地形上面的点向光源方向做射线检测得到的，如果和地形相交则该点处于阴影当中，若不相交，则需要再取一个值，这值是地形向着光源方向移动距离t长度的位置，它和地形高度的差值d和距离t的比值的最小值，乘以某个常数X（10~32等等，可以自己尝试合适的范围）后经过smoothstep限制在（0,1）范围内。这个值作为阴影系数放入光照计算后就可以得到不错的软阴影效果。<br><img src="/2024/10/11/ProceduralTerrainGeneration/calc_soft_shadow.png" alt="软阴影"></p><p>通过下面的对比图我们可以看到，在加入了软阴影计算后，地形阴影的边缘有了一种较为平滑的过度，显得没那么生硬了。想要更改软阴影的表现的话可以通过修改常数X。<br><img src="/2024/10/11/ProceduralTerrainGeneration/shadertoy_terrain.png"></p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>好了，我们已经得到了一个基础的程序化生成地形的效果了，但是它看起来还是有些单调。地形的深度表现、天空、云彩等等应该如何表现呢？</p><p>无需着急，我们将会在后面的文章中对它进行进一步的优化。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://thebookofshaders.com/13/?lan=ch">https://thebookofshaders.com/13/?lan=ch</a><br><a href="https://iquilezles.org/articles/morenoise">https://iquilezles.org/articles/morenoise</a><br><a href="https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g">https://youtu.be/BFld4EBO2RE?si=HWQMSNx5TBsOG_6g</a></p>]]></content>
    
    
    <categories>
      
      <category>技术漫谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D</tag>
      
      <tag>render</tag>
      
      <tag>渲染</tag>
      
      <tag>编程</tag>
      
      <tag>程序化生成</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>个人博客启动</title>
    <link href="/2024/10/09/StartMyBlog/"/>
    <url>/2024/10/09/StartMyBlog/</url>
    
    <content type="html"><![CDATA[<p>晚上好。</p><p>还是打算在个人的github.io继续更新自己的技术博客了。<a href="qrc-eye.com">原网站</a>本来是打算用于和朋友一起写点东西上去的，结果现在倒是变成了只有我自己的碎碎念，着实不太好。</p><p>最近一段时间会尽快的将我的部分文章搬运过来，一些琐碎的文章暂时就不管了。</p>]]></content>
    
    
    <categories>
      
      <category>生活杂谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>生活</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
